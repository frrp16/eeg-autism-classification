{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing, model_selection\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(directory, excluded_name=[]):\n",
    "    data = pd.DataFrame(columns=['data', 'label'])\n",
    "    for foldername in os.listdir(directory):        \n",
    "        folder = os.path.join(directory, foldername)\n",
    "        # print(folder)\n",
    "        # print(os.listdir(folder))\n",
    "        for name in os.listdir(folder):\n",
    "            if name in excluded_name:\n",
    "                # print(name)\n",
    "                continue\n",
    "            filename = os.path.join(folder, name)\n",
    "            # print(filename)\n",
    "            for files in os.listdir(filename):\n",
    "                rel_path = os.path.join(filename, files)\n",
    "                # print(rel_path)\n",
    "                temp_label = folder\n",
    "                if \"autism\" in temp_label:\n",
    "                    label = 'autism'\n",
    "                else:\n",
    "                    label = 'normal'\n",
    "\n",
    "                temp_data = pd.DataFrame(columns=['data', 'label'], index=[0])\n",
    "\n",
    "                rwb = np.load(rel_path)\n",
    "                rwb.astype(np.float64).reshape(-1,1)\n",
    "                                \n",
    "                temp_data.loc[0, \"data\"] = rwb\n",
    "                temp_data['label'] = label\n",
    "                data = pd.concat([data, temp_data], ignore_index=True)\n",
    "    label_map = {\"autism\": 1, \"normal\": 0}\n",
    "    data['label_map'] = data['label'].map(label_map)      \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_value(data):\n",
    "    series_list = np.vstack(data[\"data\"].values)\n",
    "    labels_list = data[\"label_map\"].values    \n",
    "    missing_indices = np.where(np.isnan(series_list).any(axis=1))[0]\n",
    "\n",
    "    clean_data = data.drop(index=data.index[missing_indices])\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_data = pd.DataFrame(columns=['data', 'label'], index=[0])\n",
    "# rwb = np.load(\"datasets/features/rwb/segment_1 seconds/autism_256/bader/Bader_segment_100.csv_bispectrum.npy\")\n",
    "# rwb.astype(np.float64).reshape(-1,1)\n",
    "# temp_data.loc[0, \"data\"] = rwb\n",
    "# temp_data['label'] = \"autism\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(data, des_path):\n",
    "    if not os.path.exists(des_path):\n",
    "        os.makedirs(des_path)\n",
    "    data.save(des_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(data, train_split: float):\n",
    "    train_x, test_x, train_y, test_y = model_selection.train_test_split(\n",
    "        data['data'],\n",
    "        data[['label', 'label_map']],\n",
    "        train_size=train_split,\n",
    "        stratify=data['label_map']\n",
    "    )\n",
    "\n",
    "    train_df = pd.DataFrame(columns=['data', 'label', 'label_map'])\n",
    "    test_df = pd.DataFrame(columns=['data', 'label', 'label_map'])\n",
    "\n",
    "    train_df[\"data\"] = train_x\n",
    "    train_df[['label', 'label_map']] = train_y\n",
    "\n",
    "    test_df[\"data\"] = test_x\n",
    "    test_df[['label', 'label_map']] = test_y\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data):\n",
    "    # loading extracted feature & label\n",
    "    # x = get_dataset(path, lag, excluded_name)\n",
    "\n",
    "    # scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    series_list = np.vstack(data[\"data\"].values)\n",
    "\n",
    "    # series_list = series_list.reshape(-1, 366, 1)\n",
    "\n",
    "    labels_list = data[\"label_map\"].values\n",
    "        \n",
    "    # y = keras.utils.to_categorical(y[0])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((series_list,labels_list))\n",
    "    dataset = dataset.shuffle(len(labels_list))\n",
    "\n",
    "    # train_size = int(train_split * len(labels_list))  \n",
    "    # test_size = len(labels_list) - train_size  \n",
    "\n",
    "    # train_dataset = dataset.take(train_size)\n",
    "    # test_dataset = dataset.skip(train_size)\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_transform(data):    \n",
    "    series_list = np.vstack(data[\"data\"].values)\n",
    "    labels_list = data[\"label_map\"].values  \n",
    "\n",
    "    relative_energy = np.zeros([series_list.shape[0], series_list.shape[1]])\n",
    "    for i, series in enumerate(series_list):\n",
    "        total_energy = np.sum(series)\n",
    "        relative_energy[i] = [(s / total_energy) * 100 for s in series]\n",
    "    relative_energy_list = [arr for arr in relative_energy]\n",
    "    data[\"data\"] = relative_energy_list\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(data):\n",
    "    series_list = np.vstack(data[\"data\"].values)\n",
    "    labels_list = data[\"label_map\"].values    \n",
    "\n",
    "    epsilon = 1e-9  # To avoid log(0) issues\n",
    "    log_transformed_series = np.log(series_list + epsilon)\n",
    "\n",
    "    log_transformed_list = [arr for arr in log_transformed_series]\n",
    "    data[\"data\"] = log_transformed_list\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"datasets/features/fft/segment_1 seconds\"\n",
    "\n",
    "train_dir = \"datasets/tf_batch/fft/segment_1 seconds/train\"\n",
    "test_dir = \"datasets/tf_batch/fft/segment_1 seconds/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15434, 3)\n",
      "(15434, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farra\\AppData\\Local\\Temp\\ipykernel_16040\\3426103326.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  relative_energy[i] = [(s / total_energy) * 100 for s in series]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15399, 3)\n",
      "train: (12319, 3)\n",
      "test: (3080, 3)\n"
     ]
    }
   ],
   "source": [
    "excluded = [\"zyad\"]\n",
    "train_split = 0.8\n",
    "# LAG = [256, 128, 64, 32, 16, 8, 4, 2]\n",
    "\n",
    "# for lag in LAG:\n",
    "data = get_dataset(data_dir, excluded)\n",
    "print(data.shape)\n",
    "data = remove_missing_value(data)\n",
    "print(data.shape)\n",
    "data = relative_transform(data)\n",
    "data = remove_missing_value(data)\n",
    "print(data.shape)\n",
    "train_data, test_data = get_train_test(data, train_split)\n",
    "print(\"train:\", train_data.shape)\n",
    "print(\"test:\", test_data.shape)\n",
    "\n",
    "train_batch = get_batch(train_data)\n",
    "test_batch = get_batch(test_data)\n",
    "tf.data.Dataset.save(train_batch, f\"{train_dir}\")\n",
    "tf.data.Dataset.save(test_batch, f\"{test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative_transform(data)\n",
    "# rel_list = [arr for arr in rel]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "signal = np.load(\"datasets/features/fft/segment_1 seconds/normal_/amer/Amer_segment_1.csv_fft.npy\")\n",
    "\n",
    "# Extract the signal values from the DataFrame\n",
    "\n",
    "# Create a time axis for the signal\n",
    "t = range(len(signal))\n",
    "print(signal.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# Plot the signal\n",
    "ax.plot(t, signal)\n",
    "ax.set_xlabel('Time (samples)')\n",
    "ax.set_ylabel('Signal amplitude')\n",
    "ax.set_title('Signal plot')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(layers.Input(shape=(80,)))\n",
    "    model.add(layers.Reshape((80, 1)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(256, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myCallbacks(log_dir):\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='acc',\n",
    "    patience=50,\n",
    "    mode='max')\n",
    "    model_path = os.path.join(log_dir,'best_model.h5')\n",
    "    mc = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    return [tensorboard_callback, early_stopping, mc]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lags = [256]\n",
    "folds = ['train_1', 'test_1', 'epoch_1', 'train_2', 'test_2', 'epoch_2']\n",
    "time_measured = ['Wall_Time_1', 'CPU_Time_1', 'Wall_Time_2', 'CPU_Time_2']\n",
    "epochs = 2000\n",
    "log_dirs = ['train_logs/logs7/FFT_ANN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farra\\AppData\\Local\\Temp\\ipykernel_16040\\2764964901.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.array(list(train_data.as_numpy_iterator())).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(385, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = tf.data.Dataset.load(train_dir)\n",
    "np.array(list(train_data.as_numpy_iterator())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 80, 1)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 80)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               41472     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,057\n",
      "Trainable params: 173,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "592/616 [===========================>..] - ETA: 0s - loss: 0.5809 - acc: 0.7261\n",
      "Epoch 1: val_acc improved from -inf to 0.75933, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.5744 - acc: 0.7281 - val_loss: 0.4647 - val_acc: 0.7593\n",
      "Epoch 2/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.4830 - acc: 0.7636\n",
      "Epoch 2: val_acc improved from 0.75933 to 0.77881, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4804 - acc: 0.7649 - val_loss: 0.4276 - val_acc: 0.7788\n",
      "Epoch 3/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.4405 - acc: 0.7869\n",
      "Epoch 3: val_acc improved from 0.77881 to 0.78815, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4400 - acc: 0.7872 - val_loss: 0.4148 - val_acc: 0.7881\n",
      "Epoch 4/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.4268 - acc: 0.7909\n",
      "Epoch 4: val_acc improved from 0.78815 to 0.80073, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4255 - acc: 0.7919 - val_loss: 0.3928 - val_acc: 0.8007\n",
      "Epoch 5/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.4092 - acc: 0.8034\n",
      "Epoch 5: val_acc improved from 0.80073 to 0.81656, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4074 - acc: 0.8048 - val_loss: 0.3781 - val_acc: 0.8166\n",
      "Epoch 6/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.4003 - acc: 0.8046\n",
      "Epoch 6: val_acc did not improve from 0.81656\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3975 - acc: 0.8060 - val_loss: 0.3708 - val_acc: 0.8137\n",
      "Epoch 7/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.3868 - acc: 0.8177\n",
      "Epoch 7: val_acc improved from 0.81656 to 0.82305, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3864 - acc: 0.8179 - val_loss: 0.3600 - val_acc: 0.8231\n",
      "Epoch 8/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.3754 - acc: 0.8227\n",
      "Epoch 8: val_acc improved from 0.82305 to 0.83847, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3754 - acc: 0.8227 - val_loss: 0.3461 - val_acc: 0.8385\n",
      "Epoch 9/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.3709 - acc: 0.8285\n",
      "Epoch 9: val_acc did not improve from 0.83847\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3709 - acc: 0.8284 - val_loss: 0.3557 - val_acc: 0.8239\n",
      "Epoch 10/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.3556 - acc: 0.8322\n",
      "Epoch 10: val_acc did not improve from 0.83847\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.3547 - acc: 0.8326 - val_loss: 0.3449 - val_acc: 0.8348\n",
      "Epoch 11/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.3514 - acc: 0.8363\n",
      "Epoch 11: val_acc improved from 0.83847 to 0.84010, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3502 - acc: 0.8369 - val_loss: 0.3341 - val_acc: 0.8401\n",
      "Epoch 12/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.3450 - acc: 0.8387\n",
      "Epoch 12: val_acc did not improve from 0.84010\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3446 - acc: 0.8387 - val_loss: 0.3345 - val_acc: 0.8381\n",
      "Epoch 13/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.3387 - acc: 0.8440\n",
      "Epoch 13: val_acc did not improve from 0.84010\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3382 - acc: 0.8441 - val_loss: 0.3371 - val_acc: 0.8332\n",
      "Epoch 14/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.3308 - acc: 0.8495\n",
      "Epoch 14: val_acc improved from 0.84010 to 0.84903, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3290 - acc: 0.8505 - val_loss: 0.3224 - val_acc: 0.8490\n",
      "Epoch 15/2000\n",
      "590/616 [===========================>..] - ETA: 0s - loss: 0.3225 - acc: 0.8484\n",
      "Epoch 15: val_acc did not improve from 0.84903\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3215 - acc: 0.8495 - val_loss: 0.3296 - val_acc: 0.8486\n",
      "Epoch 16/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.3269 - acc: 0.8465\n",
      "Epoch 16: val_acc did not improve from 0.84903\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3246 - acc: 0.8482 - val_loss: 0.3188 - val_acc: 0.8458\n",
      "Epoch 17/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.3143 - acc: 0.8582\n",
      "Epoch 17: val_acc improved from 0.84903 to 0.86039, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3129 - acc: 0.8590 - val_loss: 0.3083 - val_acc: 0.8604\n",
      "Epoch 18/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.3153 - acc: 0.8573\n",
      "Epoch 18: val_acc did not improve from 0.86039\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3156 - acc: 0.8571 - val_loss: 0.3154 - val_acc: 0.8535\n",
      "Epoch 19/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.3096 - acc: 0.8583\n",
      "Epoch 19: val_acc did not improve from 0.86039\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3080 - acc: 0.8592 - val_loss: 0.3103 - val_acc: 0.8567\n",
      "Epoch 20/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.3053 - acc: 0.8631\n",
      "Epoch 20: val_acc did not improve from 0.86039\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3037 - acc: 0.8641 - val_loss: 0.3143 - val_acc: 0.8571\n",
      "Epoch 21/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.3039 - acc: 0.8637\n",
      "Epoch 21: val_acc improved from 0.86039 to 0.86323, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3036 - acc: 0.8639 - val_loss: 0.3022 - val_acc: 0.8632\n",
      "Epoch 22/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2990 - acc: 0.8661\n",
      "Epoch 22: val_acc did not improve from 0.86323\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2987 - acc: 0.8664 - val_loss: 0.3072 - val_acc: 0.8600\n",
      "Epoch 23/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2951 - acc: 0.8655\n",
      "Epoch 23: val_acc improved from 0.86323 to 0.86567, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2939 - acc: 0.8665 - val_loss: 0.3051 - val_acc: 0.8657\n",
      "Epoch 24/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2895 - acc: 0.8681\n",
      "Epoch 24: val_acc did not improve from 0.86567\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2876 - acc: 0.8688 - val_loss: 0.3142 - val_acc: 0.8588\n",
      "Epoch 25/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.2894 - acc: 0.8668\n",
      "Epoch 25: val_acc did not improve from 0.86567\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2875 - acc: 0.8675 - val_loss: 0.3082 - val_acc: 0.8584\n",
      "Epoch 26/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2841 - acc: 0.8716\n",
      "Epoch 26: val_acc improved from 0.86567 to 0.87338, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2841 - acc: 0.8716 - val_loss: 0.3020 - val_acc: 0.8734\n",
      "Epoch 27/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2800 - acc: 0.8762\n",
      "Epoch 27: val_acc did not improve from 0.87338\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2784 - acc: 0.8767 - val_loss: 0.2979 - val_acc: 0.8653\n",
      "Epoch 28/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.8720\n",
      "Epoch 28: val_acc did not improve from 0.87338\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2787 - acc: 0.8726 - val_loss: 0.3004 - val_acc: 0.8730\n",
      "Epoch 29/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2749 - acc: 0.8757\n",
      "Epoch 29: val_acc did not improve from 0.87338\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2741 - acc: 0.8761 - val_loss: 0.2915 - val_acc: 0.8693\n",
      "Epoch 30/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2672 - acc: 0.8845\n",
      "Epoch 30: val_acc did not improve from 0.87338\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2670 - acc: 0.8846 - val_loss: 0.2999 - val_acc: 0.8713\n",
      "Epoch 31/2000\n",
      "592/616 [===========================>..] - ETA: 0s - loss: 0.2797 - acc: 0.8763\n",
      "Epoch 31: val_acc did not improve from 0.87338\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2778 - acc: 0.8772 - val_loss: 0.2978 - val_acc: 0.8693\n",
      "Epoch 32/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2671 - acc: 0.8818\n",
      "Epoch 32: val_acc did not improve from 0.87338\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2665 - acc: 0.8823 - val_loss: 0.3064 - val_acc: 0.8649\n",
      "Epoch 33/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2697 - acc: 0.8813\n",
      "Epoch 33: val_acc did not improve from 0.87338\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2682 - acc: 0.8818 - val_loss: 0.3082 - val_acc: 0.8596\n",
      "Epoch 34/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2673 - acc: 0.8837\n",
      "Epoch 34: val_acc did not improve from 0.87338\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2673 - acc: 0.8837 - val_loss: 0.3076 - val_acc: 0.8701\n",
      "Epoch 35/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2592 - acc: 0.8853\n",
      "Epoch 35: val_acc did not improve from 0.87338\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2583 - acc: 0.8855 - val_loss: 0.3106 - val_acc: 0.8657\n",
      "Epoch 36/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2675 - acc: 0.8845\n",
      "Epoch 36: val_acc improved from 0.87338 to 0.87703, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2657 - acc: 0.8850 - val_loss: 0.2848 - val_acc: 0.8770\n",
      "Epoch 37/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2580 - acc: 0.8810\n",
      "Epoch 37: val_acc improved from 0.87703 to 0.88028, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2571 - acc: 0.8816 - val_loss: 0.2888 - val_acc: 0.8803\n",
      "Epoch 38/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.2580 - acc: 0.8860\n",
      "Epoch 38: val_acc did not improve from 0.88028\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2572 - acc: 0.8864 - val_loss: 0.2999 - val_acc: 0.8750\n",
      "Epoch 39/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2623 - acc: 0.8825\n",
      "Epoch 39: val_acc did not improve from 0.88028\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2606 - acc: 0.8833 - val_loss: 0.2977 - val_acc: 0.8718\n",
      "Epoch 40/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.2551 - acc: 0.8875\n",
      "Epoch 40: val_acc did not improve from 0.88028\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2534 - acc: 0.8882 - val_loss: 0.3274 - val_acc: 0.8713\n",
      "Epoch 41/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2500 - acc: 0.8884\n",
      "Epoch 41: val_acc did not improve from 0.88028\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2496 - acc: 0.8886 - val_loss: 0.2915 - val_acc: 0.8738\n",
      "Epoch 42/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2595 - acc: 0.8860\n",
      "Epoch 42: val_acc improved from 0.88028 to 0.88636, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2582 - acc: 0.8864 - val_loss: 0.2723 - val_acc: 0.8864\n",
      "Epoch 43/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2411 - acc: 0.8927\n",
      "Epoch 43: val_acc did not improve from 0.88636\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2412 - acc: 0.8927 - val_loss: 0.3111 - val_acc: 0.8661\n",
      "Epoch 44/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2548 - acc: 0.8929\n",
      "Epoch 44: val_acc did not improve from 0.88636\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2541 - acc: 0.8934 - val_loss: 0.2800 - val_acc: 0.8843\n",
      "Epoch 45/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2394 - acc: 0.8937\n",
      "Epoch 45: val_acc improved from 0.88636 to 0.88677, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2376 - acc: 0.8945 - val_loss: 0.2677 - val_acc: 0.8868\n",
      "Epoch 46/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2430 - acc: 0.8914\n",
      "Epoch 46: val_acc improved from 0.88677 to 0.88718, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2413 - acc: 0.8925 - val_loss: 0.2733 - val_acc: 0.8872\n",
      "Epoch 47/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2417 - acc: 0.8909\n",
      "Epoch 47: val_acc did not improve from 0.88718\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2412 - acc: 0.8913 - val_loss: 0.2772 - val_acc: 0.8799\n",
      "Epoch 48/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2481 - acc: 0.8932\n",
      "Epoch 48: val_acc did not improve from 0.88718\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2468 - acc: 0.8938 - val_loss: 0.2863 - val_acc: 0.8799\n",
      "Epoch 49/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2389 - acc: 0.8958\n",
      "Epoch 49: val_acc did not improve from 0.88718\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2380 - acc: 0.8961 - val_loss: 0.3080 - val_acc: 0.8758\n",
      "Epoch 50/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.8940\n",
      "Epoch 50: val_acc did not improve from 0.88718\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2406 - acc: 0.8940 - val_loss: 0.3085 - val_acc: 0.8705\n",
      "Epoch 51/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.2366 - acc: 0.8969\n",
      "Epoch 51: val_acc did not improve from 0.88718\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2352 - acc: 0.8974 - val_loss: 0.2903 - val_acc: 0.8718\n",
      "Epoch 52/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2291 - acc: 0.8994\n",
      "Epoch 52: val_acc did not improve from 0.88718\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2283 - acc: 0.8995 - val_loss: 0.2833 - val_acc: 0.8843\n",
      "Epoch 53/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2316 - acc: 0.8964\n",
      "Epoch 53: val_acc did not improve from 0.88718\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2307 - acc: 0.8970 - val_loss: 0.2762 - val_acc: 0.8831\n",
      "Epoch 54/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2269 - acc: 0.8990\n",
      "Epoch 54: val_acc improved from 0.88718 to 0.89570, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2265 - acc: 0.8990 - val_loss: 0.2606 - val_acc: 0.8957\n",
      "Epoch 55/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2291 - acc: 0.9007\n",
      "Epoch 55: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2290 - acc: 0.9008 - val_loss: 0.2833 - val_acc: 0.8815\n",
      "Epoch 56/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2275 - acc: 0.9026\n",
      "Epoch 56: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2259 - acc: 0.9033 - val_loss: 0.2776 - val_acc: 0.8900\n",
      "Epoch 57/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2280 - acc: 0.8972\n",
      "Epoch 57: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2266 - acc: 0.8978 - val_loss: 0.2877 - val_acc: 0.8835\n",
      "Epoch 58/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2198 - acc: 0.9031\n",
      "Epoch 58: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2187 - acc: 0.9035 - val_loss: 0.2824 - val_acc: 0.8856\n",
      "Epoch 59/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.2255 - acc: 0.9021\n",
      "Epoch 59: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2251 - acc: 0.9025 - val_loss: 0.2918 - val_acc: 0.8908\n",
      "Epoch 60/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2247 - acc: 0.9019\n",
      "Epoch 60: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2243 - acc: 0.9021 - val_loss: 0.2679 - val_acc: 0.8900\n",
      "Epoch 61/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2268 - acc: 0.9011\n",
      "Epoch 61: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2268 - acc: 0.9011 - val_loss: 0.2707 - val_acc: 0.8872\n",
      "Epoch 62/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.2238 - acc: 0.9033\n",
      "Epoch 62: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2222 - acc: 0.9035 - val_loss: 0.2900 - val_acc: 0.8892\n",
      "Epoch 63/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2216 - acc: 0.9008\n",
      "Epoch 63: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2204 - acc: 0.9015 - val_loss: 0.2677 - val_acc: 0.8892\n",
      "Epoch 64/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2141 - acc: 0.9026\n",
      "Epoch 64: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2133 - acc: 0.9028 - val_loss: 0.2637 - val_acc: 0.8957\n",
      "Epoch 65/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2209 - acc: 0.9071\n",
      "Epoch 65: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2199 - acc: 0.9073 - val_loss: 0.2671 - val_acc: 0.8868\n",
      "Epoch 66/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9046\n",
      "Epoch 66: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2202 - acc: 0.9048 - val_loss: 0.2681 - val_acc: 0.8925\n",
      "Epoch 67/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.2201 - acc: 0.9060\n",
      "Epoch 67: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2182 - acc: 0.9066 - val_loss: 0.2862 - val_acc: 0.8860\n",
      "Epoch 68/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9050\n",
      "Epoch 68: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2179 - acc: 0.9053 - val_loss: 0.2737 - val_acc: 0.8876\n",
      "Epoch 69/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2182 - acc: 0.9064\n",
      "Epoch 69: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2172 - acc: 0.9067 - val_loss: 0.2814 - val_acc: 0.8908\n",
      "Epoch 70/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2184 - acc: 0.9083\n",
      "Epoch 70: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2173 - acc: 0.9091 - val_loss: 0.2907 - val_acc: 0.8823\n",
      "Epoch 71/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2076 - acc: 0.9104\n",
      "Epoch 71: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2072 - acc: 0.9106 - val_loss: 0.2968 - val_acc: 0.8811\n",
      "Epoch 72/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2027 - acc: 0.9142\n",
      "Epoch 72: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2023 - acc: 0.9147 - val_loss: 0.2992 - val_acc: 0.8937\n",
      "Epoch 73/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9114\n",
      "Epoch 73: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2110 - acc: 0.9123 - val_loss: 0.2945 - val_acc: 0.8880\n",
      "Epoch 74/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2150 - acc: 0.9138\n",
      "Epoch 74: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2141 - acc: 0.9141 - val_loss: 0.2822 - val_acc: 0.8925\n",
      "Epoch 75/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9091\n",
      "Epoch 75: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2095 - acc: 0.9096 - val_loss: 0.2806 - val_acc: 0.8864\n",
      "Epoch 76/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9107\n",
      "Epoch 76: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2098 - acc: 0.9111 - val_loss: 0.2705 - val_acc: 0.8953\n",
      "Epoch 77/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2037 - acc: 0.9114\n",
      "Epoch 77: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2037 - acc: 0.9114 - val_loss: 0.2798 - val_acc: 0.8908\n",
      "Epoch 78/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2085 - acc: 0.9123\n",
      "Epoch 78: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2079 - acc: 0.9127 - val_loss: 0.2781 - val_acc: 0.8929\n",
      "Epoch 79/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9139\n",
      "Epoch 79: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2030 - acc: 0.9142 - val_loss: 0.2696 - val_acc: 0.8916\n",
      "Epoch 80/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9118\n",
      "Epoch 80: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2081 - acc: 0.9119 - val_loss: 0.2810 - val_acc: 0.8892\n",
      "Epoch 81/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1996 - acc: 0.9133\n",
      "Epoch 81: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1986 - acc: 0.9136 - val_loss: 0.2852 - val_acc: 0.8888\n",
      "Epoch 82/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2051 - acc: 0.9161\n",
      "Epoch 82: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2038 - acc: 0.9163 - val_loss: 0.2766 - val_acc: 0.8892\n",
      "Epoch 83/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2028 - acc: 0.9122\n",
      "Epoch 83: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2019 - acc: 0.9127 - val_loss: 0.2805 - val_acc: 0.8916\n",
      "Epoch 84/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9162\n",
      "Epoch 84: val_acc improved from 0.89570 to 0.89894, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1985 - acc: 0.9162 - val_loss: 0.2711 - val_acc: 0.8989\n",
      "Epoch 85/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1962 - acc: 0.9142\n",
      "Epoch 85: val_acc did not improve from 0.89894\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1954 - acc: 0.9148 - val_loss: 0.2890 - val_acc: 0.8884\n",
      "Epoch 86/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2040 - acc: 0.9182\n",
      "Epoch 86: val_acc did not improve from 0.89894\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2030 - acc: 0.9186 - val_loss: 0.2695 - val_acc: 0.8981\n",
      "Epoch 87/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.2063 - acc: 0.9158\n",
      "Epoch 87: val_acc did not improve from 0.89894\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2049 - acc: 0.9162 - val_loss: 0.2819 - val_acc: 0.8864\n",
      "Epoch 88/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1968 - acc: 0.9151\n",
      "Epoch 88: val_acc did not improve from 0.89894\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1962 - acc: 0.9154 - val_loss: 0.2698 - val_acc: 0.8953\n",
      "Epoch 89/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1972 - acc: 0.9197\n",
      "Epoch 89: val_acc did not improve from 0.89894\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1971 - acc: 0.9201 - val_loss: 0.2778 - val_acc: 0.8880\n",
      "Epoch 90/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1949 - acc: 0.9145\n",
      "Epoch 90: val_acc did not improve from 0.89894\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1940 - acc: 0.9154 - val_loss: 0.2805 - val_acc: 0.8957\n",
      "Epoch 91/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9213\n",
      "Epoch 91: val_acc did not improve from 0.89894\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1920 - acc: 0.9212 - val_loss: 0.3028 - val_acc: 0.8949\n",
      "Epoch 92/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2020 - acc: 0.9152\n",
      "Epoch 92: val_acc did not improve from 0.89894\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2012 - acc: 0.9155 - val_loss: 0.2742 - val_acc: 0.8961\n",
      "Epoch 93/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1916 - acc: 0.9175\n",
      "Epoch 93: val_acc did not improve from 0.89894\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1913 - acc: 0.9181 - val_loss: 0.2854 - val_acc: 0.8953\n",
      "Epoch 94/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1878 - acc: 0.9148\n",
      "Epoch 94: val_acc did not improve from 0.89894\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1874 - acc: 0.9151 - val_loss: 0.2728 - val_acc: 0.8981\n",
      "Epoch 95/2000\n",
      "593/616 [===========================>..] - ETA: 0s - loss: 0.1908 - acc: 0.9192\n",
      "Epoch 95: val_acc improved from 0.89894 to 0.90097, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1898 - acc: 0.9199 - val_loss: 0.2626 - val_acc: 0.9010\n",
      "Epoch 96/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1918 - acc: 0.9203\n",
      "Epoch 96: val_acc did not improve from 0.90097\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1911 - acc: 0.9205 - val_loss: 0.2628 - val_acc: 0.8969\n",
      "Epoch 97/2000\n",
      "593/616 [===========================>..] - ETA: 0s - loss: 0.1885 - acc: 0.9217\n",
      "Epoch 97: val_acc did not improve from 0.90097\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1877 - acc: 0.9218 - val_loss: 0.2776 - val_acc: 0.8945\n",
      "Epoch 98/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9174\n",
      "Epoch 98: val_acc did not improve from 0.90097\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1956 - acc: 0.9177 - val_loss: 0.2756 - val_acc: 0.8925\n",
      "Epoch 99/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2034 - acc: 0.9187\n",
      "Epoch 99: val_acc did not improve from 0.90097\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2024 - acc: 0.9194 - val_loss: 0.2680 - val_acc: 0.8953\n",
      "Epoch 100/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9199\n",
      "Epoch 100: val_acc did not improve from 0.90097\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1960 - acc: 0.9206 - val_loss: 0.2955 - val_acc: 0.8925\n",
      "Epoch 101/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1858 - acc: 0.9202\n",
      "Epoch 101: val_acc did not improve from 0.90097\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1856 - acc: 0.9202 - val_loss: 0.2855 - val_acc: 0.8929\n",
      "Epoch 102/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1849 - acc: 0.9207\n",
      "Epoch 102: val_acc did not improve from 0.90097\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1838 - acc: 0.9215 - val_loss: 0.2861 - val_acc: 0.8929\n",
      "Epoch 103/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9214\n",
      "Epoch 103: val_acc did not improve from 0.90097\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1918 - acc: 0.9221 - val_loss: 0.2724 - val_acc: 0.8941\n",
      "Epoch 104/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1838 - acc: 0.9204\n",
      "Epoch 104: val_acc improved from 0.90097 to 0.90219, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1826 - acc: 0.9210 - val_loss: 0.2681 - val_acc: 0.9022\n",
      "Epoch 105/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9225\n",
      "Epoch 105: val_acc did not improve from 0.90219\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1837 - acc: 0.9229 - val_loss: 0.2903 - val_acc: 0.8868\n",
      "Epoch 106/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9179\n",
      "Epoch 106: val_acc did not improve from 0.90219\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1912 - acc: 0.9184 - val_loss: 0.2995 - val_acc: 0.8892\n",
      "Epoch 107/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1837 - acc: 0.9203\n",
      "Epoch 107: val_acc did not improve from 0.90219\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1832 - acc: 0.9211 - val_loss: 0.2982 - val_acc: 0.8969\n",
      "Epoch 108/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1814 - acc: 0.9212\n",
      "Epoch 108: val_acc did not improve from 0.90219\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1804 - acc: 0.9217 - val_loss: 0.2779 - val_acc: 0.8998\n",
      "Epoch 109/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1823 - acc: 0.9235\n",
      "Epoch 109: val_acc improved from 0.90219 to 0.90666, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1807 - acc: 0.9243 - val_loss: 0.2588 - val_acc: 0.9067\n",
      "Epoch 110/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1888 - acc: 0.9210\n",
      "Epoch 110: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1878 - acc: 0.9214 - val_loss: 0.2899 - val_acc: 0.8989\n",
      "Epoch 111/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1864 - acc: 0.9192\n",
      "Epoch 111: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1848 - acc: 0.9200 - val_loss: 0.2744 - val_acc: 0.8989\n",
      "Epoch 112/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1862 - acc: 0.9209\n",
      "Epoch 112: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1852 - acc: 0.9215 - val_loss: 0.2840 - val_acc: 0.8989\n",
      "Epoch 113/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1837 - acc: 0.9233\n",
      "Epoch 113: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1828 - acc: 0.9235 - val_loss: 0.2733 - val_acc: 0.8977\n",
      "Epoch 114/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1782 - acc: 0.9231\n",
      "Epoch 114: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1782 - acc: 0.9234 - val_loss: 0.2868 - val_acc: 0.8953\n",
      "Epoch 115/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1798 - acc: 0.9256\n",
      "Epoch 115: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1790 - acc: 0.9256 - val_loss: 0.2704 - val_acc: 0.8941\n",
      "Epoch 116/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9256\n",
      "Epoch 116: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1711 - acc: 0.9257 - val_loss: 0.2847 - val_acc: 0.8937\n",
      "Epoch 117/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9240\n",
      "Epoch 117: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1810 - acc: 0.9240 - val_loss: 0.2625 - val_acc: 0.8981\n",
      "Epoch 118/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9246\n",
      "Epoch 118: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1745 - acc: 0.9248 - val_loss: 0.2756 - val_acc: 0.9014\n",
      "Epoch 119/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1823 - acc: 0.9238\n",
      "Epoch 119: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1823 - acc: 0.9238 - val_loss: 0.2584 - val_acc: 0.9022\n",
      "Epoch 120/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1754 - acc: 0.9255\n",
      "Epoch 120: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1751 - acc: 0.9256 - val_loss: 0.2881 - val_acc: 0.8953\n",
      "Epoch 121/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9243\n",
      "Epoch 121: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1765 - acc: 0.9248 - val_loss: 0.2709 - val_acc: 0.8912\n",
      "Epoch 122/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1765 - acc: 0.9257\n",
      "Epoch 122: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1757 - acc: 0.9262 - val_loss: 0.2612 - val_acc: 0.9034\n",
      "Epoch 123/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9235\n",
      "Epoch 123: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1764 - acc: 0.9244 - val_loss: 0.2713 - val_acc: 0.8973\n",
      "Epoch 124/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9234\n",
      "Epoch 124: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1839 - acc: 0.9241 - val_loss: 0.2676 - val_acc: 0.8949\n",
      "Epoch 125/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1913 - acc: 0.9260\n",
      "Epoch 125: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1904 - acc: 0.9262 - val_loss: 0.2663 - val_acc: 0.9038\n",
      "Epoch 126/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9282\n",
      "Epoch 126: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1709 - acc: 0.9284 - val_loss: 0.2779 - val_acc: 0.9054\n",
      "Epoch 127/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1670 - acc: 0.9270\n",
      "Epoch 127: val_acc improved from 0.90666 to 0.90787, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1654 - acc: 0.9278 - val_loss: 0.2806 - val_acc: 0.9079\n",
      "Epoch 128/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9278\n",
      "Epoch 128: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1752 - acc: 0.9281 - val_loss: 0.2770 - val_acc: 0.9034\n",
      "Epoch 129/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1765 - acc: 0.9261\n",
      "Epoch 129: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1756 - acc: 0.9266 - val_loss: 0.2754 - val_acc: 0.9014\n",
      "Epoch 130/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1730 - acc: 0.9261\n",
      "Epoch 130: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1725 - acc: 0.9263 - val_loss: 0.2665 - val_acc: 0.8977\n",
      "Epoch 131/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1708 - acc: 0.9305\n",
      "Epoch 131: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1696 - acc: 0.9310 - val_loss: 0.2801 - val_acc: 0.9014\n",
      "Epoch 132/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9278\n",
      "Epoch 132: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1753 - acc: 0.9280 - val_loss: 0.2695 - val_acc: 0.9014\n",
      "Epoch 133/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1711 - acc: 0.9275\n",
      "Epoch 133: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1698 - acc: 0.9282 - val_loss: 0.2902 - val_acc: 0.9046\n",
      "Epoch 134/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1766 - acc: 0.9257\n",
      "Epoch 134: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1758 - acc: 0.9258 - val_loss: 0.2829 - val_acc: 0.8981\n",
      "Epoch 135/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1717 - acc: 0.9300\n",
      "Epoch 135: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1708 - acc: 0.9300 - val_loss: 0.2951 - val_acc: 0.9050\n",
      "Epoch 136/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9272\n",
      "Epoch 136: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1694 - acc: 0.9283 - val_loss: 0.2921 - val_acc: 0.9046\n",
      "Epoch 137/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9293\n",
      "Epoch 137: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1709 - acc: 0.9296 - val_loss: 0.2853 - val_acc: 0.9046\n",
      "Epoch 138/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1673 - acc: 0.9295\n",
      "Epoch 138: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1668 - acc: 0.9297 - val_loss: 0.3078 - val_acc: 0.8961\n",
      "Epoch 139/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9292\n",
      "Epoch 139: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1670 - acc: 0.9294 - val_loss: 0.2866 - val_acc: 0.9026\n",
      "Epoch 140/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9300\n",
      "Epoch 140: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1746 - acc: 0.9304 - val_loss: 0.2846 - val_acc: 0.9018\n",
      "Epoch 141/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1707 - acc: 0.9318\n",
      "Epoch 141: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1697 - acc: 0.9316 - val_loss: 0.2829 - val_acc: 0.8961\n",
      "Epoch 142/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9345\n",
      "Epoch 142: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1593 - acc: 0.9352 - val_loss: 0.2723 - val_acc: 0.9014\n",
      "Epoch 143/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1643 - acc: 0.9311\n",
      "Epoch 143: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1630 - acc: 0.9317 - val_loss: 0.3036 - val_acc: 0.8969\n",
      "Epoch 144/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9333\n",
      "Epoch 144: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1637 - acc: 0.9336 - val_loss: 0.2884 - val_acc: 0.9071\n",
      "Epoch 145/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9315\n",
      "Epoch 145: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1693 - acc: 0.9315 - val_loss: 0.2905 - val_acc: 0.9006\n",
      "Epoch 146/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9319\n",
      "Epoch 146: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1642 - acc: 0.9323 - val_loss: 0.3248 - val_acc: 0.8957\n",
      "Epoch 147/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9305\n",
      "Epoch 147: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1730 - acc: 0.9306 - val_loss: 0.2981 - val_acc: 0.8937\n",
      "Epoch 148/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1638 - acc: 0.9323\n",
      "Epoch 148: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1630 - acc: 0.9324 - val_loss: 0.2815 - val_acc: 0.9046\n",
      "Epoch 149/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9325\n",
      "Epoch 149: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1617 - acc: 0.9328 - val_loss: 0.2881 - val_acc: 0.9071\n",
      "Epoch 150/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1593 - acc: 0.9327\n",
      "Epoch 150: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1581 - acc: 0.9331 - val_loss: 0.2971 - val_acc: 0.9038\n",
      "Epoch 151/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9304\n",
      "Epoch 151: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1665 - acc: 0.9312 - val_loss: 0.2795 - val_acc: 0.9062\n",
      "Epoch 152/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1630 - acc: 0.9290\n",
      "Epoch 152: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1625 - acc: 0.9293 - val_loss: 0.2863 - val_acc: 0.8973\n",
      "Epoch 153/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9341\n",
      "Epoch 153: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1630 - acc: 0.9340 - val_loss: 0.2754 - val_acc: 0.9071\n",
      "Epoch 154/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1626 - acc: 0.9338\n",
      "Epoch 154: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1618 - acc: 0.9339 - val_loss: 0.2712 - val_acc: 0.9062\n",
      "Epoch 155/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9306\n",
      "Epoch 155: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1652 - acc: 0.9312 - val_loss: 0.2816 - val_acc: 0.9042\n",
      "Epoch 156/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9337\n",
      "Epoch 156: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1561 - acc: 0.9340 - val_loss: 0.2947 - val_acc: 0.9054\n",
      "Epoch 157/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9313\n",
      "Epoch 157: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1677 - acc: 0.9317 - val_loss: 0.2930 - val_acc: 0.9002\n",
      "Epoch 158/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9341\n",
      "Epoch 158: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1642 - acc: 0.9343 - val_loss: 0.3090 - val_acc: 0.8941\n",
      "Epoch 159/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9294\n",
      "Epoch 159: val_acc improved from 0.90787 to 0.90950, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1709 - acc: 0.9295 - val_loss: 0.2785 - val_acc: 0.9095\n",
      "Epoch 160/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9330\n",
      "Epoch 160: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1654 - acc: 0.9335 - val_loss: 0.2875 - val_acc: 0.8994\n",
      "Epoch 161/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1615 - acc: 0.9328\n",
      "Epoch 161: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1611 - acc: 0.9328 - val_loss: 0.2910 - val_acc: 0.8985\n",
      "Epoch 162/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9341\n",
      "Epoch 162: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1675 - acc: 0.9343 - val_loss: 0.2953 - val_acc: 0.9058\n",
      "Epoch 163/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1592 - acc: 0.9332\n",
      "Epoch 163: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1592 - acc: 0.9332 - val_loss: 0.2870 - val_acc: 0.9054\n",
      "Epoch 164/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9346\n",
      "Epoch 164: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1576 - acc: 0.9349 - val_loss: 0.2851 - val_acc: 0.9083\n",
      "Epoch 165/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1607 - acc: 0.9339\n",
      "Epoch 165: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1604 - acc: 0.9342 - val_loss: 0.2981 - val_acc: 0.9018\n",
      "Epoch 166/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9365\n",
      "Epoch 166: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1550 - acc: 0.9366 - val_loss: 0.3196 - val_acc: 0.9042\n",
      "Epoch 167/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9341\n",
      "Epoch 167: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1597 - acc: 0.9343 - val_loss: 0.2991 - val_acc: 0.9071\n",
      "Epoch 168/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9370\n",
      "Epoch 168: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1555 - acc: 0.9377 - val_loss: 0.3100 - val_acc: 0.9067\n",
      "Epoch 169/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9367\n",
      "Epoch 169: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1557 - acc: 0.9367 - val_loss: 0.3028 - val_acc: 0.9046\n",
      "Epoch 170/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1614 - acc: 0.9359\n",
      "Epoch 170: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1614 - acc: 0.9359 - val_loss: 0.2987 - val_acc: 0.8961\n",
      "Epoch 171/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9340\n",
      "Epoch 171: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1593 - acc: 0.9344 - val_loss: 0.3137 - val_acc: 0.9038\n",
      "Epoch 172/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1559 - acc: 0.9362\n",
      "Epoch 172: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1556 - acc: 0.9364 - val_loss: 0.2849 - val_acc: 0.9050\n",
      "Epoch 173/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9369\n",
      "Epoch 173: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1573 - acc: 0.9370 - val_loss: 0.2916 - val_acc: 0.9002\n",
      "Epoch 174/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9384\n",
      "Epoch 174: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1490 - acc: 0.9384 - val_loss: 0.2927 - val_acc: 0.9034\n",
      "Epoch 175/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9351\n",
      "Epoch 175: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1607 - acc: 0.9358 - val_loss: 0.3415 - val_acc: 0.8989\n",
      "Epoch 176/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1531 - acc: 0.9380\n",
      "Epoch 176: val_acc did not improve from 0.90950\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1523 - acc: 0.9384 - val_loss: 0.3261 - val_acc: 0.9054\n",
      "Epoch 177/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1523 - acc: 0.9380\n",
      "Epoch 177: val_acc improved from 0.90950 to 0.91477, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1513 - acc: 0.9385 - val_loss: 0.2877 - val_acc: 0.9148\n",
      "Epoch 178/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1565 - acc: 0.9367\n",
      "Epoch 178: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1559 - acc: 0.9369 - val_loss: 0.2970 - val_acc: 0.9087\n",
      "Epoch 179/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9355\n",
      "Epoch 179: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1570 - acc: 0.9358 - val_loss: 0.3176 - val_acc: 0.8892\n",
      "Epoch 180/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1467 - acc: 0.9412\n",
      "Epoch 180: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1467 - acc: 0.9412 - val_loss: 0.2933 - val_acc: 0.9030\n",
      "Epoch 181/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9394\n",
      "Epoch 181: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1631 - acc: 0.9400 - val_loss: 0.2636 - val_acc: 0.9083\n",
      "Epoch 182/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1477 - acc: 0.9407\n",
      "Epoch 182: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1467 - acc: 0.9411 - val_loss: 0.2876 - val_acc: 0.9107\n",
      "Epoch 183/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1528 - acc: 0.9369\n",
      "Epoch 183: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1521 - acc: 0.9374 - val_loss: 0.2879 - val_acc: 0.9091\n",
      "Epoch 184/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1611 - acc: 0.9368\n",
      "Epoch 184: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1601 - acc: 0.9371 - val_loss: 0.2824 - val_acc: 0.9075\n",
      "Epoch 185/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9373\n",
      "Epoch 185: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1531 - acc: 0.9381 - val_loss: 0.3143 - val_acc: 0.8994\n",
      "Epoch 186/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9352\n",
      "Epoch 186: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1590 - acc: 0.9357 - val_loss: 0.3034 - val_acc: 0.9030\n",
      "Epoch 187/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9390\n",
      "Epoch 187: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1511 - acc: 0.9393 - val_loss: 0.3024 - val_acc: 0.9107\n",
      "Epoch 188/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1544 - acc: 0.9369\n",
      "Epoch 188: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1542 - acc: 0.9369 - val_loss: 0.2777 - val_acc: 0.9079\n",
      "Epoch 189/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9370\n",
      "Epoch 189: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1572 - acc: 0.9371 - val_loss: 0.2792 - val_acc: 0.9087\n",
      "Epoch 190/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9396\n",
      "Epoch 190: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1484 - acc: 0.9399 - val_loss: 0.2978 - val_acc: 0.9067\n",
      "Epoch 191/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1520 - acc: 0.9371\n",
      "Epoch 191: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1520 - acc: 0.9371 - val_loss: 0.2820 - val_acc: 0.9099\n",
      "Epoch 192/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.9407\n",
      "Epoch 192: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1492 - acc: 0.9406 - val_loss: 0.3251 - val_acc: 0.8973\n",
      "Epoch 193/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1479 - acc: 0.9396\n",
      "Epoch 193: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1479 - acc: 0.9396 - val_loss: 0.3008 - val_acc: 0.9071\n",
      "Epoch 194/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9394\n",
      "Epoch 194: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1526 - acc: 0.9399 - val_loss: 0.3153 - val_acc: 0.9091\n",
      "Epoch 195/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9443\n",
      "Epoch 195: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1411 - acc: 0.9449 - val_loss: 0.3025 - val_acc: 0.9034\n",
      "Epoch 196/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1530 - acc: 0.9416\n",
      "Epoch 196: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1530 - acc: 0.9416 - val_loss: 0.2833 - val_acc: 0.9067\n",
      "Epoch 197/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1518 - acc: 0.9406\n",
      "Epoch 197: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1515 - acc: 0.9406 - val_loss: 0.3093 - val_acc: 0.9042\n",
      "Epoch 198/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9396\n",
      "Epoch 198: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1478 - acc: 0.9398 - val_loss: 0.2942 - val_acc: 0.9099\n",
      "Epoch 199/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9430\n",
      "Epoch 199: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1474 - acc: 0.9425 - val_loss: 0.3050 - val_acc: 0.9091\n",
      "Epoch 200/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9415\n",
      "Epoch 200: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1477 - acc: 0.9420 - val_loss: 0.3017 - val_acc: 0.9067\n",
      "Epoch 201/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9377\n",
      "Epoch 201: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1500 - acc: 0.9381 - val_loss: 0.3600 - val_acc: 0.9038\n",
      "Epoch 202/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9387\n",
      "Epoch 202: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1510 - acc: 0.9391 - val_loss: 0.3036 - val_acc: 0.9148\n",
      "Epoch 203/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1455 - acc: 0.9392\n",
      "Epoch 203: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1455 - acc: 0.9392 - val_loss: 0.3217 - val_acc: 0.9058\n",
      "Epoch 204/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9377\n",
      "Epoch 204: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1451 - acc: 0.9386 - val_loss: 0.2983 - val_acc: 0.9091\n",
      "Epoch 205/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9389\n",
      "Epoch 205: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1497 - acc: 0.9392 - val_loss: 0.3170 - val_acc: 0.8981\n",
      "Epoch 206/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1451 - acc: 0.9443\n",
      "Epoch 206: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1451 - acc: 0.9443 - val_loss: 0.3336 - val_acc: 0.9006\n",
      "Epoch 207/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9402\n",
      "Epoch 207: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1497 - acc: 0.9409 - val_loss: 0.2895 - val_acc: 0.9054\n",
      "Epoch 208/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9410\n",
      "Epoch 208: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1544 - acc: 0.9410 - val_loss: 0.2963 - val_acc: 0.9050\n",
      "Epoch 209/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9446\n",
      "Epoch 209: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1383 - acc: 0.9449 - val_loss: 0.2949 - val_acc: 0.9062\n",
      "Epoch 210/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9403\n",
      "Epoch 210: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1402 - acc: 0.9406 - val_loss: 0.3040 - val_acc: 0.9046\n",
      "Epoch 211/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9429\n",
      "Epoch 211: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1475 - acc: 0.9430 - val_loss: 0.3232 - val_acc: 0.9034\n",
      "Epoch 212/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9390\n",
      "Epoch 212: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1565 - acc: 0.9393 - val_loss: 0.3081 - val_acc: 0.9058\n",
      "Epoch 213/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9441\n",
      "Epoch 213: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1491 - acc: 0.9445 - val_loss: 0.3438 - val_acc: 0.8941\n",
      "Epoch 214/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1564 - acc: 0.9408\n",
      "Epoch 214: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1551 - acc: 0.9409 - val_loss: 0.3235 - val_acc: 0.8969\n",
      "Epoch 215/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9431\n",
      "Epoch 215: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1451 - acc: 0.9433 - val_loss: 0.3029 - val_acc: 0.9103\n",
      "Epoch 216/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9389\n",
      "Epoch 216: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1478 - acc: 0.9394 - val_loss: 0.3104 - val_acc: 0.9099\n",
      "Epoch 217/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9413\n",
      "Epoch 217: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1410 - acc: 0.9416 - val_loss: 0.3090 - val_acc: 0.8969\n",
      "Epoch 218/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9404\n",
      "Epoch 218: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1549 - acc: 0.9407 - val_loss: 0.2841 - val_acc: 0.9091\n",
      "Epoch 219/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9412\n",
      "Epoch 219: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1470 - acc: 0.9412 - val_loss: 0.3010 - val_acc: 0.9026\n",
      "Epoch 220/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9431\n",
      "Epoch 220: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1366 - acc: 0.9432 - val_loss: 0.2991 - val_acc: 0.9083\n",
      "Epoch 221/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9438\n",
      "Epoch 221: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1363 - acc: 0.9439 - val_loss: 0.3149 - val_acc: 0.9034\n",
      "Epoch 222/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9452\n",
      "Epoch 222: val_acc did not improve from 0.91477\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1391 - acc: 0.9453 - val_loss: 0.3125 - val_acc: 0.9083\n",
      "Epoch 223/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9447\n",
      "Epoch 223: val_acc improved from 0.91477 to 0.91558, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1337 - acc: 0.9448 - val_loss: 0.2852 - val_acc: 0.9156\n",
      "Epoch 224/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9408\n",
      "Epoch 224: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1553 - acc: 0.9409 - val_loss: 0.2891 - val_acc: 0.9099\n",
      "Epoch 225/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9473\n",
      "Epoch 225: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1311 - acc: 0.9474 - val_loss: 0.3183 - val_acc: 0.9083\n",
      "Epoch 226/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1488 - acc: 0.9446\n",
      "Epoch 226: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1487 - acc: 0.9446 - val_loss: 0.3338 - val_acc: 0.9026\n",
      "Epoch 227/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9427\n",
      "Epoch 227: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1362 - acc: 0.9428 - val_loss: 0.3583 - val_acc: 0.9026\n",
      "Epoch 228/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9456\n",
      "Epoch 228: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1350 - acc: 0.9455 - val_loss: 0.3188 - val_acc: 0.9091\n",
      "Epoch 229/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9393\n",
      "Epoch 229: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1472 - acc: 0.9396 - val_loss: 0.3201 - val_acc: 0.9103\n",
      "Epoch 230/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9460\n",
      "Epoch 230: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1332 - acc: 0.9461 - val_loss: 0.3339 - val_acc: 0.9136\n",
      "Epoch 231/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1450 - acc: 0.9432\n",
      "Epoch 231: val_acc improved from 0.91558 to 0.92005, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1450 - acc: 0.9432 - val_loss: 0.3048 - val_acc: 0.9200\n",
      "Epoch 232/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9401\n",
      "Epoch 232: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1377 - acc: 0.9406 - val_loss: 0.3586 - val_acc: 0.9127\n",
      "Epoch 233/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9438\n",
      "Epoch 233: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1391 - acc: 0.9443 - val_loss: 0.3386 - val_acc: 0.9099\n",
      "Epoch 234/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9459\n",
      "Epoch 234: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1354 - acc: 0.9461 - val_loss: 0.3365 - val_acc: 0.9192\n",
      "Epoch 235/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1512 - acc: 0.9401\n",
      "Epoch 235: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1495 - acc: 0.9409 - val_loss: 0.3240 - val_acc: 0.9087\n",
      "Epoch 236/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1436 - acc: 0.9449\n",
      "Epoch 236: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1436 - acc: 0.9449 - val_loss: 0.3431 - val_acc: 0.9042\n",
      "Epoch 237/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1412 - acc: 0.9426\n",
      "Epoch 237: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1412 - acc: 0.9426 - val_loss: 0.3693 - val_acc: 0.9083\n",
      "Epoch 238/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9440\n",
      "Epoch 238: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1417 - acc: 0.9440 - val_loss: 0.3222 - val_acc: 0.9188\n",
      "Epoch 239/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9429\n",
      "Epoch 239: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1370 - acc: 0.9433 - val_loss: 0.3510 - val_acc: 0.9103\n",
      "Epoch 240/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9487\n",
      "Epoch 240: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1237 - acc: 0.9487 - val_loss: 0.3895 - val_acc: 0.9071\n",
      "Epoch 241/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9431\n",
      "Epoch 241: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1541 - acc: 0.9434 - val_loss: 0.3433 - val_acc: 0.9067\n",
      "Epoch 242/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9432\n",
      "Epoch 242: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1405 - acc: 0.9433 - val_loss: 0.3255 - val_acc: 0.9034\n",
      "Epoch 243/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9469\n",
      "Epoch 243: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1375 - acc: 0.9472 - val_loss: 0.3587 - val_acc: 0.9079\n",
      "Epoch 244/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1487 - acc: 0.9436\n",
      "Epoch 244: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1487 - acc: 0.9436 - val_loss: 0.3498 - val_acc: 0.9111\n",
      "Epoch 245/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9475\n",
      "Epoch 245: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1388 - acc: 0.9475 - val_loss: 0.3474 - val_acc: 0.9144\n",
      "Epoch 246/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9439\n",
      "Epoch 246: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1376 - acc: 0.9443 - val_loss: 0.3377 - val_acc: 0.9030\n",
      "Epoch 247/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9468\n",
      "Epoch 247: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1353 - acc: 0.9471 - val_loss: 0.3307 - val_acc: 0.9123\n",
      "Epoch 248/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9457\n",
      "Epoch 248: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1380 - acc: 0.9458 - val_loss: 0.3503 - val_acc: 0.9079\n",
      "Epoch 249/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1429 - acc: 0.9432\n",
      "Epoch 249: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1417 - acc: 0.9438 - val_loss: 0.3453 - val_acc: 0.9062\n",
      "Epoch 250/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9481\n",
      "Epoch 250: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1350 - acc: 0.9482 - val_loss: 0.3049 - val_acc: 0.9115\n",
      "Epoch 251/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9499\n",
      "Epoch 251: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1335 - acc: 0.9502 - val_loss: 0.3484 - val_acc: 0.9079\n",
      "Epoch 252/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9426\n",
      "Epoch 252: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1420 - acc: 0.9428 - val_loss: 0.3435 - val_acc: 0.9050\n",
      "Epoch 253/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9437\n",
      "Epoch 253: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1411 - acc: 0.9437 - val_loss: 0.3315 - val_acc: 0.9087\n",
      "Epoch 254/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9448\n",
      "Epoch 254: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1402 - acc: 0.9450 - val_loss: 0.3340 - val_acc: 0.9079\n",
      "Epoch 255/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1523 - acc: 0.9446\n",
      "Epoch 255: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1514 - acc: 0.9446 - val_loss: 0.3416 - val_acc: 0.9119\n",
      "Epoch 256/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9451\n",
      "Epoch 256: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1456 - acc: 0.9451 - val_loss: 0.3409 - val_acc: 0.9079\n",
      "Epoch 257/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1418 - acc: 0.9458\n",
      "Epoch 257: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1410 - acc: 0.9463 - val_loss: 0.3464 - val_acc: 0.9030\n",
      "Epoch 258/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9427\n",
      "Epoch 258: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1410 - acc: 0.9431 - val_loss: 0.3248 - val_acc: 0.9168\n",
      "Epoch 259/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9461\n",
      "Epoch 259: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1366 - acc: 0.9467 - val_loss: 0.3203 - val_acc: 0.9160\n",
      "Epoch 260/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1346 - acc: 0.9465\n",
      "Epoch 260: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1337 - acc: 0.9467 - val_loss: 0.3385 - val_acc: 0.9058\n",
      "Epoch 261/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9480\n",
      "Epoch 261: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1304 - acc: 0.9482 - val_loss: 0.3573 - val_acc: 0.9014\n",
      "Epoch 262/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9466\n",
      "Epoch 262: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1392 - acc: 0.9467 - val_loss: 0.3500 - val_acc: 0.9010\n",
      "Epoch 263/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9503\n",
      "Epoch 263: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1304 - acc: 0.9504 - val_loss: 0.3232 - val_acc: 0.9131\n",
      "Epoch 264/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9470\n",
      "Epoch 264: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1326 - acc: 0.9473 - val_loss: 0.3510 - val_acc: 0.9140\n",
      "Epoch 265/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9458\n",
      "Epoch 265: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1365 - acc: 0.9461 - val_loss: 0.3291 - val_acc: 0.9067\n",
      "Epoch 266/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9464\n",
      "Epoch 266: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1339 - acc: 0.9468 - val_loss: 0.3765 - val_acc: 0.9091\n",
      "Epoch 267/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1429 - acc: 0.9448\n",
      "Epoch 267: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1424 - acc: 0.9450 - val_loss: 0.3022 - val_acc: 0.9168\n",
      "Epoch 268/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9488\n",
      "Epoch 268: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1246 - acc: 0.9494 - val_loss: 0.3422 - val_acc: 0.9184\n",
      "Epoch 269/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9471\n",
      "Epoch 269: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1380 - acc: 0.9475 - val_loss: 0.3200 - val_acc: 0.9079\n",
      "Epoch 270/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9505\n",
      "Epoch 270: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1224 - acc: 0.9507 - val_loss: 0.3505 - val_acc: 0.9103\n",
      "Epoch 271/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9479\n",
      "Epoch 271: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1322 - acc: 0.9486 - val_loss: 0.3173 - val_acc: 0.9062\n",
      "Epoch 272/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9477\n",
      "Epoch 272: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1356 - acc: 0.9475 - val_loss: 0.3157 - val_acc: 0.9079\n",
      "Epoch 273/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9500\n",
      "Epoch 273: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1352 - acc: 0.9502 - val_loss: 0.3140 - val_acc: 0.9160\n",
      "Epoch 274/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9479\n",
      "Epoch 274: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1313 - acc: 0.9480 - val_loss: 0.3103 - val_acc: 0.9144\n",
      "Epoch 275/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9472\n",
      "Epoch 275: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1264 - acc: 0.9472 - val_loss: 0.3482 - val_acc: 0.9107\n",
      "Epoch 276/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9489\n",
      "Epoch 276: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1326 - acc: 0.9491 - val_loss: 0.3246 - val_acc: 0.9144\n",
      "Epoch 277/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9438\n",
      "Epoch 277: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1485 - acc: 0.9440 - val_loss: 0.3080 - val_acc: 0.9071\n",
      "Epoch 278/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9497\n",
      "Epoch 278: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1334 - acc: 0.9498 - val_loss: 0.3080 - val_acc: 0.9152\n",
      "Epoch 279/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9463\n",
      "Epoch 279: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1329 - acc: 0.9467 - val_loss: 0.3703 - val_acc: 0.9075\n",
      "Epoch 280/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9482\n",
      "Epoch 280: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1244 - acc: 0.9482 - val_loss: 0.3648 - val_acc: 0.9156\n",
      "Epoch 281/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9448\n",
      "Epoch 281: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1341 - acc: 0.9454 - val_loss: 0.3555 - val_acc: 0.9071\n",
      "Epoch 282/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9480\n",
      "Epoch 282: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1315 - acc: 0.9485 - val_loss: 0.3579 - val_acc: 0.9164\n",
      "Epoch 283/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1247 - acc: 0.9517\n",
      "Epoch 283: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1234 - acc: 0.9522 - val_loss: 0.3758 - val_acc: 0.9127\n",
      "Epoch 284/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9473\n",
      "Epoch 284: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1387 - acc: 0.9477 - val_loss: 0.3098 - val_acc: 0.9164\n",
      "Epoch 285/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9495\n",
      "Epoch 285: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1343 - acc: 0.9497 - val_loss: 0.3253 - val_acc: 0.9148\n",
      "Epoch 286/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9498\n",
      "Epoch 286: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1226 - acc: 0.9497 - val_loss: 0.3554 - val_acc: 0.9148\n",
      "Epoch 287/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9497\n",
      "Epoch 287: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1302 - acc: 0.9500 - val_loss: 0.3209 - val_acc: 0.9148\n",
      "Epoch 288/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1382 - acc: 0.9446\n",
      "Epoch 288: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1375 - acc: 0.9451 - val_loss: 0.3905 - val_acc: 0.9111\n",
      "Epoch 289/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9485\n",
      "Epoch 289: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1337 - acc: 0.9487 - val_loss: 0.3400 - val_acc: 0.9176\n",
      "Epoch 290/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9479\n",
      "Epoch 290: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1318 - acc: 0.9482 - val_loss: 0.3879 - val_acc: 0.9103\n",
      "Epoch 291/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9473\n",
      "Epoch 291: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1350 - acc: 0.9474 - val_loss: 0.3496 - val_acc: 0.9079\n",
      "Epoch 292/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9459\n",
      "Epoch 292: val_acc did not improve from 0.92005\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1368 - acc: 0.9461 - val_loss: 0.3322 - val_acc: 0.9180\n",
      "Epoch 293/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9476\n",
      "Epoch 293: val_acc improved from 0.92005 to 0.92248, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1331 - acc: 0.9478 - val_loss: 0.3489 - val_acc: 0.9225\n",
      "Epoch 294/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9488\n",
      "Epoch 294: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1261 - acc: 0.9493 - val_loss: 0.3552 - val_acc: 0.9180\n",
      "Epoch 295/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9506\n",
      "Epoch 295: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1257 - acc: 0.9510 - val_loss: 0.3863 - val_acc: 0.9127\n",
      "Epoch 296/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1353 - acc: 0.9484\n",
      "Epoch 296: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1343 - acc: 0.9486 - val_loss: 0.3512 - val_acc: 0.9148\n",
      "Epoch 297/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9481\n",
      "Epoch 297: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1421 - acc: 0.9486 - val_loss: 0.3962 - val_acc: 0.9119\n",
      "Epoch 298/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9515\n",
      "Epoch 298: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1337 - acc: 0.9515 - val_loss: 0.4073 - val_acc: 0.9127\n",
      "Epoch 299/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9507\n",
      "Epoch 299: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1394 - acc: 0.9506 - val_loss: 0.3823 - val_acc: 0.9176\n",
      "Epoch 300/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9490\n",
      "Epoch 300: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1259 - acc: 0.9493 - val_loss: 0.3560 - val_acc: 0.9196\n",
      "Epoch 301/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1220 - acc: 0.9517\n",
      "Epoch 301: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1220 - acc: 0.9517 - val_loss: 0.3985 - val_acc: 0.9156\n",
      "Epoch 302/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9495\n",
      "Epoch 302: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1206 - acc: 0.9500 - val_loss: 0.3751 - val_acc: 0.9172\n",
      "Epoch 303/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9502\n",
      "Epoch 303: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1278 - acc: 0.9507 - val_loss: 0.3588 - val_acc: 0.9152\n",
      "Epoch 304/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9473\n",
      "Epoch 304: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1349 - acc: 0.9479 - val_loss: 0.3404 - val_acc: 0.9099\n",
      "Epoch 305/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9472\n",
      "Epoch 305: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1466 - acc: 0.9473 - val_loss: 0.3309 - val_acc: 0.9115\n",
      "Epoch 306/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9484\n",
      "Epoch 306: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1261 - acc: 0.9486 - val_loss: 0.3328 - val_acc: 0.9156\n",
      "Epoch 307/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9549\n",
      "Epoch 307: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1257 - acc: 0.9549 - val_loss: 0.3550 - val_acc: 0.9188\n",
      "Epoch 308/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9513\n",
      "Epoch 308: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1234 - acc: 0.9513 - val_loss: 0.3697 - val_acc: 0.9176\n",
      "Epoch 309/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9453\n",
      "Epoch 309: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1424 - acc: 0.9455 - val_loss: 0.3656 - val_acc: 0.9099\n",
      "Epoch 310/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9494\n",
      "Epoch 310: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1269 - acc: 0.9494 - val_loss: 0.3620 - val_acc: 0.9164\n",
      "Epoch 311/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1282 - acc: 0.9489\n",
      "Epoch 311: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1262 - acc: 0.9499 - val_loss: 0.3641 - val_acc: 0.9136\n",
      "Epoch 312/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9504\n",
      "Epoch 312: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1210 - acc: 0.9507 - val_loss: 0.3699 - val_acc: 0.9140\n",
      "Epoch 313/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9507\n",
      "Epoch 313: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1273 - acc: 0.9509 - val_loss: 0.3394 - val_acc: 0.9164\n",
      "Epoch 314/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9530\n",
      "Epoch 314: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1171 - acc: 0.9533 - val_loss: 0.3783 - val_acc: 0.9168\n",
      "Epoch 315/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9516\n",
      "Epoch 315: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1267 - acc: 0.9517 - val_loss: 0.3240 - val_acc: 0.9200\n",
      "Epoch 316/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9512\n",
      "Epoch 316: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1188 - acc: 0.9514 - val_loss: 0.3305 - val_acc: 0.9148\n",
      "Epoch 317/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9478\n",
      "Epoch 317: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1273 - acc: 0.9482 - val_loss: 0.3370 - val_acc: 0.9144\n",
      "Epoch 318/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9525\n",
      "Epoch 318: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1249 - acc: 0.9527 - val_loss: 0.4001 - val_acc: 0.9075\n",
      "Epoch 319/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9521\n",
      "Epoch 319: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1218 - acc: 0.9520 - val_loss: 0.3622 - val_acc: 0.9140\n",
      "Epoch 320/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9517\n",
      "Epoch 320: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1247 - acc: 0.9517 - val_loss: 0.3835 - val_acc: 0.9099\n",
      "Epoch 321/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9495\n",
      "Epoch 321: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1327 - acc: 0.9503 - val_loss: 0.3558 - val_acc: 0.9148\n",
      "Epoch 322/2000\n",
      "593/616 [===========================>..] - ETA: 0s - loss: 0.1194 - acc: 0.9515\n",
      "Epoch 322: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1187 - acc: 0.9519 - val_loss: 0.3768 - val_acc: 0.9079\n",
      "Epoch 323/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9516\n",
      "Epoch 323: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1255 - acc: 0.9515 - val_loss: 0.3313 - val_acc: 0.9156\n",
      "Epoch 324/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9531\n",
      "Epoch 324: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1248 - acc: 0.9534 - val_loss: 0.3618 - val_acc: 0.9152\n",
      "Epoch 325/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9542\n",
      "Epoch 325: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1234 - acc: 0.9540 - val_loss: 0.3941 - val_acc: 0.9083\n",
      "Epoch 326/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9532\n",
      "Epoch 326: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1375 - acc: 0.9534 - val_loss: 0.3792 - val_acc: 0.9099\n",
      "Epoch 327/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9517\n",
      "Epoch 327: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1209 - acc: 0.9522 - val_loss: 0.3642 - val_acc: 0.9156\n",
      "Epoch 328/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1230 - acc: 0.9538\n",
      "Epoch 328: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1215 - acc: 0.9542 - val_loss: 0.4161 - val_acc: 0.9107\n",
      "Epoch 329/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9483\n",
      "Epoch 329: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1299 - acc: 0.9488 - val_loss: 0.3745 - val_acc: 0.9164\n",
      "Epoch 330/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9527\n",
      "Epoch 330: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1270 - acc: 0.9534 - val_loss: 0.3494 - val_acc: 0.9168\n",
      "Epoch 331/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9480\n",
      "Epoch 331: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1330 - acc: 0.9487 - val_loss: 0.3497 - val_acc: 0.9172\n",
      "Epoch 332/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9526\n",
      "Epoch 332: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1228 - acc: 0.9529 - val_loss: 0.3467 - val_acc: 0.9152\n",
      "Epoch 333/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9523\n",
      "Epoch 333: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1214 - acc: 0.9523 - val_loss: 0.3794 - val_acc: 0.9188\n",
      "Epoch 334/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9529\n",
      "Epoch 334: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1312 - acc: 0.9530 - val_loss: 0.3370 - val_acc: 0.9168\n",
      "Epoch 335/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9515\n",
      "Epoch 335: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1202 - acc: 0.9516 - val_loss: 0.3796 - val_acc: 0.9119\n",
      "Epoch 336/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9513\n",
      "Epoch 336: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1204 - acc: 0.9518 - val_loss: 0.3703 - val_acc: 0.9144\n",
      "Epoch 337/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9514\n",
      "Epoch 337: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1200 - acc: 0.9517 - val_loss: 0.3778 - val_acc: 0.9144\n",
      "Epoch 338/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9513\n",
      "Epoch 338: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1192 - acc: 0.9521 - val_loss: 0.3639 - val_acc: 0.9136\n",
      "Epoch 339/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1331 - acc: 0.9537\n",
      "Epoch 339: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1318 - acc: 0.9545 - val_loss: 0.3757 - val_acc: 0.9152\n",
      "Epoch 340/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9544\n",
      "Epoch 340: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1141 - acc: 0.9545 - val_loss: 0.3891 - val_acc: 0.9148\n",
      "Epoch 341/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9519\n",
      "Epoch 341: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1260 - acc: 0.9520 - val_loss: 0.4236 - val_acc: 0.9058\n",
      "Epoch 342/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9512\n",
      "Epoch 342: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1215 - acc: 0.9515 - val_loss: 0.3944 - val_acc: 0.9144\n",
      "Epoch 343/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9541\n",
      "Epoch 343: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1148 - acc: 0.9545 - val_loss: 0.3885 - val_acc: 0.9111\n",
      "Epoch 344/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9476\n",
      "Epoch 344: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1432 - acc: 0.9477 - val_loss: 0.3884 - val_acc: 0.9111\n",
      "Epoch 345/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9536\n",
      "Epoch 345: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1191 - acc: 0.9538 - val_loss: 0.3861 - val_acc: 0.9127\n",
      "Epoch 346/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9549\n",
      "Epoch 346: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1128 - acc: 0.9550 - val_loss: 0.4465 - val_acc: 0.9067\n",
      "Epoch 347/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9542\n",
      "Epoch 347: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1164 - acc: 0.9545 - val_loss: 0.3940 - val_acc: 0.9188\n",
      "Epoch 348/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9506\n",
      "Epoch 348: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1279 - acc: 0.9506 - val_loss: 0.4224 - val_acc: 0.9095\n",
      "Epoch 349/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9547\n",
      "Epoch 349: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1229 - acc: 0.9548 - val_loss: 0.3796 - val_acc: 0.9164\n",
      "Epoch 350/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9506\n",
      "Epoch 350: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1178 - acc: 0.9511 - val_loss: 0.4175 - val_acc: 0.9180\n",
      "Epoch 351/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9549\n",
      "Epoch 351: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1306 - acc: 0.9550 - val_loss: 0.3444 - val_acc: 0.9144\n",
      "Epoch 352/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9523\n",
      "Epoch 352: val_acc improved from 0.92248 to 0.92330, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1196 - acc: 0.9530 - val_loss: 0.3720 - val_acc: 0.9233\n",
      "Epoch 353/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9538\n",
      "Epoch 353: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1235 - acc: 0.9540 - val_loss: 0.3930 - val_acc: 0.9127\n",
      "Epoch 354/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9529\n",
      "Epoch 354: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1229 - acc: 0.9529 - val_loss: 0.4057 - val_acc: 0.9107\n",
      "Epoch 355/2000\n",
      "591/616 [===========================>..] - ETA: 0s - loss: 0.1228 - acc: 0.9535\n",
      "Epoch 355: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1212 - acc: 0.9538 - val_loss: 0.3692 - val_acc: 0.9140\n",
      "Epoch 356/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9540\n",
      "Epoch 356: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1177 - acc: 0.9541 - val_loss: 0.3862 - val_acc: 0.9071\n",
      "Epoch 357/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9557\n",
      "Epoch 357: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1213 - acc: 0.9560 - val_loss: 0.4071 - val_acc: 0.9136\n",
      "Epoch 358/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9515\n",
      "Epoch 358: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1244 - acc: 0.9520 - val_loss: 0.3944 - val_acc: 0.9205\n",
      "Epoch 359/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9513\n",
      "Epoch 359: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1261 - acc: 0.9514 - val_loss: 0.3801 - val_acc: 0.9123\n",
      "Epoch 360/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9481\n",
      "Epoch 360: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1288 - acc: 0.9486 - val_loss: 0.3643 - val_acc: 0.9148\n",
      "Epoch 361/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9533\n",
      "Epoch 361: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1217 - acc: 0.9536 - val_loss: 0.4197 - val_acc: 0.9192\n",
      "Epoch 362/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9509\n",
      "Epoch 362: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1236 - acc: 0.9511 - val_loss: 0.3906 - val_acc: 0.9156\n",
      "Epoch 363/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9490\n",
      "Epoch 363: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1353 - acc: 0.9498 - val_loss: 0.3620 - val_acc: 0.9196\n",
      "Epoch 364/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9511\n",
      "Epoch 364: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1219 - acc: 0.9518 - val_loss: 0.3561 - val_acc: 0.9136\n",
      "Epoch 365/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1270 - acc: 0.9538\n",
      "Epoch 365: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1251 - acc: 0.9542 - val_loss: 0.3446 - val_acc: 0.9180\n",
      "Epoch 366/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9554\n",
      "Epoch 366: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1153 - acc: 0.9555 - val_loss: 0.4028 - val_acc: 0.9164\n",
      "Epoch 367/2000\n",
      "593/616 [===========================>..] - ETA: 0s - loss: 0.1293 - acc: 0.9524\n",
      "Epoch 367: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1274 - acc: 0.9530 - val_loss: 0.3882 - val_acc: 0.9168\n",
      "Epoch 368/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9571\n",
      "Epoch 368: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1070 - acc: 0.9572 - val_loss: 0.4470 - val_acc: 0.9091\n",
      "Epoch 369/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1065 - acc: 0.9567\n",
      "Epoch 369: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1059 - acc: 0.9571 - val_loss: 0.4069 - val_acc: 0.9156\n",
      "Epoch 370/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9529\n",
      "Epoch 370: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1238 - acc: 0.9529 - val_loss: 0.4255 - val_acc: 0.8994\n",
      "Epoch 371/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9551\n",
      "Epoch 371: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1168 - acc: 0.9556 - val_loss: 0.4081 - val_acc: 0.9205\n",
      "Epoch 372/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9522\n",
      "Epoch 372: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1259 - acc: 0.9523 - val_loss: 0.3938 - val_acc: 0.9131\n",
      "Epoch 373/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9523\n",
      "Epoch 373: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1266 - acc: 0.9525 - val_loss: 0.3545 - val_acc: 0.9127\n",
      "Epoch 374/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1164 - acc: 0.9541\n",
      "Epoch 374: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1148 - acc: 0.9546 - val_loss: 0.3977 - val_acc: 0.9164\n",
      "Epoch 375/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1268 - acc: 0.9551\n",
      "Epoch 375: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1255 - acc: 0.9554 - val_loss: 0.3919 - val_acc: 0.9168\n",
      "Epoch 376/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9565\n",
      "Epoch 376: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1154 - acc: 0.9567 - val_loss: 0.4053 - val_acc: 0.9164\n",
      "Epoch 377/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9541\n",
      "Epoch 377: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1217 - acc: 0.9540 - val_loss: 0.3947 - val_acc: 0.9180\n",
      "Epoch 378/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9542\n",
      "Epoch 378: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1286 - acc: 0.9547 - val_loss: 0.3904 - val_acc: 0.9123\n",
      "Epoch 379/2000\n",
      "593/616 [===========================>..] - ETA: 0s - loss: 0.1155 - acc: 0.9560\n",
      "Epoch 379: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1150 - acc: 0.9560 - val_loss: 0.4462 - val_acc: 0.9095\n",
      "Epoch 380/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9558\n",
      "Epoch 380: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1150 - acc: 0.9561 - val_loss: 0.4028 - val_acc: 0.9136\n",
      "Epoch 381/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9575\n",
      "Epoch 381: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1226 - acc: 0.9577 - val_loss: 0.4447 - val_acc: 0.9164\n",
      "Epoch 382/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9582\n",
      "Epoch 382: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1168 - acc: 0.9583 - val_loss: 0.4233 - val_acc: 0.9103\n",
      "Epoch 383/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9571\n",
      "Epoch 383: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1088 - acc: 0.9578 - val_loss: 0.4010 - val_acc: 0.9196\n",
      "Epoch 384/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9536\n",
      "Epoch 384: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1175 - acc: 0.9536 - val_loss: 0.3647 - val_acc: 0.9115\n",
      "Epoch 385/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9570\n",
      "Epoch 385: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1115 - acc: 0.9573 - val_loss: 0.4305 - val_acc: 0.9168\n",
      "Epoch 386/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9561\n",
      "Epoch 386: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1277 - acc: 0.9562 - val_loss: 0.4131 - val_acc: 0.9079\n",
      "Epoch 387/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9555\n",
      "Epoch 387: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1235 - acc: 0.9557 - val_loss: 0.3612 - val_acc: 0.9184\n",
      "Epoch 388/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9542\n",
      "Epoch 388: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1163 - acc: 0.9545 - val_loss: 0.4156 - val_acc: 0.9217\n",
      "Epoch 389/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9553\n",
      "Epoch 389: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1114 - acc: 0.9555 - val_loss: 0.4097 - val_acc: 0.9209\n",
      "Epoch 390/2000\n",
      "592/616 [===========================>..] - ETA: 0s - loss: 0.1270 - acc: 0.9540\n",
      "Epoch 390: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 1s 2ms/step - loss: 0.1268 - acc: 0.9536 - val_loss: 0.4305 - val_acc: 0.9115\n",
      "Epoch 391/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9528\n",
      "Epoch 391: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1215 - acc: 0.9531 - val_loss: 0.4180 - val_acc: 0.9172\n",
      "Epoch 392/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9571\n",
      "Epoch 392: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1108 - acc: 0.9571 - val_loss: 0.3978 - val_acc: 0.9160\n",
      "Epoch 393/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9523\n",
      "Epoch 393: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1183 - acc: 0.9524 - val_loss: 0.3871 - val_acc: 0.9176\n",
      "Epoch 394/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9552\n",
      "Epoch 394: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1299 - acc: 0.9553 - val_loss: 0.4035 - val_acc: 0.9176\n",
      "Epoch 395/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1164 - acc: 0.9555\n",
      "Epoch 395: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1164 - acc: 0.9555 - val_loss: 0.3933 - val_acc: 0.9140\n",
      "Epoch 396/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9513\n",
      "Epoch 396: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1186 - acc: 0.9514 - val_loss: 0.3835 - val_acc: 0.9131\n",
      "Epoch 397/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1171 - acc: 0.9522\n",
      "Epoch 397: val_acc did not improve from 0.92330\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1171 - acc: 0.9522 - val_loss: 0.4133 - val_acc: 0.9172\n",
      "Epoch 398/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9598\n",
      "Epoch 398: val_acc improved from 0.92330 to 0.92411, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1118 - acc: 0.9598 - val_loss: 0.3758 - val_acc: 0.9241\n",
      "Epoch 399/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9550\n",
      "Epoch 399: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1171 - acc: 0.9549 - val_loss: 0.4073 - val_acc: 0.9176\n",
      "Epoch 400/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1143 - acc: 0.9575\n",
      "Epoch 400: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1132 - acc: 0.9582 - val_loss: 0.4155 - val_acc: 0.9184\n",
      "Epoch 401/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9505\n",
      "Epoch 401: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1306 - acc: 0.9512 - val_loss: 0.3500 - val_acc: 0.9160\n",
      "Epoch 402/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9547\n",
      "Epoch 402: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 2ms/step - loss: 0.1136 - acc: 0.9546 - val_loss: 0.4203 - val_acc: 0.9131\n",
      "Epoch 403/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9560\n",
      "Epoch 403: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1149 - acc: 0.9565 - val_loss: 0.4087 - val_acc: 0.9099\n",
      "Epoch 404/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9566\n",
      "Epoch 404: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1074 - acc: 0.9570 - val_loss: 0.3999 - val_acc: 0.9180\n",
      "Epoch 405/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1239 - acc: 0.9533\n",
      "Epoch 405: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1227 - acc: 0.9537 - val_loss: 0.3672 - val_acc: 0.9176\n",
      "Epoch 406/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9543\n",
      "Epoch 406: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1132 - acc: 0.9546 - val_loss: 0.4066 - val_acc: 0.9087\n",
      "Epoch 407/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9569\n",
      "Epoch 407: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1217 - acc: 0.9570 - val_loss: 0.3958 - val_acc: 0.9136\n",
      "Epoch 408/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1313 - acc: 0.9543\n",
      "Epoch 408: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1291 - acc: 0.9551 - val_loss: 0.4237 - val_acc: 0.9160\n",
      "Epoch 409/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9552\n",
      "Epoch 409: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1113 - acc: 0.9559 - val_loss: 0.3867 - val_acc: 0.9213\n",
      "Epoch 410/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9545\n",
      "Epoch 410: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1122 - acc: 0.9544 - val_loss: 0.4047 - val_acc: 0.9160\n",
      "Epoch 411/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9560\n",
      "Epoch 411: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1054 - acc: 0.9564 - val_loss: 0.5090 - val_acc: 0.9034\n",
      "Epoch 412/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9555\n",
      "Epoch 412: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1262 - acc: 0.9558 - val_loss: 0.3839 - val_acc: 0.9176\n",
      "Epoch 413/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9549\n",
      "Epoch 413: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1137 - acc: 0.9549 - val_loss: 0.3874 - val_acc: 0.9237\n",
      "Epoch 414/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1204 - acc: 0.9531\n",
      "Epoch 414: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1186 - acc: 0.9538 - val_loss: 0.4160 - val_acc: 0.9225\n",
      "Epoch 415/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9529\n",
      "Epoch 415: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1275 - acc: 0.9530 - val_loss: 0.3928 - val_acc: 0.9127\n",
      "Epoch 416/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9563\n",
      "Epoch 416: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1112 - acc: 0.9566 - val_loss: 0.3917 - val_acc: 0.9176\n",
      "Epoch 417/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9557\n",
      "Epoch 417: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1208 - acc: 0.9562 - val_loss: 0.4472 - val_acc: 0.9119\n",
      "Epoch 418/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9557\n",
      "Epoch 418: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1335 - acc: 0.9558 - val_loss: 0.3564 - val_acc: 0.9196\n",
      "Epoch 419/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9597\n",
      "Epoch 419: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1020 - acc: 0.9597 - val_loss: 0.3709 - val_acc: 0.9103\n",
      "Epoch 420/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9558\n",
      "Epoch 420: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1152 - acc: 0.9558 - val_loss: 0.3336 - val_acc: 0.9168\n",
      "Epoch 421/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9590\n",
      "Epoch 421: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1120 - acc: 0.9590 - val_loss: 0.3571 - val_acc: 0.9172\n",
      "Epoch 422/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9535\n",
      "Epoch 422: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1330 - acc: 0.9537 - val_loss: 0.4091 - val_acc: 0.9131\n",
      "Epoch 423/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9522\n",
      "Epoch 423: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1301 - acc: 0.9524 - val_loss: 0.4297 - val_acc: 0.9042\n",
      "Epoch 424/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9548\n",
      "Epoch 424: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1249 - acc: 0.9548 - val_loss: 0.3800 - val_acc: 0.9200\n",
      "Epoch 425/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9561\n",
      "Epoch 425: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1184 - acc: 0.9565 - val_loss: 0.3984 - val_acc: 0.9156\n",
      "Epoch 426/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9546\n",
      "Epoch 426: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1240 - acc: 0.9548 - val_loss: 0.3466 - val_acc: 0.9136\n",
      "Epoch 427/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9552\n",
      "Epoch 427: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1258 - acc: 0.9549 - val_loss: 0.3669 - val_acc: 0.9172\n",
      "Epoch 428/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9557\n",
      "Epoch 428: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1132 - acc: 0.9562 - val_loss: 0.3842 - val_acc: 0.9042\n",
      "Epoch 429/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1120 - acc: 0.9564\n",
      "Epoch 429: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1102 - acc: 0.9570 - val_loss: 0.4371 - val_acc: 0.9152\n",
      "Epoch 430/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9559\n",
      "Epoch 430: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1152 - acc: 0.9563 - val_loss: 0.3985 - val_acc: 0.9140\n",
      "Epoch 431/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9554\n",
      "Epoch 431: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1213 - acc: 0.9560 - val_loss: 0.4303 - val_acc: 0.9156\n",
      "Epoch 432/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9549\n",
      "Epoch 432: val_acc improved from 0.92411 to 0.92532, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1244 - acc: 0.9554 - val_loss: 0.3785 - val_acc: 0.9253\n",
      "Epoch 433/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9571\n",
      "Epoch 433: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1211 - acc: 0.9575 - val_loss: 0.4095 - val_acc: 0.9140\n",
      "Epoch 434/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9542\n",
      "Epoch 434: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1146 - acc: 0.9541 - val_loss: 0.3902 - val_acc: 0.9200\n",
      "Epoch 435/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1118 - acc: 0.9566\n",
      "Epoch 435: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1118 - acc: 0.9566 - val_loss: 0.4171 - val_acc: 0.9217\n",
      "Epoch 436/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9556\n",
      "Epoch 436: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1064 - acc: 0.9556 - val_loss: 0.3941 - val_acc: 0.9148\n",
      "Epoch 437/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9585\n",
      "Epoch 437: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1058 - acc: 0.9589 - val_loss: 0.4169 - val_acc: 0.9213\n",
      "Epoch 438/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1210 - acc: 0.9554\n",
      "Epoch 438: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1210 - acc: 0.9554 - val_loss: 0.3664 - val_acc: 0.9225\n",
      "Epoch 439/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9578\n",
      "Epoch 439: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1079 - acc: 0.9580 - val_loss: 0.4034 - val_acc: 0.9160\n",
      "Epoch 440/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9559\n",
      "Epoch 440: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1180 - acc: 0.9563 - val_loss: 0.3747 - val_acc: 0.9152\n",
      "Epoch 441/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9571\n",
      "Epoch 441: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1386 - acc: 0.9573 - val_loss: 0.4089 - val_acc: 0.9176\n",
      "Epoch 442/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9562\n",
      "Epoch 442: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1101 - acc: 0.9564 - val_loss: 0.3618 - val_acc: 0.9200\n",
      "Epoch 443/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9557\n",
      "Epoch 443: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1189 - acc: 0.9561 - val_loss: 0.4386 - val_acc: 0.9119\n",
      "Epoch 444/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9570\n",
      "Epoch 444: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1138 - acc: 0.9573 - val_loss: 0.3826 - val_acc: 0.9205\n",
      "Epoch 445/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9603\n",
      "Epoch 445: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1118 - acc: 0.9600 - val_loss: 0.3950 - val_acc: 0.9156\n",
      "Epoch 446/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9535\n",
      "Epoch 446: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1300 - acc: 0.9537 - val_loss: 0.4362 - val_acc: 0.9172\n",
      "Epoch 447/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9575\n",
      "Epoch 447: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1152 - acc: 0.9576 - val_loss: 0.4269 - val_acc: 0.9160\n",
      "Epoch 448/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9579\n",
      "Epoch 448: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1125 - acc: 0.9581 - val_loss: 0.4414 - val_acc: 0.9217\n",
      "Epoch 449/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9550\n",
      "Epoch 449: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1184 - acc: 0.9550 - val_loss: 0.4774 - val_acc: 0.9156\n",
      "Epoch 450/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1135 - acc: 0.9570\n",
      "Epoch 450: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1115 - acc: 0.9577 - val_loss: 0.4026 - val_acc: 0.9217\n",
      "Epoch 451/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9542\n",
      "Epoch 451: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1110 - acc: 0.9541 - val_loss: 0.4058 - val_acc: 0.9160\n",
      "Epoch 452/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9598\n",
      "Epoch 452: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1044 - acc: 0.9602 - val_loss: 0.3868 - val_acc: 0.9205\n",
      "Epoch 453/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9599\n",
      "Epoch 453: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1011 - acc: 0.9602 - val_loss: 0.4135 - val_acc: 0.9221\n",
      "Epoch 454/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9582\n",
      "Epoch 454: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1120 - acc: 0.9583 - val_loss: 0.3545 - val_acc: 0.9176\n",
      "Epoch 455/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1065 - acc: 0.9600\n",
      "Epoch 455: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1065 - acc: 0.9600 - val_loss: 0.4262 - val_acc: 0.9205\n",
      "Epoch 456/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9604\n",
      "Epoch 456: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1071 - acc: 0.9606 - val_loss: 0.4321 - val_acc: 0.9172\n",
      "Epoch 457/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9555\n",
      "Epoch 457: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1129 - acc: 0.9556 - val_loss: 0.4091 - val_acc: 0.9164\n",
      "Epoch 458/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9562\n",
      "Epoch 458: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1058 - acc: 0.9569 - val_loss: 0.4092 - val_acc: 0.9160\n",
      "Epoch 459/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9567\n",
      "Epoch 459: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1129 - acc: 0.9570 - val_loss: 0.3807 - val_acc: 0.9168\n",
      "Epoch 460/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9587\n",
      "Epoch 460: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1085 - acc: 0.9589 - val_loss: 0.4420 - val_acc: 0.9115\n",
      "Epoch 461/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9581\n",
      "Epoch 461: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1149 - acc: 0.9585 - val_loss: 0.3971 - val_acc: 0.9217\n",
      "Epoch 462/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9561\n",
      "Epoch 462: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1123 - acc: 0.9563 - val_loss: 0.4006 - val_acc: 0.9237\n",
      "Epoch 463/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9548\n",
      "Epoch 463: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1267 - acc: 0.9553 - val_loss: 0.3744 - val_acc: 0.9209\n",
      "Epoch 464/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9535\n",
      "Epoch 464: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1246 - acc: 0.9535 - val_loss: 0.4206 - val_acc: 0.9136\n",
      "Epoch 465/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9579\n",
      "Epoch 465: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1198 - acc: 0.9580 - val_loss: 0.4218 - val_acc: 0.9156\n",
      "Epoch 466/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9583\n",
      "Epoch 466: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1078 - acc: 0.9588 - val_loss: 0.4340 - val_acc: 0.9160\n",
      "Epoch 467/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9602\n",
      "Epoch 467: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1131 - acc: 0.9607 - val_loss: 0.3981 - val_acc: 0.9136\n",
      "Epoch 468/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9602\n",
      "Epoch 468: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1070 - acc: 0.9605 - val_loss: 0.4199 - val_acc: 0.9217\n",
      "Epoch 469/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9599\n",
      "Epoch 469: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1028 - acc: 0.9605 - val_loss: 0.4021 - val_acc: 0.9192\n",
      "Epoch 470/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9581\n",
      "Epoch 470: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1202 - acc: 0.9584 - val_loss: 0.4765 - val_acc: 0.9168\n",
      "Epoch 471/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9565\n",
      "Epoch 471: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1128 - acc: 0.9567 - val_loss: 0.4470 - val_acc: 0.9176\n",
      "Epoch 472/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1084 - acc: 0.9606\n",
      "Epoch 472: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1084 - acc: 0.9606 - val_loss: 0.4144 - val_acc: 0.9188\n",
      "Epoch 473/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9583\n",
      "Epoch 473: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1086 - acc: 0.9589 - val_loss: 0.3962 - val_acc: 0.9233\n",
      "Epoch 474/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9583\n",
      "Epoch 474: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1140 - acc: 0.9583 - val_loss: 0.4122 - val_acc: 0.9188\n",
      "Epoch 475/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9585\n",
      "Epoch 475: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1086 - acc: 0.9588 - val_loss: 0.4273 - val_acc: 0.9180\n",
      "Epoch 476/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9598\n",
      "Epoch 476: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1140 - acc: 0.9601 - val_loss: 0.4531 - val_acc: 0.9168\n",
      "Epoch 477/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9589\n",
      "Epoch 477: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1020 - acc: 0.9592 - val_loss: 0.4286 - val_acc: 0.9213\n",
      "Epoch 478/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9571\n",
      "Epoch 478: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1147 - acc: 0.9574 - val_loss: 0.4397 - val_acc: 0.9176\n",
      "Epoch 479/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1180 - acc: 0.9603\n",
      "Epoch 479: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1180 - acc: 0.9603 - val_loss: 0.4654 - val_acc: 0.9180\n",
      "Epoch 480/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9586\n",
      "Epoch 480: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1212 - acc: 0.9589 - val_loss: 0.4362 - val_acc: 0.9164\n",
      "Epoch 481/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9562\n",
      "Epoch 481: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1098 - acc: 0.9567 - val_loss: 0.4500 - val_acc: 0.9237\n",
      "Epoch 482/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9613\n",
      "Epoch 482: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1039 - acc: 0.9614 - val_loss: 0.4743 - val_acc: 0.9200\n",
      "Epoch 483/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9584\n",
      "Epoch 483: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1112 - acc: 0.9587 - val_loss: 0.3960 - val_acc: 0.9160\n",
      "Epoch 484/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9589\n",
      "Epoch 484: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1064 - acc: 0.9592 - val_loss: 0.4112 - val_acc: 0.9188\n",
      "Epoch 485/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9616\n",
      "Epoch 485: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1025 - acc: 0.9617 - val_loss: 0.4357 - val_acc: 0.9225\n",
      "Epoch 486/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9622\n",
      "Epoch 486: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1060 - acc: 0.9620 - val_loss: 0.4621 - val_acc: 0.9156\n",
      "Epoch 487/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9583\n",
      "Epoch 487: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1096 - acc: 0.9586 - val_loss: 0.4468 - val_acc: 0.9209\n",
      "Epoch 488/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9587\n",
      "Epoch 488: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1105 - acc: 0.9588 - val_loss: 0.4298 - val_acc: 0.9209\n",
      "Epoch 489/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1160 - acc: 0.9576\n",
      "Epoch 489: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1160 - acc: 0.9576 - val_loss: 0.4068 - val_acc: 0.9131\n",
      "Epoch 490/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9612\n",
      "Epoch 490: val_acc improved from 0.92532 to 0.92776, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1210 - acc: 0.9616 - val_loss: 0.4552 - val_acc: 0.9278\n",
      "Epoch 491/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9615\n",
      "Epoch 491: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1095 - acc: 0.9617 - val_loss: 0.4115 - val_acc: 0.9213\n",
      "Epoch 492/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9602\n",
      "Epoch 492: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1076 - acc: 0.9600 - val_loss: 0.4207 - val_acc: 0.9168\n",
      "Epoch 493/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9566\n",
      "Epoch 493: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1122 - acc: 0.9569 - val_loss: 0.4667 - val_acc: 0.9221\n",
      "Epoch 494/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9592\n",
      "Epoch 494: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1048 - acc: 0.9596 - val_loss: 0.5247 - val_acc: 0.9176\n",
      "Epoch 495/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9600\n",
      "Epoch 495: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1021 - acc: 0.9600 - val_loss: 0.4795 - val_acc: 0.9225\n",
      "Epoch 496/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9557\n",
      "Epoch 496: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1263 - acc: 0.9559 - val_loss: 0.3907 - val_acc: 0.9265\n",
      "Epoch 497/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1030 - acc: 0.9572\n",
      "Epoch 497: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1030 - acc: 0.9572 - val_loss: 0.4851 - val_acc: 0.9229\n",
      "Epoch 498/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9596\n",
      "Epoch 498: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1027 - acc: 0.9598 - val_loss: 0.4628 - val_acc: 0.9221\n",
      "Epoch 499/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9577\n",
      "Epoch 499: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1043 - acc: 0.9577 - val_loss: 0.4311 - val_acc: 0.9168\n",
      "Epoch 500/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9569\n",
      "Epoch 500: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1158 - acc: 0.9570 - val_loss: 0.4723 - val_acc: 0.9209\n",
      "Epoch 501/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9588\n",
      "Epoch 501: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1080 - acc: 0.9593 - val_loss: 0.4547 - val_acc: 0.9209\n",
      "Epoch 502/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9609\n",
      "Epoch 502: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1084 - acc: 0.9610 - val_loss: 0.4664 - val_acc: 0.9176\n",
      "Epoch 503/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9601\n",
      "Epoch 503: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1069 - acc: 0.9602 - val_loss: 0.4820 - val_acc: 0.9160\n",
      "Epoch 504/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9628\n",
      "Epoch 504: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0946 - acc: 0.9632 - val_loss: 0.5031 - val_acc: 0.9144\n",
      "Epoch 505/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9586\n",
      "Epoch 505: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1079 - acc: 0.9589 - val_loss: 0.4488 - val_acc: 0.9144\n",
      "Epoch 506/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1034 - acc: 0.9600\n",
      "Epoch 506: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1034 - acc: 0.9600 - val_loss: 0.4900 - val_acc: 0.9213\n",
      "Epoch 507/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9608\n",
      "Epoch 507: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1199 - acc: 0.9609 - val_loss: 0.4250 - val_acc: 0.9269\n",
      "Epoch 508/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9595\n",
      "Epoch 508: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1174 - acc: 0.9598 - val_loss: 0.4680 - val_acc: 0.9196\n",
      "Epoch 509/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9590\n",
      "Epoch 509: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1031 - acc: 0.9598 - val_loss: 0.4678 - val_acc: 0.9176\n",
      "Epoch 510/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9630\n",
      "Epoch 510: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0992 - acc: 0.9635 - val_loss: 0.4845 - val_acc: 0.9192\n",
      "Epoch 511/2000\n",
      "593/616 [===========================>..] - ETA: 0s - loss: 0.1035 - acc: 0.9605\n",
      "Epoch 511: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1033 - acc: 0.9605 - val_loss: 0.5034 - val_acc: 0.9123\n",
      "Epoch 512/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9617\n",
      "Epoch 512: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0951 - acc: 0.9622 - val_loss: 0.5407 - val_acc: 0.9136\n",
      "Epoch 513/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9575\n",
      "Epoch 513: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1075 - acc: 0.9578 - val_loss: 0.4710 - val_acc: 0.9205\n",
      "Epoch 514/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9629\n",
      "Epoch 514: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1016 - acc: 0.9628 - val_loss: 0.4655 - val_acc: 0.9221\n",
      "Epoch 515/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9616\n",
      "Epoch 515: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1045 - acc: 0.9617 - val_loss: 0.4803 - val_acc: 0.9176\n",
      "Epoch 516/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1153 - acc: 0.9618\n",
      "Epoch 516: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1145 - acc: 0.9618 - val_loss: 0.4732 - val_acc: 0.9083\n",
      "Epoch 517/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9612\n",
      "Epoch 517: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1142 - acc: 0.9614 - val_loss: 0.4725 - val_acc: 0.9188\n",
      "Epoch 518/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9592\n",
      "Epoch 518: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1045 - acc: 0.9594 - val_loss: 0.4887 - val_acc: 0.9229\n",
      "Epoch 519/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9580\n",
      "Epoch 519: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1108 - acc: 0.9580 - val_loss: 0.4428 - val_acc: 0.9237\n",
      "Epoch 520/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9622\n",
      "Epoch 520: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1195 - acc: 0.9620 - val_loss: 0.4329 - val_acc: 0.9200\n",
      "Epoch 521/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1188 - acc: 0.9594\n",
      "Epoch 521: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1176 - acc: 0.9600 - val_loss: 0.4914 - val_acc: 0.9180\n",
      "Epoch 522/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9630\n",
      "Epoch 522: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1128 - acc: 0.9633 - val_loss: 0.4183 - val_acc: 0.9249\n",
      "Epoch 523/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9629\n",
      "Epoch 523: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1033 - acc: 0.9632 - val_loss: 0.4260 - val_acc: 0.9261\n",
      "Epoch 524/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9594\n",
      "Epoch 524: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1099 - acc: 0.9595 - val_loss: 0.4324 - val_acc: 0.9241\n",
      "Epoch 525/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9622\n",
      "Epoch 525: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1044 - acc: 0.9622 - val_loss: 0.4602 - val_acc: 0.9209\n",
      "Epoch 526/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9595\n",
      "Epoch 526: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1081 - acc: 0.9595 - val_loss: 0.4301 - val_acc: 0.9217\n",
      "Epoch 527/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9625\n",
      "Epoch 527: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1019 - acc: 0.9629 - val_loss: 0.4356 - val_acc: 0.9233\n",
      "Epoch 528/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9647\n",
      "Epoch 528: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0987 - acc: 0.9649 - val_loss: 0.4558 - val_acc: 0.9217\n",
      "Epoch 529/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9611\n",
      "Epoch 529: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1097 - acc: 0.9612 - val_loss: 0.4302 - val_acc: 0.9209\n",
      "Epoch 530/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9581\n",
      "Epoch 530: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1120 - acc: 0.9582 - val_loss: 0.4227 - val_acc: 0.9200\n",
      "Epoch 531/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9585\n",
      "Epoch 531: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1042 - acc: 0.9591 - val_loss: 0.4749 - val_acc: 0.9209\n",
      "Epoch 532/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9611\n",
      "Epoch 532: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1093 - acc: 0.9615 - val_loss: 0.4203 - val_acc: 0.9184\n",
      "Epoch 533/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9585\n",
      "Epoch 533: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1130 - acc: 0.9588 - val_loss: 0.4395 - val_acc: 0.9225\n",
      "Epoch 534/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9607\n",
      "Epoch 534: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0958 - acc: 0.9606 - val_loss: 0.4453 - val_acc: 0.9148\n",
      "Epoch 535/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9639\n",
      "Epoch 535: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0941 - acc: 0.9642 - val_loss: 0.4362 - val_acc: 0.9217\n",
      "Epoch 536/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1014 - acc: 0.9611\n",
      "Epoch 536: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1013 - acc: 0.9610 - val_loss: 0.4920 - val_acc: 0.9095\n",
      "Epoch 537/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9601\n",
      "Epoch 537: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1032 - acc: 0.9601 - val_loss: 0.5168 - val_acc: 0.9140\n",
      "Epoch 538/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9607\n",
      "Epoch 538: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1166 - acc: 0.9609 - val_loss: 0.4824 - val_acc: 0.9176\n",
      "Epoch 539/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9610\n",
      "Epoch 539: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1029 - acc: 0.9612 - val_loss: 0.4862 - val_acc: 0.9172\n",
      "Epoch 540/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9635\n",
      "Epoch 540: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0934 - acc: 0.9639 - val_loss: 0.4626 - val_acc: 0.9261\n",
      "Epoch 541/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9608\n",
      "Epoch 541: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1110 - acc: 0.9610 - val_loss: 0.4825 - val_acc: 0.9225\n",
      "Epoch 542/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1157 - acc: 0.9602\n",
      "Epoch 542: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1139 - acc: 0.9607 - val_loss: 0.4727 - val_acc: 0.9188\n",
      "Epoch 543/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9610\n",
      "Epoch 543: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1110 - acc: 0.9610 - val_loss: 0.4443 - val_acc: 0.9229\n",
      "Epoch 544/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9606\n",
      "Epoch 544: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1085 - acc: 0.9609 - val_loss: 0.4611 - val_acc: 0.9274\n",
      "Epoch 545/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9591\n",
      "Epoch 545: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1091 - acc: 0.9594 - val_loss: 0.4960 - val_acc: 0.9213\n",
      "Epoch 546/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9606\n",
      "Epoch 546: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1077 - acc: 0.9608 - val_loss: 0.4858 - val_acc: 0.9261\n",
      "Epoch 547/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1068 - acc: 0.9598\n",
      "Epoch 547: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1068 - acc: 0.9598 - val_loss: 0.4478 - val_acc: 0.9265\n",
      "Epoch 548/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1139 - acc: 0.9591\n",
      "Epoch 548: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1120 - acc: 0.9598 - val_loss: 0.5088 - val_acc: 0.9168\n",
      "Epoch 549/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9594\n",
      "Epoch 549: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1033 - acc: 0.9596 - val_loss: 0.4879 - val_acc: 0.9205\n",
      "Epoch 550/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9645\n",
      "Epoch 550: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0961 - acc: 0.9646 - val_loss: 0.5163 - val_acc: 0.9249\n",
      "Epoch 551/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9618\n",
      "Epoch 551: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1060 - acc: 0.9622 - val_loss: 0.4638 - val_acc: 0.9253\n",
      "Epoch 552/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9587\n",
      "Epoch 552: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1070 - acc: 0.9588 - val_loss: 0.5078 - val_acc: 0.9200\n",
      "Epoch 553/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9598\n",
      "Epoch 553: val_acc did not improve from 0.92776\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1099 - acc: 0.9598 - val_loss: 0.4922 - val_acc: 0.9265\n",
      "Epoch 554/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9610\n",
      "Epoch 554: val_acc improved from 0.92776 to 0.92857, saving model to train_logs/logs7/FFT_ANN\\1\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1039 - acc: 0.9610 - val_loss: 0.4826 - val_acc: 0.9286\n",
      "Epoch 555/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1160 - acc: 0.9593\n",
      "Epoch 555: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1160 - acc: 0.9593 - val_loss: 0.4715 - val_acc: 0.9213\n",
      "Epoch 556/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9597\n",
      "Epoch 556: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1175 - acc: 0.9599 - val_loss: 0.4700 - val_acc: 0.9180\n",
      "Epoch 557/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9630\n",
      "Epoch 557: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1003 - acc: 0.9634 - val_loss: 0.4937 - val_acc: 0.9205\n",
      "Epoch 558/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9605\n",
      "Epoch 558: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1065 - acc: 0.9607 - val_loss: 0.4691 - val_acc: 0.9209\n",
      "Epoch 559/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9590\n",
      "Epoch 559: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1037 - acc: 0.9594 - val_loss: 0.5101 - val_acc: 0.9176\n",
      "Epoch 560/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9585\n",
      "Epoch 560: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1092 - acc: 0.9590 - val_loss: 0.4838 - val_acc: 0.9184\n",
      "Epoch 561/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9590\n",
      "Epoch 561: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1034 - acc: 0.9596 - val_loss: 0.5031 - val_acc: 0.9205\n",
      "Epoch 562/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1068 - acc: 0.9587\n",
      "Epoch 562: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1068 - acc: 0.9587 - val_loss: 0.4763 - val_acc: 0.9168\n",
      "Epoch 563/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9615\n",
      "Epoch 563: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1004 - acc: 0.9615 - val_loss: 0.4659 - val_acc: 0.9257\n",
      "Epoch 564/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9611\n",
      "Epoch 564: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1026 - acc: 0.9612 - val_loss: 0.5282 - val_acc: 0.9184\n",
      "Epoch 565/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9647\n",
      "Epoch 565: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0913 - acc: 0.9648 - val_loss: 0.5232 - val_acc: 0.9225\n",
      "Epoch 566/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9612\n",
      "Epoch 566: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1066 - acc: 0.9614 - val_loss: 0.5543 - val_acc: 0.9184\n",
      "Epoch 567/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9629\n",
      "Epoch 567: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1046 - acc: 0.9631 - val_loss: 0.4333 - val_acc: 0.9164\n",
      "Epoch 568/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.0941 - acc: 0.9633\n",
      "Epoch 568: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0941 - acc: 0.9633 - val_loss: 0.5555 - val_acc: 0.9144\n",
      "Epoch 569/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9622\n",
      "Epoch 569: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0965 - acc: 0.9627 - val_loss: 0.5518 - val_acc: 0.9168\n",
      "Epoch 570/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9627\n",
      "Epoch 570: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1000 - acc: 0.9632 - val_loss: 0.4733 - val_acc: 0.9164\n",
      "Epoch 571/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9623\n",
      "Epoch 571: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1057 - acc: 0.9627 - val_loss: 0.4884 - val_acc: 0.9213\n",
      "Epoch 572/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9643\n",
      "Epoch 572: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1020 - acc: 0.9642 - val_loss: 0.4740 - val_acc: 0.9176\n",
      "Epoch 573/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9608\n",
      "Epoch 573: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1018 - acc: 0.9609 - val_loss: 0.4909 - val_acc: 0.9257\n",
      "Epoch 574/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9610\n",
      "Epoch 574: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1045 - acc: 0.9611 - val_loss: 0.4917 - val_acc: 0.9184\n",
      "Epoch 575/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9615\n",
      "Epoch 575: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1058 - acc: 0.9613 - val_loss: 0.4867 - val_acc: 0.9205\n",
      "Epoch 576/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9592\n",
      "Epoch 576: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1111 - acc: 0.9596 - val_loss: 0.5069 - val_acc: 0.9213\n",
      "Epoch 577/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9636\n",
      "Epoch 577: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1114 - acc: 0.9638 - val_loss: 0.5307 - val_acc: 0.9261\n",
      "Epoch 578/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9629\n",
      "Epoch 578: val_acc did not improve from 0.92857\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0939 - acc: 0.9633 - val_loss: 0.5080 - val_acc: 0.9221\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_1 (Reshape)         (None, 80, 1)             0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               41472     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,057\n",
      "Trainable params: 173,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.5825 - acc: 0.7222\n",
      "Epoch 1: val_acc improved from -inf to 0.78044, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.5823 - acc: 0.7221 - val_loss: 0.4413 - val_acc: 0.7804\n",
      "Epoch 2/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.4756 - acc: 0.7672\n",
      "Epoch 2: val_acc improved from 0.78044 to 0.79140, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4744 - acc: 0.7675 - val_loss: 0.4126 - val_acc: 0.7914\n",
      "Epoch 3/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.4388 - acc: 0.7794\n",
      "Epoch 3: val_acc improved from 0.79140 to 0.79992, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4373 - acc: 0.7803 - val_loss: 0.4005 - val_acc: 0.7999\n",
      "Epoch 4/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.4222 - acc: 0.7968\n",
      "Epoch 4: val_acc improved from 0.79992 to 0.80560, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4206 - acc: 0.7976 - val_loss: 0.3889 - val_acc: 0.8056\n",
      "Epoch 5/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.4091 - acc: 0.8006\n",
      "Epoch 5: val_acc improved from 0.80560 to 0.82183, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4091 - acc: 0.8006 - val_loss: 0.3699 - val_acc: 0.8218\n",
      "Epoch 6/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.4011 - acc: 0.8062\n",
      "Epoch 6: val_acc improved from 0.82183 to 0.82589, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3993 - acc: 0.8071 - val_loss: 0.3635 - val_acc: 0.8259\n",
      "Epoch 7/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.3901 - acc: 0.8155\n",
      "Epoch 7: val_acc improved from 0.82589 to 0.83685, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3883 - acc: 0.8169 - val_loss: 0.3519 - val_acc: 0.8369\n",
      "Epoch 8/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.3757 - acc: 0.8177\n",
      "Epoch 8: val_acc did not improve from 0.83685\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3731 - acc: 0.8190 - val_loss: 0.3599 - val_acc: 0.8320\n",
      "Epoch 9/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.3725 - acc: 0.8212\n",
      "Epoch 9: val_acc improved from 0.83685 to 0.84131, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3703 - acc: 0.8219 - val_loss: 0.3441 - val_acc: 0.8413\n",
      "Epoch 10/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.3600 - acc: 0.8276\n",
      "Epoch 10: val_acc improved from 0.84131 to 0.84172, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3573 - acc: 0.8287 - val_loss: 0.3457 - val_acc: 0.8417\n",
      "Epoch 11/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.3586 - acc: 0.8301\n",
      "Epoch 11: val_acc improved from 0.84172 to 0.84497, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3560 - acc: 0.8312 - val_loss: 0.3422 - val_acc: 0.8450\n",
      "Epoch 12/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.3501 - acc: 0.8354\n",
      "Epoch 12: val_acc improved from 0.84497 to 0.85308, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3485 - acc: 0.8361 - val_loss: 0.3286 - val_acc: 0.8531\n",
      "Epoch 13/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.3408 - acc: 0.8402\n",
      "Epoch 13: val_acc improved from 0.85308 to 0.85674, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3395 - acc: 0.8411 - val_loss: 0.3192 - val_acc: 0.8567\n",
      "Epoch 14/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.3360 - acc: 0.8466\n",
      "Epoch 14: val_acc did not improve from 0.85674\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3350 - acc: 0.8469 - val_loss: 0.3190 - val_acc: 0.8527\n",
      "Epoch 15/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.3291 - acc: 0.8454\n",
      "Epoch 15: val_acc improved from 0.85674 to 0.86039, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3287 - acc: 0.8455 - val_loss: 0.3174 - val_acc: 0.8604\n",
      "Epoch 16/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.3276 - acc: 0.8493\n",
      "Epoch 16: val_acc did not improve from 0.86039\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3274 - acc: 0.8493 - val_loss: 0.3100 - val_acc: 0.8600\n",
      "Epoch 17/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.3200 - acc: 0.8526\n",
      "Epoch 17: val_acc improved from 0.86039 to 0.86607, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3177 - acc: 0.8537 - val_loss: 0.3051 - val_acc: 0.8661\n",
      "Epoch 18/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.3183 - acc: 0.8537\n",
      "Epoch 18: val_acc did not improve from 0.86607\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3168 - acc: 0.8544 - val_loss: 0.3051 - val_acc: 0.8640\n",
      "Epoch 19/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.3128 - acc: 0.8578\n",
      "Epoch 19: val_acc did not improve from 0.86607\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3128 - acc: 0.8578 - val_loss: 0.3017 - val_acc: 0.8653\n",
      "Epoch 20/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.3145 - acc: 0.8602\n",
      "Epoch 20: val_acc improved from 0.86607 to 0.86810, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3123 - acc: 0.8613 - val_loss: 0.3046 - val_acc: 0.8681\n",
      "Epoch 21/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.3009 - acc: 0.8631\n",
      "Epoch 21: val_acc did not improve from 0.86810\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2988 - acc: 0.8642 - val_loss: 0.2973 - val_acc: 0.8665\n",
      "Epoch 22/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2983 - acc: 0.8643\n",
      "Epoch 22: val_acc improved from 0.86810 to 0.87135, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2981 - acc: 0.8642 - val_loss: 0.2908 - val_acc: 0.8713\n",
      "Epoch 23/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2976 - acc: 0.8646\n",
      "Epoch 23: val_acc improved from 0.87135 to 0.87256, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2964 - acc: 0.8649 - val_loss: 0.2988 - val_acc: 0.8726\n",
      "Epoch 24/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2971 - acc: 0.8648\n",
      "Epoch 24: val_acc improved from 0.87256 to 0.87419, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2971 - acc: 0.8648 - val_loss: 0.2938 - val_acc: 0.8742\n",
      "Epoch 25/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2898 - acc: 0.8701\n",
      "Epoch 25: val_acc did not improve from 0.87419\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2880 - acc: 0.8706 - val_loss: 0.2903 - val_acc: 0.8665\n",
      "Epoch 26/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2917 - acc: 0.8681\n",
      "Epoch 26: val_acc improved from 0.87419 to 0.87581, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2917 - acc: 0.8679 - val_loss: 0.2806 - val_acc: 0.8758\n",
      "Epoch 27/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2864 - acc: 0.8704\n",
      "Epoch 27: val_acc did not improve from 0.87581\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2858 - acc: 0.8709 - val_loss: 0.2907 - val_acc: 0.8746\n",
      "Epoch 28/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2799 - acc: 0.8741\n",
      "Epoch 28: val_acc did not improve from 0.87581\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2798 - acc: 0.8742 - val_loss: 0.2876 - val_acc: 0.8730\n",
      "Epoch 29/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.2782 - acc: 0.8750\n",
      "Epoch 29: val_acc improved from 0.87581 to 0.87784, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2763 - acc: 0.8757 - val_loss: 0.2870 - val_acc: 0.8778\n",
      "Epoch 30/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.2747 - acc: 0.8773\n",
      "Epoch 30: val_acc improved from 0.87784 to 0.87946, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2724 - acc: 0.8780 - val_loss: 0.2737 - val_acc: 0.8795\n",
      "Epoch 31/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2734 - acc: 0.8741\n",
      "Epoch 31: val_acc improved from 0.87946 to 0.88028, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2731 - acc: 0.8742 - val_loss: 0.2699 - val_acc: 0.8803\n",
      "Epoch 32/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2697 - acc: 0.8787\n",
      "Epoch 32: val_acc improved from 0.88028 to 0.88271, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2697 - acc: 0.8785 - val_loss: 0.2747 - val_acc: 0.8827\n",
      "Epoch 33/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2635 - acc: 0.8849\n",
      "Epoch 33: val_acc did not improve from 0.88271\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2634 - acc: 0.8849 - val_loss: 0.2773 - val_acc: 0.8827\n",
      "Epoch 34/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2671 - acc: 0.8833\n",
      "Epoch 34: val_acc improved from 0.88271 to 0.88433, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2670 - acc: 0.8831 - val_loss: 0.2845 - val_acc: 0.8843\n",
      "Epoch 35/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2612 - acc: 0.8836\n",
      "Epoch 35: val_acc improved from 0.88433 to 0.88515, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2612 - acc: 0.8836 - val_loss: 0.2809 - val_acc: 0.8851\n",
      "Epoch 36/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2700 - acc: 0.8811\n",
      "Epoch 36: val_acc improved from 0.88515 to 0.89367, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2692 - acc: 0.8817 - val_loss: 0.2726 - val_acc: 0.8937\n",
      "Epoch 37/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2538 - acc: 0.8855\n",
      "Epoch 37: val_acc did not improve from 0.89367\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2536 - acc: 0.8855 - val_loss: 0.2692 - val_acc: 0.8831\n",
      "Epoch 38/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2535 - acc: 0.8862\n",
      "Epoch 38: val_acc did not improve from 0.89367\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2526 - acc: 0.8870 - val_loss: 0.2627 - val_acc: 0.8843\n",
      "Epoch 39/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2507 - acc: 0.8867\n",
      "Epoch 39: val_acc did not improve from 0.89367\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2495 - acc: 0.8872 - val_loss: 0.2724 - val_acc: 0.8892\n",
      "Epoch 40/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2513 - acc: 0.8902\n",
      "Epoch 40: val_acc did not improve from 0.89367\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2508 - acc: 0.8904 - val_loss: 0.2578 - val_acc: 0.8860\n",
      "Epoch 41/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2599 - acc: 0.8890\n",
      "Epoch 41: val_acc did not improve from 0.89367\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2578 - acc: 0.8895 - val_loss: 0.2600 - val_acc: 0.8811\n",
      "Epoch 42/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2515 - acc: 0.8891\n",
      "Epoch 42: val_acc did not improve from 0.89367\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2508 - acc: 0.8892 - val_loss: 0.2750 - val_acc: 0.8827\n",
      "Epoch 43/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2516 - acc: 0.8895\n",
      "Epoch 43: val_acc did not improve from 0.89367\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2511 - acc: 0.8897 - val_loss: 0.2830 - val_acc: 0.8762\n",
      "Epoch 44/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2451 - acc: 0.8911\n",
      "Epoch 44: val_acc improved from 0.89367 to 0.89570, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2446 - acc: 0.8915 - val_loss: 0.2567 - val_acc: 0.8957\n",
      "Epoch 45/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2452 - acc: 0.8873\n",
      "Epoch 45: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2451 - acc: 0.8874 - val_loss: 0.2659 - val_acc: 0.8851\n",
      "Epoch 46/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2352 - acc: 0.8938\n",
      "Epoch 46: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2352 - acc: 0.8938 - val_loss: 0.2793 - val_acc: 0.8819\n",
      "Epoch 47/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2453 - acc: 0.8952\n",
      "Epoch 47: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2453 - acc: 0.8952 - val_loss: 0.2689 - val_acc: 0.8782\n",
      "Epoch 48/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2337 - acc: 0.8974\n",
      "Epoch 48: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2330 - acc: 0.8977 - val_loss: 0.2615 - val_acc: 0.8888\n",
      "Epoch 49/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.8967\n",
      "Epoch 49: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2343 - acc: 0.8969 - val_loss: 0.2602 - val_acc: 0.8839\n",
      "Epoch 50/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2374 - acc: 0.8939\n",
      "Epoch 50: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2374 - acc: 0.8939 - val_loss: 0.2623 - val_acc: 0.8949\n",
      "Epoch 51/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2308 - acc: 0.8997\n",
      "Epoch 51: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2304 - acc: 0.8998 - val_loss: 0.2580 - val_acc: 0.8904\n",
      "Epoch 52/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2306 - acc: 0.8942\n",
      "Epoch 52: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2306 - acc: 0.8944 - val_loss: 0.2635 - val_acc: 0.8860\n",
      "Epoch 53/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.8941\n",
      "Epoch 53: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2283 - acc: 0.8941 - val_loss: 0.2549 - val_acc: 0.8904\n",
      "Epoch 54/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2365 - acc: 0.8979\n",
      "Epoch 54: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2354 - acc: 0.8984 - val_loss: 0.2687 - val_acc: 0.8912\n",
      "Epoch 55/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.2447 - acc: 0.8993\n",
      "Epoch 55: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2425 - acc: 0.8997 - val_loss: 0.2654 - val_acc: 0.8872\n",
      "Epoch 56/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2266 - acc: 0.9033\n",
      "Epoch 56: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2268 - acc: 0.9031 - val_loss: 0.2618 - val_acc: 0.8872\n",
      "Epoch 57/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2308 - acc: 0.9052\n",
      "Epoch 57: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2308 - acc: 0.9049 - val_loss: 0.2622 - val_acc: 0.8888\n",
      "Epoch 58/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2305 - acc: 0.9013\n",
      "Epoch 58: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2303 - acc: 0.9015 - val_loss: 0.2614 - val_acc: 0.8908\n",
      "Epoch 59/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.2258 - acc: 0.9047\n",
      "Epoch 59: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2245 - acc: 0.9048 - val_loss: 0.2722 - val_acc: 0.8908\n",
      "Epoch 60/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9055\n",
      "Epoch 60: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2192 - acc: 0.9055 - val_loss: 0.2673 - val_acc: 0.8884\n",
      "Epoch 61/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9019\n",
      "Epoch 61: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2241 - acc: 0.9021 - val_loss: 0.2659 - val_acc: 0.8823\n",
      "Epoch 62/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.2157 - acc: 0.9055\n",
      "Epoch 62: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2146 - acc: 0.9060 - val_loss: 0.2712 - val_acc: 0.8876\n",
      "Epoch 63/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9017\n",
      "Epoch 63: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2236 - acc: 0.9018 - val_loss: 0.2686 - val_acc: 0.8876\n",
      "Epoch 64/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9037\n",
      "Epoch 64: val_acc did not improve from 0.89570\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2225 - acc: 0.9046 - val_loss: 0.2643 - val_acc: 0.8896\n",
      "Epoch 65/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2219 - acc: 0.9004\n",
      "Epoch 65: val_acc improved from 0.89570 to 0.90016, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2205 - acc: 0.9012 - val_loss: 0.2612 - val_acc: 0.9002\n",
      "Epoch 66/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2143 - acc: 0.9061\n",
      "Epoch 66: val_acc did not improve from 0.90016\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2133 - acc: 0.9063 - val_loss: 0.2675 - val_acc: 0.8953\n",
      "Epoch 67/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2122 - acc: 0.9060\n",
      "Epoch 67: val_acc did not improve from 0.90016\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2116 - acc: 0.9061 - val_loss: 0.2719 - val_acc: 0.8937\n",
      "Epoch 68/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2158 - acc: 0.9036\n",
      "Epoch 68: val_acc improved from 0.90016 to 0.90138, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2154 - acc: 0.9038 - val_loss: 0.2606 - val_acc: 0.9014\n",
      "Epoch 69/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2141 - acc: 0.9093\n",
      "Epoch 69: val_acc did not improve from 0.90138\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2140 - acc: 0.9093 - val_loss: 0.2531 - val_acc: 0.8981\n",
      "Epoch 70/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.2130 - acc: 0.9084\n",
      "Epoch 70: val_acc did not improve from 0.90138\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2114 - acc: 0.9095 - val_loss: 0.2694 - val_acc: 0.8945\n",
      "Epoch 71/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.2080 - acc: 0.9100\n",
      "Epoch 71: val_acc did not improve from 0.90138\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2072 - acc: 0.9108 - val_loss: 0.2660 - val_acc: 0.8945\n",
      "Epoch 72/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9090\n",
      "Epoch 72: val_acc did not improve from 0.90138\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2122 - acc: 0.9094 - val_loss: 0.2629 - val_acc: 0.8973\n",
      "Epoch 73/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9073\n",
      "Epoch 73: val_acc did not improve from 0.90138\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2126 - acc: 0.9071 - val_loss: 0.2699 - val_acc: 0.8933\n",
      "Epoch 74/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9059\n",
      "Epoch 74: val_acc did not improve from 0.90138\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2134 - acc: 0.9056 - val_loss: 0.2667 - val_acc: 0.8977\n",
      "Epoch 75/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2089 - acc: 0.9106\n",
      "Epoch 75: val_acc improved from 0.90138 to 0.90260, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2087 - acc: 0.9104 - val_loss: 0.2683 - val_acc: 0.9026\n",
      "Epoch 76/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2121 - acc: 0.9104\n",
      "Epoch 76: val_acc did not improve from 0.90260\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2123 - acc: 0.9102 - val_loss: 0.2594 - val_acc: 0.9026\n",
      "Epoch 77/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2062 - acc: 0.9119\n",
      "Epoch 77: val_acc did not improve from 0.90260\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2061 - acc: 0.9115 - val_loss: 0.2618 - val_acc: 0.8998\n",
      "Epoch 78/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1968 - acc: 0.9159\n",
      "Epoch 78: val_acc did not improve from 0.90260\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1961 - acc: 0.9158 - val_loss: 0.2548 - val_acc: 0.8998\n",
      "Epoch 79/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2084 - acc: 0.9088\n",
      "Epoch 79: val_acc improved from 0.90260 to 0.90503, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2084 - acc: 0.9089 - val_loss: 0.2554 - val_acc: 0.9050\n",
      "Epoch 80/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2042 - acc: 0.9142\n",
      "Epoch 80: val_acc did not improve from 0.90503\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2038 - acc: 0.9141 - val_loss: 0.2748 - val_acc: 0.8929\n",
      "Epoch 81/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9158\n",
      "Epoch 81: val_acc did not improve from 0.90503\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2023 - acc: 0.9159 - val_loss: 0.2497 - val_acc: 0.9042\n",
      "Epoch 82/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9145\n",
      "Epoch 82: val_acc improved from 0.90503 to 0.91356, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1981 - acc: 0.9150 - val_loss: 0.2443 - val_acc: 0.9136\n",
      "Epoch 83/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2027 - acc: 0.9140\n",
      "Epoch 83: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2039 - acc: 0.9139 - val_loss: 0.2586 - val_acc: 0.9042\n",
      "Epoch 84/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1939 - acc: 0.9161\n",
      "Epoch 84: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1932 - acc: 0.9164 - val_loss: 0.2461 - val_acc: 0.9054\n",
      "Epoch 85/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1997 - acc: 0.9117\n",
      "Epoch 85: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2001 - acc: 0.9115 - val_loss: 0.2520 - val_acc: 0.9071\n",
      "Epoch 86/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1973 - acc: 0.9167\n",
      "Epoch 86: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1967 - acc: 0.9169 - val_loss: 0.2711 - val_acc: 0.8864\n",
      "Epoch 87/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9181\n",
      "Epoch 87: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1948 - acc: 0.9180 - val_loss: 0.2848 - val_acc: 0.8929\n",
      "Epoch 88/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2094 - acc: 0.9131\n",
      "Epoch 88: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2088 - acc: 0.9129 - val_loss: 0.2722 - val_acc: 0.8994\n",
      "Epoch 89/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9188\n",
      "Epoch 89: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1986 - acc: 0.9187 - val_loss: 0.2614 - val_acc: 0.9022\n",
      "Epoch 90/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9167\n",
      "Epoch 90: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1931 - acc: 0.9169 - val_loss: 0.2605 - val_acc: 0.8981\n",
      "Epoch 91/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1911 - acc: 0.9217\n",
      "Epoch 91: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1908 - acc: 0.9219 - val_loss: 0.2563 - val_acc: 0.9030\n",
      "Epoch 92/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1964 - acc: 0.9157\n",
      "Epoch 92: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1963 - acc: 0.9158 - val_loss: 0.2478 - val_acc: 0.9062\n",
      "Epoch 93/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1934 - acc: 0.9154\n",
      "Epoch 93: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1931 - acc: 0.9155 - val_loss: 0.2500 - val_acc: 0.9091\n",
      "Epoch 94/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1901 - acc: 0.9205\n",
      "Epoch 94: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1901 - acc: 0.9202 - val_loss: 0.2621 - val_acc: 0.9022\n",
      "Epoch 95/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1901 - acc: 0.9166\n",
      "Epoch 95: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1894 - acc: 0.9167 - val_loss: 0.2649 - val_acc: 0.9034\n",
      "Epoch 96/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9224\n",
      "Epoch 96: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1930 - acc: 0.9223 - val_loss: 0.2493 - val_acc: 0.9050\n",
      "Epoch 97/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9197\n",
      "Epoch 97: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1945 - acc: 0.9197 - val_loss: 0.2513 - val_acc: 0.9042\n",
      "Epoch 98/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1915 - acc: 0.9212\n",
      "Epoch 98: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1908 - acc: 0.9209 - val_loss: 0.2500 - val_acc: 0.9018\n",
      "Epoch 99/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1777 - acc: 0.9200\n",
      "Epoch 99: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1776 - acc: 0.9200 - val_loss: 0.2542 - val_acc: 0.9119\n",
      "Epoch 100/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1884 - acc: 0.9175\n",
      "Epoch 100: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1880 - acc: 0.9178 - val_loss: 0.2609 - val_acc: 0.9002\n",
      "Epoch 101/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9201\n",
      "Epoch 101: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1828 - acc: 0.9202 - val_loss: 0.2592 - val_acc: 0.9083\n",
      "Epoch 102/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9212\n",
      "Epoch 102: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1894 - acc: 0.9211 - val_loss: 0.2465 - val_acc: 0.8977\n",
      "Epoch 103/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9201\n",
      "Epoch 103: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1889 - acc: 0.9198 - val_loss: 0.2589 - val_acc: 0.9054\n",
      "Epoch 104/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1870 - acc: 0.9202\n",
      "Epoch 104: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1870 - acc: 0.9200 - val_loss: 0.2446 - val_acc: 0.9107\n",
      "Epoch 105/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9203\n",
      "Epoch 105: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1844 - acc: 0.9201 - val_loss: 0.2652 - val_acc: 0.9054\n",
      "Epoch 106/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9263\n",
      "Epoch 106: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1831 - acc: 0.9264 - val_loss: 0.2682 - val_acc: 0.9026\n",
      "Epoch 107/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9250\n",
      "Epoch 107: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1812 - acc: 0.9254 - val_loss: 0.2622 - val_acc: 0.9067\n",
      "Epoch 108/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1911 - acc: 0.9222\n",
      "Epoch 108: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1900 - acc: 0.9224 - val_loss: 0.2639 - val_acc: 0.9002\n",
      "Epoch 109/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1799 - acc: 0.9243\n",
      "Epoch 109: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1785 - acc: 0.9247 - val_loss: 0.2554 - val_acc: 0.9071\n",
      "Epoch 110/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1836 - acc: 0.9243\n",
      "Epoch 110: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1821 - acc: 0.9249 - val_loss: 0.2636 - val_acc: 0.9123\n",
      "Epoch 111/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1876 - acc: 0.9180\n",
      "Epoch 111: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1865 - acc: 0.9184 - val_loss: 0.2740 - val_acc: 0.9046\n",
      "Epoch 112/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1802 - acc: 0.9257\n",
      "Epoch 112: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1791 - acc: 0.9260 - val_loss: 0.2644 - val_acc: 0.9083\n",
      "Epoch 113/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1814 - acc: 0.9242\n",
      "Epoch 113: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1802 - acc: 0.9247 - val_loss: 0.2602 - val_acc: 0.9131\n",
      "Epoch 114/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1815 - acc: 0.9235\n",
      "Epoch 114: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1809 - acc: 0.9235 - val_loss: 0.2646 - val_acc: 0.9050\n",
      "Epoch 115/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9236\n",
      "Epoch 115: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1787 - acc: 0.9237 - val_loss: 0.2604 - val_acc: 0.9038\n",
      "Epoch 116/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1732 - acc: 0.9284\n",
      "Epoch 116: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1726 - acc: 0.9285 - val_loss: 0.2628 - val_acc: 0.9087\n",
      "Epoch 117/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1763 - acc: 0.9261\n",
      "Epoch 117: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1764 - acc: 0.9261 - val_loss: 0.2712 - val_acc: 0.9115\n",
      "Epoch 118/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1846 - acc: 0.9261\n",
      "Epoch 118: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1846 - acc: 0.9261 - val_loss: 0.2606 - val_acc: 0.9111\n",
      "Epoch 119/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1832 - acc: 0.9233\n",
      "Epoch 119: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1829 - acc: 0.9234 - val_loss: 0.2702 - val_acc: 0.9038\n",
      "Epoch 120/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9254\n",
      "Epoch 120: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1725 - acc: 0.9256 - val_loss: 0.2780 - val_acc: 0.9079\n",
      "Epoch 121/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1726 - acc: 0.9293\n",
      "Epoch 121: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1720 - acc: 0.9296 - val_loss: 0.2864 - val_acc: 0.9046\n",
      "Epoch 122/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1814 - acc: 0.9253\n",
      "Epoch 122: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1814 - acc: 0.9253 - val_loss: 0.2777 - val_acc: 0.9119\n",
      "Epoch 123/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9279\n",
      "Epoch 123: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1713 - acc: 0.9279 - val_loss: 0.2786 - val_acc: 0.9079\n",
      "Epoch 124/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9228\n",
      "Epoch 124: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1771 - acc: 0.9226 - val_loss: 0.2685 - val_acc: 0.9075\n",
      "Epoch 125/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1726 - acc: 0.9279\n",
      "Epoch 125: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1724 - acc: 0.9278 - val_loss: 0.2746 - val_acc: 0.8985\n",
      "Epoch 126/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9315\n",
      "Epoch 126: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1757 - acc: 0.9315 - val_loss: 0.2659 - val_acc: 0.9127\n",
      "Epoch 127/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1741 - acc: 0.9238\n",
      "Epoch 127: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1740 - acc: 0.9238 - val_loss: 0.3026 - val_acc: 0.9026\n",
      "Epoch 128/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9334\n",
      "Epoch 128: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1608 - acc: 0.9334 - val_loss: 0.2736 - val_acc: 0.9083\n",
      "Epoch 129/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1814 - acc: 0.9265\n",
      "Epoch 129: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1816 - acc: 0.9263 - val_loss: 0.2714 - val_acc: 0.9042\n",
      "Epoch 130/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9269\n",
      "Epoch 130: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1867 - acc: 0.9269 - val_loss: 0.2699 - val_acc: 0.9030\n",
      "Epoch 131/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1706 - acc: 0.9286\n",
      "Epoch 131: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1696 - acc: 0.9290 - val_loss: 0.2655 - val_acc: 0.9067\n",
      "Epoch 132/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1671 - acc: 0.9305\n",
      "Epoch 132: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1667 - acc: 0.9306 - val_loss: 0.2785 - val_acc: 0.9046\n",
      "Epoch 133/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9286\n",
      "Epoch 133: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1995 - acc: 0.9285 - val_loss: 0.2633 - val_acc: 0.9042\n",
      "Epoch 134/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9289\n",
      "Epoch 134: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1678 - acc: 0.9288 - val_loss: 0.2807 - val_acc: 0.9083\n",
      "Epoch 135/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1718 - acc: 0.9307\n",
      "Epoch 135: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1714 - acc: 0.9305 - val_loss: 0.2762 - val_acc: 0.9087\n",
      "Epoch 136/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9310\n",
      "Epoch 136: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1664 - acc: 0.9310 - val_loss: 0.2709 - val_acc: 0.9131\n",
      "Epoch 137/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9279\n",
      "Epoch 137: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1742 - acc: 0.9283 - val_loss: 0.2555 - val_acc: 0.9071\n",
      "Epoch 138/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9299\n",
      "Epoch 138: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1666 - acc: 0.9299 - val_loss: 0.2685 - val_acc: 0.9058\n",
      "Epoch 139/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9304\n",
      "Epoch 139: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1647 - acc: 0.9304 - val_loss: 0.2664 - val_acc: 0.9123\n",
      "Epoch 140/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1649 - acc: 0.9312\n",
      "Epoch 140: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1645 - acc: 0.9312 - val_loss: 0.2733 - val_acc: 0.9087\n",
      "Epoch 141/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9277\n",
      "Epoch 141: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1700 - acc: 0.9275 - val_loss: 0.2733 - val_acc: 0.9111\n",
      "Epoch 142/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1727 - acc: 0.9338\n",
      "Epoch 142: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1715 - acc: 0.9339 - val_loss: 0.2791 - val_acc: 0.9107\n",
      "Epoch 143/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1745 - acc: 0.9293\n",
      "Epoch 143: val_acc did not improve from 0.91356\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1740 - acc: 0.9294 - val_loss: 0.2707 - val_acc: 0.9095\n",
      "Epoch 144/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1689 - acc: 0.9326\n",
      "Epoch 144: val_acc improved from 0.91356 to 0.91721, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1676 - acc: 0.9325 - val_loss: 0.2690 - val_acc: 0.9172\n",
      "Epoch 145/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1590 - acc: 0.9332\n",
      "Epoch 145: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1586 - acc: 0.9335 - val_loss: 0.2902 - val_acc: 0.9050\n",
      "Epoch 146/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9311\n",
      "Epoch 146: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1663 - acc: 0.9315 - val_loss: 0.2723 - val_acc: 0.9140\n",
      "Epoch 147/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9301\n",
      "Epoch 147: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1595 - acc: 0.9303 - val_loss: 0.2586 - val_acc: 0.9062\n",
      "Epoch 148/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1652 - acc: 0.9299\n",
      "Epoch 148: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1640 - acc: 0.9303 - val_loss: 0.2729 - val_acc: 0.9127\n",
      "Epoch 149/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9347\n",
      "Epoch 149: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1608 - acc: 0.9353 - val_loss: 0.2751 - val_acc: 0.9083\n",
      "Epoch 150/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1648 - acc: 0.9347\n",
      "Epoch 150: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1644 - acc: 0.9349 - val_loss: 0.3004 - val_acc: 0.9107\n",
      "Epoch 151/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1684 - acc: 0.9339\n",
      "Epoch 151: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1684 - acc: 0.9340 - val_loss: 0.2496 - val_acc: 0.9115\n",
      "Epoch 152/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1545 - acc: 0.9344\n",
      "Epoch 152: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1545 - acc: 0.9344 - val_loss: 0.2574 - val_acc: 0.9144\n",
      "Epoch 153/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1638 - acc: 0.9350\n",
      "Epoch 153: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1638 - acc: 0.9351 - val_loss: 0.2733 - val_acc: 0.9083\n",
      "Epoch 154/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1654 - acc: 0.9321\n",
      "Epoch 154: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1654 - acc: 0.9321 - val_loss: 0.2748 - val_acc: 0.9115\n",
      "Epoch 155/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1659 - acc: 0.9337\n",
      "Epoch 155: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1653 - acc: 0.9337 - val_loss: 0.2901 - val_acc: 0.9087\n",
      "Epoch 156/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1659 - acc: 0.9331\n",
      "Epoch 156: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1653 - acc: 0.9333 - val_loss: 0.2731 - val_acc: 0.9168\n",
      "Epoch 157/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9284\n",
      "Epoch 157: val_acc did not improve from 0.91721\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1697 - acc: 0.9294 - val_loss: 0.2933 - val_acc: 0.9058\n",
      "Epoch 158/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9350\n",
      "Epoch 158: val_acc improved from 0.91721 to 0.91883, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1572 - acc: 0.9349 - val_loss: 0.2639 - val_acc: 0.9188\n",
      "Epoch 159/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9338\n",
      "Epoch 159: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1548 - acc: 0.9340 - val_loss: 0.2661 - val_acc: 0.9111\n",
      "Epoch 160/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9365\n",
      "Epoch 160: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1533 - acc: 0.9372 - val_loss: 0.2853 - val_acc: 0.9136\n",
      "Epoch 161/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1601 - acc: 0.9324\n",
      "Epoch 161: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1594 - acc: 0.9327 - val_loss: 0.3197 - val_acc: 0.9079\n",
      "Epoch 162/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9376\n",
      "Epoch 162: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1557 - acc: 0.9374 - val_loss: 0.2865 - val_acc: 0.9006\n",
      "Epoch 163/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9317\n",
      "Epoch 163: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1624 - acc: 0.9315 - val_loss: 0.2948 - val_acc: 0.9119\n",
      "Epoch 164/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1632 - acc: 0.9339\n",
      "Epoch 164: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1621 - acc: 0.9339 - val_loss: 0.2481 - val_acc: 0.9180\n",
      "Epoch 165/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9343\n",
      "Epoch 165: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1638 - acc: 0.9343 - val_loss: 0.2852 - val_acc: 0.9123\n",
      "Epoch 166/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9364\n",
      "Epoch 166: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1565 - acc: 0.9366 - val_loss: 0.2726 - val_acc: 0.9180\n",
      "Epoch 167/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9393\n",
      "Epoch 167: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1495 - acc: 0.9396 - val_loss: 0.2937 - val_acc: 0.9091\n",
      "Epoch 168/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1635 - acc: 0.9308\n",
      "Epoch 168: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1636 - acc: 0.9306 - val_loss: 0.2901 - val_acc: 0.9119\n",
      "Epoch 169/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9350\n",
      "Epoch 169: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1608 - acc: 0.9346 - val_loss: 0.2919 - val_acc: 0.9111\n",
      "Epoch 170/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9369\n",
      "Epoch 170: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1521 - acc: 0.9368 - val_loss: 0.3084 - val_acc: 0.9172\n",
      "Epoch 171/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1631 - acc: 0.9352\n",
      "Epoch 171: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1622 - acc: 0.9354 - val_loss: 0.3023 - val_acc: 0.9180\n",
      "Epoch 172/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1498 - acc: 0.9382\n",
      "Epoch 172: val_acc improved from 0.91883 to 0.91964, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1496 - acc: 0.9383 - val_loss: 0.2896 - val_acc: 0.9196\n",
      "Epoch 173/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9355\n",
      "Epoch 173: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1605 - acc: 0.9356 - val_loss: 0.2744 - val_acc: 0.9160\n",
      "Epoch 174/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1629 - acc: 0.9326\n",
      "Epoch 174: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1633 - acc: 0.9325 - val_loss: 0.3005 - val_acc: 0.9107\n",
      "Epoch 175/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1565 - acc: 0.9345\n",
      "Epoch 175: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1567 - acc: 0.9343 - val_loss: 0.3022 - val_acc: 0.9087\n",
      "Epoch 176/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1603 - acc: 0.9331\n",
      "Epoch 176: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1590 - acc: 0.9335 - val_loss: 0.2525 - val_acc: 0.9172\n",
      "Epoch 177/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1570 - acc: 0.9371\n",
      "Epoch 177: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1570 - acc: 0.9371 - val_loss: 0.3056 - val_acc: 0.9022\n",
      "Epoch 178/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9366\n",
      "Epoch 178: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1513 - acc: 0.9365 - val_loss: 0.2997 - val_acc: 0.9091\n",
      "Epoch 179/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9352\n",
      "Epoch 179: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1573 - acc: 0.9356 - val_loss: 0.3045 - val_acc: 0.9140\n",
      "Epoch 180/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9398\n",
      "Epoch 180: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1506 - acc: 0.9400 - val_loss: 0.3310 - val_acc: 0.9152\n",
      "Epoch 181/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1561 - acc: 0.9355\n",
      "Epoch 181: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1559 - acc: 0.9358 - val_loss: 0.2930 - val_acc: 0.9123\n",
      "Epoch 182/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9354\n",
      "Epoch 182: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1547 - acc: 0.9357 - val_loss: 0.2899 - val_acc: 0.9115\n",
      "Epoch 183/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1519 - acc: 0.9423\n",
      "Epoch 183: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1514 - acc: 0.9423 - val_loss: 0.3085 - val_acc: 0.9136\n",
      "Epoch 184/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9352\n",
      "Epoch 184: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1528 - acc: 0.9352 - val_loss: 0.2857 - val_acc: 0.9107\n",
      "Epoch 185/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9393\n",
      "Epoch 185: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1482 - acc: 0.9394 - val_loss: 0.3202 - val_acc: 0.9034\n",
      "Epoch 186/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9427\n",
      "Epoch 186: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1453 - acc: 0.9427 - val_loss: 0.3192 - val_acc: 0.9087\n",
      "Epoch 187/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1477 - acc: 0.9387\n",
      "Epoch 187: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1477 - acc: 0.9387 - val_loss: 0.2880 - val_acc: 0.9172\n",
      "Epoch 188/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1470 - acc: 0.9400\n",
      "Epoch 188: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1466 - acc: 0.9399 - val_loss: 0.3259 - val_acc: 0.9075\n",
      "Epoch 189/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9371\n",
      "Epoch 189: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1558 - acc: 0.9371 - val_loss: 0.3044 - val_acc: 0.9123\n",
      "Epoch 190/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9345\n",
      "Epoch 190: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1617 - acc: 0.9349 - val_loss: 0.3159 - val_acc: 0.9099\n",
      "Epoch 191/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1571 - acc: 0.9356\n",
      "Epoch 191: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1563 - acc: 0.9357 - val_loss: 0.3218 - val_acc: 0.9095\n",
      "Epoch 192/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9410\n",
      "Epoch 192: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1424 - acc: 0.9409 - val_loss: 0.2968 - val_acc: 0.9144\n",
      "Epoch 193/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1495 - acc: 0.9419\n",
      "Epoch 193: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1494 - acc: 0.9419 - val_loss: 0.2775 - val_acc: 0.9196\n",
      "Epoch 194/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9398\n",
      "Epoch 194: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1481 - acc: 0.9402 - val_loss: 0.2839 - val_acc: 0.9099\n",
      "Epoch 195/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1559 - acc: 0.9380\n",
      "Epoch 195: val_acc did not improve from 0.91964\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1549 - acc: 0.9385 - val_loss: 0.2707 - val_acc: 0.9192\n",
      "Epoch 196/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9405\n",
      "Epoch 196: val_acc improved from 0.91964 to 0.92127, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1426 - acc: 0.9401 - val_loss: 0.2804 - val_acc: 0.9213\n",
      "Epoch 197/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9418\n",
      "Epoch 197: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1508 - acc: 0.9417 - val_loss: 0.3047 - val_acc: 0.9103\n",
      "Epoch 198/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1523 - acc: 0.9386\n",
      "Epoch 198: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1522 - acc: 0.9386 - val_loss: 0.2778 - val_acc: 0.9127\n",
      "Epoch 199/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9438\n",
      "Epoch 199: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1490 - acc: 0.9437 - val_loss: 0.2813 - val_acc: 0.9168\n",
      "Epoch 200/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9389\n",
      "Epoch 200: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1505 - acc: 0.9387 - val_loss: 0.2775 - val_acc: 0.9119\n",
      "Epoch 201/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9431\n",
      "Epoch 201: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1424 - acc: 0.9434 - val_loss: 0.2849 - val_acc: 0.9131\n",
      "Epoch 202/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9406\n",
      "Epoch 202: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1507 - acc: 0.9403 - val_loss: 0.2951 - val_acc: 0.8981\n",
      "Epoch 203/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9419\n",
      "Epoch 203: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1427 - acc: 0.9419 - val_loss: 0.2952 - val_acc: 0.9123\n",
      "Epoch 204/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9430\n",
      "Epoch 204: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1491 - acc: 0.9434 - val_loss: 0.2701 - val_acc: 0.9192\n",
      "Epoch 205/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9409\n",
      "Epoch 205: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1518 - acc: 0.9402 - val_loss: 0.2562 - val_acc: 0.9156\n",
      "Epoch 206/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9391\n",
      "Epoch 206: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1478 - acc: 0.9387 - val_loss: 0.2807 - val_acc: 0.9136\n",
      "Epoch 207/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1495 - acc: 0.9375\n",
      "Epoch 207: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1487 - acc: 0.9380 - val_loss: 0.2952 - val_acc: 0.9103\n",
      "Epoch 208/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9418\n",
      "Epoch 208: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1447 - acc: 0.9421 - val_loss: 0.2893 - val_acc: 0.9156\n",
      "Epoch 209/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1443 - acc: 0.9396\n",
      "Epoch 209: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1433 - acc: 0.9397 - val_loss: 0.2994 - val_acc: 0.9127\n",
      "Epoch 210/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9406\n",
      "Epoch 210: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1455 - acc: 0.9413 - val_loss: 0.3021 - val_acc: 0.9152\n",
      "Epoch 211/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9438\n",
      "Epoch 211: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1385 - acc: 0.9438 - val_loss: 0.3072 - val_acc: 0.9144\n",
      "Epoch 212/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9406\n",
      "Epoch 212: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1477 - acc: 0.9408 - val_loss: 0.2788 - val_acc: 0.9176\n",
      "Epoch 213/2000\n",
      "593/616 [===========================>..] - ETA: 0s - loss: 0.1563 - acc: 0.9409\n",
      "Epoch 213: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1552 - acc: 0.9405 - val_loss: 0.2824 - val_acc: 0.9180\n",
      "Epoch 214/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9385\n",
      "Epoch 214: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1524 - acc: 0.9382 - val_loss: 0.2802 - val_acc: 0.9079\n",
      "Epoch 215/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9435\n",
      "Epoch 215: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1463 - acc: 0.9437 - val_loss: 0.2988 - val_acc: 0.9180\n",
      "Epoch 216/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9414\n",
      "Epoch 216: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1444 - acc: 0.9418 - val_loss: 0.3076 - val_acc: 0.9107\n",
      "Epoch 217/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1427 - acc: 0.9445\n",
      "Epoch 217: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1433 - acc: 0.9443 - val_loss: 0.3122 - val_acc: 0.9103\n",
      "Epoch 218/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9431\n",
      "Epoch 218: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1450 - acc: 0.9431 - val_loss: 0.3006 - val_acc: 0.9164\n",
      "Epoch 219/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9428\n",
      "Epoch 219: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1456 - acc: 0.9429 - val_loss: 0.2949 - val_acc: 0.9103\n",
      "Epoch 220/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9423\n",
      "Epoch 220: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1449 - acc: 0.9420 - val_loss: 0.2896 - val_acc: 0.9123\n",
      "Epoch 221/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9410\n",
      "Epoch 221: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1536 - acc: 0.9415 - val_loss: 0.2955 - val_acc: 0.9144\n",
      "Epoch 222/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9431\n",
      "Epoch 222: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1353 - acc: 0.9431 - val_loss: 0.3160 - val_acc: 0.9091\n",
      "Epoch 223/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9437\n",
      "Epoch 223: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1382 - acc: 0.9436 - val_loss: 0.3096 - val_acc: 0.9188\n",
      "Epoch 224/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9448\n",
      "Epoch 224: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1421 - acc: 0.9447 - val_loss: 0.3229 - val_acc: 0.9119\n",
      "Epoch 225/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9427\n",
      "Epoch 225: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1388 - acc: 0.9431 - val_loss: 0.3114 - val_acc: 0.9103\n",
      "Epoch 226/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9421\n",
      "Epoch 226: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1454 - acc: 0.9424 - val_loss: 0.3020 - val_acc: 0.9200\n",
      "Epoch 227/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9455\n",
      "Epoch 227: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1493 - acc: 0.9455 - val_loss: 0.3233 - val_acc: 0.9156\n",
      "Epoch 228/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9410\n",
      "Epoch 228: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1513 - acc: 0.9407 - val_loss: 0.3637 - val_acc: 0.9071\n",
      "Epoch 229/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9422\n",
      "Epoch 229: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1433 - acc: 0.9427 - val_loss: 0.3136 - val_acc: 0.9103\n",
      "Epoch 230/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9423\n",
      "Epoch 230: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1445 - acc: 0.9429 - val_loss: 0.3089 - val_acc: 0.9180\n",
      "Epoch 231/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9417\n",
      "Epoch 231: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1405 - acc: 0.9419 - val_loss: 0.3221 - val_acc: 0.9152\n",
      "Epoch 232/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9437\n",
      "Epoch 232: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1370 - acc: 0.9438 - val_loss: 0.3312 - val_acc: 0.9168\n",
      "Epoch 233/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1431 - acc: 0.9407\n",
      "Epoch 233: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1431 - acc: 0.9407 - val_loss: 0.2813 - val_acc: 0.9152\n",
      "Epoch 234/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9432\n",
      "Epoch 234: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1472 - acc: 0.9432 - val_loss: 0.3352 - val_acc: 0.9091\n",
      "Epoch 235/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9410\n",
      "Epoch 235: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1515 - acc: 0.9409 - val_loss: 0.2881 - val_acc: 0.9119\n",
      "Epoch 236/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9427\n",
      "Epoch 236: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1368 - acc: 0.9437 - val_loss: 0.2975 - val_acc: 0.9131\n",
      "Epoch 237/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9457\n",
      "Epoch 237: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1386 - acc: 0.9459 - val_loss: 0.3156 - val_acc: 0.9152\n",
      "Epoch 238/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9447\n",
      "Epoch 238: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1355 - acc: 0.9453 - val_loss: 0.3051 - val_acc: 0.9123\n",
      "Epoch 239/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1347 - acc: 0.9453\n",
      "Epoch 239: val_acc improved from 0.92127 to 0.92411, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1339 - acc: 0.9458 - val_loss: 0.2749 - val_acc: 0.9241\n",
      "Epoch 240/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9482\n",
      "Epoch 240: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1320 - acc: 0.9481 - val_loss: 0.3273 - val_acc: 0.9136\n",
      "Epoch 241/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9444\n",
      "Epoch 241: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1366 - acc: 0.9445 - val_loss: 0.3105 - val_acc: 0.9119\n",
      "Epoch 242/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9445\n",
      "Epoch 242: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1380 - acc: 0.9446 - val_loss: 0.3322 - val_acc: 0.9136\n",
      "Epoch 243/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9453\n",
      "Epoch 243: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1411 - acc: 0.9453 - val_loss: 0.3176 - val_acc: 0.9111\n",
      "Epoch 244/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9418\n",
      "Epoch 244: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1415 - acc: 0.9421 - val_loss: 0.3108 - val_acc: 0.9156\n",
      "Epoch 245/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9452\n",
      "Epoch 245: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1360 - acc: 0.9455 - val_loss: 0.3081 - val_acc: 0.9168\n",
      "Epoch 246/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9430\n",
      "Epoch 246: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1306 - acc: 0.9428 - val_loss: 0.3206 - val_acc: 0.9103\n",
      "Epoch 247/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9451\n",
      "Epoch 247: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1437 - acc: 0.9453 - val_loss: 0.3142 - val_acc: 0.9237\n",
      "Epoch 248/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9476\n",
      "Epoch 248: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1316 - acc: 0.9475 - val_loss: 0.3136 - val_acc: 0.9172\n",
      "Epoch 249/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9444\n",
      "Epoch 249: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1467 - acc: 0.9441 - val_loss: 0.3067 - val_acc: 0.9217\n",
      "Epoch 250/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9490\n",
      "Epoch 250: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1266 - acc: 0.9489 - val_loss: 0.3005 - val_acc: 0.9172\n",
      "Epoch 251/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9417\n",
      "Epoch 251: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1392 - acc: 0.9416 - val_loss: 0.3224 - val_acc: 0.9107\n",
      "Epoch 252/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1397 - acc: 0.9453\n",
      "Epoch 252: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1397 - acc: 0.9453 - val_loss: 0.3182 - val_acc: 0.9079\n",
      "Epoch 253/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9461\n",
      "Epoch 253: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1367 - acc: 0.9459 - val_loss: 0.3411 - val_acc: 0.9091\n",
      "Epoch 254/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9430\n",
      "Epoch 254: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1405 - acc: 0.9435 - val_loss: 0.2903 - val_acc: 0.9140\n",
      "Epoch 255/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9416\n",
      "Epoch 255: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1439 - acc: 0.9418 - val_loss: 0.3039 - val_acc: 0.9156\n",
      "Epoch 256/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9478\n",
      "Epoch 256: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1291 - acc: 0.9484 - val_loss: 0.2920 - val_acc: 0.9168\n",
      "Epoch 257/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9455\n",
      "Epoch 257: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1371 - acc: 0.9461 - val_loss: 0.3089 - val_acc: 0.9164\n",
      "Epoch 258/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9454\n",
      "Epoch 258: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1415 - acc: 0.9456 - val_loss: 0.3416 - val_acc: 0.9180\n",
      "Epoch 259/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9478\n",
      "Epoch 259: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1326 - acc: 0.9478 - val_loss: 0.3681 - val_acc: 0.9205\n",
      "Epoch 260/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9432\n",
      "Epoch 260: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1375 - acc: 0.9436 - val_loss: 0.3221 - val_acc: 0.9229\n",
      "Epoch 261/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9458\n",
      "Epoch 261: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1351 - acc: 0.9460 - val_loss: 0.3030 - val_acc: 0.9160\n",
      "Epoch 262/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1356 - acc: 0.9464\n",
      "Epoch 262: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1350 - acc: 0.9468 - val_loss: 0.3283 - val_acc: 0.9188\n",
      "Epoch 263/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9461\n",
      "Epoch 263: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1299 - acc: 0.9461 - val_loss: 0.3163 - val_acc: 0.9213\n",
      "Epoch 264/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1404 - acc: 0.9445\n",
      "Epoch 264: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1393 - acc: 0.9448 - val_loss: 0.3501 - val_acc: 0.9164\n",
      "Epoch 265/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9470\n",
      "Epoch 265: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1237 - acc: 0.9470 - val_loss: 0.3589 - val_acc: 0.9152\n",
      "Epoch 266/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9465\n",
      "Epoch 266: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1324 - acc: 0.9462 - val_loss: 0.3708 - val_acc: 0.9156\n",
      "Epoch 267/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9476\n",
      "Epoch 267: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1401 - acc: 0.9478 - val_loss: 0.3340 - val_acc: 0.9136\n",
      "Epoch 268/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9452\n",
      "Epoch 268: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1383 - acc: 0.9452 - val_loss: 0.3481 - val_acc: 0.9152\n",
      "Epoch 269/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9434\n",
      "Epoch 269: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1458 - acc: 0.9432 - val_loss: 0.3601 - val_acc: 0.9091\n",
      "Epoch 270/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1411 - acc: 0.9449\n",
      "Epoch 270: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1397 - acc: 0.9455 - val_loss: 0.3660 - val_acc: 0.9131\n",
      "Epoch 271/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9460\n",
      "Epoch 271: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1320 - acc: 0.9459 - val_loss: 0.3551 - val_acc: 0.9087\n",
      "Epoch 272/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9460\n",
      "Epoch 272: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1360 - acc: 0.9464 - val_loss: 0.3291 - val_acc: 0.9095\n",
      "Epoch 273/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9496\n",
      "Epoch 273: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1359 - acc: 0.9497 - val_loss: 0.3187 - val_acc: 0.9144\n",
      "Epoch 274/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9464\n",
      "Epoch 274: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1349 - acc: 0.9468 - val_loss: 0.3045 - val_acc: 0.9144\n",
      "Epoch 275/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9459\n",
      "Epoch 275: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1393 - acc: 0.9456 - val_loss: 0.3525 - val_acc: 0.9180\n",
      "Epoch 276/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1242 - acc: 0.9495\n",
      "Epoch 276: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1242 - acc: 0.9495 - val_loss: 0.3160 - val_acc: 0.9172\n",
      "Epoch 277/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9478\n",
      "Epoch 277: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1255 - acc: 0.9478 - val_loss: 0.3344 - val_acc: 0.9205\n",
      "Epoch 278/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9447\n",
      "Epoch 278: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1403 - acc: 0.9449 - val_loss: 0.3509 - val_acc: 0.9160\n",
      "Epoch 279/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1460 - acc: 0.9457\n",
      "Epoch 279: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1457 - acc: 0.9456 - val_loss: 0.3598 - val_acc: 0.9176\n",
      "Epoch 280/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9489\n",
      "Epoch 280: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1360 - acc: 0.9490 - val_loss: 0.3351 - val_acc: 0.9160\n",
      "Epoch 281/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9497\n",
      "Epoch 281: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1274 - acc: 0.9496 - val_loss: 0.3294 - val_acc: 0.9168\n",
      "Epoch 282/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9498\n",
      "Epoch 282: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1272 - acc: 0.9498 - val_loss: 0.3213 - val_acc: 0.9213\n",
      "Epoch 283/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9488\n",
      "Epoch 283: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1270 - acc: 0.9491 - val_loss: 0.3132 - val_acc: 0.9205\n",
      "Epoch 284/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9485\n",
      "Epoch 284: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1357 - acc: 0.9491 - val_loss: 0.3603 - val_acc: 0.9140\n",
      "Epoch 285/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9492\n",
      "Epoch 285: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1304 - acc: 0.9492 - val_loss: 0.3464 - val_acc: 0.9123\n",
      "Epoch 286/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9475\n",
      "Epoch 286: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1304 - acc: 0.9476 - val_loss: 0.3809 - val_acc: 0.9148\n",
      "Epoch 287/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9434\n",
      "Epoch 287: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1384 - acc: 0.9436 - val_loss: 0.3237 - val_acc: 0.9131\n",
      "Epoch 288/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9483\n",
      "Epoch 288: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1279 - acc: 0.9489 - val_loss: 0.3473 - val_acc: 0.9131\n",
      "Epoch 289/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9482\n",
      "Epoch 289: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1312 - acc: 0.9481 - val_loss: 0.3407 - val_acc: 0.9148\n",
      "Epoch 290/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9463\n",
      "Epoch 290: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1368 - acc: 0.9465 - val_loss: 0.3548 - val_acc: 0.9172\n",
      "Epoch 291/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9466\n",
      "Epoch 291: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1480 - acc: 0.9467 - val_loss: 0.3437 - val_acc: 0.9156\n",
      "Epoch 292/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9483\n",
      "Epoch 292: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1331 - acc: 0.9485 - val_loss: 0.3371 - val_acc: 0.9160\n",
      "Epoch 293/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9521\n",
      "Epoch 293: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1395 - acc: 0.9518 - val_loss: 0.3422 - val_acc: 0.9156\n",
      "Epoch 294/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9478\n",
      "Epoch 294: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1357 - acc: 0.9480 - val_loss: 0.3619 - val_acc: 0.9136\n",
      "Epoch 295/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9502\n",
      "Epoch 295: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1269 - acc: 0.9505 - val_loss: 0.3305 - val_acc: 0.9192\n",
      "Epoch 296/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9459\n",
      "Epoch 296: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1364 - acc: 0.9459 - val_loss: 0.3062 - val_acc: 0.9196\n",
      "Epoch 297/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9504\n",
      "Epoch 297: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1277 - acc: 0.9510 - val_loss: 0.2843 - val_acc: 0.9152\n",
      "Epoch 298/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9502\n",
      "Epoch 298: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1233 - acc: 0.9505 - val_loss: 0.3109 - val_acc: 0.9136\n",
      "Epoch 299/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9447\n",
      "Epoch 299: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1368 - acc: 0.9449 - val_loss: 0.2893 - val_acc: 0.9188\n",
      "Epoch 300/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9491\n",
      "Epoch 300: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1314 - acc: 0.9495 - val_loss: 0.2885 - val_acc: 0.9200\n",
      "Epoch 301/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9462\n",
      "Epoch 301: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1312 - acc: 0.9461 - val_loss: 0.3096 - val_acc: 0.9221\n",
      "Epoch 302/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1273 - acc: 0.9482\n",
      "Epoch 302: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1259 - acc: 0.9484 - val_loss: 0.3088 - val_acc: 0.9168\n",
      "Epoch 303/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9495\n",
      "Epoch 303: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1327 - acc: 0.9496 - val_loss: 0.3093 - val_acc: 0.9176\n",
      "Epoch 304/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9470\n",
      "Epoch 304: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1287 - acc: 0.9471 - val_loss: 0.3181 - val_acc: 0.9176\n",
      "Epoch 305/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9487\n",
      "Epoch 305: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1331 - acc: 0.9489 - val_loss: 0.3337 - val_acc: 0.9156\n",
      "Epoch 306/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9502\n",
      "Epoch 306: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1326 - acc: 0.9502 - val_loss: 0.3100 - val_acc: 0.9229\n",
      "Epoch 307/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9474\n",
      "Epoch 307: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1342 - acc: 0.9474 - val_loss: 0.2987 - val_acc: 0.9217\n",
      "Epoch 308/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9499\n",
      "Epoch 308: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1264 - acc: 0.9500 - val_loss: 0.3243 - val_acc: 0.9196\n",
      "Epoch 309/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1303 - acc: 0.9484\n",
      "Epoch 309: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1303 - acc: 0.9484 - val_loss: 0.3212 - val_acc: 0.9217\n",
      "Epoch 310/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9502\n",
      "Epoch 310: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1240 - acc: 0.9504 - val_loss: 0.3186 - val_acc: 0.9217\n",
      "Epoch 311/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9524\n",
      "Epoch 311: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1257 - acc: 0.9524 - val_loss: 0.3496 - val_acc: 0.9229\n",
      "Epoch 312/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9505\n",
      "Epoch 312: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1355 - acc: 0.9506 - val_loss: 0.3124 - val_acc: 0.9111\n",
      "Epoch 313/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9485\n",
      "Epoch 313: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1390 - acc: 0.9486 - val_loss: 0.3226 - val_acc: 0.9209\n",
      "Epoch 314/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9524\n",
      "Epoch 314: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1329 - acc: 0.9525 - val_loss: 0.3682 - val_acc: 0.9233\n",
      "Epoch 315/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1174 - acc: 0.9514\n",
      "Epoch 315: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1160 - acc: 0.9517 - val_loss: 0.3475 - val_acc: 0.9160\n",
      "Epoch 316/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9511\n",
      "Epoch 316: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1235 - acc: 0.9513 - val_loss: 0.3327 - val_acc: 0.9184\n",
      "Epoch 317/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9520\n",
      "Epoch 317: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1353 - acc: 0.9519 - val_loss: 0.3370 - val_acc: 0.9148\n",
      "Epoch 318/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9517\n",
      "Epoch 318: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1303 - acc: 0.9513 - val_loss: 0.3315 - val_acc: 0.9164\n",
      "Epoch 319/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9492\n",
      "Epoch 319: val_acc did not improve from 0.92411\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1326 - acc: 0.9493 - val_loss: 0.3024 - val_acc: 0.9205\n",
      "Epoch 320/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9501\n",
      "Epoch 320: val_acc improved from 0.92411 to 0.92614, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1202 - acc: 0.9504 - val_loss: 0.3158 - val_acc: 0.9261\n",
      "Epoch 321/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9476\n",
      "Epoch 321: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1376 - acc: 0.9476 - val_loss: 0.3132 - val_acc: 0.9192\n",
      "Epoch 322/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9482\n",
      "Epoch 322: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1399 - acc: 0.9487 - val_loss: 0.3788 - val_acc: 0.9144\n",
      "Epoch 323/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9473\n",
      "Epoch 323: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1358 - acc: 0.9471 - val_loss: 0.3292 - val_acc: 0.9221\n",
      "Epoch 324/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9503\n",
      "Epoch 324: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1382 - acc: 0.9503 - val_loss: 0.3220 - val_acc: 0.9225\n",
      "Epoch 325/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9524\n",
      "Epoch 325: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1258 - acc: 0.9525 - val_loss: 0.3244 - val_acc: 0.9168\n",
      "Epoch 326/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9509\n",
      "Epoch 326: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1216 - acc: 0.9509 - val_loss: 0.3605 - val_acc: 0.9152\n",
      "Epoch 327/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9514\n",
      "Epoch 327: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1329 - acc: 0.9514 - val_loss: 0.3683 - val_acc: 0.9188\n",
      "Epoch 328/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9519\n",
      "Epoch 328: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1226 - acc: 0.9526 - val_loss: 0.3535 - val_acc: 0.9188\n",
      "Epoch 329/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9498\n",
      "Epoch 329: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1338 - acc: 0.9497 - val_loss: 0.3280 - val_acc: 0.9168\n",
      "Epoch 330/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9497\n",
      "Epoch 330: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1313 - acc: 0.9505 - val_loss: 0.3298 - val_acc: 0.9176\n",
      "Epoch 331/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9507\n",
      "Epoch 331: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1287 - acc: 0.9511 - val_loss: 0.3597 - val_acc: 0.9184\n",
      "Epoch 332/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1347 - acc: 0.9473\n",
      "Epoch 332: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1332 - acc: 0.9477 - val_loss: 0.3388 - val_acc: 0.9152\n",
      "Epoch 333/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9521\n",
      "Epoch 333: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1293 - acc: 0.9521 - val_loss: 0.3414 - val_acc: 0.9180\n",
      "Epoch 334/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9522\n",
      "Epoch 334: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1226 - acc: 0.9522 - val_loss: 0.3423 - val_acc: 0.9176\n",
      "Epoch 335/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9551\n",
      "Epoch 335: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1185 - acc: 0.9549 - val_loss: 0.3340 - val_acc: 0.9233\n",
      "Epoch 336/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9498\n",
      "Epoch 336: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1314 - acc: 0.9498 - val_loss: 0.3189 - val_acc: 0.9156\n",
      "Epoch 337/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9510\n",
      "Epoch 337: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1229 - acc: 0.9512 - val_loss: 0.3330 - val_acc: 0.9253\n",
      "Epoch 338/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9524\n",
      "Epoch 338: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1220 - acc: 0.9525 - val_loss: 0.3086 - val_acc: 0.9131\n",
      "Epoch 339/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1166 - acc: 0.9518\n",
      "Epoch 339: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1166 - acc: 0.9518 - val_loss: 0.3214 - val_acc: 0.9180\n",
      "Epoch 340/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9519\n",
      "Epoch 340: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1299 - acc: 0.9521 - val_loss: 0.3352 - val_acc: 0.9160\n",
      "Epoch 341/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9487\n",
      "Epoch 341: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1228 - acc: 0.9492 - val_loss: 0.3286 - val_acc: 0.9213\n",
      "Epoch 342/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9522\n",
      "Epoch 342: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1287 - acc: 0.9524 - val_loss: 0.3383 - val_acc: 0.9200\n",
      "Epoch 343/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9509\n",
      "Epoch 343: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1179 - acc: 0.9510 - val_loss: 0.3307 - val_acc: 0.9225\n",
      "Epoch 344/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9516\n",
      "Epoch 344: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1277 - acc: 0.9518 - val_loss: 0.3640 - val_acc: 0.9115\n",
      "Epoch 345/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9539\n",
      "Epoch 345: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1217 - acc: 0.9539 - val_loss: 0.3490 - val_acc: 0.9213\n",
      "Epoch 346/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1292 - acc: 0.9494\n",
      "Epoch 346: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1296 - acc: 0.9494 - val_loss: 0.3414 - val_acc: 0.9176\n",
      "Epoch 347/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9521\n",
      "Epoch 347: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1215 - acc: 0.9522 - val_loss: 0.3565 - val_acc: 0.9184\n",
      "Epoch 348/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9526\n",
      "Epoch 348: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1240 - acc: 0.9525 - val_loss: 0.3273 - val_acc: 0.9253\n",
      "Epoch 349/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9503\n",
      "Epoch 349: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1202 - acc: 0.9510 - val_loss: 0.3517 - val_acc: 0.9241\n",
      "Epoch 350/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9531\n",
      "Epoch 350: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1211 - acc: 0.9538 - val_loss: 0.3510 - val_acc: 0.9217\n",
      "Epoch 351/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9527\n",
      "Epoch 351: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1176 - acc: 0.9527 - val_loss: 0.4027 - val_acc: 0.9188\n",
      "Epoch 352/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9519\n",
      "Epoch 352: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1306 - acc: 0.9522 - val_loss: 0.3355 - val_acc: 0.9180\n",
      "Epoch 353/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9521\n",
      "Epoch 353: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1219 - acc: 0.9523 - val_loss: 0.3553 - val_acc: 0.9217\n",
      "Epoch 354/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9520\n",
      "Epoch 354: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1198 - acc: 0.9521 - val_loss: 0.3211 - val_acc: 0.9184\n",
      "Epoch 355/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9514\n",
      "Epoch 355: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1278 - acc: 0.9513 - val_loss: 0.3202 - val_acc: 0.9152\n",
      "Epoch 356/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9537\n",
      "Epoch 356: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1330 - acc: 0.9538 - val_loss: 0.3409 - val_acc: 0.9160\n",
      "Epoch 357/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9486\n",
      "Epoch 357: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1265 - acc: 0.9490 - val_loss: 0.3628 - val_acc: 0.9180\n",
      "Epoch 358/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9540\n",
      "Epoch 358: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1169 - acc: 0.9541 - val_loss: 0.3711 - val_acc: 0.9180\n",
      "Epoch 359/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9529\n",
      "Epoch 359: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1170 - acc: 0.9531 - val_loss: 0.3591 - val_acc: 0.9184\n",
      "Epoch 360/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9530\n",
      "Epoch 360: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1204 - acc: 0.9529 - val_loss: 0.3690 - val_acc: 0.9156\n",
      "Epoch 361/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9562\n",
      "Epoch 361: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1187 - acc: 0.9561 - val_loss: 0.3851 - val_acc: 0.9160\n",
      "Epoch 362/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9533\n",
      "Epoch 362: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1229 - acc: 0.9537 - val_loss: 0.3538 - val_acc: 0.9241\n",
      "Epoch 363/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9498\n",
      "Epoch 363: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1288 - acc: 0.9500 - val_loss: 0.3482 - val_acc: 0.9176\n",
      "Epoch 364/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9508\n",
      "Epoch 364: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1190 - acc: 0.9505 - val_loss: 0.3749 - val_acc: 0.9180\n",
      "Epoch 365/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9541\n",
      "Epoch 365: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1160 - acc: 0.9540 - val_loss: 0.3265 - val_acc: 0.9261\n",
      "Epoch 366/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9564\n",
      "Epoch 366: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1169 - acc: 0.9561 - val_loss: 0.3488 - val_acc: 0.9233\n",
      "Epoch 367/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9538\n",
      "Epoch 367: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1224 - acc: 0.9538 - val_loss: 0.3766 - val_acc: 0.9192\n",
      "Epoch 368/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9513\n",
      "Epoch 368: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1199 - acc: 0.9516 - val_loss: 0.3709 - val_acc: 0.9176\n",
      "Epoch 369/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9545\n",
      "Epoch 369: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1198 - acc: 0.9546 - val_loss: 0.3538 - val_acc: 0.9180\n",
      "Epoch 370/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9562\n",
      "Epoch 370: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1156 - acc: 0.9564 - val_loss: 0.3235 - val_acc: 0.9237\n",
      "Epoch 371/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1235 - acc: 0.9525\n",
      "Epoch 371: val_acc did not improve from 0.92614\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1235 - acc: 0.9525 - val_loss: 0.3289 - val_acc: 0.9261\n",
      "Epoch 372/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1350 - acc: 0.9542\n",
      "Epoch 372: val_acc improved from 0.92614 to 0.92898, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1350 - acc: 0.9542 - val_loss: 0.4020 - val_acc: 0.9290\n",
      "Epoch 373/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9563\n",
      "Epoch 373: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1245 - acc: 0.9564 - val_loss: 0.4064 - val_acc: 0.9168\n",
      "Epoch 374/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9543\n",
      "Epoch 374: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1178 - acc: 0.9545 - val_loss: 0.3699 - val_acc: 0.9221\n",
      "Epoch 375/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9518\n",
      "Epoch 375: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1219 - acc: 0.9516 - val_loss: 0.4420 - val_acc: 0.9225\n",
      "Epoch 376/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9525\n",
      "Epoch 376: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1355 - acc: 0.9528 - val_loss: 0.3615 - val_acc: 0.9152\n",
      "Epoch 377/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9539\n",
      "Epoch 377: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1164 - acc: 0.9539 - val_loss: 0.3820 - val_acc: 0.9237\n",
      "Epoch 378/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9555\n",
      "Epoch 378: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1244 - acc: 0.9556 - val_loss: 0.3293 - val_acc: 0.9168\n",
      "Epoch 379/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9514\n",
      "Epoch 379: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1259 - acc: 0.9514 - val_loss: 0.3683 - val_acc: 0.9176\n",
      "Epoch 380/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9552\n",
      "Epoch 380: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1137 - acc: 0.9548 - val_loss: 0.3869 - val_acc: 0.9213\n",
      "Epoch 381/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9538\n",
      "Epoch 381: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1219 - acc: 0.9537 - val_loss: 0.4042 - val_acc: 0.9196\n",
      "Epoch 382/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9506\n",
      "Epoch 382: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1240 - acc: 0.9506 - val_loss: 0.3175 - val_acc: 0.9213\n",
      "Epoch 383/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9566\n",
      "Epoch 383: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1136 - acc: 0.9568 - val_loss: 0.3624 - val_acc: 0.9249\n",
      "Epoch 384/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9507\n",
      "Epoch 384: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1243 - acc: 0.9509 - val_loss: 0.3666 - val_acc: 0.9229\n",
      "Epoch 385/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9527\n",
      "Epoch 385: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1248 - acc: 0.9527 - val_loss: 0.3295 - val_acc: 0.9172\n",
      "Epoch 386/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9533\n",
      "Epoch 386: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1220 - acc: 0.9530 - val_loss: 0.3422 - val_acc: 0.9233\n",
      "Epoch 387/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9532\n",
      "Epoch 387: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1216 - acc: 0.9531 - val_loss: 0.3464 - val_acc: 0.9188\n",
      "Epoch 388/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9519\n",
      "Epoch 388: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1230 - acc: 0.9520 - val_loss: 0.3230 - val_acc: 0.9180\n",
      "Epoch 389/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9528\n",
      "Epoch 389: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1253 - acc: 0.9533 - val_loss: 0.3216 - val_acc: 0.9225\n",
      "Epoch 390/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9540\n",
      "Epoch 390: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1241 - acc: 0.9539 - val_loss: 0.3077 - val_acc: 0.9184\n",
      "Epoch 391/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9551\n",
      "Epoch 391: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1131 - acc: 0.9554 - val_loss: 0.3711 - val_acc: 0.9192\n",
      "Epoch 392/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9542\n",
      "Epoch 392: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1161 - acc: 0.9541 - val_loss: 0.3718 - val_acc: 0.9176\n",
      "Epoch 393/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9562\n",
      "Epoch 393: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1113 - acc: 0.9561 - val_loss: 0.3905 - val_acc: 0.9205\n",
      "Epoch 394/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9557\n",
      "Epoch 394: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1137 - acc: 0.9557 - val_loss: 0.3874 - val_acc: 0.9180\n",
      "Epoch 395/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9568\n",
      "Epoch 395: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1140 - acc: 0.9573 - val_loss: 0.3363 - val_acc: 0.9237\n",
      "Epoch 396/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9535\n",
      "Epoch 396: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1175 - acc: 0.9538 - val_loss: 0.3372 - val_acc: 0.9217\n",
      "Epoch 397/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9551\n",
      "Epoch 397: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1276 - acc: 0.9555 - val_loss: 0.3725 - val_acc: 0.9221\n",
      "Epoch 398/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1180 - acc: 0.9549\n",
      "Epoch 398: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1180 - acc: 0.9549 - val_loss: 0.3811 - val_acc: 0.9237\n",
      "Epoch 399/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9592\n",
      "Epoch 399: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1099 - acc: 0.9596 - val_loss: 0.4021 - val_acc: 0.9172\n",
      "Epoch 400/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9537\n",
      "Epoch 400: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1172 - acc: 0.9539 - val_loss: 0.4042 - val_acc: 0.9152\n",
      "Epoch 401/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9542\n",
      "Epoch 401: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1111 - acc: 0.9542 - val_loss: 0.3823 - val_acc: 0.9221\n",
      "Epoch 402/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9530\n",
      "Epoch 402: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1270 - acc: 0.9530 - val_loss: 0.4162 - val_acc: 0.9205\n",
      "Epoch 403/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9563\n",
      "Epoch 403: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1350 - acc: 0.9563 - val_loss: 0.3708 - val_acc: 0.9205\n",
      "Epoch 404/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9531\n",
      "Epoch 404: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1199 - acc: 0.9537 - val_loss: 0.3642 - val_acc: 0.9229\n",
      "Epoch 405/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9561\n",
      "Epoch 405: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1104 - acc: 0.9560 - val_loss: 0.4265 - val_acc: 0.9144\n",
      "Epoch 406/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9529\n",
      "Epoch 406: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1236 - acc: 0.9530 - val_loss: 0.3579 - val_acc: 0.9188\n",
      "Epoch 407/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9567\n",
      "Epoch 407: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1123 - acc: 0.9567 - val_loss: 0.3531 - val_acc: 0.9269\n",
      "Epoch 408/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9555\n",
      "Epoch 408: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1177 - acc: 0.9557 - val_loss: 0.3303 - val_acc: 0.9225\n",
      "Epoch 409/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9590\n",
      "Epoch 409: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1073 - acc: 0.9590 - val_loss: 0.3764 - val_acc: 0.9237\n",
      "Epoch 410/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9574\n",
      "Epoch 410: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1189 - acc: 0.9577 - val_loss: 0.3854 - val_acc: 0.9225\n",
      "Epoch 411/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9566\n",
      "Epoch 411: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1218 - acc: 0.9565 - val_loss: 0.4503 - val_acc: 0.9168\n",
      "Epoch 412/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1176 - acc: 0.9539\n",
      "Epoch 412: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1166 - acc: 0.9543 - val_loss: 0.3949 - val_acc: 0.9123\n",
      "Epoch 413/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9534\n",
      "Epoch 413: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1130 - acc: 0.9539 - val_loss: 0.4031 - val_acc: 0.9205\n",
      "Epoch 414/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9567\n",
      "Epoch 414: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1157 - acc: 0.9569 - val_loss: 0.3633 - val_acc: 0.9245\n",
      "Epoch 415/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9580\n",
      "Epoch 415: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1153 - acc: 0.9580 - val_loss: 0.3818 - val_acc: 0.9253\n",
      "Epoch 416/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9557\n",
      "Epoch 416: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1072 - acc: 0.9557 - val_loss: 0.3995 - val_acc: 0.9213\n",
      "Epoch 417/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9557\n",
      "Epoch 417: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1129 - acc: 0.9558 - val_loss: 0.3957 - val_acc: 0.9274\n",
      "Epoch 418/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9564\n",
      "Epoch 418: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1109 - acc: 0.9565 - val_loss: 0.4158 - val_acc: 0.9209\n",
      "Epoch 419/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9549\n",
      "Epoch 419: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1130 - acc: 0.9550 - val_loss: 0.3736 - val_acc: 0.9217\n",
      "Epoch 420/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9553\n",
      "Epoch 420: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1313 - acc: 0.9555 - val_loss: 0.3847 - val_acc: 0.9192\n",
      "Epoch 421/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9556\n",
      "Epoch 421: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1083 - acc: 0.9560 - val_loss: 0.4079 - val_acc: 0.9156\n",
      "Epoch 422/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9546\n",
      "Epoch 422: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1269 - acc: 0.9546 - val_loss: 0.3692 - val_acc: 0.9217\n",
      "Epoch 423/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9563\n",
      "Epoch 423: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1094 - acc: 0.9564 - val_loss: 0.3664 - val_acc: 0.9164\n",
      "Epoch 424/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9596\n",
      "Epoch 424: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1063 - acc: 0.9596 - val_loss: 0.3997 - val_acc: 0.9205\n",
      "Epoch 425/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9596\n",
      "Epoch 425: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1094 - acc: 0.9597 - val_loss: 0.3543 - val_acc: 0.9229\n",
      "Epoch 426/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9585\n",
      "Epoch 426: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1045 - acc: 0.9586 - val_loss: 0.4205 - val_acc: 0.9282\n",
      "Epoch 427/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9561\n",
      "Epoch 427: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1264 - acc: 0.9560 - val_loss: 0.3991 - val_acc: 0.9192\n",
      "Epoch 428/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9543\n",
      "Epoch 428: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1174 - acc: 0.9543 - val_loss: 0.4178 - val_acc: 0.9176\n",
      "Epoch 429/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1138 - acc: 0.9590\n",
      "Epoch 429: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1138 - acc: 0.9590 - val_loss: 0.3911 - val_acc: 0.9152\n",
      "Epoch 430/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9569\n",
      "Epoch 430: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1152 - acc: 0.9569 - val_loss: 0.3979 - val_acc: 0.9237\n",
      "Epoch 431/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9564\n",
      "Epoch 431: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1188 - acc: 0.9566 - val_loss: 0.4341 - val_acc: 0.9209\n",
      "Epoch 432/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1148 - acc: 0.9571\n",
      "Epoch 432: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1148 - acc: 0.9571 - val_loss: 0.3667 - val_acc: 0.9253\n",
      "Epoch 433/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9560\n",
      "Epoch 433: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1117 - acc: 0.9558 - val_loss: 0.4149 - val_acc: 0.9200\n",
      "Epoch 434/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9571\n",
      "Epoch 434: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1151 - acc: 0.9569 - val_loss: 0.3595 - val_acc: 0.9188\n",
      "Epoch 435/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9552\n",
      "Epoch 435: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1148 - acc: 0.9554 - val_loss: 0.3896 - val_acc: 0.9188\n",
      "Epoch 436/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9566\n",
      "Epoch 436: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1080 - acc: 0.9568 - val_loss: 0.4339 - val_acc: 0.9131\n",
      "Epoch 437/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9556\n",
      "Epoch 437: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1292 - acc: 0.9551 - val_loss: 0.3840 - val_acc: 0.9180\n",
      "Epoch 438/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9550\n",
      "Epoch 438: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1165 - acc: 0.9551 - val_loss: 0.4094 - val_acc: 0.9164\n",
      "Epoch 439/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9567\n",
      "Epoch 439: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1257 - acc: 0.9567 - val_loss: 0.3756 - val_acc: 0.9180\n",
      "Epoch 440/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9587\n",
      "Epoch 440: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1123 - acc: 0.9585 - val_loss: 0.3453 - val_acc: 0.9229\n",
      "Epoch 441/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9587\n",
      "Epoch 441: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1037 - acc: 0.9591 - val_loss: 0.4049 - val_acc: 0.9225\n",
      "Epoch 442/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9560\n",
      "Epoch 442: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1172 - acc: 0.9563 - val_loss: 0.3404 - val_acc: 0.9164\n",
      "Epoch 443/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9574\n",
      "Epoch 443: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1200 - acc: 0.9576 - val_loss: 0.4415 - val_acc: 0.9196\n",
      "Epoch 444/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9568\n",
      "Epoch 444: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1145 - acc: 0.9570 - val_loss: 0.3772 - val_acc: 0.9213\n",
      "Epoch 445/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9563\n",
      "Epoch 445: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1133 - acc: 0.9566 - val_loss: 0.4131 - val_acc: 0.9213\n",
      "Epoch 446/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9573\n",
      "Epoch 446: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1289 - acc: 0.9571 - val_loss: 0.3878 - val_acc: 0.9213\n",
      "Epoch 447/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9585\n",
      "Epoch 447: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1146 - acc: 0.9584 - val_loss: 0.4140 - val_acc: 0.9245\n",
      "Epoch 448/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1143 - acc: 0.9558\n",
      "Epoch 448: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1137 - acc: 0.9558 - val_loss: 0.3798 - val_acc: 0.9192\n",
      "Epoch 449/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9586\n",
      "Epoch 449: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1059 - acc: 0.9588 - val_loss: 0.4147 - val_acc: 0.9257\n",
      "Epoch 450/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9595\n",
      "Epoch 450: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1093 - acc: 0.9596 - val_loss: 0.4198 - val_acc: 0.9221\n",
      "Epoch 451/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9593\n",
      "Epoch 451: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1101 - acc: 0.9593 - val_loss: 0.4310 - val_acc: 0.9233\n",
      "Epoch 452/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9600\n",
      "Epoch 452: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1148 - acc: 0.9599 - val_loss: 0.4183 - val_acc: 0.9265\n",
      "Epoch 453/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1151 - acc: 0.9573\n",
      "Epoch 453: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1151 - acc: 0.9573 - val_loss: 0.4073 - val_acc: 0.9205\n",
      "Epoch 454/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1243 - acc: 0.9549\n",
      "Epoch 454: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1243 - acc: 0.9549 - val_loss: 0.3803 - val_acc: 0.9265\n",
      "Epoch 455/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9604\n",
      "Epoch 455: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1236 - acc: 0.9603 - val_loss: 0.3994 - val_acc: 0.9200\n",
      "Epoch 456/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9563\n",
      "Epoch 456: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1170 - acc: 0.9567 - val_loss: 0.3856 - val_acc: 0.9274\n",
      "Epoch 457/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9589\n",
      "Epoch 457: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1098 - acc: 0.9589 - val_loss: 0.4251 - val_acc: 0.9213\n",
      "Epoch 458/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9561\n",
      "Epoch 458: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1374 - acc: 0.9563 - val_loss: 0.3832 - val_acc: 0.9249\n",
      "Epoch 459/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9581\n",
      "Epoch 459: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1136 - acc: 0.9579 - val_loss: 0.3779 - val_acc: 0.9184\n",
      "Epoch 460/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9559\n",
      "Epoch 460: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1201 - acc: 0.9561 - val_loss: 0.3727 - val_acc: 0.9233\n",
      "Epoch 461/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9554\n",
      "Epoch 461: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1113 - acc: 0.9557 - val_loss: 0.3568 - val_acc: 0.9200\n",
      "Epoch 462/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9598\n",
      "Epoch 462: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1012 - acc: 0.9602 - val_loss: 0.3678 - val_acc: 0.9245\n",
      "Epoch 463/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9587\n",
      "Epoch 463: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1086 - acc: 0.9587 - val_loss: 0.4018 - val_acc: 0.9217\n",
      "Epoch 464/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9598\n",
      "Epoch 464: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1227 - acc: 0.9599 - val_loss: 0.4050 - val_acc: 0.9196\n",
      "Epoch 465/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9557\n",
      "Epoch 465: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1081 - acc: 0.9558 - val_loss: 0.4487 - val_acc: 0.9205\n",
      "Epoch 466/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9589\n",
      "Epoch 466: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1129 - acc: 0.9589 - val_loss: 0.4135 - val_acc: 0.9229\n",
      "Epoch 467/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9571\n",
      "Epoch 467: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1066 - acc: 0.9577 - val_loss: 0.4518 - val_acc: 0.9156\n",
      "Epoch 468/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9569\n",
      "Epoch 468: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1074 - acc: 0.9567 - val_loss: 0.3909 - val_acc: 0.9257\n",
      "Epoch 469/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9563\n",
      "Epoch 469: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1248 - acc: 0.9567 - val_loss: 0.3689 - val_acc: 0.9245\n",
      "Epoch 470/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9562\n",
      "Epoch 470: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1101 - acc: 0.9563 - val_loss: 0.4317 - val_acc: 0.9217\n",
      "Epoch 471/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9599\n",
      "Epoch 471: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1085 - acc: 0.9599 - val_loss: 0.4052 - val_acc: 0.9282\n",
      "Epoch 472/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9579\n",
      "Epoch 472: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1085 - acc: 0.9580 - val_loss: 0.3841 - val_acc: 0.9265\n",
      "Epoch 473/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9586\n",
      "Epoch 473: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1028 - acc: 0.9584 - val_loss: 0.4434 - val_acc: 0.9229\n",
      "Epoch 474/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9584\n",
      "Epoch 474: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1175 - acc: 0.9586 - val_loss: 0.3753 - val_acc: 0.9241\n",
      "Epoch 475/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9553\n",
      "Epoch 475: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1362 - acc: 0.9555 - val_loss: 0.4118 - val_acc: 0.9225\n",
      "Epoch 476/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9566\n",
      "Epoch 476: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1147 - acc: 0.9566 - val_loss: 0.3985 - val_acc: 0.9253\n",
      "Epoch 477/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9574\n",
      "Epoch 477: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1063 - acc: 0.9575 - val_loss: 0.4250 - val_acc: 0.9180\n",
      "Epoch 478/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.9585\n",
      "Epoch 478: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1183 - acc: 0.9586 - val_loss: 0.3973 - val_acc: 0.9237\n",
      "Epoch 479/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9600\n",
      "Epoch 479: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1014 - acc: 0.9601 - val_loss: 0.4016 - val_acc: 0.9152\n",
      "Epoch 480/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9608\n",
      "Epoch 480: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1033 - acc: 0.9608 - val_loss: 0.4487 - val_acc: 0.9192\n",
      "Epoch 481/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9572\n",
      "Epoch 481: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1138 - acc: 0.9571 - val_loss: 0.3736 - val_acc: 0.9209\n",
      "Epoch 482/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9565\n",
      "Epoch 482: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1161 - acc: 0.9565 - val_loss: 0.4071 - val_acc: 0.9217\n",
      "Epoch 483/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9587\n",
      "Epoch 483: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1125 - acc: 0.9589 - val_loss: 0.4352 - val_acc: 0.9249\n",
      "Epoch 484/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9613\n",
      "Epoch 484: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1123 - acc: 0.9614 - val_loss: 0.3961 - val_acc: 0.9229\n",
      "Epoch 485/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9567\n",
      "Epoch 485: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1108 - acc: 0.9569 - val_loss: 0.4233 - val_acc: 0.9225\n",
      "Epoch 486/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9585\n",
      "Epoch 486: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1110 - acc: 0.9582 - val_loss: 0.3915 - val_acc: 0.9261\n",
      "Epoch 487/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9565\n",
      "Epoch 487: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1184 - acc: 0.9563 - val_loss: 0.3860 - val_acc: 0.9253\n",
      "Epoch 488/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9586\n",
      "Epoch 488: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1145 - acc: 0.9586 - val_loss: 0.3899 - val_acc: 0.9229\n",
      "Epoch 489/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9582\n",
      "Epoch 489: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1065 - acc: 0.9583 - val_loss: 0.4276 - val_acc: 0.9196\n",
      "Epoch 490/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9581\n",
      "Epoch 490: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1221 - acc: 0.9580 - val_loss: 0.4197 - val_acc: 0.9209\n",
      "Epoch 491/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9566\n",
      "Epoch 491: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1070 - acc: 0.9566 - val_loss: 0.3906 - val_acc: 0.9196\n",
      "Epoch 492/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9625\n",
      "Epoch 492: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0989 - acc: 0.9623 - val_loss: 0.4112 - val_acc: 0.9217\n",
      "Epoch 493/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9566\n",
      "Epoch 493: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1194 - acc: 0.9567 - val_loss: 0.4434 - val_acc: 0.9225\n",
      "Epoch 494/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1014 - acc: 0.9623\n",
      "Epoch 494: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1014 - acc: 0.9623 - val_loss: 0.4587 - val_acc: 0.9196\n",
      "Epoch 495/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9592\n",
      "Epoch 495: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1103 - acc: 0.9594 - val_loss: 0.4272 - val_acc: 0.9188\n",
      "Epoch 496/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9632\n",
      "Epoch 496: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1158 - acc: 0.9633 - val_loss: 0.4658 - val_acc: 0.9205\n",
      "Epoch 497/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9590\n",
      "Epoch 497: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1056 - acc: 0.9593 - val_loss: 0.4774 - val_acc: 0.9184\n",
      "Epoch 498/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9583\n",
      "Epoch 498: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1119 - acc: 0.9583 - val_loss: 0.4594 - val_acc: 0.9152\n",
      "Epoch 499/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9590\n",
      "Epoch 499: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1060 - acc: 0.9589 - val_loss: 0.5580 - val_acc: 0.9213\n",
      "Epoch 500/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9582\n",
      "Epoch 500: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1138 - acc: 0.9581 - val_loss: 0.4444 - val_acc: 0.9176\n",
      "Epoch 501/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9590\n",
      "Epoch 501: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1037 - acc: 0.9589 - val_loss: 0.3904 - val_acc: 0.9188\n",
      "Epoch 502/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9590\n",
      "Epoch 502: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1241 - acc: 0.9585 - val_loss: 0.3603 - val_acc: 0.9156\n",
      "Epoch 503/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9584\n",
      "Epoch 503: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1089 - acc: 0.9588 - val_loss: 0.4405 - val_acc: 0.9180\n",
      "Epoch 504/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9535\n",
      "Epoch 504: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1143 - acc: 0.9536 - val_loss: 0.4310 - val_acc: 0.9192\n",
      "Epoch 505/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9602\n",
      "Epoch 505: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1145 - acc: 0.9603 - val_loss: 0.4599 - val_acc: 0.9221\n",
      "Epoch 506/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9590\n",
      "Epoch 506: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1069 - acc: 0.9593 - val_loss: 0.5131 - val_acc: 0.9172\n",
      "Epoch 507/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9583\n",
      "Epoch 507: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1032 - acc: 0.9583 - val_loss: 0.4465 - val_acc: 0.9164\n",
      "Epoch 508/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9557\n",
      "Epoch 508: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1287 - acc: 0.9559 - val_loss: 0.4102 - val_acc: 0.9225\n",
      "Epoch 509/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9544\n",
      "Epoch 509: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1112 - acc: 0.9545 - val_loss: 0.4129 - val_acc: 0.9209\n",
      "Epoch 510/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9614\n",
      "Epoch 510: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1131 - acc: 0.9615 - val_loss: 0.4529 - val_acc: 0.9184\n",
      "Epoch 511/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9623\n",
      "Epoch 511: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.0978 - acc: 0.9622 - val_loss: 0.4488 - val_acc: 0.9233\n",
      "Epoch 512/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9539\n",
      "Epoch 512: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1152 - acc: 0.9544 - val_loss: 0.4334 - val_acc: 0.9205\n",
      "Epoch 513/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9569\n",
      "Epoch 513: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1155 - acc: 0.9570 - val_loss: 0.4116 - val_acc: 0.9188\n",
      "Epoch 514/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9609\n",
      "Epoch 514: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1123 - acc: 0.9609 - val_loss: 0.4452 - val_acc: 0.9192\n",
      "Epoch 515/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9619\n",
      "Epoch 515: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1102 - acc: 0.9618 - val_loss: 0.4382 - val_acc: 0.9176\n",
      "Epoch 516/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9586\n",
      "Epoch 516: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1073 - acc: 0.9589 - val_loss: 0.4456 - val_acc: 0.9205\n",
      "Epoch 517/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9599\n",
      "Epoch 517: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1063 - acc: 0.9598 - val_loss: 0.4885 - val_acc: 0.9152\n",
      "Epoch 518/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1120 - acc: 0.9602\n",
      "Epoch 518: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1120 - acc: 0.9602 - val_loss: 0.3827 - val_acc: 0.9241\n",
      "Epoch 519/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9641\n",
      "Epoch 519: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0975 - acc: 0.9640 - val_loss: 0.4406 - val_acc: 0.9209\n",
      "Epoch 520/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9595\n",
      "Epoch 520: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1022 - acc: 0.9594 - val_loss: 0.3767 - val_acc: 0.9269\n",
      "Epoch 521/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9602\n",
      "Epoch 521: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0994 - acc: 0.9603 - val_loss: 0.4262 - val_acc: 0.9237\n",
      "Epoch 522/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9585\n",
      "Epoch 522: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1087 - acc: 0.9586 - val_loss: 0.4427 - val_acc: 0.9221\n",
      "Epoch 523/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9591\n",
      "Epoch 523: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1355 - acc: 0.9593 - val_loss: 0.4672 - val_acc: 0.9237\n",
      "Epoch 524/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9587\n",
      "Epoch 524: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1130 - acc: 0.9587 - val_loss: 0.5833 - val_acc: 0.9229\n",
      "Epoch 525/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9579\n",
      "Epoch 525: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1095 - acc: 0.9580 - val_loss: 0.3778 - val_acc: 0.9257\n",
      "Epoch 526/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9584\n",
      "Epoch 526: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1120 - acc: 0.9583 - val_loss: 0.4436 - val_acc: 0.9217\n",
      "Epoch 527/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9572\n",
      "Epoch 527: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1139 - acc: 0.9569 - val_loss: 0.4325 - val_acc: 0.9229\n",
      "Epoch 528/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9579\n",
      "Epoch 528: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1073 - acc: 0.9582 - val_loss: 0.5235 - val_acc: 0.9205\n",
      "Epoch 529/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9618\n",
      "Epoch 529: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0958 - acc: 0.9616 - val_loss: 0.4702 - val_acc: 0.9217\n",
      "Epoch 530/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9585\n",
      "Epoch 530: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1054 - acc: 0.9586 - val_loss: 0.4350 - val_acc: 0.9261\n",
      "Epoch 531/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9615\n",
      "Epoch 531: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1035 - acc: 0.9616 - val_loss: 0.4404 - val_acc: 0.9221\n",
      "Epoch 532/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9583\n",
      "Epoch 532: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1135 - acc: 0.9586 - val_loss: 0.4278 - val_acc: 0.9225\n",
      "Epoch 533/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9587\n",
      "Epoch 533: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1056 - acc: 0.9587 - val_loss: 0.4351 - val_acc: 0.9286\n",
      "Epoch 534/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9621\n",
      "Epoch 534: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1066 - acc: 0.9620 - val_loss: 0.4293 - val_acc: 0.9221\n",
      "Epoch 535/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9614\n",
      "Epoch 535: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1059 - acc: 0.9615 - val_loss: 0.5113 - val_acc: 0.9200\n",
      "Epoch 536/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9616\n",
      "Epoch 536: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1036 - acc: 0.9615 - val_loss: 0.4630 - val_acc: 0.9209\n",
      "Epoch 537/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9603\n",
      "Epoch 537: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1035 - acc: 0.9602 - val_loss: 0.4716 - val_acc: 0.9148\n",
      "Epoch 538/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9540\n",
      "Epoch 538: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1261 - acc: 0.9540 - val_loss: 0.4540 - val_acc: 0.9172\n",
      "Epoch 539/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9581\n",
      "Epoch 539: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1036 - acc: 0.9579 - val_loss: 0.4344 - val_acc: 0.9225\n",
      "Epoch 540/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9613\n",
      "Epoch 540: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1067 - acc: 0.9612 - val_loss: 0.4203 - val_acc: 0.9111\n",
      "Epoch 541/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9605\n",
      "Epoch 541: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1010 - acc: 0.9605 - val_loss: 0.5055 - val_acc: 0.9164\n",
      "Epoch 542/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9596\n",
      "Epoch 542: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1072 - acc: 0.9596 - val_loss: 0.4594 - val_acc: 0.9164\n",
      "Epoch 543/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9637\n",
      "Epoch 543: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1026 - acc: 0.9638 - val_loss: 0.4466 - val_acc: 0.9168\n",
      "Epoch 544/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9606\n",
      "Epoch 544: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1097 - acc: 0.9606 - val_loss: 0.4287 - val_acc: 0.9131\n",
      "Epoch 545/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1011 - acc: 0.9606\n",
      "Epoch 545: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1011 - acc: 0.9606 - val_loss: 0.4541 - val_acc: 0.9172\n",
      "Epoch 546/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9591\n",
      "Epoch 546: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1105 - acc: 0.9593 - val_loss: 0.4903 - val_acc: 0.9164\n",
      "Epoch 547/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9606\n",
      "Epoch 547: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0995 - acc: 0.9606 - val_loss: 0.4751 - val_acc: 0.9253\n",
      "Epoch 548/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9605\n",
      "Epoch 548: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1111 - acc: 0.9602 - val_loss: 0.4546 - val_acc: 0.9200\n",
      "Epoch 549/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9580\n",
      "Epoch 549: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1118 - acc: 0.9581 - val_loss: 0.3876 - val_acc: 0.9221\n",
      "Epoch 550/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9604\n",
      "Epoch 550: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1131 - acc: 0.9605 - val_loss: 0.4316 - val_acc: 0.9257\n",
      "Epoch 551/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9600\n",
      "Epoch 551: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1071 - acc: 0.9603 - val_loss: 0.4242 - val_acc: 0.9257\n",
      "Epoch 552/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9624\n",
      "Epoch 552: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1033 - acc: 0.9626 - val_loss: 0.4054 - val_acc: 0.9253\n",
      "Epoch 553/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9608\n",
      "Epoch 553: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0979 - acc: 0.9609 - val_loss: 0.4847 - val_acc: 0.9217\n",
      "Epoch 554/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9612\n",
      "Epoch 554: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1124 - acc: 0.9615 - val_loss: 0.4314 - val_acc: 0.9249\n",
      "Epoch 555/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9605\n",
      "Epoch 555: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1206 - acc: 0.9604 - val_loss: 0.4609 - val_acc: 0.9205\n",
      "Epoch 556/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9628\n",
      "Epoch 556: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1079 - acc: 0.9631 - val_loss: 0.4846 - val_acc: 0.9237\n",
      "Epoch 557/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9611\n",
      "Epoch 557: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1010 - acc: 0.9616 - val_loss: 0.4983 - val_acc: 0.9282\n",
      "Epoch 558/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9599\n",
      "Epoch 558: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1017 - acc: 0.9599 - val_loss: 0.4495 - val_acc: 0.9176\n",
      "Epoch 559/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9623\n",
      "Epoch 559: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0964 - acc: 0.9630 - val_loss: 0.5439 - val_acc: 0.9188\n",
      "Epoch 560/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9611\n",
      "Epoch 560: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1028 - acc: 0.9612 - val_loss: 0.4784 - val_acc: 0.9245\n",
      "Epoch 561/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.0950 - acc: 0.9644\n",
      "Epoch 561: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0950 - acc: 0.9644 - val_loss: 0.4484 - val_acc: 0.9265\n",
      "Epoch 562/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9637\n",
      "Epoch 562: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0975 - acc: 0.9636 - val_loss: 0.4618 - val_acc: 0.9274\n",
      "Epoch 563/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9613\n",
      "Epoch 563: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1108 - acc: 0.9611 - val_loss: 0.3959 - val_acc: 0.9217\n",
      "Epoch 564/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9621\n",
      "Epoch 564: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1052 - acc: 0.9624 - val_loss: 0.4160 - val_acc: 0.9213\n",
      "Epoch 565/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9584\n",
      "Epoch 565: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1170 - acc: 0.9585 - val_loss: 0.4393 - val_acc: 0.9176\n",
      "Epoch 566/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9631\n",
      "Epoch 566: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0948 - acc: 0.9633 - val_loss: 0.5075 - val_acc: 0.9237\n",
      "Epoch 567/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9565\n",
      "Epoch 567: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1058 - acc: 0.9565 - val_loss: 0.4398 - val_acc: 0.9249\n",
      "Epoch 568/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9588\n",
      "Epoch 568: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1214 - acc: 0.9587 - val_loss: 0.3846 - val_acc: 0.9237\n",
      "Epoch 569/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9617\n",
      "Epoch 569: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1023 - acc: 0.9616 - val_loss: 0.4347 - val_acc: 0.9269\n",
      "Epoch 570/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9644\n",
      "Epoch 570: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1002 - acc: 0.9646 - val_loss: 0.4703 - val_acc: 0.9229\n",
      "Epoch 571/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9619\n",
      "Epoch 571: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1110 - acc: 0.9624 - val_loss: 0.4521 - val_acc: 0.9269\n",
      "Epoch 572/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9606\n",
      "Epoch 572: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1033 - acc: 0.9607 - val_loss: 0.4772 - val_acc: 0.9257\n",
      "Epoch 573/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1030 - acc: 0.9602\n",
      "Epoch 573: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1030 - acc: 0.9602 - val_loss: 0.4938 - val_acc: 0.9233\n",
      "Epoch 574/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9592\n",
      "Epoch 574: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1107 - acc: 0.9593 - val_loss: 0.4717 - val_acc: 0.9253\n",
      "Epoch 575/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9626\n",
      "Epoch 575: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1066 - acc: 0.9628 - val_loss: 0.4905 - val_acc: 0.9209\n",
      "Epoch 576/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1157 - acc: 0.9597\n",
      "Epoch 576: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1157 - acc: 0.9597 - val_loss: 0.4654 - val_acc: 0.9241\n",
      "Epoch 577/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9628\n",
      "Epoch 577: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1037 - acc: 0.9632 - val_loss: 0.5712 - val_acc: 0.9192\n",
      "Epoch 578/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9584\n",
      "Epoch 578: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1145 - acc: 0.9584 - val_loss: 0.4881 - val_acc: 0.9217\n",
      "Epoch 579/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9641\n",
      "Epoch 579: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1139 - acc: 0.9641 - val_loss: 0.4069 - val_acc: 0.9148\n",
      "Epoch 580/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9603\n",
      "Epoch 580: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0978 - acc: 0.9605 - val_loss: 0.4605 - val_acc: 0.9245\n",
      "Epoch 581/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9610\n",
      "Epoch 581: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0936 - acc: 0.9609 - val_loss: 0.4915 - val_acc: 0.9225\n",
      "Epoch 582/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9633\n",
      "Epoch 582: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1042 - acc: 0.9632 - val_loss: 0.5394 - val_acc: 0.9196\n",
      "Epoch 583/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1020 - acc: 0.9670\n",
      "Epoch 583: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1020 - acc: 0.9670 - val_loss: 0.5606 - val_acc: 0.9196\n",
      "Epoch 584/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9632\n",
      "Epoch 584: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0992 - acc: 0.9634 - val_loss: 0.5492 - val_acc: 0.9237\n",
      "Epoch 585/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9643\n",
      "Epoch 585: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0977 - acc: 0.9646 - val_loss: 0.5058 - val_acc: 0.9229\n",
      "Epoch 586/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9636\n",
      "Epoch 586: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0958 - acc: 0.9637 - val_loss: 0.5833 - val_acc: 0.9217\n",
      "Epoch 587/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1089 - acc: 0.9624\n",
      "Epoch 587: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1089 - acc: 0.9624 - val_loss: 0.5451 - val_acc: 0.9172\n",
      "Epoch 588/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9633\n",
      "Epoch 588: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1120 - acc: 0.9635 - val_loss: 0.5320 - val_acc: 0.9233\n",
      "Epoch 589/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9609\n",
      "Epoch 589: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1073 - acc: 0.9610 - val_loss: 0.4858 - val_acc: 0.9249\n",
      "Epoch 590/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9630\n",
      "Epoch 590: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1041 - acc: 0.9636 - val_loss: 0.4606 - val_acc: 0.9245\n",
      "Epoch 591/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9630\n",
      "Epoch 591: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1109 - acc: 0.9629 - val_loss: 0.4490 - val_acc: 0.9196\n",
      "Epoch 592/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9646\n",
      "Epoch 592: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.0953 - acc: 0.9647 - val_loss: 0.5337 - val_acc: 0.9217\n",
      "Epoch 593/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9617\n",
      "Epoch 593: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1069 - acc: 0.9617 - val_loss: 0.5648 - val_acc: 0.9253\n",
      "Epoch 594/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9589\n",
      "Epoch 594: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1075 - acc: 0.9591 - val_loss: 0.5076 - val_acc: 0.9249\n",
      "Epoch 595/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9635\n",
      "Epoch 595: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1018 - acc: 0.9635 - val_loss: 0.4997 - val_acc: 0.9278\n",
      "Epoch 596/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9643\n",
      "Epoch 596: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0986 - acc: 0.9643 - val_loss: 0.5162 - val_acc: 0.9290\n",
      "Epoch 597/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9612\n",
      "Epoch 597: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.1486 - acc: 0.9611 - val_loss: 0.5536 - val_acc: 0.9221\n",
      "Epoch 598/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9598\n",
      "Epoch 598: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1410 - acc: 0.9599 - val_loss: 0.4470 - val_acc: 0.9261\n",
      "Epoch 599/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9632\n",
      "Epoch 599: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1036 - acc: 0.9632 - val_loss: 0.4491 - val_acc: 0.9249\n",
      "Epoch 600/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9624\n",
      "Epoch 600: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1122 - acc: 0.9625 - val_loss: 0.5556 - val_acc: 0.9225\n",
      "Epoch 601/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9609\n",
      "Epoch 601: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1120 - acc: 0.9609 - val_loss: 0.5381 - val_acc: 0.9213\n",
      "Epoch 602/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1033 - acc: 0.9599\n",
      "Epoch 602: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1033 - acc: 0.9599 - val_loss: 0.5148 - val_acc: 0.9188\n",
      "Epoch 603/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9637\n",
      "Epoch 603: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0904 - acc: 0.9638 - val_loss: 0.5377 - val_acc: 0.9261\n",
      "Epoch 604/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9634\n",
      "Epoch 604: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0991 - acc: 0.9637 - val_loss: 0.4756 - val_acc: 0.9209\n",
      "Epoch 605/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1030 - acc: 0.9605\n",
      "Epoch 605: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1030 - acc: 0.9605 - val_loss: 0.4942 - val_acc: 0.9205\n",
      "Epoch 606/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9654\n",
      "Epoch 606: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1036 - acc: 0.9656 - val_loss: 0.5217 - val_acc: 0.9213\n",
      "Epoch 607/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9633\n",
      "Epoch 607: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1014 - acc: 0.9635 - val_loss: 0.5972 - val_acc: 0.9213\n",
      "Epoch 608/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9621\n",
      "Epoch 608: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1033 - acc: 0.9620 - val_loss: 0.4809 - val_acc: 0.9176\n",
      "Epoch 609/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9609\n",
      "Epoch 609: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1102 - acc: 0.9608 - val_loss: 0.4603 - val_acc: 0.9217\n",
      "Epoch 610/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9636\n",
      "Epoch 610: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1003 - acc: 0.9635 - val_loss: 0.4679 - val_acc: 0.9261\n",
      "Epoch 611/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9617\n",
      "Epoch 611: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1048 - acc: 0.9618 - val_loss: 0.4961 - val_acc: 0.9269\n",
      "Epoch 612/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9688\n",
      "Epoch 612: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0940 - acc: 0.9688 - val_loss: 0.5078 - val_acc: 0.9265\n",
      "Epoch 613/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1030 - acc: 0.9628\n",
      "Epoch 613: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1030 - acc: 0.9628 - val_loss: 0.5276 - val_acc: 0.9221\n",
      "Epoch 614/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9607\n",
      "Epoch 614: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1037 - acc: 0.9610 - val_loss: 0.5214 - val_acc: 0.9290\n",
      "Epoch 615/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9646\n",
      "Epoch 615: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0946 - acc: 0.9646 - val_loss: 0.5478 - val_acc: 0.9184\n",
      "Epoch 616/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9641\n",
      "Epoch 616: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1201 - acc: 0.9641 - val_loss: 0.4808 - val_acc: 0.9253\n",
      "Epoch 617/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9641\n",
      "Epoch 617: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1004 - acc: 0.9641 - val_loss: 0.4735 - val_acc: 0.9282\n",
      "Epoch 618/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9627\n",
      "Epoch 618: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1017 - acc: 0.9626 - val_loss: 0.4613 - val_acc: 0.9241\n",
      "Epoch 619/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9628\n",
      "Epoch 619: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1067 - acc: 0.9629 - val_loss: 0.5410 - val_acc: 0.9282\n",
      "Epoch 620/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9647\n",
      "Epoch 620: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0967 - acc: 0.9648 - val_loss: 0.5230 - val_acc: 0.9249\n",
      "Epoch 621/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9646\n",
      "Epoch 621: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0935 - acc: 0.9645 - val_loss: 0.4967 - val_acc: 0.9286\n",
      "Epoch 622/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9665\n",
      "Epoch 622: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1003 - acc: 0.9665 - val_loss: 0.5081 - val_acc: 0.9269\n",
      "Epoch 623/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9614\n",
      "Epoch 623: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1033 - acc: 0.9613 - val_loss: 0.5487 - val_acc: 0.9196\n",
      "Epoch 624/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9656\n",
      "Epoch 624: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0966 - acc: 0.9657 - val_loss: 0.5109 - val_acc: 0.9188\n",
      "Epoch 625/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9611\n",
      "Epoch 625: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0998 - acc: 0.9612 - val_loss: 0.5015 - val_acc: 0.9237\n",
      "Epoch 626/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1163 - acc: 0.9592\n",
      "Epoch 626: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1163 - acc: 0.9592 - val_loss: 0.4308 - val_acc: 0.9205\n",
      "Epoch 627/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9638\n",
      "Epoch 627: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1034 - acc: 0.9638 - val_loss: 0.5025 - val_acc: 0.9269\n",
      "Epoch 628/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9622\n",
      "Epoch 628: val_acc improved from 0.92898 to 0.92938, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1036 - acc: 0.9625 - val_loss: 0.4517 - val_acc: 0.9294\n",
      "Epoch 629/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9613\n",
      "Epoch 629: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1040 - acc: 0.9613 - val_loss: 0.4986 - val_acc: 0.9257\n",
      "Epoch 630/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9655\n",
      "Epoch 630: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0883 - acc: 0.9651 - val_loss: 0.4999 - val_acc: 0.9221\n",
      "Epoch 631/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9640\n",
      "Epoch 631: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0976 - acc: 0.9641 - val_loss: 0.5688 - val_acc: 0.9290\n",
      "Epoch 632/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9614\n",
      "Epoch 632: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0997 - acc: 0.9615 - val_loss: 0.5230 - val_acc: 0.9160\n",
      "Epoch 633/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9666\n",
      "Epoch 633: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0894 - acc: 0.9669 - val_loss: 0.4804 - val_acc: 0.9290\n",
      "Epoch 634/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9636\n",
      "Epoch 634: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1096 - acc: 0.9638 - val_loss: 0.4472 - val_acc: 0.9269\n",
      "Epoch 635/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9650\n",
      "Epoch 635: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0925 - acc: 0.9649 - val_loss: 0.5414 - val_acc: 0.9261\n",
      "Epoch 636/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9597\n",
      "Epoch 636: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1219 - acc: 0.9598 - val_loss: 0.4940 - val_acc: 0.9249\n",
      "Epoch 637/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9633\n",
      "Epoch 637: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1146 - acc: 0.9633 - val_loss: 0.4705 - val_acc: 0.9290\n",
      "Epoch 638/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9623\n",
      "Epoch 638: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1018 - acc: 0.9628 - val_loss: 0.4821 - val_acc: 0.9217\n",
      "Epoch 639/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9610\n",
      "Epoch 639: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1022 - acc: 0.9612 - val_loss: 0.4713 - val_acc: 0.9294\n",
      "Epoch 640/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9653\n",
      "Epoch 640: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.0925 - acc: 0.9652 - val_loss: 0.5133 - val_acc: 0.9253\n",
      "Epoch 641/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9648\n",
      "Epoch 641: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.0957 - acc: 0.9649 - val_loss: 0.5000 - val_acc: 0.9205\n",
      "Epoch 642/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9658\n",
      "Epoch 642: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.0997 - acc: 0.9655 - val_loss: 0.5165 - val_acc: 0.9176\n",
      "Epoch 643/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9655\n",
      "Epoch 643: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1030 - acc: 0.9655 - val_loss: 0.4480 - val_acc: 0.9217\n",
      "Epoch 644/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9610\n",
      "Epoch 644: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1041 - acc: 0.9610 - val_loss: 0.4970 - val_acc: 0.9176\n",
      "Epoch 645/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1191 - acc: 0.9613\n",
      "Epoch 645: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1190 - acc: 0.9613 - val_loss: 0.4185 - val_acc: 0.9290\n",
      "Epoch 646/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1005 - acc: 0.9613\n",
      "Epoch 646: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1005 - acc: 0.9613 - val_loss: 0.4967 - val_acc: 0.9209\n",
      "Epoch 647/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9626\n",
      "Epoch 647: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1023 - acc: 0.9626 - val_loss: 0.5192 - val_acc: 0.9241\n",
      "Epoch 648/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9668\n",
      "Epoch 648: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0876 - acc: 0.9671 - val_loss: 0.5056 - val_acc: 0.9245\n",
      "Epoch 649/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9613\n",
      "Epoch 649: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0994 - acc: 0.9613 - val_loss: 0.5950 - val_acc: 0.9205\n",
      "Epoch 650/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9638\n",
      "Epoch 650: val_acc did not improve from 0.92938\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1001 - acc: 0.9641 - val_loss: 0.4743 - val_acc: 0.9278\n",
      "Epoch 651/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1061 - acc: 0.9630\n",
      "Epoch 651: val_acc improved from 0.92938 to 0.93141, saving model to train_logs/logs7/FFT_ANN\\2\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1061 - acc: 0.9630 - val_loss: 0.5011 - val_acc: 0.9314\n",
      "Epoch 652/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9615\n",
      "Epoch 652: val_acc did not improve from 0.93141\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1000 - acc: 0.9616 - val_loss: 0.5086 - val_acc: 0.9233\n",
      "Epoch 653/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9633\n",
      "Epoch 653: val_acc did not improve from 0.93141\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0960 - acc: 0.9631 - val_loss: 0.5250 - val_acc: 0.9261\n",
      "Epoch 654/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9623\n",
      "Epoch 654: val_acc did not improve from 0.93141\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0918 - acc: 0.9623 - val_loss: 0.4855 - val_acc: 0.9298\n",
      "Epoch 655/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9615\n",
      "Epoch 655: val_acc did not improve from 0.93141\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1052 - acc: 0.9613 - val_loss: 0.5102 - val_acc: 0.9188\n",
      "Epoch 656/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9595\n",
      "Epoch 656: val_acc did not improve from 0.93141\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1046 - acc: 0.9599 - val_loss: 0.5406 - val_acc: 0.9274\n",
      "Epoch 657/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9606\n",
      "Epoch 657: val_acc did not improve from 0.93141\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1235 - acc: 0.9607 - val_loss: 0.5479 - val_acc: 0.9217\n",
      "Epoch 658/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9638\n",
      "Epoch 658: val_acc did not improve from 0.93141\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1067 - acc: 0.9640 - val_loss: 0.5276 - val_acc: 0.9249\n",
      "Epoch 659/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9637\n",
      "Epoch 659: val_acc did not improve from 0.93141\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0975 - acc: 0.9641 - val_loss: 0.5418 - val_acc: 0.9269\n",
      "Epoch 660/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9642\n",
      "Epoch 660: val_acc did not improve from 0.93141\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1002 - acc: 0.9642 - val_loss: 0.6197 - val_acc: 0.9237\n",
      "Epoch 661/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9643\n",
      "Epoch 661: val_acc did not improve from 0.93141\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1013 - acc: 0.9642 - val_loss: 0.5665 - val_acc: 0.9253\n",
      "Epoch 662/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9647\n",
      "Epoch 662: val_acc did not improve from 0.93141\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0916 - acc: 0.9648 - val_loss: 0.4936 - val_acc: 0.9306\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_2 (Reshape)         (None, 80, 1)             0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               41472     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,057\n",
      "Trainable params: 173,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.5940 - acc: 0.7174\n",
      "Epoch 1: val_acc improved from -inf to 0.78369, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.5907 - acc: 0.7180 - val_loss: 0.4566 - val_acc: 0.7837\n",
      "Epoch 2/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.4744 - acc: 0.7680\n",
      "Epoch 2: val_acc improved from 0.78369 to 0.80357, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.4736 - acc: 0.7681 - val_loss: 0.4223 - val_acc: 0.8036\n",
      "Epoch 3/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.7802\n",
      "Epoch 3: val_acc improved from 0.80357 to 0.81291, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.4495 - acc: 0.7803 - val_loss: 0.4030 - val_acc: 0.8129\n",
      "Epoch 4/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.4270 - acc: 0.7962\n",
      "Epoch 4: val_acc improved from 0.81291 to 0.81899, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.4254 - acc: 0.7970 - val_loss: 0.3737 - val_acc: 0.8190\n",
      "Epoch 5/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.4090 - acc: 0.8055\n",
      "Epoch 5: val_acc improved from 0.81899 to 0.82468, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.4084 - acc: 0.8059 - val_loss: 0.3714 - val_acc: 0.8247\n",
      "Epoch 6/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.3990 - acc: 0.8112\n",
      "Epoch 6: val_acc improved from 0.82468 to 0.82752, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3988 - acc: 0.8111 - val_loss: 0.3741 - val_acc: 0.8275\n",
      "Epoch 7/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.3860 - acc: 0.8189\n",
      "Epoch 7: val_acc improved from 0.82752 to 0.84253, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3854 - acc: 0.8191 - val_loss: 0.3485 - val_acc: 0.8425\n",
      "Epoch 8/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.3776 - acc: 0.8224\n",
      "Epoch 8: val_acc improved from 0.84253 to 0.84619, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3771 - acc: 0.8228 - val_loss: 0.3488 - val_acc: 0.8462\n",
      "Epoch 9/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.3730 - acc: 0.8243\n",
      "Epoch 9: val_acc did not improve from 0.84619\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3720 - acc: 0.8248 - val_loss: 0.3520 - val_acc: 0.8446\n",
      "Epoch 10/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.3625 - acc: 0.8309\n",
      "Epoch 10: val_acc did not improve from 0.84619\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3609 - acc: 0.8314 - val_loss: 0.3441 - val_acc: 0.8429\n",
      "Epoch 11/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.3555 - acc: 0.8353\n",
      "Epoch 11: val_acc improved from 0.84619 to 0.85024, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3544 - acc: 0.8357 - val_loss: 0.3325 - val_acc: 0.8502\n",
      "Epoch 12/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.3499 - acc: 0.8386\n",
      "Epoch 12: val_acc did not improve from 0.85024\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3492 - acc: 0.8391 - val_loss: 0.3342 - val_acc: 0.8462\n",
      "Epoch 13/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.3404 - acc: 0.8409\n",
      "Epoch 13: val_acc did not improve from 0.85024\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3395 - acc: 0.8413 - val_loss: 0.3345 - val_acc: 0.8478\n",
      "Epoch 14/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.3452 - acc: 0.8447\n",
      "Epoch 14: val_acc improved from 0.85024 to 0.85674, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3434 - acc: 0.8457 - val_loss: 0.3175 - val_acc: 0.8567\n",
      "Epoch 15/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.3328 - acc: 0.8460\n",
      "Epoch 15: val_acc improved from 0.85674 to 0.86445, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3316 - acc: 0.8467 - val_loss: 0.3234 - val_acc: 0.8644\n",
      "Epoch 16/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.3223 - acc: 0.8538\n",
      "Epoch 16: val_acc did not improve from 0.86445\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3218 - acc: 0.8539 - val_loss: 0.3140 - val_acc: 0.8604\n",
      "Epoch 17/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.3202 - acc: 0.8522\n",
      "Epoch 17: val_acc did not improve from 0.86445\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3196 - acc: 0.8525 - val_loss: 0.3111 - val_acc: 0.8644\n",
      "Epoch 18/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.8560\n",
      "Epoch 18: val_acc improved from 0.86445 to 0.86891, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3150 - acc: 0.8566 - val_loss: 0.3067 - val_acc: 0.8689\n",
      "Epoch 19/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.3111 - acc: 0.8630\n",
      "Epoch 19: val_acc improved from 0.86891 to 0.87297, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3108 - acc: 0.8626 - val_loss: 0.3076 - val_acc: 0.8730\n",
      "Epoch 20/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.3056 - acc: 0.8646\n",
      "Epoch 20: val_acc did not improve from 0.87297\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3056 - acc: 0.8644 - val_loss: 0.3065 - val_acc: 0.8624\n",
      "Epoch 21/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.8631\n",
      "Epoch 21: val_acc did not improve from 0.87297\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.3032 - acc: 0.8634 - val_loss: 0.2952 - val_acc: 0.8685\n",
      "Epoch 22/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2987 - acc: 0.8622\n",
      "Epoch 22: val_acc did not improve from 0.87297\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2983 - acc: 0.8620 - val_loss: 0.3021 - val_acc: 0.8669\n",
      "Epoch 23/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.3033 - acc: 0.8683\n",
      "Epoch 23: val_acc did not improve from 0.87297\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.3034 - acc: 0.8681 - val_loss: 0.3013 - val_acc: 0.8649\n",
      "Epoch 24/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2916 - acc: 0.8696\n",
      "Epoch 24: val_acc improved from 0.87297 to 0.87500, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2908 - acc: 0.8699 - val_loss: 0.2911 - val_acc: 0.8750\n",
      "Epoch 25/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2876 - acc: 0.8684\n",
      "Epoch 25: val_acc did not improve from 0.87500\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.2876 - acc: 0.8682 - val_loss: 0.2932 - val_acc: 0.8746\n",
      "Epoch 26/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.2871 - acc: 0.8688\n",
      "Epoch 26: val_acc improved from 0.87500 to 0.87703, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2855 - acc: 0.8693 - val_loss: 0.2937 - val_acc: 0.8770\n",
      "Epoch 27/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2867 - acc: 0.8732\n",
      "Epoch 27: val_acc improved from 0.87703 to 0.87865, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2864 - acc: 0.8735 - val_loss: 0.2908 - val_acc: 0.8787\n",
      "Epoch 28/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2828 - acc: 0.8735\n",
      "Epoch 28: val_acc improved from 0.87865 to 0.88109, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2826 - acc: 0.8738 - val_loss: 0.2778 - val_acc: 0.8811\n",
      "Epoch 29/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2824 - acc: 0.8781\n",
      "Epoch 29: val_acc did not improve from 0.88109\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2820 - acc: 0.8779 - val_loss: 0.2826 - val_acc: 0.8774\n",
      "Epoch 30/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2778 - acc: 0.8768\n",
      "Epoch 30: val_acc improved from 0.88109 to 0.88433, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2786 - acc: 0.8761 - val_loss: 0.2825 - val_acc: 0.8843\n",
      "Epoch 31/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2719 - acc: 0.8819\n",
      "Epoch 31: val_acc did not improve from 0.88433\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2718 - acc: 0.8822 - val_loss: 0.2763 - val_acc: 0.8839\n",
      "Epoch 32/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2664 - acc: 0.8788\n",
      "Epoch 32: val_acc improved from 0.88433 to 0.88596, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.2660 - acc: 0.8789 - val_loss: 0.2785 - val_acc: 0.8860\n",
      "Epoch 33/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2674 - acc: 0.8804\n",
      "Epoch 33: val_acc improved from 0.88596 to 0.89002, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2674 - acc: 0.8804 - val_loss: 0.2692 - val_acc: 0.8900\n",
      "Epoch 34/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2660 - acc: 0.8818\n",
      "Epoch 34: val_acc did not improve from 0.89002\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2656 - acc: 0.8816 - val_loss: 0.2880 - val_acc: 0.8819\n",
      "Epoch 35/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2637 - acc: 0.8829\n",
      "Epoch 35: val_acc did not improve from 0.89002\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2640 - acc: 0.8829 - val_loss: 0.2764 - val_acc: 0.8831\n",
      "Epoch 36/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2602 - acc: 0.8842\n",
      "Epoch 36: val_acc did not improve from 0.89002\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2603 - acc: 0.8840 - val_loss: 0.2853 - val_acc: 0.8888\n",
      "Epoch 37/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2579 - acc: 0.8857\n",
      "Epoch 37: val_acc improved from 0.89002 to 0.89164, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2574 - acc: 0.8860 - val_loss: 0.2779 - val_acc: 0.8916\n",
      "Epoch 38/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2548 - acc: 0.8879\n",
      "Epoch 38: val_acc did not improve from 0.89164\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2545 - acc: 0.8879 - val_loss: 0.2777 - val_acc: 0.8908\n",
      "Epoch 39/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2570 - acc: 0.8883\n",
      "Epoch 39: val_acc improved from 0.89164 to 0.89245, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2567 - acc: 0.8885 - val_loss: 0.2656 - val_acc: 0.8925\n",
      "Epoch 40/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2532 - acc: 0.8931\n",
      "Epoch 40: val_acc did not improve from 0.89245\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2531 - acc: 0.8932 - val_loss: 0.2750 - val_acc: 0.8892\n",
      "Epoch 41/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.8853\n",
      "Epoch 41: val_acc did not improve from 0.89245\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2609 - acc: 0.8851 - val_loss: 0.2803 - val_acc: 0.8896\n",
      "Epoch 42/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2494 - acc: 0.8894\n",
      "Epoch 42: val_acc improved from 0.89245 to 0.89367, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2493 - acc: 0.8895 - val_loss: 0.2715 - val_acc: 0.8937\n",
      "Epoch 43/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.2464 - acc: 0.8925\n",
      "Epoch 43: val_acc did not improve from 0.89367\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2455 - acc: 0.8929 - val_loss: 0.2885 - val_acc: 0.8839\n",
      "Epoch 44/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.8904\n",
      "Epoch 44: val_acc did not improve from 0.89367\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2466 - acc: 0.8903 - val_loss: 0.2837 - val_acc: 0.8925\n",
      "Epoch 45/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2388 - acc: 0.8953\n",
      "Epoch 45: val_acc improved from 0.89367 to 0.89773, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2380 - acc: 0.8958 - val_loss: 0.2665 - val_acc: 0.8977\n",
      "Epoch 46/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2451 - acc: 0.8967\n",
      "Epoch 46: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2452 - acc: 0.8964 - val_loss: 0.2846 - val_acc: 0.8851\n",
      "Epoch 47/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2459 - acc: 0.8942\n",
      "Epoch 47: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2456 - acc: 0.8941 - val_loss: 0.2705 - val_acc: 0.8908\n",
      "Epoch 48/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2345 - acc: 0.8960\n",
      "Epoch 48: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2343 - acc: 0.8957 - val_loss: 0.2909 - val_acc: 0.8803\n",
      "Epoch 49/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2427 - acc: 0.8942\n",
      "Epoch 49: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2418 - acc: 0.8946 - val_loss: 0.2828 - val_acc: 0.8864\n",
      "Epoch 50/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.8979\n",
      "Epoch 50: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2421 - acc: 0.8979 - val_loss: 0.2710 - val_acc: 0.8969\n",
      "Epoch 51/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.2327 - acc: 0.9009\n",
      "Epoch 51: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2327 - acc: 0.9008 - val_loss: 0.2786 - val_acc: 0.8888\n",
      "Epoch 52/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.8978\n",
      "Epoch 52: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2357 - acc: 0.8978 - val_loss: 0.2845 - val_acc: 0.8868\n",
      "Epoch 53/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2364 - acc: 0.8993\n",
      "Epoch 53: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2353 - acc: 0.8998 - val_loss: 0.2784 - val_acc: 0.8961\n",
      "Epoch 54/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2309 - acc: 0.9005\n",
      "Epoch 54: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2304 - acc: 0.9006 - val_loss: 0.2726 - val_acc: 0.8961\n",
      "Epoch 55/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9003\n",
      "Epoch 55: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2293 - acc: 0.9006 - val_loss: 0.2670 - val_acc: 0.8977\n",
      "Epoch 56/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2333 - acc: 0.9009\n",
      "Epoch 56: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2329 - acc: 0.9008 - val_loss: 0.2741 - val_acc: 0.8945\n",
      "Epoch 57/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2276 - acc: 0.9000\n",
      "Epoch 57: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2273 - acc: 0.9003 - val_loss: 0.2581 - val_acc: 0.8957\n",
      "Epoch 58/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2213 - acc: 0.9075\n",
      "Epoch 58: val_acc did not improve from 0.89773\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2211 - acc: 0.9076 - val_loss: 0.2679 - val_acc: 0.8908\n",
      "Epoch 59/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2293 - acc: 0.9028\n",
      "Epoch 59: val_acc improved from 0.89773 to 0.90057, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2288 - acc: 0.9030 - val_loss: 0.2564 - val_acc: 0.9006\n",
      "Epoch 60/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9016\n",
      "Epoch 60: val_acc did not improve from 0.90057\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2230 - acc: 0.9016 - val_loss: 0.2632 - val_acc: 0.8989\n",
      "Epoch 61/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2207 - acc: 0.9042\n",
      "Epoch 61: val_acc did not improve from 0.90057\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2207 - acc: 0.9042 - val_loss: 0.2619 - val_acc: 0.8969\n",
      "Epoch 62/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2179 - acc: 0.9049\n",
      "Epoch 62: val_acc improved from 0.90057 to 0.90219, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2179 - acc: 0.9049 - val_loss: 0.2722 - val_acc: 0.9022\n",
      "Epoch 63/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2235 - acc: 0.9039\n",
      "Epoch 63: val_acc did not improve from 0.90219\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2234 - acc: 0.9038 - val_loss: 0.2668 - val_acc: 0.9022\n",
      "Epoch 64/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2210 - acc: 0.9038\n",
      "Epoch 64: val_acc did not improve from 0.90219\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2214 - acc: 0.9036 - val_loss: 0.2632 - val_acc: 0.8985\n",
      "Epoch 65/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2181 - acc: 0.9066\n",
      "Epoch 65: val_acc improved from 0.90219 to 0.90300, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2176 - acc: 0.9068 - val_loss: 0.2697 - val_acc: 0.9030\n",
      "Epoch 66/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.2247 - acc: 0.9061\n",
      "Epoch 66: val_acc did not improve from 0.90300\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2245 - acc: 0.9063 - val_loss: 0.2665 - val_acc: 0.9022\n",
      "Epoch 67/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2113 - acc: 0.9089\n",
      "Epoch 67: val_acc did not improve from 0.90300\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2110 - acc: 0.9089 - val_loss: 0.2778 - val_acc: 0.8888\n",
      "Epoch 68/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2234 - acc: 0.9054\n",
      "Epoch 68: val_acc improved from 0.90300 to 0.90544, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2226 - acc: 0.9059 - val_loss: 0.2699 - val_acc: 0.9054\n",
      "Epoch 69/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9071\n",
      "Epoch 69: val_acc did not improve from 0.90544\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2121 - acc: 0.9076 - val_loss: 0.2734 - val_acc: 0.8998\n",
      "Epoch 70/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2155 - acc: 0.9095\n",
      "Epoch 70: val_acc did not improve from 0.90544\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2149 - acc: 0.9098 - val_loss: 0.3118 - val_acc: 0.9006\n",
      "Epoch 71/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9128\n",
      "Epoch 71: val_acc did not improve from 0.90544\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2138 - acc: 0.9125 - val_loss: 0.2769 - val_acc: 0.9030\n",
      "Epoch 72/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2117 - acc: 0.9093\n",
      "Epoch 72: val_acc did not improve from 0.90544\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2114 - acc: 0.9095 - val_loss: 0.2849 - val_acc: 0.8981\n",
      "Epoch 73/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2043 - acc: 0.9121\n",
      "Epoch 73: val_acc did not improve from 0.90544\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2037 - acc: 0.9124 - val_loss: 0.2720 - val_acc: 0.8957\n",
      "Epoch 74/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2139 - acc: 0.9119\n",
      "Epoch 74: val_acc did not improve from 0.90544\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2139 - acc: 0.9118 - val_loss: 0.2648 - val_acc: 0.9030\n",
      "Epoch 75/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2050 - acc: 0.9122\n",
      "Epoch 75: val_acc did not improve from 0.90544\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2050 - acc: 0.9120 - val_loss: 0.2747 - val_acc: 0.8957\n",
      "Epoch 76/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.2045 - acc: 0.9097\n",
      "Epoch 76: val_acc improved from 0.90544 to 0.90666, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2041 - acc: 0.9099 - val_loss: 0.2700 - val_acc: 0.9067\n",
      "Epoch 77/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2030 - acc: 0.9135\n",
      "Epoch 77: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2029 - acc: 0.9134 - val_loss: 0.2712 - val_acc: 0.9014\n",
      "Epoch 78/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2097 - acc: 0.9130\n",
      "Epoch 78: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2091 - acc: 0.9130 - val_loss: 0.2969 - val_acc: 0.9018\n",
      "Epoch 79/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9120\n",
      "Epoch 79: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2066 - acc: 0.9121 - val_loss: 0.2640 - val_acc: 0.9042\n",
      "Epoch 80/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9101\n",
      "Epoch 80: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2021 - acc: 0.9100 - val_loss: 0.2992 - val_acc: 0.8896\n",
      "Epoch 81/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2035 - acc: 0.9153\n",
      "Epoch 81: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2029 - acc: 0.9152 - val_loss: 0.2879 - val_acc: 0.8973\n",
      "Epoch 82/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2014 - acc: 0.9138\n",
      "Epoch 82: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2022 - acc: 0.9136 - val_loss: 0.2979 - val_acc: 0.8908\n",
      "Epoch 83/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.2076 - acc: 0.9143\n",
      "Epoch 83: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2064 - acc: 0.9149 - val_loss: 0.3002 - val_acc: 0.8985\n",
      "Epoch 84/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2042 - acc: 0.9132\n",
      "Epoch 84: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2043 - acc: 0.9130 - val_loss: 0.2930 - val_acc: 0.9046\n",
      "Epoch 85/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.2046 - acc: 0.9158\n",
      "Epoch 85: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2043 - acc: 0.9158 - val_loss: 0.2891 - val_acc: 0.8953\n",
      "Epoch 86/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9153\n",
      "Epoch 86: val_acc did not improve from 0.90666\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1953 - acc: 0.9154 - val_loss: 0.2759 - val_acc: 0.9018\n",
      "Epoch 87/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1963 - acc: 0.9200\n",
      "Epoch 87: val_acc improved from 0.90666 to 0.90869, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1961 - acc: 0.9200 - val_loss: 0.2838 - val_acc: 0.9087\n",
      "Epoch 88/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1999 - acc: 0.9121\n",
      "Epoch 88: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1998 - acc: 0.9121 - val_loss: 0.2753 - val_acc: 0.9030\n",
      "Epoch 89/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9189\n",
      "Epoch 89: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2035 - acc: 0.9190 - val_loss: 0.2742 - val_acc: 0.9046\n",
      "Epoch 90/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1951 - acc: 0.9184\n",
      "Epoch 90: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1946 - acc: 0.9182 - val_loss: 0.2962 - val_acc: 0.9062\n",
      "Epoch 91/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9167\n",
      "Epoch 91: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1976 - acc: 0.9169 - val_loss: 0.2972 - val_acc: 0.9079\n",
      "Epoch 92/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9161\n",
      "Epoch 92: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1966 - acc: 0.9163 - val_loss: 0.2888 - val_acc: 0.9042\n",
      "Epoch 93/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1969 - acc: 0.9190\n",
      "Epoch 93: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1967 - acc: 0.9187 - val_loss: 0.2669 - val_acc: 0.9022\n",
      "Epoch 94/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1944 - acc: 0.9148\n",
      "Epoch 94: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1942 - acc: 0.9150 - val_loss: 0.3032 - val_acc: 0.8998\n",
      "Epoch 95/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1969 - acc: 0.9198\n",
      "Epoch 95: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1967 - acc: 0.9194 - val_loss: 0.2833 - val_acc: 0.8973\n",
      "Epoch 96/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1952 - acc: 0.9202\n",
      "Epoch 96: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1950 - acc: 0.9202 - val_loss: 0.2733 - val_acc: 0.9054\n",
      "Epoch 97/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1897 - acc: 0.9160\n",
      "Epoch 97: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1894 - acc: 0.9162 - val_loss: 0.2846 - val_acc: 0.9079\n",
      "Epoch 98/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9168\n",
      "Epoch 98: val_acc improved from 0.90869 to 0.90909, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1908 - acc: 0.9170 - val_loss: 0.2831 - val_acc: 0.9091\n",
      "Epoch 99/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1957 - acc: 0.9191\n",
      "Epoch 99: val_acc did not improve from 0.90909\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1956 - acc: 0.9191 - val_loss: 0.2872 - val_acc: 0.9038\n",
      "Epoch 100/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9205\n",
      "Epoch 100: val_acc did not improve from 0.90909\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1838 - acc: 0.9208 - val_loss: 0.3084 - val_acc: 0.9034\n",
      "Epoch 101/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1943 - acc: 0.9193\n",
      "Epoch 101: val_acc did not improve from 0.90909\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1936 - acc: 0.9197 - val_loss: 0.2920 - val_acc: 0.9030\n",
      "Epoch 102/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1842 - acc: 0.9211\n",
      "Epoch 102: val_acc did not improve from 0.90909\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1842 - acc: 0.9211 - val_loss: 0.3064 - val_acc: 0.9046\n",
      "Epoch 103/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1783 - acc: 0.9251\n",
      "Epoch 103: val_acc did not improve from 0.90909\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1781 - acc: 0.9252 - val_loss: 0.3234 - val_acc: 0.9046\n",
      "Epoch 104/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1867 - acc: 0.9226\n",
      "Epoch 104: val_acc improved from 0.90909 to 0.91112, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1863 - acc: 0.9227 - val_loss: 0.2909 - val_acc: 0.9111\n",
      "Epoch 105/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1798 - acc: 0.9243\n",
      "Epoch 105: val_acc improved from 0.91112 to 0.91153, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1789 - acc: 0.9247 - val_loss: 0.3121 - val_acc: 0.9115\n",
      "Epoch 106/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1851 - acc: 0.9233\n",
      "Epoch 106: val_acc improved from 0.91153 to 0.91234, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1849 - acc: 0.9234 - val_loss: 0.2749 - val_acc: 0.9123\n",
      "Epoch 107/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9273\n",
      "Epoch 107: val_acc did not improve from 0.91234\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1804 - acc: 0.9273 - val_loss: 0.2681 - val_acc: 0.9071\n",
      "Epoch 108/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9226\n",
      "Epoch 108: val_acc did not improve from 0.91234\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1916 - acc: 0.9228 - val_loss: 0.2808 - val_acc: 0.9079\n",
      "Epoch 109/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9210\n",
      "Epoch 109: val_acc improved from 0.91234 to 0.91274, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1826 - acc: 0.9212 - val_loss: 0.2868 - val_acc: 0.9127\n",
      "Epoch 110/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1869 - acc: 0.9224\n",
      "Epoch 110: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1863 - acc: 0.9228 - val_loss: 0.2858 - val_acc: 0.9075\n",
      "Epoch 111/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1829 - acc: 0.9219\n",
      "Epoch 111: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1829 - acc: 0.9219 - val_loss: 0.3007 - val_acc: 0.8920\n",
      "Epoch 112/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9229\n",
      "Epoch 112: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1829 - acc: 0.9232 - val_loss: 0.2877 - val_acc: 0.9050\n",
      "Epoch 113/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1788 - acc: 0.9240\n",
      "Epoch 113: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1782 - acc: 0.9243 - val_loss: 0.2973 - val_acc: 0.9054\n",
      "Epoch 114/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9258\n",
      "Epoch 114: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1815 - acc: 0.9260 - val_loss: 0.3029 - val_acc: 0.9062\n",
      "Epoch 115/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1818 - acc: 0.9270\n",
      "Epoch 115: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1804 - acc: 0.9275 - val_loss: 0.3236 - val_acc: 0.9067\n",
      "Epoch 116/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9251\n",
      "Epoch 116: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1861 - acc: 0.9255 - val_loss: 0.3108 - val_acc: 0.9095\n",
      "Epoch 117/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1760 - acc: 0.9279\n",
      "Epoch 117: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1758 - acc: 0.9281 - val_loss: 0.3231 - val_acc: 0.9067\n",
      "Epoch 118/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9255\n",
      "Epoch 118: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1759 - acc: 0.9256 - val_loss: 0.3134 - val_acc: 0.9099\n",
      "Epoch 119/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.9274\n",
      "Epoch 119: val_acc improved from 0.91274 to 0.91558, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1756 - acc: 0.9277 - val_loss: 0.2994 - val_acc: 0.9156\n",
      "Epoch 120/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9252\n",
      "Epoch 120: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1749 - acc: 0.9256 - val_loss: 0.2935 - val_acc: 0.9107\n",
      "Epoch 121/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2013 - acc: 0.9266\n",
      "Epoch 121: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2008 - acc: 0.9270 - val_loss: 0.3105 - val_acc: 0.9111\n",
      "Epoch 122/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9291\n",
      "Epoch 122: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1734 - acc: 0.9293 - val_loss: 0.3214 - val_acc: 0.9123\n",
      "Epoch 123/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1797 - acc: 0.9248\n",
      "Epoch 123: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1791 - acc: 0.9252 - val_loss: 0.3132 - val_acc: 0.9038\n",
      "Epoch 124/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1727 - acc: 0.9271\n",
      "Epoch 124: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1727 - acc: 0.9271 - val_loss: 0.3230 - val_acc: 0.9030\n",
      "Epoch 125/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1773 - acc: 0.9235\n",
      "Epoch 125: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1773 - acc: 0.9235 - val_loss: 0.2971 - val_acc: 0.9127\n",
      "Epoch 126/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1721 - acc: 0.9284\n",
      "Epoch 126: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1720 - acc: 0.9286 - val_loss: 0.3175 - val_acc: 0.9083\n",
      "Epoch 127/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1732 - acc: 0.9270\n",
      "Epoch 127: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1726 - acc: 0.9272 - val_loss: 0.3071 - val_acc: 0.9087\n",
      "Epoch 128/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1736 - acc: 0.9297\n",
      "Epoch 128: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1730 - acc: 0.9300 - val_loss: 0.3092 - val_acc: 0.9079\n",
      "Epoch 129/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9266\n",
      "Epoch 129: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1773 - acc: 0.9266 - val_loss: 0.3114 - val_acc: 0.9038\n",
      "Epoch 130/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9300\n",
      "Epoch 130: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1703 - acc: 0.9304 - val_loss: 0.3029 - val_acc: 0.9062\n",
      "Epoch 131/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1760 - acc: 0.9285\n",
      "Epoch 131: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1767 - acc: 0.9282 - val_loss: 0.2912 - val_acc: 0.9083\n",
      "Epoch 132/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9277\n",
      "Epoch 132: val_acc improved from 0.91558 to 0.92127, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1668 - acc: 0.9278 - val_loss: 0.2965 - val_acc: 0.9213\n",
      "Epoch 133/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9309\n",
      "Epoch 133: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1729 - acc: 0.9307 - val_loss: 0.3137 - val_acc: 0.9144\n",
      "Epoch 134/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1803 - acc: 0.9311\n",
      "Epoch 134: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1804 - acc: 0.9311 - val_loss: 0.3203 - val_acc: 0.9095\n",
      "Epoch 135/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1773 - acc: 0.9308\n",
      "Epoch 135: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1771 - acc: 0.9310 - val_loss: 0.2968 - val_acc: 0.9054\n",
      "Epoch 136/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1784 - acc: 0.9279\n",
      "Epoch 136: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1782 - acc: 0.9281 - val_loss: 0.2818 - val_acc: 0.9160\n",
      "Epoch 137/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1662 - acc: 0.9315\n",
      "Epoch 137: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1662 - acc: 0.9315 - val_loss: 0.3140 - val_acc: 0.9046\n",
      "Epoch 138/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9299\n",
      "Epoch 138: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1686 - acc: 0.9303 - val_loss: 0.3111 - val_acc: 0.9083\n",
      "Epoch 139/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9326\n",
      "Epoch 139: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1680 - acc: 0.9326 - val_loss: 0.3043 - val_acc: 0.9196\n",
      "Epoch 140/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9312\n",
      "Epoch 140: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1673 - acc: 0.9315 - val_loss: 0.3095 - val_acc: 0.9164\n",
      "Epoch 141/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9292\n",
      "Epoch 141: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1670 - acc: 0.9296 - val_loss: 0.3489 - val_acc: 0.9050\n",
      "Epoch 142/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1667 - acc: 0.9352\n",
      "Epoch 142: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1665 - acc: 0.9353 - val_loss: 0.3116 - val_acc: 0.9152\n",
      "Epoch 143/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9305\n",
      "Epoch 143: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1737 - acc: 0.9306 - val_loss: 0.3074 - val_acc: 0.9144\n",
      "Epoch 144/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9318\n",
      "Epoch 144: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1659 - acc: 0.9320 - val_loss: 0.3434 - val_acc: 0.9103\n",
      "Epoch 145/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1640 - acc: 0.9325\n",
      "Epoch 145: val_acc did not improve from 0.92127\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1636 - acc: 0.9328 - val_loss: 0.3327 - val_acc: 0.9156\n",
      "Epoch 146/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9338\n",
      "Epoch 146: val_acc improved from 0.92127 to 0.92208, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1604 - acc: 0.9338 - val_loss: 0.3221 - val_acc: 0.9221\n",
      "Epoch 147/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1671 - acc: 0.9333\n",
      "Epoch 147: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1667 - acc: 0.9334 - val_loss: 0.3304 - val_acc: 0.9095\n",
      "Epoch 148/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9335\n",
      "Epoch 148: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1597 - acc: 0.9335 - val_loss: 0.3421 - val_acc: 0.9119\n",
      "Epoch 149/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9352\n",
      "Epoch 149: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1620 - acc: 0.9349 - val_loss: 0.3400 - val_acc: 0.9107\n",
      "Epoch 150/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9338\n",
      "Epoch 150: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1558 - acc: 0.9337 - val_loss: 0.3621 - val_acc: 0.9160\n",
      "Epoch 151/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1619 - acc: 0.9337\n",
      "Epoch 151: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1619 - acc: 0.9337 - val_loss: 0.3322 - val_acc: 0.9038\n",
      "Epoch 152/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1754 - acc: 0.9311\n",
      "Epoch 152: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1747 - acc: 0.9311 - val_loss: 0.3095 - val_acc: 0.9188\n",
      "Epoch 153/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9357\n",
      "Epoch 153: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1592 - acc: 0.9360 - val_loss: 0.3377 - val_acc: 0.9127\n",
      "Epoch 154/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9329\n",
      "Epoch 154: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1625 - acc: 0.9326 - val_loss: 0.3381 - val_acc: 0.9107\n",
      "Epoch 155/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1663 - acc: 0.9352\n",
      "Epoch 155: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1663 - acc: 0.9352 - val_loss: 0.3440 - val_acc: 0.9103\n",
      "Epoch 156/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1612 - acc: 0.9372\n",
      "Epoch 156: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1610 - acc: 0.9372 - val_loss: 0.3460 - val_acc: 0.9022\n",
      "Epoch 157/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1590 - acc: 0.9352\n",
      "Epoch 157: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1582 - acc: 0.9357 - val_loss: 0.2867 - val_acc: 0.9217\n",
      "Epoch 158/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1573 - acc: 0.9305\n",
      "Epoch 158: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1569 - acc: 0.9307 - val_loss: 0.3136 - val_acc: 0.9184\n",
      "Epoch 159/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9385\n",
      "Epoch 159: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1506 - acc: 0.9383 - val_loss: 0.3116 - val_acc: 0.9168\n",
      "Epoch 160/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1615 - acc: 0.9343\n",
      "Epoch 160: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1611 - acc: 0.9344 - val_loss: 0.3728 - val_acc: 0.9071\n",
      "Epoch 161/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1612 - acc: 0.9382\n",
      "Epoch 161: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1604 - acc: 0.9385 - val_loss: 0.3249 - val_acc: 0.9160\n",
      "Epoch 162/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9340\n",
      "Epoch 162: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1580 - acc: 0.9343 - val_loss: 0.3462 - val_acc: 0.9127\n",
      "Epoch 163/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1651 - acc: 0.9367\n",
      "Epoch 163: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1648 - acc: 0.9367 - val_loss: 0.3156 - val_acc: 0.9042\n",
      "Epoch 164/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9391\n",
      "Epoch 164: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1516 - acc: 0.9393 - val_loss: 0.3136 - val_acc: 0.9127\n",
      "Epoch 165/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9375\n",
      "Epoch 165: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1550 - acc: 0.9376 - val_loss: 0.3139 - val_acc: 0.9119\n",
      "Epoch 166/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1615 - acc: 0.9340\n",
      "Epoch 166: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1613 - acc: 0.9340 - val_loss: 0.3241 - val_acc: 0.9164\n",
      "Epoch 167/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9369\n",
      "Epoch 167: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1650 - acc: 0.9366 - val_loss: 0.3261 - val_acc: 0.9184\n",
      "Epoch 168/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9368\n",
      "Epoch 168: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1541 - acc: 0.9371 - val_loss: 0.2960 - val_acc: 0.9148\n",
      "Epoch 169/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9362\n",
      "Epoch 169: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1536 - acc: 0.9360 - val_loss: 0.3177 - val_acc: 0.9115\n",
      "Epoch 170/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9368\n",
      "Epoch 170: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1596 - acc: 0.9366 - val_loss: 0.3560 - val_acc: 0.9067\n",
      "Epoch 171/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9373\n",
      "Epoch 171: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1541 - acc: 0.9375 - val_loss: 0.3766 - val_acc: 0.9127\n",
      "Epoch 172/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9391\n",
      "Epoch 172: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1503 - acc: 0.9392 - val_loss: 0.3687 - val_acc: 0.9176\n",
      "Epoch 173/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9375\n",
      "Epoch 173: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1530 - acc: 0.9372 - val_loss: 0.3525 - val_acc: 0.9091\n",
      "Epoch 174/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9374\n",
      "Epoch 174: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1549 - acc: 0.9376 - val_loss: 0.3477 - val_acc: 0.9200\n",
      "Epoch 175/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9379\n",
      "Epoch 175: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1500 - acc: 0.9380 - val_loss: 0.3358 - val_acc: 0.9152\n",
      "Epoch 176/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9396\n",
      "Epoch 176: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1563 - acc: 0.9396 - val_loss: 0.3601 - val_acc: 0.9188\n",
      "Epoch 177/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9393\n",
      "Epoch 177: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1513 - acc: 0.9392 - val_loss: 0.3432 - val_acc: 0.9123\n",
      "Epoch 178/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1561 - acc: 0.9376\n",
      "Epoch 178: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1551 - acc: 0.9379 - val_loss: 0.3544 - val_acc: 0.9115\n",
      "Epoch 179/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9383\n",
      "Epoch 179: val_acc did not improve from 0.92208\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1519 - acc: 0.9383 - val_loss: 0.3108 - val_acc: 0.9221\n",
      "Epoch 180/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9430\n",
      "Epoch 180: val_acc improved from 0.92208 to 0.92492, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1466 - acc: 0.9432 - val_loss: 0.3399 - val_acc: 0.9249\n",
      "Epoch 181/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9411\n",
      "Epoch 181: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1472 - acc: 0.9413 - val_loss: 0.3353 - val_acc: 0.9196\n",
      "Epoch 182/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9412\n",
      "Epoch 182: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1578 - acc: 0.9411 - val_loss: 0.3324 - val_acc: 0.9188\n",
      "Epoch 183/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1590 - acc: 0.9370\n",
      "Epoch 183: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1577 - acc: 0.9373 - val_loss: 0.3254 - val_acc: 0.9136\n",
      "Epoch 184/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9377\n",
      "Epoch 184: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1448 - acc: 0.9381 - val_loss: 0.3462 - val_acc: 0.9192\n",
      "Epoch 185/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9387\n",
      "Epoch 185: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1531 - acc: 0.9381 - val_loss: 0.3282 - val_acc: 0.9205\n",
      "Epoch 186/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1471 - acc: 0.9378\n",
      "Epoch 186: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1466 - acc: 0.9380 - val_loss: 0.3381 - val_acc: 0.9184\n",
      "Epoch 187/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9402\n",
      "Epoch 187: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1543 - acc: 0.9399 - val_loss: 0.3754 - val_acc: 0.9164\n",
      "Epoch 188/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9406\n",
      "Epoch 188: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1485 - acc: 0.9413 - val_loss: 0.3806 - val_acc: 0.9160\n",
      "Epoch 189/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9403\n",
      "Epoch 189: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1495 - acc: 0.9404 - val_loss: 0.3286 - val_acc: 0.9180\n",
      "Epoch 190/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9439\n",
      "Epoch 190: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1431 - acc: 0.9437 - val_loss: 0.3312 - val_acc: 0.9205\n",
      "Epoch 191/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1427 - acc: 0.9380\n",
      "Epoch 191: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1424 - acc: 0.9380 - val_loss: 0.3619 - val_acc: 0.9200\n",
      "Epoch 192/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9399\n",
      "Epoch 192: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1499 - acc: 0.9401 - val_loss: 0.3547 - val_acc: 0.9160\n",
      "Epoch 193/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9375\n",
      "Epoch 193: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1545 - acc: 0.9374 - val_loss: 0.3125 - val_acc: 0.9176\n",
      "Epoch 194/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1531 - acc: 0.9412\n",
      "Epoch 194: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1531 - acc: 0.9412 - val_loss: 0.3272 - val_acc: 0.9067\n",
      "Epoch 195/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9422\n",
      "Epoch 195: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1403 - acc: 0.9421 - val_loss: 0.3216 - val_acc: 0.9119\n",
      "Epoch 196/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9393\n",
      "Epoch 196: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1533 - acc: 0.9395 - val_loss: 0.3331 - val_acc: 0.9144\n",
      "Epoch 197/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9417\n",
      "Epoch 197: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1499 - acc: 0.9419 - val_loss: 0.3390 - val_acc: 0.9144\n",
      "Epoch 198/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9395\n",
      "Epoch 198: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1414 - acc: 0.9400 - val_loss: 0.3438 - val_acc: 0.9144\n",
      "Epoch 199/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9401\n",
      "Epoch 199: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1545 - acc: 0.9404 - val_loss: 0.3221 - val_acc: 0.9188\n",
      "Epoch 200/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9410\n",
      "Epoch 200: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1428 - acc: 0.9409 - val_loss: 0.3265 - val_acc: 0.9087\n",
      "Epoch 201/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9385\n",
      "Epoch 201: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1503 - acc: 0.9386 - val_loss: 0.3297 - val_acc: 0.9111\n",
      "Epoch 202/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9424\n",
      "Epoch 202: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1435 - acc: 0.9424 - val_loss: 0.3726 - val_acc: 0.9144\n",
      "Epoch 203/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9399\n",
      "Epoch 203: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1484 - acc: 0.9401 - val_loss: 0.3518 - val_acc: 0.9131\n",
      "Epoch 204/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9407\n",
      "Epoch 204: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1441 - acc: 0.9413 - val_loss: 0.3602 - val_acc: 0.9156\n",
      "Epoch 205/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9457\n",
      "Epoch 205: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1403 - acc: 0.9456 - val_loss: 0.3874 - val_acc: 0.9164\n",
      "Epoch 206/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9408\n",
      "Epoch 206: val_acc did not improve from 0.92492\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1354 - acc: 0.9409 - val_loss: 0.3767 - val_acc: 0.9245\n",
      "Epoch 207/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9406\n",
      "Epoch 207: val_acc improved from 0.92492 to 0.92532, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1431 - acc: 0.9410 - val_loss: 0.3666 - val_acc: 0.9253\n",
      "Epoch 208/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1350 - acc: 0.9451\n",
      "Epoch 208: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1342 - acc: 0.9453 - val_loss: 0.3898 - val_acc: 0.9213\n",
      "Epoch 209/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9390\n",
      "Epoch 209: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1517 - acc: 0.9393 - val_loss: 0.3524 - val_acc: 0.9160\n",
      "Epoch 210/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9464\n",
      "Epoch 210: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1291 - acc: 0.9462 - val_loss: 0.4190 - val_acc: 0.9119\n",
      "Epoch 211/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1514 - acc: 0.9443\n",
      "Epoch 211: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1511 - acc: 0.9444 - val_loss: 0.3551 - val_acc: 0.9237\n",
      "Epoch 212/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9414\n",
      "Epoch 212: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1449 - acc: 0.9413 - val_loss: 0.3856 - val_acc: 0.9115\n",
      "Epoch 213/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9406\n",
      "Epoch 213: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1526 - acc: 0.9410 - val_loss: 0.3627 - val_acc: 0.9180\n",
      "Epoch 214/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9406\n",
      "Epoch 214: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1405 - acc: 0.9409 - val_loss: 0.3622 - val_acc: 0.9119\n",
      "Epoch 215/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9427\n",
      "Epoch 215: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1514 - acc: 0.9428 - val_loss: 0.3728 - val_acc: 0.9168\n",
      "Epoch 216/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9424\n",
      "Epoch 216: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1427 - acc: 0.9425 - val_loss: 0.3559 - val_acc: 0.9188\n",
      "Epoch 217/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9424\n",
      "Epoch 217: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1387 - acc: 0.9425 - val_loss: 0.3676 - val_acc: 0.9213\n",
      "Epoch 218/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9463\n",
      "Epoch 218: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1481 - acc: 0.9463 - val_loss: 0.3391 - val_acc: 0.9192\n",
      "Epoch 219/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9420\n",
      "Epoch 219: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1416 - acc: 0.9420 - val_loss: 0.3237 - val_acc: 0.9176\n",
      "Epoch 220/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1400 - acc: 0.9440\n",
      "Epoch 220: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1400 - acc: 0.9440 - val_loss: 0.3538 - val_acc: 0.9168\n",
      "Epoch 221/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9412\n",
      "Epoch 221: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1431 - acc: 0.9415 - val_loss: 0.3658 - val_acc: 0.9164\n",
      "Epoch 222/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9445\n",
      "Epoch 222: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1515 - acc: 0.9448 - val_loss: 0.3700 - val_acc: 0.9196\n",
      "Epoch 223/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9450\n",
      "Epoch 223: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1437 - acc: 0.9452 - val_loss: 0.3822 - val_acc: 0.9184\n",
      "Epoch 224/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9441\n",
      "Epoch 224: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1435 - acc: 0.9445 - val_loss: 0.3817 - val_acc: 0.9253\n",
      "Epoch 225/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9434\n",
      "Epoch 225: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1437 - acc: 0.9436 - val_loss: 0.3688 - val_acc: 0.9205\n",
      "Epoch 226/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9442\n",
      "Epoch 226: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1484 - acc: 0.9444 - val_loss: 0.4188 - val_acc: 0.9115\n",
      "Epoch 227/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1350 - acc: 0.9463\n",
      "Epoch 227: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1344 - acc: 0.9466 - val_loss: 0.4114 - val_acc: 0.9168\n",
      "Epoch 228/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9434\n",
      "Epoch 228: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1399 - acc: 0.9436 - val_loss: 0.3623 - val_acc: 0.9188\n",
      "Epoch 229/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9431\n",
      "Epoch 229: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1431 - acc: 0.9431 - val_loss: 0.3439 - val_acc: 0.9241\n",
      "Epoch 230/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9488\n",
      "Epoch 230: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1288 - acc: 0.9490 - val_loss: 0.4041 - val_acc: 0.9188\n",
      "Epoch 231/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1434 - acc: 0.9438\n",
      "Epoch 231: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1434 - acc: 0.9438 - val_loss: 0.3917 - val_acc: 0.9123\n",
      "Epoch 232/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9487\n",
      "Epoch 232: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1334 - acc: 0.9487 - val_loss: 0.3828 - val_acc: 0.9164\n",
      "Epoch 233/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9429\n",
      "Epoch 233: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1554 - acc: 0.9431 - val_loss: 0.4000 - val_acc: 0.9156\n",
      "Epoch 234/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9446\n",
      "Epoch 234: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1331 - acc: 0.9447 - val_loss: 0.3869 - val_acc: 0.9131\n",
      "Epoch 235/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9420\n",
      "Epoch 235: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1657 - acc: 0.9420 - val_loss: 0.4427 - val_acc: 0.9140\n",
      "Epoch 236/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1460 - acc: 0.9439\n",
      "Epoch 236: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1457 - acc: 0.9441 - val_loss: 0.3444 - val_acc: 0.9213\n",
      "Epoch 237/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9452\n",
      "Epoch 237: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1373 - acc: 0.9454 - val_loss: 0.3824 - val_acc: 0.9176\n",
      "Epoch 238/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1346 - acc: 0.9460\n",
      "Epoch 238: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1343 - acc: 0.9459 - val_loss: 0.3927 - val_acc: 0.9176\n",
      "Epoch 239/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1410 - acc: 0.9454\n",
      "Epoch 239: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1410 - acc: 0.9454 - val_loss: 0.3532 - val_acc: 0.9083\n",
      "Epoch 240/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9448\n",
      "Epoch 240: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1375 - acc: 0.9448 - val_loss: 0.3878 - val_acc: 0.9213\n",
      "Epoch 241/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9468\n",
      "Epoch 241: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1391 - acc: 0.9465 - val_loss: 0.4248 - val_acc: 0.9196\n",
      "Epoch 242/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9425\n",
      "Epoch 242: val_acc did not improve from 0.92532\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1363 - acc: 0.9428 - val_loss: 0.4009 - val_acc: 0.9180\n",
      "Epoch 243/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9431\n",
      "Epoch 243: val_acc improved from 0.92532 to 0.92573, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1411 - acc: 0.9434 - val_loss: 0.4019 - val_acc: 0.9257\n",
      "Epoch 244/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9502\n",
      "Epoch 244: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1283 - acc: 0.9503 - val_loss: 0.4024 - val_acc: 0.9164\n",
      "Epoch 245/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9435\n",
      "Epoch 245: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1360 - acc: 0.9436 - val_loss: 0.3543 - val_acc: 0.9172\n",
      "Epoch 246/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9452\n",
      "Epoch 246: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1422 - acc: 0.9453 - val_loss: 0.3710 - val_acc: 0.9229\n",
      "Epoch 247/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9452\n",
      "Epoch 247: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1340 - acc: 0.9455 - val_loss: 0.3677 - val_acc: 0.9229\n",
      "Epoch 248/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9431\n",
      "Epoch 248: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1323 - acc: 0.9432 - val_loss: 0.3882 - val_acc: 0.9131\n",
      "Epoch 249/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9453\n",
      "Epoch 249: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1401 - acc: 0.9458 - val_loss: 0.3953 - val_acc: 0.9205\n",
      "Epoch 250/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1663 - acc: 0.9457\n",
      "Epoch 250: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1659 - acc: 0.9458 - val_loss: 0.4423 - val_acc: 0.9140\n",
      "Epoch 251/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9477\n",
      "Epoch 251: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1394 - acc: 0.9477 - val_loss: 0.4124 - val_acc: 0.9209\n",
      "Epoch 252/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9492\n",
      "Epoch 252: val_acc improved from 0.92573 to 0.92654, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1286 - acc: 0.9496 - val_loss: 0.3968 - val_acc: 0.9265\n",
      "Epoch 253/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9458\n",
      "Epoch 253: val_acc did not improve from 0.92654\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1368 - acc: 0.9459 - val_loss: 0.4503 - val_acc: 0.9205\n",
      "Epoch 254/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1562 - acc: 0.9446\n",
      "Epoch 254: val_acc did not improve from 0.92654\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1549 - acc: 0.9452 - val_loss: 0.3987 - val_acc: 0.9217\n",
      "Epoch 255/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9466\n",
      "Epoch 255: val_acc did not improve from 0.92654\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1339 - acc: 0.9469 - val_loss: 0.4230 - val_acc: 0.9205\n",
      "Epoch 256/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9480\n",
      "Epoch 256: val_acc did not improve from 0.92654\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1253 - acc: 0.9481 - val_loss: 0.4381 - val_acc: 0.9241\n",
      "Epoch 257/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9471\n",
      "Epoch 257: val_acc did not improve from 0.92654\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1335 - acc: 0.9472 - val_loss: 0.3830 - val_acc: 0.9148\n",
      "Epoch 258/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9449\n",
      "Epoch 258: val_acc did not improve from 0.92654\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1366 - acc: 0.9454 - val_loss: 0.4102 - val_acc: 0.9213\n",
      "Epoch 259/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9460\n",
      "Epoch 259: val_acc did not improve from 0.92654\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1340 - acc: 0.9458 - val_loss: 0.4179 - val_acc: 0.9176\n",
      "Epoch 260/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1555 - acc: 0.9430\n",
      "Epoch 260: val_acc did not improve from 0.92654\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1557 - acc: 0.9433 - val_loss: 0.4068 - val_acc: 0.9209\n",
      "Epoch 261/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9514\n",
      "Epoch 261: val_acc did not improve from 0.92654\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1199 - acc: 0.9515 - val_loss: 0.4288 - val_acc: 0.9172\n",
      "Epoch 262/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9437\n",
      "Epoch 262: val_acc did not improve from 0.92654\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1335 - acc: 0.9440 - val_loss: 0.3702 - val_acc: 0.9253\n",
      "Epoch 263/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1329 - acc: 0.9486\n",
      "Epoch 263: val_acc did not improve from 0.92654\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1329 - acc: 0.9486 - val_loss: 0.4296 - val_acc: 0.9200\n",
      "Epoch 264/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9477\n",
      "Epoch 264: val_acc did not improve from 0.92654\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1236 - acc: 0.9479 - val_loss: 0.4400 - val_acc: 0.9180\n",
      "Epoch 265/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1301 - acc: 0.9475\n",
      "Epoch 265: val_acc improved from 0.92654 to 0.92817, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1301 - acc: 0.9475 - val_loss: 0.4181 - val_acc: 0.9282\n",
      "Epoch 266/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9498\n",
      "Epoch 266: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1308 - acc: 0.9501 - val_loss: 0.4214 - val_acc: 0.9213\n",
      "Epoch 267/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9465\n",
      "Epoch 267: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1316 - acc: 0.9466 - val_loss: 0.3822 - val_acc: 0.9213\n",
      "Epoch 268/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9505\n",
      "Epoch 268: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1306 - acc: 0.9504 - val_loss: 0.4453 - val_acc: 0.9164\n",
      "Epoch 269/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9483\n",
      "Epoch 269: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1296 - acc: 0.9487 - val_loss: 0.4487 - val_acc: 0.9144\n",
      "Epoch 270/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9512\n",
      "Epoch 270: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1270 - acc: 0.9515 - val_loss: 0.4301 - val_acc: 0.9164\n",
      "Epoch 271/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9516\n",
      "Epoch 271: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1271 - acc: 0.9516 - val_loss: 0.3967 - val_acc: 0.9205\n",
      "Epoch 272/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9452\n",
      "Epoch 272: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1362 - acc: 0.9452 - val_loss: 0.3753 - val_acc: 0.9200\n",
      "Epoch 273/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9495\n",
      "Epoch 273: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1349 - acc: 0.9497 - val_loss: 0.4133 - val_acc: 0.9188\n",
      "Epoch 274/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9473\n",
      "Epoch 274: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1331 - acc: 0.9473 - val_loss: 0.3870 - val_acc: 0.9200\n",
      "Epoch 275/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9483\n",
      "Epoch 275: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1544 - acc: 0.9489 - val_loss: 0.4404 - val_acc: 0.9253\n",
      "Epoch 276/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9489\n",
      "Epoch 276: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1311 - acc: 0.9494 - val_loss: 0.4192 - val_acc: 0.9188\n",
      "Epoch 277/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9478\n",
      "Epoch 277: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1270 - acc: 0.9477 - val_loss: 0.4150 - val_acc: 0.9099\n",
      "Epoch 278/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9525\n",
      "Epoch 278: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1278 - acc: 0.9528 - val_loss: 0.4132 - val_acc: 0.9184\n",
      "Epoch 279/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9467\n",
      "Epoch 279: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1327 - acc: 0.9467 - val_loss: 0.4214 - val_acc: 0.9249\n",
      "Epoch 280/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9504\n",
      "Epoch 280: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1369 - acc: 0.9505 - val_loss: 0.4136 - val_acc: 0.9233\n",
      "Epoch 281/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9472\n",
      "Epoch 281: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1372 - acc: 0.9472 - val_loss: 0.4448 - val_acc: 0.9221\n",
      "Epoch 282/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9496\n",
      "Epoch 282: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1249 - acc: 0.9497 - val_loss: 0.4119 - val_acc: 0.9225\n",
      "Epoch 283/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9522\n",
      "Epoch 283: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1195 - acc: 0.9523 - val_loss: 0.4574 - val_acc: 0.9180\n",
      "Epoch 284/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9498\n",
      "Epoch 284: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1333 - acc: 0.9499 - val_loss: 0.4765 - val_acc: 0.9136\n",
      "Epoch 285/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9497\n",
      "Epoch 285: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1357 - acc: 0.9495 - val_loss: 0.3814 - val_acc: 0.9168\n",
      "Epoch 286/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9527\n",
      "Epoch 286: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1209 - acc: 0.9528 - val_loss: 0.4152 - val_acc: 0.9152\n",
      "Epoch 287/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9493\n",
      "Epoch 287: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1253 - acc: 0.9495 - val_loss: 0.4330 - val_acc: 0.9205\n",
      "Epoch 288/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9521\n",
      "Epoch 288: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1259 - acc: 0.9521 - val_loss: 0.4225 - val_acc: 0.9180\n",
      "Epoch 289/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9496\n",
      "Epoch 289: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1234 - acc: 0.9495 - val_loss: 0.4673 - val_acc: 0.9176\n",
      "Epoch 290/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9508\n",
      "Epoch 290: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1230 - acc: 0.9511 - val_loss: 0.4239 - val_acc: 0.9099\n",
      "Epoch 291/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9502\n",
      "Epoch 291: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1273 - acc: 0.9505 - val_loss: 0.4192 - val_acc: 0.9229\n",
      "Epoch 292/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9525\n",
      "Epoch 292: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1200 - acc: 0.9524 - val_loss: 0.4412 - val_acc: 0.9172\n",
      "Epoch 293/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9507\n",
      "Epoch 293: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1291 - acc: 0.9507 - val_loss: 0.4079 - val_acc: 0.9209\n",
      "Epoch 294/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9503\n",
      "Epoch 294: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1369 - acc: 0.9505 - val_loss: 0.4695 - val_acc: 0.9213\n",
      "Epoch 295/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9507\n",
      "Epoch 295: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1298 - acc: 0.9509 - val_loss: 0.4260 - val_acc: 0.9241\n",
      "Epoch 296/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9515\n",
      "Epoch 296: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1227 - acc: 0.9515 - val_loss: 0.4323 - val_acc: 0.9180\n",
      "Epoch 297/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9526\n",
      "Epoch 297: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1304 - acc: 0.9529 - val_loss: 0.4137 - val_acc: 0.9229\n",
      "Epoch 298/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9516\n",
      "Epoch 298: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1218 - acc: 0.9520 - val_loss: 0.4250 - val_acc: 0.9225\n",
      "Epoch 299/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9494\n",
      "Epoch 299: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1253 - acc: 0.9495 - val_loss: 0.4360 - val_acc: 0.9209\n",
      "Epoch 300/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9503\n",
      "Epoch 300: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1202 - acc: 0.9506 - val_loss: 0.4517 - val_acc: 0.9196\n",
      "Epoch 301/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1328 - acc: 0.9482\n",
      "Epoch 301: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1328 - acc: 0.9480 - val_loss: 0.4062 - val_acc: 0.9087\n",
      "Epoch 302/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9529\n",
      "Epoch 302: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1236 - acc: 0.9529 - val_loss: 0.4139 - val_acc: 0.9200\n",
      "Epoch 303/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9525\n",
      "Epoch 303: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1251 - acc: 0.9527 - val_loss: 0.4394 - val_acc: 0.9217\n",
      "Epoch 304/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9523\n",
      "Epoch 304: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1315 - acc: 0.9523 - val_loss: 0.4101 - val_acc: 0.9180\n",
      "Epoch 305/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9506\n",
      "Epoch 305: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1168 - acc: 0.9507 - val_loss: 0.4792 - val_acc: 0.9253\n",
      "Epoch 306/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9510\n",
      "Epoch 306: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1241 - acc: 0.9510 - val_loss: 0.4037 - val_acc: 0.9180\n",
      "Epoch 307/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9492\n",
      "Epoch 307: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1309 - acc: 0.9493 - val_loss: 0.3734 - val_acc: 0.9200\n",
      "Epoch 308/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9536\n",
      "Epoch 308: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1223 - acc: 0.9536 - val_loss: 0.4182 - val_acc: 0.9180\n",
      "Epoch 309/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9525\n",
      "Epoch 309: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1206 - acc: 0.9526 - val_loss: 0.4155 - val_acc: 0.9144\n",
      "Epoch 310/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9511\n",
      "Epoch 310: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1378 - acc: 0.9513 - val_loss: 0.3924 - val_acc: 0.9205\n",
      "Epoch 311/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9521\n",
      "Epoch 311: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1171 - acc: 0.9522 - val_loss: 0.4080 - val_acc: 0.9225\n",
      "Epoch 312/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9540\n",
      "Epoch 312: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1218 - acc: 0.9541 - val_loss: 0.4536 - val_acc: 0.9071\n",
      "Epoch 313/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9563\n",
      "Epoch 313: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1135 - acc: 0.9566 - val_loss: 0.4759 - val_acc: 0.9144\n",
      "Epoch 314/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9523\n",
      "Epoch 314: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1222 - acc: 0.9522 - val_loss: 0.4749 - val_acc: 0.9209\n",
      "Epoch 315/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9499\n",
      "Epoch 315: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1321 - acc: 0.9504 - val_loss: 0.4907 - val_acc: 0.9168\n",
      "Epoch 316/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9519\n",
      "Epoch 316: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1197 - acc: 0.9520 - val_loss: 0.4417 - val_acc: 0.9188\n",
      "Epoch 317/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9480\n",
      "Epoch 317: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1412 - acc: 0.9480 - val_loss: 0.4391 - val_acc: 0.9213\n",
      "Epoch 318/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9525\n",
      "Epoch 318: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1236 - acc: 0.9525 - val_loss: 0.4276 - val_acc: 0.9140\n",
      "Epoch 319/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9541\n",
      "Epoch 319: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1275 - acc: 0.9541 - val_loss: 0.4782 - val_acc: 0.9119\n",
      "Epoch 320/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9506\n",
      "Epoch 320: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1232 - acc: 0.9507 - val_loss: 0.4968 - val_acc: 0.9200\n",
      "Epoch 321/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9543\n",
      "Epoch 321: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1169 - acc: 0.9545 - val_loss: 0.5014 - val_acc: 0.9225\n",
      "Epoch 322/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9539\n",
      "Epoch 322: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1136 - acc: 0.9539 - val_loss: 0.4871 - val_acc: 0.9229\n",
      "Epoch 323/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9569\n",
      "Epoch 323: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1095 - acc: 0.9572 - val_loss: 0.5311 - val_acc: 0.9196\n",
      "Epoch 324/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9532\n",
      "Epoch 324: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1362 - acc: 0.9534 - val_loss: 0.4617 - val_acc: 0.9099\n",
      "Epoch 325/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9507\n",
      "Epoch 325: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1218 - acc: 0.9510 - val_loss: 0.4453 - val_acc: 0.9233\n",
      "Epoch 326/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1214 - acc: 0.9551\n",
      "Epoch 326: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1214 - acc: 0.9551 - val_loss: 0.4394 - val_acc: 0.9225\n",
      "Epoch 327/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1182 - acc: 0.9542\n",
      "Epoch 327: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1182 - acc: 0.9542 - val_loss: 0.4835 - val_acc: 0.9140\n",
      "Epoch 328/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9528\n",
      "Epoch 328: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1200 - acc: 0.9524 - val_loss: 0.4519 - val_acc: 0.9172\n",
      "Epoch 329/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9564\n",
      "Epoch 329: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1141 - acc: 0.9564 - val_loss: 0.4730 - val_acc: 0.9152\n",
      "Epoch 330/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9527\n",
      "Epoch 330: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1174 - acc: 0.9532 - val_loss: 0.4724 - val_acc: 0.9188\n",
      "Epoch 331/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9538\n",
      "Epoch 331: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1276 - acc: 0.9541 - val_loss: 0.4885 - val_acc: 0.9221\n",
      "Epoch 332/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9549\n",
      "Epoch 332: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1107 - acc: 0.9548 - val_loss: 0.5006 - val_acc: 0.9164\n",
      "Epoch 333/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9548\n",
      "Epoch 333: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1219 - acc: 0.9548 - val_loss: 0.5444 - val_acc: 0.9217\n",
      "Epoch 334/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9541\n",
      "Epoch 334: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1314 - acc: 0.9540 - val_loss: 0.4115 - val_acc: 0.9245\n",
      "Epoch 335/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9509\n",
      "Epoch 335: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1200 - acc: 0.9506 - val_loss: 0.5003 - val_acc: 0.9196\n",
      "Epoch 336/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9528\n",
      "Epoch 336: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1218 - acc: 0.9531 - val_loss: 0.4497 - val_acc: 0.9184\n",
      "Epoch 337/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9545\n",
      "Epoch 337: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1277 - acc: 0.9546 - val_loss: 0.4402 - val_acc: 0.9200\n",
      "Epoch 338/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9529\n",
      "Epoch 338: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1222 - acc: 0.9532 - val_loss: 0.4856 - val_acc: 0.9176\n",
      "Epoch 339/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9550\n",
      "Epoch 339: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1157 - acc: 0.9553 - val_loss: 0.4648 - val_acc: 0.9249\n",
      "Epoch 340/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1340 - acc: 0.9554\n",
      "Epoch 340: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1340 - acc: 0.9554 - val_loss: 0.5056 - val_acc: 0.9213\n",
      "Epoch 341/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9553\n",
      "Epoch 341: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1199 - acc: 0.9548 - val_loss: 0.4757 - val_acc: 0.9144\n",
      "Epoch 342/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9531\n",
      "Epoch 342: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1213 - acc: 0.9534 - val_loss: 0.5029 - val_acc: 0.9180\n",
      "Epoch 343/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9525\n",
      "Epoch 343: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1175 - acc: 0.9524 - val_loss: 0.5750 - val_acc: 0.9188\n",
      "Epoch 344/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9537\n",
      "Epoch 344: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1178 - acc: 0.9538 - val_loss: 0.4641 - val_acc: 0.9229\n",
      "Epoch 345/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1107 - acc: 0.9588\n",
      "Epoch 345: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1107 - acc: 0.9588 - val_loss: 0.5140 - val_acc: 0.9221\n",
      "Epoch 346/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9511\n",
      "Epoch 346: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1162 - acc: 0.9511 - val_loss: 0.4871 - val_acc: 0.9205\n",
      "Epoch 347/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9545\n",
      "Epoch 347: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1179 - acc: 0.9542 - val_loss: 0.5358 - val_acc: 0.9156\n",
      "Epoch 348/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9514\n",
      "Epoch 348: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1284 - acc: 0.9514 - val_loss: 0.4867 - val_acc: 0.9140\n",
      "Epoch 349/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9537\n",
      "Epoch 349: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1177 - acc: 0.9540 - val_loss: 0.4985 - val_acc: 0.9131\n",
      "Epoch 350/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9516\n",
      "Epoch 350: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1258 - acc: 0.9518 - val_loss: 0.5058 - val_acc: 0.9164\n",
      "Epoch 351/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9551\n",
      "Epoch 351: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1149 - acc: 0.9554 - val_loss: 0.5476 - val_acc: 0.9180\n",
      "Epoch 352/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9530\n",
      "Epoch 352: val_acc did not improve from 0.92817\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1172 - acc: 0.9530 - val_loss: 0.5232 - val_acc: 0.9261\n",
      "Epoch 353/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9551\n",
      "Epoch 353: val_acc improved from 0.92817 to 0.92898, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1250 - acc: 0.9550 - val_loss: 0.5213 - val_acc: 0.9290\n",
      "Epoch 354/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9563\n",
      "Epoch 354: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1174 - acc: 0.9564 - val_loss: 0.5416 - val_acc: 0.9192\n",
      "Epoch 355/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9547\n",
      "Epoch 355: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1200 - acc: 0.9545 - val_loss: 0.5792 - val_acc: 0.9233\n",
      "Epoch 356/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9568\n",
      "Epoch 356: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1130 - acc: 0.9571 - val_loss: 0.5755 - val_acc: 0.9225\n",
      "Epoch 357/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9560\n",
      "Epoch 357: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1072 - acc: 0.9560 - val_loss: 0.6033 - val_acc: 0.9172\n",
      "Epoch 358/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9510\n",
      "Epoch 358: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1302 - acc: 0.9513 - val_loss: 0.5086 - val_acc: 0.9192\n",
      "Epoch 359/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9551\n",
      "Epoch 359: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1189 - acc: 0.9551 - val_loss: 0.5222 - val_acc: 0.9192\n",
      "Epoch 360/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9537\n",
      "Epoch 360: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1226 - acc: 0.9536 - val_loss: 0.4597 - val_acc: 0.9241\n",
      "Epoch 361/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9509\n",
      "Epoch 361: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1298 - acc: 0.9511 - val_loss: 0.4505 - val_acc: 0.9229\n",
      "Epoch 362/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9551\n",
      "Epoch 362: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1304 - acc: 0.9554 - val_loss: 0.4764 - val_acc: 0.9136\n",
      "Epoch 363/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9531\n",
      "Epoch 363: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1210 - acc: 0.9533 - val_loss: 0.5044 - val_acc: 0.9196\n",
      "Epoch 364/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9568\n",
      "Epoch 364: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1101 - acc: 0.9574 - val_loss: 0.5160 - val_acc: 0.9245\n",
      "Epoch 365/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9557\n",
      "Epoch 365: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1148 - acc: 0.9554 - val_loss: 0.4698 - val_acc: 0.9221\n",
      "Epoch 366/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9554\n",
      "Epoch 366: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1194 - acc: 0.9558 - val_loss: 0.5522 - val_acc: 0.9221\n",
      "Epoch 367/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9530\n",
      "Epoch 367: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1249 - acc: 0.9530 - val_loss: 0.5179 - val_acc: 0.9188\n",
      "Epoch 368/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9535\n",
      "Epoch 368: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1262 - acc: 0.9535 - val_loss: 0.4479 - val_acc: 0.9253\n",
      "Epoch 369/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9588\n",
      "Epoch 369: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1059 - acc: 0.9588 - val_loss: 0.5573 - val_acc: 0.9188\n",
      "Epoch 370/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9573\n",
      "Epoch 370: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1182 - acc: 0.9574 - val_loss: 0.5537 - val_acc: 0.9136\n",
      "Epoch 371/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9589\n",
      "Epoch 371: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1095 - acc: 0.9590 - val_loss: 0.5225 - val_acc: 0.9225\n",
      "Epoch 372/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9528\n",
      "Epoch 372: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1186 - acc: 0.9525 - val_loss: 0.5379 - val_acc: 0.9237\n",
      "Epoch 373/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9537\n",
      "Epoch 373: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1215 - acc: 0.9539 - val_loss: 0.5424 - val_acc: 0.9196\n",
      "Epoch 374/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9536\n",
      "Epoch 374: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1190 - acc: 0.9535 - val_loss: 0.4975 - val_acc: 0.9245\n",
      "Epoch 375/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9529\n",
      "Epoch 375: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1213 - acc: 0.9533 - val_loss: 0.5590 - val_acc: 0.9176\n",
      "Epoch 376/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9522\n",
      "Epoch 376: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1232 - acc: 0.9525 - val_loss: 0.5007 - val_acc: 0.9225\n",
      "Epoch 377/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9546\n",
      "Epoch 377: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1159 - acc: 0.9546 - val_loss: 0.4721 - val_acc: 0.9217\n",
      "Epoch 378/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9574\n",
      "Epoch 378: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1167 - acc: 0.9578 - val_loss: 0.4621 - val_acc: 0.9180\n",
      "Epoch 379/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9547\n",
      "Epoch 379: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1169 - acc: 0.9548 - val_loss: 0.4727 - val_acc: 0.9205\n",
      "Epoch 380/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9597\n",
      "Epoch 380: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1085 - acc: 0.9597 - val_loss: 0.4823 - val_acc: 0.9225\n",
      "Epoch 381/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9613\n",
      "Epoch 381: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1137 - acc: 0.9607 - val_loss: 0.5153 - val_acc: 0.9188\n",
      "Epoch 382/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9584\n",
      "Epoch 382: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1076 - acc: 0.9585 - val_loss: 0.4903 - val_acc: 0.9172\n",
      "Epoch 383/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9568\n",
      "Epoch 383: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1082 - acc: 0.9573 - val_loss: 0.4962 - val_acc: 0.9229\n",
      "Epoch 384/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9553\n",
      "Epoch 384: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1154 - acc: 0.9554 - val_loss: 0.5119 - val_acc: 0.9172\n",
      "Epoch 385/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9571\n",
      "Epoch 385: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1216 - acc: 0.9572 - val_loss: 0.4522 - val_acc: 0.9115\n",
      "Epoch 386/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9563\n",
      "Epoch 386: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1141 - acc: 0.9564 - val_loss: 0.4626 - val_acc: 0.9245\n",
      "Epoch 387/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9574\n",
      "Epoch 387: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1113 - acc: 0.9577 - val_loss: 0.4816 - val_acc: 0.9172\n",
      "Epoch 388/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9573\n",
      "Epoch 388: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1155 - acc: 0.9574 - val_loss: 0.5084 - val_acc: 0.9152\n",
      "Epoch 389/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9560\n",
      "Epoch 389: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1185 - acc: 0.9563 - val_loss: 0.5015 - val_acc: 0.9172\n",
      "Epoch 390/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9557\n",
      "Epoch 390: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1207 - acc: 0.9557 - val_loss: 0.4732 - val_acc: 0.9188\n",
      "Epoch 391/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9588\n",
      "Epoch 391: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1061 - acc: 0.9584 - val_loss: 0.5036 - val_acc: 0.9217\n",
      "Epoch 392/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9553\n",
      "Epoch 392: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1174 - acc: 0.9557 - val_loss: 0.5785 - val_acc: 0.9188\n",
      "Epoch 393/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1350 - acc: 0.9536\n",
      "Epoch 393: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1332 - acc: 0.9540 - val_loss: 0.5492 - val_acc: 0.9205\n",
      "Epoch 394/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9546\n",
      "Epoch 394: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1256 - acc: 0.9547 - val_loss: 0.5840 - val_acc: 0.9205\n",
      "Epoch 395/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9593\n",
      "Epoch 395: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1112 - acc: 0.9596 - val_loss: 0.6002 - val_acc: 0.9205\n",
      "Epoch 396/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9571\n",
      "Epoch 396: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1211 - acc: 0.9573 - val_loss: 0.5298 - val_acc: 0.9131\n",
      "Epoch 397/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9544\n",
      "Epoch 397: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1150 - acc: 0.9546 - val_loss: 0.5057 - val_acc: 0.9205\n",
      "Epoch 398/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9567\n",
      "Epoch 398: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1134 - acc: 0.9568 - val_loss: 0.4664 - val_acc: 0.9233\n",
      "Epoch 399/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9587\n",
      "Epoch 399: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1105 - acc: 0.9588 - val_loss: 0.5157 - val_acc: 0.9156\n",
      "Epoch 400/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9593\n",
      "Epoch 400: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1043 - acc: 0.9595 - val_loss: 0.5225 - val_acc: 0.9164\n",
      "Epoch 401/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9546\n",
      "Epoch 401: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1160 - acc: 0.9547 - val_loss: 0.5224 - val_acc: 0.9176\n",
      "Epoch 402/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9602\n",
      "Epoch 402: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1079 - acc: 0.9604 - val_loss: 0.5967 - val_acc: 0.9184\n",
      "Epoch 403/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9564\n",
      "Epoch 403: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1176 - acc: 0.9566 - val_loss: 0.6058 - val_acc: 0.9188\n",
      "Epoch 404/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9551\n",
      "Epoch 404: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1210 - acc: 0.9553 - val_loss: 0.5978 - val_acc: 0.9115\n",
      "Epoch 405/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9569\n",
      "Epoch 405: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1150 - acc: 0.9573 - val_loss: 0.4929 - val_acc: 0.9196\n",
      "Epoch 406/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9605\n",
      "Epoch 406: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1087 - acc: 0.9606 - val_loss: 0.6521 - val_acc: 0.9192\n",
      "Epoch 407/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9577\n",
      "Epoch 407: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1160 - acc: 0.9581 - val_loss: 0.6468 - val_acc: 0.9225\n",
      "Epoch 408/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9571\n",
      "Epoch 408: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1151 - acc: 0.9573 - val_loss: 0.6195 - val_acc: 0.9188\n",
      "Epoch 409/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1178 - acc: 0.9567\n",
      "Epoch 409: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1178 - acc: 0.9567 - val_loss: 0.5800 - val_acc: 0.9253\n",
      "Epoch 410/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9558\n",
      "Epoch 410: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1086 - acc: 0.9559 - val_loss: 0.5835 - val_acc: 0.9237\n",
      "Epoch 411/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9588\n",
      "Epoch 411: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1076 - acc: 0.9586 - val_loss: 0.5227 - val_acc: 0.9241\n",
      "Epoch 412/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9568\n",
      "Epoch 412: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1364 - acc: 0.9570 - val_loss: 0.6742 - val_acc: 0.9144\n",
      "Epoch 413/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9537\n",
      "Epoch 413: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1165 - acc: 0.9536 - val_loss: 0.5682 - val_acc: 0.9265\n",
      "Epoch 414/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1099 - acc: 0.9601\n",
      "Epoch 414: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1099 - acc: 0.9601 - val_loss: 0.6706 - val_acc: 0.9217\n",
      "Epoch 415/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9541\n",
      "Epoch 415: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1323 - acc: 0.9543 - val_loss: 0.5190 - val_acc: 0.9213\n",
      "Epoch 416/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9601\n",
      "Epoch 416: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0993 - acc: 0.9604 - val_loss: 0.5967 - val_acc: 0.9148\n",
      "Epoch 417/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9554\n",
      "Epoch 417: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1180 - acc: 0.9559 - val_loss: 0.5203 - val_acc: 0.9286\n",
      "Epoch 418/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9577\n",
      "Epoch 418: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1018 - acc: 0.9578 - val_loss: 0.5803 - val_acc: 0.9172\n",
      "Epoch 419/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9588\n",
      "Epoch 419: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1122 - acc: 0.9589 - val_loss: 0.5944 - val_acc: 0.9200\n",
      "Epoch 420/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9577\n",
      "Epoch 420: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1228 - acc: 0.9582 - val_loss: 0.6520 - val_acc: 0.9249\n",
      "Epoch 421/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9575\n",
      "Epoch 421: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1208 - acc: 0.9577 - val_loss: 0.5740 - val_acc: 0.9099\n",
      "Epoch 422/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9552\n",
      "Epoch 422: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1176 - acc: 0.9550 - val_loss: 0.6562 - val_acc: 0.9152\n",
      "Epoch 423/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9576\n",
      "Epoch 423: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1209 - acc: 0.9577 - val_loss: 0.6251 - val_acc: 0.9192\n",
      "Epoch 424/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9594\n",
      "Epoch 424: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1128 - acc: 0.9596 - val_loss: 0.6553 - val_acc: 0.9168\n",
      "Epoch 425/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9586\n",
      "Epoch 425: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1060 - acc: 0.9588 - val_loss: 0.6661 - val_acc: 0.9184\n",
      "Epoch 426/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9566\n",
      "Epoch 426: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1159 - acc: 0.9565 - val_loss: 0.6152 - val_acc: 0.9136\n",
      "Epoch 427/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9585\n",
      "Epoch 427: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1089 - acc: 0.9585 - val_loss: 0.5663 - val_acc: 0.9221\n",
      "Epoch 428/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9605\n",
      "Epoch 428: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1110 - acc: 0.9604 - val_loss: 0.6484 - val_acc: 0.9152\n",
      "Epoch 429/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.0973 - acc: 0.9614\n",
      "Epoch 429: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0973 - acc: 0.9614 - val_loss: 0.6050 - val_acc: 0.9164\n",
      "Epoch 430/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9572\n",
      "Epoch 430: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1155 - acc: 0.9574 - val_loss: 0.5125 - val_acc: 0.9229\n",
      "Epoch 431/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9567\n",
      "Epoch 431: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1247 - acc: 0.9567 - val_loss: 0.5985 - val_acc: 0.9221\n",
      "Epoch 432/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9602\n",
      "Epoch 432: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1083 - acc: 0.9604 - val_loss: 0.5360 - val_acc: 0.9261\n",
      "Epoch 433/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9579\n",
      "Epoch 433: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1073 - acc: 0.9580 - val_loss: 0.5794 - val_acc: 0.9213\n",
      "Epoch 434/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9561\n",
      "Epoch 434: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1183 - acc: 0.9561 - val_loss: 0.7026 - val_acc: 0.9136\n",
      "Epoch 435/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9578\n",
      "Epoch 435: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1175 - acc: 0.9578 - val_loss: 0.6425 - val_acc: 0.9176\n",
      "Epoch 436/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9605\n",
      "Epoch 436: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0988 - acc: 0.9608 - val_loss: 0.6126 - val_acc: 0.9200\n",
      "Epoch 437/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1085 - acc: 0.9584\n",
      "Epoch 437: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1085 - acc: 0.9584 - val_loss: 0.6053 - val_acc: 0.9217\n",
      "Epoch 438/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9589\n",
      "Epoch 438: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1028 - acc: 0.9588 - val_loss: 0.5907 - val_acc: 0.9237\n",
      "Epoch 439/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9589\n",
      "Epoch 439: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1050 - acc: 0.9593 - val_loss: 0.6271 - val_acc: 0.9221\n",
      "Epoch 440/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9586\n",
      "Epoch 440: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1200 - acc: 0.9588 - val_loss: 0.6229 - val_acc: 0.9172\n",
      "Epoch 441/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9581\n",
      "Epoch 441: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1123 - acc: 0.9583 - val_loss: 0.5638 - val_acc: 0.9148\n",
      "Epoch 442/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9564\n",
      "Epoch 442: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1174 - acc: 0.9565 - val_loss: 0.5644 - val_acc: 0.9257\n",
      "Epoch 443/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9600\n",
      "Epoch 443: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1075 - acc: 0.9601 - val_loss: 0.5948 - val_acc: 0.9200\n",
      "Epoch 444/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9566\n",
      "Epoch 444: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1199 - acc: 0.9569 - val_loss: 0.5723 - val_acc: 0.9213\n",
      "Epoch 445/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9607\n",
      "Epoch 445: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1063 - acc: 0.9608 - val_loss: 0.6220 - val_acc: 0.9217\n",
      "Epoch 446/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9608\n",
      "Epoch 446: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1035 - acc: 0.9609 - val_loss: 0.6677 - val_acc: 0.9229\n",
      "Epoch 447/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9605\n",
      "Epoch 447: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1044 - acc: 0.9606 - val_loss: 0.6424 - val_acc: 0.9192\n",
      "Epoch 448/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9597\n",
      "Epoch 448: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1014 - acc: 0.9600 - val_loss: 0.6184 - val_acc: 0.9209\n",
      "Epoch 449/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9580\n",
      "Epoch 449: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1092 - acc: 0.9585 - val_loss: 0.6211 - val_acc: 0.9245\n",
      "Epoch 450/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9592\n",
      "Epoch 450: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1068 - acc: 0.9594 - val_loss: 0.7097 - val_acc: 0.9209\n",
      "Epoch 451/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9569\n",
      "Epoch 451: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1124 - acc: 0.9570 - val_loss: 0.6404 - val_acc: 0.9172\n",
      "Epoch 452/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9609\n",
      "Epoch 452: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1112 - acc: 0.9609 - val_loss: 0.5540 - val_acc: 0.9111\n",
      "Epoch 453/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9584\n",
      "Epoch 453: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1091 - acc: 0.9583 - val_loss: 0.5829 - val_acc: 0.9123\n",
      "Epoch 454/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9564\n",
      "Epoch 454: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1190 - acc: 0.9566 - val_loss: 0.6192 - val_acc: 0.9213\n",
      "Epoch 455/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9596\n",
      "Epoch 455: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1034 - acc: 0.9597 - val_loss: 0.5751 - val_acc: 0.9152\n",
      "Epoch 456/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9567\n",
      "Epoch 456: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1195 - acc: 0.9570 - val_loss: 0.5821 - val_acc: 0.9233\n",
      "Epoch 457/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9593\n",
      "Epoch 457: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1087 - acc: 0.9596 - val_loss: 0.5640 - val_acc: 0.9188\n",
      "Epoch 458/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9589\n",
      "Epoch 458: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1118 - acc: 0.9590 - val_loss: 0.6659 - val_acc: 0.9160\n",
      "Epoch 459/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9604\n",
      "Epoch 459: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1167 - acc: 0.9602 - val_loss: 0.6703 - val_acc: 0.9144\n",
      "Epoch 460/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9596\n",
      "Epoch 460: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1068 - acc: 0.9596 - val_loss: 0.6362 - val_acc: 0.9217\n",
      "Epoch 461/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9618\n",
      "Epoch 461: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1010 - acc: 0.9618 - val_loss: 0.5697 - val_acc: 0.9188\n",
      "Epoch 462/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9576\n",
      "Epoch 462: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1091 - acc: 0.9580 - val_loss: 0.6585 - val_acc: 0.9213\n",
      "Epoch 463/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9599\n",
      "Epoch 463: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1165 - acc: 0.9601 - val_loss: 0.7484 - val_acc: 0.9156\n",
      "Epoch 464/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9571\n",
      "Epoch 464: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1147 - acc: 0.9572 - val_loss: 0.6063 - val_acc: 0.9205\n",
      "Epoch 465/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9602\n",
      "Epoch 465: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1055 - acc: 0.9602 - val_loss: 0.7241 - val_acc: 0.9205\n",
      "Epoch 466/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9605\n",
      "Epoch 466: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1236 - acc: 0.9605 - val_loss: 0.6318 - val_acc: 0.9131\n",
      "Epoch 467/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9588\n",
      "Epoch 467: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1088 - acc: 0.9590 - val_loss: 0.5722 - val_acc: 0.9257\n",
      "Epoch 468/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9602\n",
      "Epoch 468: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1055 - acc: 0.9602 - val_loss: 0.5682 - val_acc: 0.9225\n",
      "Epoch 469/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9599\n",
      "Epoch 469: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1005 - acc: 0.9601 - val_loss: 0.6101 - val_acc: 0.9217\n",
      "Epoch 470/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9601\n",
      "Epoch 470: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1015 - acc: 0.9602 - val_loss: 0.5707 - val_acc: 0.9148\n",
      "Epoch 471/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9623\n",
      "Epoch 471: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1099 - acc: 0.9624 - val_loss: 0.5610 - val_acc: 0.9233\n",
      "Epoch 472/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9618\n",
      "Epoch 472: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1180 - acc: 0.9619 - val_loss: 0.5859 - val_acc: 0.9144\n",
      "Epoch 473/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9612\n",
      "Epoch 473: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1006 - acc: 0.9614 - val_loss: 0.5680 - val_acc: 0.9200\n",
      "Epoch 474/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9624\n",
      "Epoch 474: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1021 - acc: 0.9624 - val_loss: 0.5994 - val_acc: 0.9131\n",
      "Epoch 475/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9573\n",
      "Epoch 475: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1178 - acc: 0.9570 - val_loss: 0.5291 - val_acc: 0.9119\n",
      "Epoch 476/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9612\n",
      "Epoch 476: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1031 - acc: 0.9615 - val_loss: 0.6287 - val_acc: 0.9245\n",
      "Epoch 477/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9598\n",
      "Epoch 477: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1115 - acc: 0.9598 - val_loss: 0.6001 - val_acc: 0.9200\n",
      "Epoch 478/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9581\n",
      "Epoch 478: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1100 - acc: 0.9577 - val_loss: 0.6575 - val_acc: 0.9188\n",
      "Epoch 479/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1044 - acc: 0.9628\n",
      "Epoch 479: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1044 - acc: 0.9628 - val_loss: 0.6611 - val_acc: 0.9140\n",
      "Epoch 480/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9596\n",
      "Epoch 480: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1086 - acc: 0.9597 - val_loss: 0.6512 - val_acc: 0.9209\n",
      "Epoch 481/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9576\n",
      "Epoch 481: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1113 - acc: 0.9578 - val_loss: 0.6978 - val_acc: 0.9200\n",
      "Epoch 482/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9604\n",
      "Epoch 482: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1073 - acc: 0.9602 - val_loss: 0.5471 - val_acc: 0.9107\n",
      "Epoch 483/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9597\n",
      "Epoch 483: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1074 - acc: 0.9600 - val_loss: 0.5997 - val_acc: 0.9180\n",
      "Epoch 484/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9619\n",
      "Epoch 484: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1050 - acc: 0.9619 - val_loss: 0.6201 - val_acc: 0.9200\n",
      "Epoch 485/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9617\n",
      "Epoch 485: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1034 - acc: 0.9617 - val_loss: 0.6806 - val_acc: 0.9200\n",
      "Epoch 486/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1628 - acc: 0.9594\n",
      "Epoch 486: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1614 - acc: 0.9588 - val_loss: 0.6590 - val_acc: 0.9184\n",
      "Epoch 487/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9618\n",
      "Epoch 487: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1026 - acc: 0.9620 - val_loss: 0.6543 - val_acc: 0.9192\n",
      "Epoch 488/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9601\n",
      "Epoch 488: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1066 - acc: 0.9602 - val_loss: 0.6718 - val_acc: 0.9123\n",
      "Epoch 489/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9619\n",
      "Epoch 489: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1116 - acc: 0.9619 - val_loss: 0.6135 - val_acc: 0.9213\n",
      "Epoch 490/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9607\n",
      "Epoch 490: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1164 - acc: 0.9609 - val_loss: 0.6633 - val_acc: 0.9119\n",
      "Epoch 491/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9623\n",
      "Epoch 491: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0998 - acc: 0.9625 - val_loss: 0.6130 - val_acc: 0.9209\n",
      "Epoch 492/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9627\n",
      "Epoch 492: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1037 - acc: 0.9627 - val_loss: 0.5919 - val_acc: 0.9160\n",
      "Epoch 493/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1288 - acc: 0.9607\n",
      "Epoch 493: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1288 - acc: 0.9607 - val_loss: 0.6998 - val_acc: 0.9136\n",
      "Epoch 494/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9569\n",
      "Epoch 494: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1183 - acc: 0.9569 - val_loss: 0.6555 - val_acc: 0.9119\n",
      "Epoch 495/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9619\n",
      "Epoch 495: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0986 - acc: 0.9618 - val_loss: 0.6471 - val_acc: 0.9192\n",
      "Epoch 496/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9625\n",
      "Epoch 496: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0921 - acc: 0.9628 - val_loss: 0.6213 - val_acc: 0.9209\n",
      "Epoch 497/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9595\n",
      "Epoch 497: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1102 - acc: 0.9593 - val_loss: 0.6997 - val_acc: 0.9180\n",
      "Epoch 498/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9650\n",
      "Epoch 498: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1016 - acc: 0.9655 - val_loss: 0.5574 - val_acc: 0.9172\n",
      "Epoch 499/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9619\n",
      "Epoch 499: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1024 - acc: 0.9622 - val_loss: 0.6175 - val_acc: 0.9209\n",
      "Epoch 500/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9625\n",
      "Epoch 500: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0944 - acc: 0.9625 - val_loss: 0.6102 - val_acc: 0.9192\n",
      "Epoch 501/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9583\n",
      "Epoch 501: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1174 - acc: 0.9580 - val_loss: 0.5908 - val_acc: 0.9164\n",
      "Epoch 502/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9623\n",
      "Epoch 502: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1054 - acc: 0.9619 - val_loss: 0.5588 - val_acc: 0.9168\n",
      "Epoch 503/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1055 - acc: 0.9615\n",
      "Epoch 503: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1055 - acc: 0.9615 - val_loss: 0.6094 - val_acc: 0.9188\n",
      "Epoch 504/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9580\n",
      "Epoch 504: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1078 - acc: 0.9584 - val_loss: 0.6160 - val_acc: 0.9156\n",
      "Epoch 505/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9621\n",
      "Epoch 505: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1000 - acc: 0.9622 - val_loss: 0.6724 - val_acc: 0.9221\n",
      "Epoch 506/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9572\n",
      "Epoch 506: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1238 - acc: 0.9573 - val_loss: 0.5349 - val_acc: 0.9164\n",
      "Epoch 507/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9593\n",
      "Epoch 507: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1013 - acc: 0.9591 - val_loss: 0.6427 - val_acc: 0.9192\n",
      "Epoch 508/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9602\n",
      "Epoch 508: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1043 - acc: 0.9609 - val_loss: 0.6271 - val_acc: 0.9192\n",
      "Epoch 509/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9608\n",
      "Epoch 509: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1054 - acc: 0.9609 - val_loss: 0.6149 - val_acc: 0.9229\n",
      "Epoch 510/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9600\n",
      "Epoch 510: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1019 - acc: 0.9601 - val_loss: 0.6439 - val_acc: 0.9249\n",
      "Epoch 511/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9642\n",
      "Epoch 511: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0985 - acc: 0.9642 - val_loss: 0.6303 - val_acc: 0.9217\n",
      "Epoch 512/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9627\n",
      "Epoch 512: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1081 - acc: 0.9629 - val_loss: 0.5945 - val_acc: 0.9172\n",
      "Epoch 513/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9595\n",
      "Epoch 513: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1064 - acc: 0.9596 - val_loss: 0.5715 - val_acc: 0.9245\n",
      "Epoch 514/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9616\n",
      "Epoch 514: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1133 - acc: 0.9617 - val_loss: 0.6258 - val_acc: 0.9196\n",
      "Epoch 515/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9618\n",
      "Epoch 515: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1038 - acc: 0.9618 - val_loss: 0.5581 - val_acc: 0.9156\n",
      "Epoch 516/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9611\n",
      "Epoch 516: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1006 - acc: 0.9616 - val_loss: 0.7132 - val_acc: 0.9257\n",
      "Epoch 517/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9628\n",
      "Epoch 517: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1162 - acc: 0.9629 - val_loss: 0.5769 - val_acc: 0.9180\n",
      "Epoch 518/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1143 - acc: 0.9584\n",
      "Epoch 518: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1146 - acc: 0.9587 - val_loss: 0.7521 - val_acc: 0.9209\n",
      "Epoch 519/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9618\n",
      "Epoch 519: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1097 - acc: 0.9618 - val_loss: 0.6119 - val_acc: 0.9188\n",
      "Epoch 520/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9598\n",
      "Epoch 520: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1060 - acc: 0.9601 - val_loss: 0.6711 - val_acc: 0.9282\n",
      "Epoch 521/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9632\n",
      "Epoch 521: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1004 - acc: 0.9634 - val_loss: 0.6654 - val_acc: 0.9225\n",
      "Epoch 522/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9606\n",
      "Epoch 522: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.0999 - acc: 0.9608 - val_loss: 0.6816 - val_acc: 0.9221\n",
      "Epoch 523/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9602\n",
      "Epoch 523: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1083 - acc: 0.9606 - val_loss: 0.5095 - val_acc: 0.9172\n",
      "Epoch 524/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9632\n",
      "Epoch 524: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0981 - acc: 0.9633 - val_loss: 0.5911 - val_acc: 0.9265\n",
      "Epoch 525/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9610\n",
      "Epoch 525: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1018 - acc: 0.9608 - val_loss: 0.5687 - val_acc: 0.9233\n",
      "Epoch 526/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9596\n",
      "Epoch 526: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1055 - acc: 0.9596 - val_loss: 0.6231 - val_acc: 0.9225\n",
      "Epoch 527/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9630\n",
      "Epoch 527: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1046 - acc: 0.9630 - val_loss: 0.5791 - val_acc: 0.9188\n",
      "Epoch 528/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9635\n",
      "Epoch 528: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1046 - acc: 0.9636 - val_loss: 0.5901 - val_acc: 0.9205\n",
      "Epoch 529/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9594\n",
      "Epoch 529: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0999 - acc: 0.9595 - val_loss: 0.6076 - val_acc: 0.9213\n",
      "Epoch 530/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9625\n",
      "Epoch 530: val_acc did not improve from 0.92898\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1030 - acc: 0.9626 - val_loss: 0.5903 - val_acc: 0.9221\n",
      "Epoch 531/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9640\n",
      "Epoch 531: val_acc improved from 0.92898 to 0.92979, saving model to train_logs/logs7/FFT_ANN\\3\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0937 - acc: 0.9641 - val_loss: 0.6983 - val_acc: 0.9298\n",
      "Epoch 532/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9605\n",
      "Epoch 532: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1059 - acc: 0.9606 - val_loss: 0.5891 - val_acc: 0.9265\n",
      "Epoch 533/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9583\n",
      "Epoch 533: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1056 - acc: 0.9587 - val_loss: 0.6592 - val_acc: 0.9265\n",
      "Epoch 534/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9664\n",
      "Epoch 534: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.0973 - acc: 0.9664 - val_loss: 0.6276 - val_acc: 0.9205\n",
      "Epoch 535/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9625\n",
      "Epoch 535: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.0973 - acc: 0.9626 - val_loss: 0.7229 - val_acc: 0.9221\n",
      "Epoch 536/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9634\n",
      "Epoch 536: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 5s 8ms/step - loss: 0.0985 - acc: 0.9632 - val_loss: 0.6260 - val_acc: 0.9233\n",
      "Epoch 537/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9594\n",
      "Epoch 537: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1028 - acc: 0.9592 - val_loss: 0.6526 - val_acc: 0.9176\n",
      "Epoch 538/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9657\n",
      "Epoch 538: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1069 - acc: 0.9656 - val_loss: 0.6518 - val_acc: 0.9180\n",
      "Epoch 539/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9656\n",
      "Epoch 539: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1060 - acc: 0.9653 - val_loss: 0.6331 - val_acc: 0.9180\n",
      "Epoch 540/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9624\n",
      "Epoch 540: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1071 - acc: 0.9626 - val_loss: 0.6749 - val_acc: 0.9200\n",
      "Epoch 541/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9624\n",
      "Epoch 541: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1010 - acc: 0.9624 - val_loss: 0.7099 - val_acc: 0.9237\n",
      "Epoch 542/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9618\n",
      "Epoch 542: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1080 - acc: 0.9618 - val_loss: 0.6973 - val_acc: 0.9192\n",
      "Epoch 543/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9622\n",
      "Epoch 543: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1134 - acc: 0.9622 - val_loss: 0.6374 - val_acc: 0.9144\n",
      "Epoch 544/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9626\n",
      "Epoch 544: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1079 - acc: 0.9629 - val_loss: 0.5656 - val_acc: 0.9282\n",
      "Epoch 545/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9617\n",
      "Epoch 545: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1268 - acc: 0.9619 - val_loss: 0.6806 - val_acc: 0.9217\n",
      "Epoch 546/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1088 - acc: 0.9610\n",
      "Epoch 546: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1088 - acc: 0.9610 - val_loss: 0.6411 - val_acc: 0.9233\n",
      "Epoch 547/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9622\n",
      "Epoch 547: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.1084 - acc: 0.9624 - val_loss: 0.6361 - val_acc: 0.9278\n",
      "Epoch 548/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1126 - acc: 0.9649\n",
      "Epoch 548: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 5s 7ms/step - loss: 0.1126 - acc: 0.9649 - val_loss: 0.6044 - val_acc: 0.9217\n",
      "Epoch 549/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9650\n",
      "Epoch 549: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 5s 8ms/step - loss: 0.0852 - acc: 0.9652 - val_loss: 0.7091 - val_acc: 0.9245\n",
      "Epoch 550/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9626\n",
      "Epoch 550: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 5s 8ms/step - loss: 0.1106 - acc: 0.9626 - val_loss: 0.5959 - val_acc: 0.9119\n",
      "Epoch 551/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9637\n",
      "Epoch 551: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.0956 - acc: 0.9638 - val_loss: 0.6575 - val_acc: 0.9278\n",
      "Epoch 552/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9603\n",
      "Epoch 552: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.1048 - acc: 0.9603 - val_loss: 0.6531 - val_acc: 0.9192\n",
      "Epoch 553/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9602\n",
      "Epoch 553: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.1141 - acc: 0.9604 - val_loss: 0.7002 - val_acc: 0.9253\n",
      "Epoch 554/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9634\n",
      "Epoch 554: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.1060 - acc: 0.9635 - val_loss: 0.5918 - val_acc: 0.9253\n",
      "Epoch 555/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9631\n",
      "Epoch 555: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1034 - acc: 0.9634 - val_loss: 0.5977 - val_acc: 0.9249\n",
      "Epoch 556/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9636\n",
      "Epoch 556: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.1015 - acc: 0.9638 - val_loss: 0.5743 - val_acc: 0.9180\n",
      "Epoch 557/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9627\n",
      "Epoch 557: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.1094 - acc: 0.9628 - val_loss: 0.6518 - val_acc: 0.9200\n",
      "Epoch 558/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9621\n",
      "Epoch 558: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0929 - acc: 0.9624 - val_loss: 0.7290 - val_acc: 0.9213\n",
      "Epoch 559/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9643\n",
      "Epoch 559: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1032 - acc: 0.9646 - val_loss: 0.6492 - val_acc: 0.9205\n",
      "Epoch 560/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9627\n",
      "Epoch 560: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1092 - acc: 0.9631 - val_loss: 0.6816 - val_acc: 0.9229\n",
      "Epoch 561/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9634\n",
      "Epoch 561: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0937 - acc: 0.9636 - val_loss: 0.7286 - val_acc: 0.9241\n",
      "Epoch 562/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9631\n",
      "Epoch 562: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1129 - acc: 0.9634 - val_loss: 0.5998 - val_acc: 0.9184\n",
      "Epoch 563/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9640\n",
      "Epoch 563: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0984 - acc: 0.9640 - val_loss: 0.7321 - val_acc: 0.9176\n",
      "Epoch 564/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9644\n",
      "Epoch 564: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.0949 - acc: 0.9645 - val_loss: 0.6415 - val_acc: 0.9269\n",
      "Epoch 565/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9623\n",
      "Epoch 565: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0928 - acc: 0.9624 - val_loss: 0.6542 - val_acc: 0.9188\n",
      "Epoch 566/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9624\n",
      "Epoch 566: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.0906 - acc: 0.9626 - val_loss: 0.6959 - val_acc: 0.9225\n",
      "Epoch 567/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9631\n",
      "Epoch 567: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0999 - acc: 0.9634 - val_loss: 0.6607 - val_acc: 0.9180\n",
      "Epoch 568/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9619\n",
      "Epoch 568: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0953 - acc: 0.9618 - val_loss: 0.7873 - val_acc: 0.9209\n",
      "Epoch 569/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9611\n",
      "Epoch 569: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1203 - acc: 0.9613 - val_loss: 0.7216 - val_acc: 0.9213\n",
      "Epoch 570/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9639\n",
      "Epoch 570: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1000 - acc: 0.9639 - val_loss: 0.7529 - val_acc: 0.9164\n",
      "Epoch 571/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9635\n",
      "Epoch 571: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1065 - acc: 0.9639 - val_loss: 0.6481 - val_acc: 0.9225\n",
      "Epoch 572/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9649\n",
      "Epoch 572: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.0971 - acc: 0.9651 - val_loss: 0.6143 - val_acc: 0.9233\n",
      "Epoch 573/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1350 - acc: 0.9647\n",
      "Epoch 573: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1345 - acc: 0.9648 - val_loss: 0.6455 - val_acc: 0.9233\n",
      "Epoch 574/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9641\n",
      "Epoch 574: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1066 - acc: 0.9645 - val_loss: 0.6164 - val_acc: 0.9188\n",
      "Epoch 575/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9633\n",
      "Epoch 575: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1044 - acc: 0.9632 - val_loss: 0.6288 - val_acc: 0.9152\n",
      "Epoch 576/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9632\n",
      "Epoch 576: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1056 - acc: 0.9633 - val_loss: 0.6384 - val_acc: 0.9286\n",
      "Epoch 577/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9632\n",
      "Epoch 577: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1053 - acc: 0.9635 - val_loss: 0.5823 - val_acc: 0.9286\n",
      "Epoch 578/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9638\n",
      "Epoch 578: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1080 - acc: 0.9641 - val_loss: 0.6114 - val_acc: 0.9221\n",
      "Epoch 579/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9597\n",
      "Epoch 579: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1163 - acc: 0.9599 - val_loss: 0.6356 - val_acc: 0.9261\n",
      "Epoch 580/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9662\n",
      "Epoch 580: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1023 - acc: 0.9664 - val_loss: 0.6064 - val_acc: 0.9257\n",
      "Epoch 581/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9630\n",
      "Epoch 581: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1014 - acc: 0.9631 - val_loss: 0.6204 - val_acc: 0.9196\n",
      "Epoch 582/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9630\n",
      "Epoch 582: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1140 - acc: 0.9634 - val_loss: 0.6064 - val_acc: 0.9196\n",
      "Epoch 583/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9637\n",
      "Epoch 583: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1033 - acc: 0.9638 - val_loss: 0.6559 - val_acc: 0.9249\n",
      "Epoch 584/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9643\n",
      "Epoch 584: val_acc did not improve from 0.92979\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.0949 - acc: 0.9646 - val_loss: 0.6733 - val_acc: 0.9213\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_3 (Reshape)         (None, 80, 1)             0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 512)               41472     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,057\n",
      "Trainable params: 173,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.5996 - acc: 0.7177\n",
      "Epoch 1: val_acc improved from -inf to 0.76380, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.5975 - acc: 0.7182 - val_loss: 0.4614 - val_acc: 0.7638\n",
      "Epoch 2/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.4738 - acc: 0.7672\n",
      "Epoch 2: val_acc improved from 0.76380 to 0.79018, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4736 - acc: 0.7674 - val_loss: 0.4212 - val_acc: 0.7902\n",
      "Epoch 3/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.4419 - acc: 0.7850\n",
      "Epoch 3: val_acc improved from 0.79018 to 0.79221, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4400 - acc: 0.7857 - val_loss: 0.4068 - val_acc: 0.7922\n",
      "Epoch 4/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.4261 - acc: 0.7933\n",
      "Epoch 4: val_acc improved from 0.79221 to 0.81047, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4238 - acc: 0.7944 - val_loss: 0.3963 - val_acc: 0.8105\n",
      "Epoch 5/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.4046 - acc: 0.8056\n",
      "Epoch 5: val_acc improved from 0.81047 to 0.81940, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.4036 - acc: 0.8061 - val_loss: 0.3796 - val_acc: 0.8194\n",
      "Epoch 6/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.3976 - acc: 0.8130\n",
      "Epoch 6: val_acc improved from 0.81940 to 0.83117, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3966 - acc: 0.8137 - val_loss: 0.3773 - val_acc: 0.8312\n",
      "Epoch 7/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.3850 - acc: 0.8154\n",
      "Epoch 7: val_acc did not improve from 0.83117\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3829 - acc: 0.8160 - val_loss: 0.3653 - val_acc: 0.8271\n",
      "Epoch 8/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.3649 - acc: 0.8295\n",
      "Epoch 8: val_acc improved from 0.83117 to 0.83320, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3650 - acc: 0.8294 - val_loss: 0.3620 - val_acc: 0.8332\n",
      "Epoch 9/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.3703 - acc: 0.8262\n",
      "Epoch 9: val_acc improved from 0.83320 to 0.84131, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3694 - acc: 0.8265 - val_loss: 0.3531 - val_acc: 0.8413\n",
      "Epoch 10/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.3576 - acc: 0.8329\n",
      "Epoch 10: val_acc did not improve from 0.84131\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3566 - acc: 0.8333 - val_loss: 0.3642 - val_acc: 0.8401\n",
      "Epoch 11/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.3520 - acc: 0.8399\n",
      "Epoch 11: val_acc did not improve from 0.84131\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3501 - acc: 0.8406 - val_loss: 0.3580 - val_acc: 0.8389\n",
      "Epoch 12/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.3476 - acc: 0.8376\n",
      "Epoch 12: val_acc improved from 0.84131 to 0.84537, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3476 - acc: 0.8376 - val_loss: 0.3537 - val_acc: 0.8454\n",
      "Epoch 13/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.3369 - acc: 0.8433\n",
      "Epoch 13: val_acc improved from 0.84537 to 0.85430, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3369 - acc: 0.8432 - val_loss: 0.3529 - val_acc: 0.8543\n",
      "Epoch 14/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.3234 - acc: 0.8501\n",
      "Epoch 14: val_acc improved from 0.85430 to 0.85714, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3239 - acc: 0.8498 - val_loss: 0.3527 - val_acc: 0.8571\n",
      "Epoch 15/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.3271 - acc: 0.8509\n",
      "Epoch 15: val_acc did not improve from 0.85714\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3272 - acc: 0.8507 - val_loss: 0.3486 - val_acc: 0.8571\n",
      "Epoch 16/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.3201 - acc: 0.8542\n",
      "Epoch 16: val_acc improved from 0.85714 to 0.86080, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3198 - acc: 0.8542 - val_loss: 0.3544 - val_acc: 0.8608\n",
      "Epoch 17/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.3164 - acc: 0.8551\n",
      "Epoch 17: val_acc improved from 0.86080 to 0.86526, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3163 - acc: 0.8555 - val_loss: 0.3462 - val_acc: 0.8653\n",
      "Epoch 18/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.3104 - acc: 0.8592\n",
      "Epoch 18: val_acc did not improve from 0.86526\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3101 - acc: 0.8589 - val_loss: 0.3414 - val_acc: 0.8612\n",
      "Epoch 19/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.3122 - acc: 0.8571\n",
      "Epoch 19: val_acc did not improve from 0.86526\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3118 - acc: 0.8574 - val_loss: 0.3417 - val_acc: 0.8559\n",
      "Epoch 20/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.3017 - acc: 0.8610\n",
      "Epoch 20: val_acc did not improve from 0.86526\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3008 - acc: 0.8615 - val_loss: 0.3436 - val_acc: 0.8640\n",
      "Epoch 21/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2947 - acc: 0.8633\n",
      "Epoch 21: val_acc did not improve from 0.86526\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2940 - acc: 0.8636 - val_loss: 0.3542 - val_acc: 0.8620\n",
      "Epoch 22/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.2970 - acc: 0.8671\n",
      "Epoch 22: val_acc did not improve from 0.86526\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2954 - acc: 0.8679 - val_loss: 0.3586 - val_acc: 0.8628\n",
      "Epoch 23/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2983 - acc: 0.8655\n",
      "Epoch 23: val_acc improved from 0.86526 to 0.87013, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2977 - acc: 0.8660 - val_loss: 0.3601 - val_acc: 0.8701\n",
      "Epoch 24/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.2890 - acc: 0.8718\n",
      "Epoch 24: val_acc did not improve from 0.87013\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2879 - acc: 0.8721 - val_loss: 0.3754 - val_acc: 0.8669\n",
      "Epoch 25/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2886 - acc: 0.8695\n",
      "Epoch 25: val_acc did not improve from 0.87013\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2873 - acc: 0.8701 - val_loss: 0.3577 - val_acc: 0.8669\n",
      "Epoch 26/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2872 - acc: 0.8742\n",
      "Epoch 26: val_acc did not improve from 0.87013\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2872 - acc: 0.8742 - val_loss: 0.3430 - val_acc: 0.8657\n",
      "Epoch 27/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2766 - acc: 0.8747\n",
      "Epoch 27: val_acc improved from 0.87013 to 0.87256, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2762 - acc: 0.8748 - val_loss: 0.3453 - val_acc: 0.8726\n",
      "Epoch 28/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.2805 - acc: 0.8767\n",
      "Epoch 28: val_acc did not improve from 0.87256\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2789 - acc: 0.8769 - val_loss: 0.3375 - val_acc: 0.8718\n",
      "Epoch 29/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2702 - acc: 0.8788\n",
      "Epoch 29: val_acc improved from 0.87256 to 0.87378, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2704 - acc: 0.8785 - val_loss: 0.3429 - val_acc: 0.8738\n",
      "Epoch 30/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.2667 - acc: 0.8791\n",
      "Epoch 30: val_acc improved from 0.87378 to 0.87622, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2660 - acc: 0.8794 - val_loss: 0.3475 - val_acc: 0.8762\n",
      "Epoch 31/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2690 - acc: 0.8791\n",
      "Epoch 31: val_acc did not improve from 0.87622\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2695 - acc: 0.8791 - val_loss: 0.3426 - val_acc: 0.8754\n",
      "Epoch 32/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2603 - acc: 0.8827\n",
      "Epoch 32: val_acc did not improve from 0.87622\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2600 - acc: 0.8832 - val_loss: 0.3570 - val_acc: 0.8718\n",
      "Epoch 33/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2686 - acc: 0.8805\n",
      "Epoch 33: val_acc did not improve from 0.87622\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2679 - acc: 0.8805 - val_loss: 0.3668 - val_acc: 0.8705\n",
      "Epoch 34/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.2682 - acc: 0.8813\n",
      "Epoch 34: val_acc improved from 0.87622 to 0.87703, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2675 - acc: 0.8817 - val_loss: 0.3561 - val_acc: 0.8770\n",
      "Epoch 35/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2531 - acc: 0.8886\n",
      "Epoch 35: val_acc did not improve from 0.87703\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2534 - acc: 0.8884 - val_loss: 0.3727 - val_acc: 0.8730\n",
      "Epoch 36/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2557 - acc: 0.8845\n",
      "Epoch 36: val_acc improved from 0.87703 to 0.87744, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2557 - acc: 0.8845 - val_loss: 0.3711 - val_acc: 0.8774\n",
      "Epoch 37/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2534 - acc: 0.8856\n",
      "Epoch 37: val_acc did not improve from 0.87744\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2526 - acc: 0.8859 - val_loss: 0.3710 - val_acc: 0.8770\n",
      "Epoch 38/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.2559 - acc: 0.8861\n",
      "Epoch 38: val_acc improved from 0.87744 to 0.88028, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2551 - acc: 0.8865 - val_loss: 0.3525 - val_acc: 0.8803\n",
      "Epoch 39/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2511 - acc: 0.8891\n",
      "Epoch 39: val_acc did not improve from 0.88028\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2510 - acc: 0.8891 - val_loss: 0.3479 - val_acc: 0.8795\n",
      "Epoch 40/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2491 - acc: 0.8919\n",
      "Epoch 40: val_acc did not improve from 0.88028\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2486 - acc: 0.8920 - val_loss: 0.3667 - val_acc: 0.8722\n",
      "Epoch 41/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2507 - acc: 0.8919\n",
      "Epoch 41: val_acc did not improve from 0.88028\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2514 - acc: 0.8917 - val_loss: 0.3736 - val_acc: 0.8742\n",
      "Epoch 42/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.2448 - acc: 0.8908\n",
      "Epoch 42: val_acc improved from 0.88028 to 0.88880, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2437 - acc: 0.8913 - val_loss: 0.3725 - val_acc: 0.8888\n",
      "Epoch 43/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2489 - acc: 0.8956\n",
      "Epoch 43: val_acc did not improve from 0.88880\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2485 - acc: 0.8955 - val_loss: 0.3645 - val_acc: 0.8839\n",
      "Epoch 44/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2471 - acc: 0.8913\n",
      "Epoch 44: val_acc did not improve from 0.88880\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2468 - acc: 0.8914 - val_loss: 0.3767 - val_acc: 0.8787\n",
      "Epoch 45/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2361 - acc: 0.8930\n",
      "Epoch 45: val_acc did not improve from 0.88880\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2366 - acc: 0.8927 - val_loss: 0.3708 - val_acc: 0.8746\n",
      "Epoch 46/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2411 - acc: 0.8911\n",
      "Epoch 46: val_acc did not improve from 0.88880\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2403 - acc: 0.8912 - val_loss: 0.3635 - val_acc: 0.8795\n",
      "Epoch 47/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2405 - acc: 0.8910\n",
      "Epoch 47: val_acc did not improve from 0.88880\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2405 - acc: 0.8909 - val_loss: 0.3581 - val_acc: 0.8876\n",
      "Epoch 48/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2458 - acc: 0.8940\n",
      "Epoch 48: val_acc did not improve from 0.88880\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2456 - acc: 0.8939 - val_loss: 0.3532 - val_acc: 0.8782\n",
      "Epoch 49/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2373 - acc: 0.8950\n",
      "Epoch 49: val_acc did not improve from 0.88880\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2372 - acc: 0.8950 - val_loss: 0.3517 - val_acc: 0.8872\n",
      "Epoch 50/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2288 - acc: 0.8992\n",
      "Epoch 50: val_acc did not improve from 0.88880\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2291 - acc: 0.8990 - val_loss: 0.3656 - val_acc: 0.8774\n",
      "Epoch 51/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.2331 - acc: 0.8949\n",
      "Epoch 51: val_acc did not improve from 0.88880\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2319 - acc: 0.8954 - val_loss: 0.3854 - val_acc: 0.8823\n",
      "Epoch 52/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.8978\n",
      "Epoch 52: val_acc did not improve from 0.88880\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2357 - acc: 0.8974 - val_loss: 0.3685 - val_acc: 0.8819\n",
      "Epoch 53/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2239 - acc: 0.9022\n",
      "Epoch 53: val_acc improved from 0.88880 to 0.89123, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2236 - acc: 0.9022 - val_loss: 0.3802 - val_acc: 0.8912\n",
      "Epoch 54/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2311 - acc: 0.8989\n",
      "Epoch 54: val_acc did not improve from 0.89123\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2307 - acc: 0.8988 - val_loss: 0.3797 - val_acc: 0.8896\n",
      "Epoch 55/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.2198 - acc: 0.9027\n",
      "Epoch 55: val_acc improved from 0.89123 to 0.89205, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2189 - acc: 0.9029 - val_loss: 0.4034 - val_acc: 0.8920\n",
      "Epoch 56/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2281 - acc: 0.8986\n",
      "Epoch 56: val_acc improved from 0.89205 to 0.89407, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2277 - acc: 0.8987 - val_loss: 0.3819 - val_acc: 0.8941\n",
      "Epoch 57/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2217 - acc: 0.9032\n",
      "Epoch 57: val_acc did not improve from 0.89407\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2221 - acc: 0.9029 - val_loss: 0.4016 - val_acc: 0.8823\n",
      "Epoch 58/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2345 - acc: 0.9015\n",
      "Epoch 58: val_acc did not improve from 0.89407\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2338 - acc: 0.9018 - val_loss: 0.3595 - val_acc: 0.8868\n",
      "Epoch 59/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2260 - acc: 0.9081\n",
      "Epoch 59: val_acc did not improve from 0.89407\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2260 - acc: 0.9082 - val_loss: 0.3727 - val_acc: 0.8900\n",
      "Epoch 60/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.2206 - acc: 0.9022\n",
      "Epoch 60: val_acc did not improve from 0.89407\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2194 - acc: 0.9026 - val_loss: 0.3795 - val_acc: 0.8884\n",
      "Epoch 61/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9025\n",
      "Epoch 61: val_acc did not improve from 0.89407\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2249 - acc: 0.9024 - val_loss: 0.3779 - val_acc: 0.8835\n",
      "Epoch 62/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2113 - acc: 0.9099\n",
      "Epoch 62: val_acc did not improve from 0.89407\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2114 - acc: 0.9096 - val_loss: 0.3973 - val_acc: 0.8933\n",
      "Epoch 63/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9058\n",
      "Epoch 63: val_acc did not improve from 0.89407\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2122 - acc: 0.9061 - val_loss: 0.4437 - val_acc: 0.8831\n",
      "Epoch 64/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.2184 - acc: 0.9061\n",
      "Epoch 64: val_acc did not improve from 0.89407\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2187 - acc: 0.9061 - val_loss: 0.4151 - val_acc: 0.8920\n",
      "Epoch 65/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9089\n",
      "Epoch 65: val_acc improved from 0.89407 to 0.89448, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2126 - acc: 0.9092 - val_loss: 0.4049 - val_acc: 0.8945\n",
      "Epoch 66/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.2155 - acc: 0.9069\n",
      "Epoch 66: val_acc improved from 0.89448 to 0.89489, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2144 - acc: 0.9070 - val_loss: 0.4069 - val_acc: 0.8949\n",
      "Epoch 67/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2168 - acc: 0.9081\n",
      "Epoch 67: val_acc did not improve from 0.89489\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2166 - acc: 0.9081 - val_loss: 0.3870 - val_acc: 0.8835\n",
      "Epoch 68/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2053 - acc: 0.9095\n",
      "Epoch 68: val_acc did not improve from 0.89489\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2046 - acc: 0.9099 - val_loss: 0.3926 - val_acc: 0.8941\n",
      "Epoch 69/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2101 - acc: 0.9138\n",
      "Epoch 69: val_acc did not improve from 0.89489\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2099 - acc: 0.9137 - val_loss: 0.3836 - val_acc: 0.8937\n",
      "Epoch 70/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2147 - acc: 0.9090\n",
      "Epoch 70: val_acc improved from 0.89489 to 0.89651, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2140 - acc: 0.9090 - val_loss: 0.3787 - val_acc: 0.8965\n",
      "Epoch 71/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9080\n",
      "Epoch 71: val_acc improved from 0.89651 to 0.89732, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2098 - acc: 0.9077 - val_loss: 0.4121 - val_acc: 0.8973\n",
      "Epoch 72/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.9129\n",
      "Epoch 72: val_acc improved from 0.89732 to 0.90138, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2040 - acc: 0.9125 - val_loss: 0.3980 - val_acc: 0.9014\n",
      "Epoch 73/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2059 - acc: 0.9125\n",
      "Epoch 73: val_acc did not improve from 0.90138\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2048 - acc: 0.9130 - val_loss: 0.4078 - val_acc: 0.8989\n",
      "Epoch 74/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9048\n",
      "Epoch 74: val_acc did not improve from 0.90138\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2117 - acc: 0.9048 - val_loss: 0.4030 - val_acc: 0.8981\n",
      "Epoch 75/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9084\n",
      "Epoch 75: val_acc did not improve from 0.90138\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2114 - acc: 0.9089 - val_loss: 0.3944 - val_acc: 0.8868\n",
      "Epoch 76/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2027 - acc: 0.9151\n",
      "Epoch 76: val_acc did not improve from 0.90138\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2027 - acc: 0.9151 - val_loss: 0.4059 - val_acc: 0.8998\n",
      "Epoch 77/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2055 - acc: 0.9110\n",
      "Epoch 77: val_acc improved from 0.90138 to 0.90381, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2058 - acc: 0.9108 - val_loss: 0.4074 - val_acc: 0.9038\n",
      "Epoch 78/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2057 - acc: 0.9117\n",
      "Epoch 78: val_acc did not improve from 0.90381\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2054 - acc: 0.9118 - val_loss: 0.3919 - val_acc: 0.9010\n",
      "Epoch 79/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2043 - acc: 0.9133\n",
      "Epoch 79: val_acc did not improve from 0.90381\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2043 - acc: 0.9130 - val_loss: 0.4129 - val_acc: 0.9022\n",
      "Epoch 80/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2080 - acc: 0.9090\n",
      "Epoch 80: val_acc did not improve from 0.90381\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2075 - acc: 0.9091 - val_loss: 0.3881 - val_acc: 0.8957\n",
      "Epoch 81/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2031 - acc: 0.9131\n",
      "Epoch 81: val_acc did not improve from 0.90381\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2031 - acc: 0.9131 - val_loss: 0.3971 - val_acc: 0.8876\n",
      "Epoch 82/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1983 - acc: 0.9113\n",
      "Epoch 82: val_acc did not improve from 0.90381\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1985 - acc: 0.9112 - val_loss: 0.4070 - val_acc: 0.9006\n",
      "Epoch 83/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1985 - acc: 0.9110\n",
      "Epoch 83: val_acc did not improve from 0.90381\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1974 - acc: 0.9116 - val_loss: 0.4181 - val_acc: 0.9002\n",
      "Epoch 84/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1937 - acc: 0.9183\n",
      "Epoch 84: val_acc did not improve from 0.90381\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1927 - acc: 0.9189 - val_loss: 0.4055 - val_acc: 0.8925\n",
      "Epoch 85/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9130\n",
      "Epoch 85: val_acc did not improve from 0.90381\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2002 - acc: 0.9130 - val_loss: 0.3965 - val_acc: 0.8961\n",
      "Epoch 86/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9166\n",
      "Epoch 86: val_acc did not improve from 0.90381\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1951 - acc: 0.9167 - val_loss: 0.4017 - val_acc: 0.8908\n",
      "Epoch 87/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1963 - acc: 0.9165\n",
      "Epoch 87: val_acc did not improve from 0.90381\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1958 - acc: 0.9166 - val_loss: 0.4042 - val_acc: 0.8912\n",
      "Epoch 88/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1963 - acc: 0.9162\n",
      "Epoch 88: val_acc did not improve from 0.90381\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1958 - acc: 0.9161 - val_loss: 0.4157 - val_acc: 0.9034\n",
      "Epoch 89/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1909 - acc: 0.9179\n",
      "Epoch 89: val_acc did not improve from 0.90381\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1908 - acc: 0.9182 - val_loss: 0.4425 - val_acc: 0.8941\n",
      "Epoch 90/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1997 - acc: 0.9149\n",
      "Epoch 90: val_acc improved from 0.90381 to 0.90463, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1984 - acc: 0.9150 - val_loss: 0.4163 - val_acc: 0.9046\n",
      "Epoch 91/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9153\n",
      "Epoch 91: val_acc did not improve from 0.90463\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1916 - acc: 0.9154 - val_loss: 0.4191 - val_acc: 0.8937\n",
      "Epoch 92/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9178\n",
      "Epoch 92: val_acc did not improve from 0.90463\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1920 - acc: 0.9178 - val_loss: 0.4131 - val_acc: 0.9030\n",
      "Epoch 93/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9183\n",
      "Epoch 93: val_acc improved from 0.90463 to 0.90787, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2107 - acc: 0.9182 - val_loss: 0.3843 - val_acc: 0.9079\n",
      "Epoch 94/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1917 - acc: 0.9175\n",
      "Epoch 94: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1912 - acc: 0.9176 - val_loss: 0.4138 - val_acc: 0.9018\n",
      "Epoch 95/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9206\n",
      "Epoch 95: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1953 - acc: 0.9210 - val_loss: 0.4358 - val_acc: 0.8998\n",
      "Epoch 96/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1838 - acc: 0.9215\n",
      "Epoch 96: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1837 - acc: 0.9215 - val_loss: 0.4092 - val_acc: 0.9010\n",
      "Epoch 97/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1901 - acc: 0.9191\n",
      "Epoch 97: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1899 - acc: 0.9191 - val_loss: 0.4218 - val_acc: 0.9038\n",
      "Epoch 98/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1917 - acc: 0.9184\n",
      "Epoch 98: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1898 - acc: 0.9193 - val_loss: 0.4328 - val_acc: 0.9042\n",
      "Epoch 99/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1915 - acc: 0.9200\n",
      "Epoch 99: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1898 - acc: 0.9203 - val_loss: 0.4608 - val_acc: 0.8981\n",
      "Epoch 100/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9203\n",
      "Epoch 100: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1831 - acc: 0.9203 - val_loss: 0.4407 - val_acc: 0.8973\n",
      "Epoch 101/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1909 - acc: 0.9190\n",
      "Epoch 101: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1900 - acc: 0.9196 - val_loss: 0.4445 - val_acc: 0.9034\n",
      "Epoch 102/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1902 - acc: 0.9194\n",
      "Epoch 102: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1908 - acc: 0.9188 - val_loss: 0.4627 - val_acc: 0.8989\n",
      "Epoch 103/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1906 - acc: 0.9171\n",
      "Epoch 103: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1906 - acc: 0.9170 - val_loss: 0.4534 - val_acc: 0.8973\n",
      "Epoch 104/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9202\n",
      "Epoch 104: val_acc did not improve from 0.90787\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1808 - acc: 0.9200 - val_loss: 0.4374 - val_acc: 0.9014\n",
      "Epoch 105/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9209\n",
      "Epoch 105: val_acc improved from 0.90787 to 0.90869, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1806 - acc: 0.9215 - val_loss: 0.4282 - val_acc: 0.9087\n",
      "Epoch 106/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9204\n",
      "Epoch 106: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1958 - acc: 0.9205 - val_loss: 0.4485 - val_acc: 0.8994\n",
      "Epoch 107/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1805 - acc: 0.9217\n",
      "Epoch 107: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1800 - acc: 0.9221 - val_loss: 0.4306 - val_acc: 0.9026\n",
      "Epoch 108/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1856 - acc: 0.9203\n",
      "Epoch 108: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1857 - acc: 0.9202 - val_loss: 0.4555 - val_acc: 0.8904\n",
      "Epoch 109/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1821 - acc: 0.9255\n",
      "Epoch 109: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1815 - acc: 0.9255 - val_loss: 0.4526 - val_acc: 0.9054\n",
      "Epoch 110/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1818 - acc: 0.9278\n",
      "Epoch 110: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1818 - acc: 0.9279 - val_loss: 0.4604 - val_acc: 0.9018\n",
      "Epoch 111/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9240\n",
      "Epoch 111: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1821 - acc: 0.9241 - val_loss: 0.5056 - val_acc: 0.9050\n",
      "Epoch 112/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1835 - acc: 0.9230\n",
      "Epoch 112: val_acc did not improve from 0.90869\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1830 - acc: 0.9231 - val_loss: 0.4696 - val_acc: 0.8981\n",
      "Epoch 113/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1818 - acc: 0.9233\n",
      "Epoch 113: val_acc improved from 0.90869 to 0.91112, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1813 - acc: 0.9239 - val_loss: 0.4787 - val_acc: 0.9111\n",
      "Epoch 114/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1751 - acc: 0.9253\n",
      "Epoch 114: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1751 - acc: 0.9253 - val_loss: 0.5142 - val_acc: 0.9111\n",
      "Epoch 115/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1793 - acc: 0.9232\n",
      "Epoch 115: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1793 - acc: 0.9232 - val_loss: 0.4680 - val_acc: 0.9071\n",
      "Epoch 116/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1803 - acc: 0.9257\n",
      "Epoch 116: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1800 - acc: 0.9259 - val_loss: 0.4488 - val_acc: 0.8994\n",
      "Epoch 117/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1706 - acc: 0.9236\n",
      "Epoch 117: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1700 - acc: 0.9241 - val_loss: 0.4562 - val_acc: 0.9099\n",
      "Epoch 118/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1723 - acc: 0.9289\n",
      "Epoch 118: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1723 - acc: 0.9289 - val_loss: 0.4544 - val_acc: 0.9075\n",
      "Epoch 119/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9237\n",
      "Epoch 119: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1757 - acc: 0.9238 - val_loss: 0.4577 - val_acc: 0.8969\n",
      "Epoch 120/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9290\n",
      "Epoch 120: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1812 - acc: 0.9291 - val_loss: 0.4942 - val_acc: 0.9042\n",
      "Epoch 121/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1740 - acc: 0.9287\n",
      "Epoch 121: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1736 - acc: 0.9289 - val_loss: 0.5119 - val_acc: 0.9067\n",
      "Epoch 122/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1769 - acc: 0.9269\n",
      "Epoch 122: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1770 - acc: 0.9268 - val_loss: 0.4881 - val_acc: 0.9079\n",
      "Epoch 123/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1769 - acc: 0.9286\n",
      "Epoch 123: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1764 - acc: 0.9290 - val_loss: 0.4904 - val_acc: 0.9075\n",
      "Epoch 124/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9261\n",
      "Epoch 124: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1752 - acc: 0.9262 - val_loss: 0.4882 - val_acc: 0.9018\n",
      "Epoch 125/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9317\n",
      "Epoch 125: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1689 - acc: 0.9318 - val_loss: 0.4878 - val_acc: 0.9054\n",
      "Epoch 126/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9297\n",
      "Epoch 126: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1683 - acc: 0.9296 - val_loss: 0.4983 - val_acc: 0.9079\n",
      "Epoch 127/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9303\n",
      "Epoch 127: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1683 - acc: 0.9308 - val_loss: 0.5088 - val_acc: 0.9091\n",
      "Epoch 128/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1688 - acc: 0.9278\n",
      "Epoch 128: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1678 - acc: 0.9284 - val_loss: 0.5057 - val_acc: 0.8985\n",
      "Epoch 129/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.9272\n",
      "Epoch 129: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1725 - acc: 0.9274 - val_loss: 0.5111 - val_acc: 0.9030\n",
      "Epoch 130/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9254\n",
      "Epoch 130: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1767 - acc: 0.9256 - val_loss: 0.5282 - val_acc: 0.9062\n",
      "Epoch 131/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1697 - acc: 0.9330\n",
      "Epoch 131: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1692 - acc: 0.9330 - val_loss: 0.4705 - val_acc: 0.9018\n",
      "Epoch 132/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1667 - acc: 0.9301\n",
      "Epoch 132: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1669 - acc: 0.9300 - val_loss: 0.5019 - val_acc: 0.9079\n",
      "Epoch 133/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1676 - acc: 0.9339\n",
      "Epoch 133: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1681 - acc: 0.9333 - val_loss: 0.5089 - val_acc: 0.9058\n",
      "Epoch 134/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1706 - acc: 0.9286\n",
      "Epoch 134: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1691 - acc: 0.9295 - val_loss: 0.5396 - val_acc: 0.9042\n",
      "Epoch 135/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9332\n",
      "Epoch 135: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1604 - acc: 0.9335 - val_loss: 0.5303 - val_acc: 0.9058\n",
      "Epoch 136/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1671 - acc: 0.9248\n",
      "Epoch 136: val_acc did not improve from 0.91112\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1660 - acc: 0.9252 - val_loss: 0.4934 - val_acc: 0.9083\n",
      "Epoch 137/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9300\n",
      "Epoch 137: val_acc improved from 0.91112 to 0.91274, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1707 - acc: 0.9298 - val_loss: 0.5805 - val_acc: 0.9127\n",
      "Epoch 138/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9315\n",
      "Epoch 138: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1657 - acc: 0.9318 - val_loss: 0.5429 - val_acc: 0.9103\n",
      "Epoch 139/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9255\n",
      "Epoch 139: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1724 - acc: 0.9257 - val_loss: 0.5571 - val_acc: 0.9067\n",
      "Epoch 140/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9315\n",
      "Epoch 140: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1561 - acc: 0.9321 - val_loss: 0.5358 - val_acc: 0.9054\n",
      "Epoch 141/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1647 - acc: 0.9310\n",
      "Epoch 141: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1643 - acc: 0.9310 - val_loss: 0.5534 - val_acc: 0.8989\n",
      "Epoch 142/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9326\n",
      "Epoch 142: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1645 - acc: 0.9322 - val_loss: 0.5683 - val_acc: 0.9075\n",
      "Epoch 143/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9306\n",
      "Epoch 143: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1691 - acc: 0.9308 - val_loss: 0.5607 - val_acc: 0.9079\n",
      "Epoch 144/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1643 - acc: 0.9329\n",
      "Epoch 144: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1638 - acc: 0.9330 - val_loss: 0.5498 - val_acc: 0.9091\n",
      "Epoch 145/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9303\n",
      "Epoch 145: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1628 - acc: 0.9307 - val_loss: 0.6000 - val_acc: 0.9026\n",
      "Epoch 146/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9346\n",
      "Epoch 146: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1709 - acc: 0.9348 - val_loss: 0.5656 - val_acc: 0.9099\n",
      "Epoch 147/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9316\n",
      "Epoch 147: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1692 - acc: 0.9316 - val_loss: 0.5571 - val_acc: 0.9107\n",
      "Epoch 148/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9326\n",
      "Epoch 148: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1609 - acc: 0.9324 - val_loss: 0.5732 - val_acc: 0.9054\n",
      "Epoch 149/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9326\n",
      "Epoch 149: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1604 - acc: 0.9326 - val_loss: 0.5809 - val_acc: 0.9091\n",
      "Epoch 150/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1638 - acc: 0.9318\n",
      "Epoch 150: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1628 - acc: 0.9322 - val_loss: 0.5475 - val_acc: 0.9099\n",
      "Epoch 151/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9325\n",
      "Epoch 151: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1588 - acc: 0.9332 - val_loss: 0.5500 - val_acc: 0.9075\n",
      "Epoch 152/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1635 - acc: 0.9340\n",
      "Epoch 152: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1627 - acc: 0.9343 - val_loss: 0.6052 - val_acc: 0.9103\n",
      "Epoch 153/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1541 - acc: 0.9356\n",
      "Epoch 153: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1530 - acc: 0.9360 - val_loss: 0.6396 - val_acc: 0.9091\n",
      "Epoch 154/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9349\n",
      "Epoch 154: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1561 - acc: 0.9348 - val_loss: 0.6512 - val_acc: 0.9099\n",
      "Epoch 155/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1614 - acc: 0.9325\n",
      "Epoch 155: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1606 - acc: 0.9327 - val_loss: 0.5823 - val_acc: 0.9083\n",
      "Epoch 156/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9333\n",
      "Epoch 156: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1617 - acc: 0.9334 - val_loss: 0.5951 - val_acc: 0.9075\n",
      "Epoch 157/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1585 - acc: 0.9319\n",
      "Epoch 157: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1588 - acc: 0.9319 - val_loss: 0.5611 - val_acc: 0.9050\n",
      "Epoch 158/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1603 - acc: 0.9343\n",
      "Epoch 158: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1605 - acc: 0.9344 - val_loss: 0.5816 - val_acc: 0.9099\n",
      "Epoch 159/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1612 - acc: 0.9316\n",
      "Epoch 159: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1612 - acc: 0.9316 - val_loss: 0.6221 - val_acc: 0.9071\n",
      "Epoch 160/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1545 - acc: 0.9345\n",
      "Epoch 160: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1546 - acc: 0.9344 - val_loss: 0.6017 - val_acc: 0.9119\n",
      "Epoch 161/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1582 - acc: 0.9328\n",
      "Epoch 161: val_acc did not improve from 0.91274\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1582 - acc: 0.9330 - val_loss: 0.5940 - val_acc: 0.9062\n",
      "Epoch 162/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9352\n",
      "Epoch 162: val_acc improved from 0.91274 to 0.91396, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1602 - acc: 0.9350 - val_loss: 0.6050 - val_acc: 0.9140\n",
      "Epoch 163/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9318\n",
      "Epoch 163: val_acc did not improve from 0.91396\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1672 - acc: 0.9319 - val_loss: 0.6231 - val_acc: 0.9050\n",
      "Epoch 164/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9365\n",
      "Epoch 164: val_acc did not improve from 0.91396\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1615 - acc: 0.9367 - val_loss: 0.5958 - val_acc: 0.9095\n",
      "Epoch 165/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1643 - acc: 0.9334\n",
      "Epoch 165: val_acc improved from 0.91396 to 0.91558, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1643 - acc: 0.9334 - val_loss: 0.6095 - val_acc: 0.9156\n",
      "Epoch 166/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9333\n",
      "Epoch 166: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1580 - acc: 0.9333 - val_loss: 0.6080 - val_acc: 0.9038\n",
      "Epoch 167/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9374\n",
      "Epoch 167: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1580 - acc: 0.9376 - val_loss: 0.6538 - val_acc: 0.9054\n",
      "Epoch 168/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9322\n",
      "Epoch 168: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1590 - acc: 0.9325 - val_loss: 0.6540 - val_acc: 0.9062\n",
      "Epoch 169/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1484 - acc: 0.9362\n",
      "Epoch 169: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1484 - acc: 0.9362 - val_loss: 0.7019 - val_acc: 0.9115\n",
      "Epoch 170/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9347\n",
      "Epoch 170: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1588 - acc: 0.9350 - val_loss: 0.5927 - val_acc: 0.9140\n",
      "Epoch 171/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1589 - acc: 0.9344\n",
      "Epoch 171: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1589 - acc: 0.9344 - val_loss: 0.6869 - val_acc: 0.9087\n",
      "Epoch 172/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9351\n",
      "Epoch 172: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1597 - acc: 0.9351 - val_loss: 0.6887 - val_acc: 0.9087\n",
      "Epoch 173/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9355\n",
      "Epoch 173: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1553 - acc: 0.9356 - val_loss: 0.6098 - val_acc: 0.9099\n",
      "Epoch 174/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9373\n",
      "Epoch 174: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1505 - acc: 0.9374 - val_loss: 0.7138 - val_acc: 0.9087\n",
      "Epoch 175/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1567 - acc: 0.9341\n",
      "Epoch 175: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1564 - acc: 0.9343 - val_loss: 0.6817 - val_acc: 0.9083\n",
      "Epoch 176/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9361\n",
      "Epoch 176: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1513 - acc: 0.9362 - val_loss: 0.6886 - val_acc: 0.9099\n",
      "Epoch 177/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9350\n",
      "Epoch 177: val_acc did not improve from 0.91558\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1586 - acc: 0.9354 - val_loss: 0.6827 - val_acc: 0.9079\n",
      "Epoch 178/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9356\n",
      "Epoch 178: val_acc improved from 0.91558 to 0.91599, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1563 - acc: 0.9363 - val_loss: 0.6995 - val_acc: 0.9160\n",
      "Epoch 179/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1531 - acc: 0.9366\n",
      "Epoch 179: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1519 - acc: 0.9366 - val_loss: 0.7264 - val_acc: 0.9095\n",
      "Epoch 180/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9411\n",
      "Epoch 180: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1549 - acc: 0.9410 - val_loss: 0.7522 - val_acc: 0.9091\n",
      "Epoch 181/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1625 - acc: 0.9363\n",
      "Epoch 181: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1623 - acc: 0.9364 - val_loss: 0.6502 - val_acc: 0.9103\n",
      "Epoch 182/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9317\n",
      "Epoch 182: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1643 - acc: 0.9321 - val_loss: 0.7027 - val_acc: 0.9103\n",
      "Epoch 183/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9378\n",
      "Epoch 183: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1558 - acc: 0.9376 - val_loss: 0.6232 - val_acc: 0.9119\n",
      "Epoch 184/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9406\n",
      "Epoch 184: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1426 - acc: 0.9409 - val_loss: 0.6872 - val_acc: 0.9099\n",
      "Epoch 185/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1525 - acc: 0.9369\n",
      "Epoch 185: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1520 - acc: 0.9372 - val_loss: 0.6924 - val_acc: 0.9087\n",
      "Epoch 186/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9398\n",
      "Epoch 186: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1462 - acc: 0.9400 - val_loss: 0.6953 - val_acc: 0.9091\n",
      "Epoch 187/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1548 - acc: 0.9412\n",
      "Epoch 187: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1548 - acc: 0.9412 - val_loss: 0.6522 - val_acc: 0.9119\n",
      "Epoch 188/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9404\n",
      "Epoch 188: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1405 - acc: 0.9411 - val_loss: 0.7319 - val_acc: 0.9115\n",
      "Epoch 189/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1581 - acc: 0.9387\n",
      "Epoch 189: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1581 - acc: 0.9387 - val_loss: 0.6126 - val_acc: 0.9127\n",
      "Epoch 190/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9356\n",
      "Epoch 190: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1495 - acc: 0.9359 - val_loss: 0.6398 - val_acc: 0.9119\n",
      "Epoch 191/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9404\n",
      "Epoch 191: val_acc did not improve from 0.91599\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1524 - acc: 0.9405 - val_loss: 0.6393 - val_acc: 0.9156\n",
      "Epoch 192/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9405\n",
      "Epoch 192: val_acc improved from 0.91599 to 0.91640, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1428 - acc: 0.9403 - val_loss: 0.6645 - val_acc: 0.9164\n",
      "Epoch 193/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9387\n",
      "Epoch 193: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1447 - acc: 0.9390 - val_loss: 0.6219 - val_acc: 0.9079\n",
      "Epoch 194/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9411\n",
      "Epoch 194: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1601 - acc: 0.9410 - val_loss: 0.6620 - val_acc: 0.9075\n",
      "Epoch 195/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9367\n",
      "Epoch 195: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1607 - acc: 0.9367 - val_loss: 0.7544 - val_acc: 0.9148\n",
      "Epoch 196/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9379\n",
      "Epoch 196: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1506 - acc: 0.9380 - val_loss: 0.7094 - val_acc: 0.9148\n",
      "Epoch 197/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9448\n",
      "Epoch 197: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1421 - acc: 0.9450 - val_loss: 0.7008 - val_acc: 0.9075\n",
      "Epoch 198/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9396\n",
      "Epoch 198: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1403 - acc: 0.9398 - val_loss: 0.7128 - val_acc: 0.9083\n",
      "Epoch 199/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9446\n",
      "Epoch 199: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1387 - acc: 0.9448 - val_loss: 0.7090 - val_acc: 0.9148\n",
      "Epoch 200/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1522 - acc: 0.9387\n",
      "Epoch 200: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1522 - acc: 0.9387 - val_loss: 0.6988 - val_acc: 0.9115\n",
      "Epoch 201/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1511 - acc: 0.9427\n",
      "Epoch 201: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1509 - acc: 0.9430 - val_loss: 0.6830 - val_acc: 0.9152\n",
      "Epoch 202/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9380\n",
      "Epoch 202: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1523 - acc: 0.9385 - val_loss: 0.6213 - val_acc: 0.9091\n",
      "Epoch 203/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9420\n",
      "Epoch 203: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1528 - acc: 0.9425 - val_loss: 0.6702 - val_acc: 0.9079\n",
      "Epoch 204/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9399\n",
      "Epoch 204: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1463 - acc: 0.9402 - val_loss: 0.6495 - val_acc: 0.9071\n",
      "Epoch 205/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9442\n",
      "Epoch 205: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1404 - acc: 0.9441 - val_loss: 0.7510 - val_acc: 0.9075\n",
      "Epoch 206/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9381\n",
      "Epoch 206: val_acc did not improve from 0.91640\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1478 - acc: 0.9381 - val_loss: 0.6382 - val_acc: 0.9087\n",
      "Epoch 207/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9424\n",
      "Epoch 207: val_acc improved from 0.91640 to 0.91843, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1402 - acc: 0.9427 - val_loss: 0.6908 - val_acc: 0.9184\n",
      "Epoch 208/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9425\n",
      "Epoch 208: val_acc did not improve from 0.91843\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1459 - acc: 0.9425 - val_loss: 0.6967 - val_acc: 0.9071\n",
      "Epoch 209/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9406\n",
      "Epoch 209: val_acc did not improve from 0.91843\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1474 - acc: 0.9409 - val_loss: 0.6580 - val_acc: 0.9123\n",
      "Epoch 210/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1479 - acc: 0.9393\n",
      "Epoch 210: val_acc did not improve from 0.91843\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1466 - acc: 0.9399 - val_loss: 0.6226 - val_acc: 0.9144\n",
      "Epoch 211/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9445\n",
      "Epoch 211: val_acc did not improve from 0.91843\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1408 - acc: 0.9445 - val_loss: 0.7025 - val_acc: 0.9127\n",
      "Epoch 212/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9415\n",
      "Epoch 212: val_acc did not improve from 0.91843\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1478 - acc: 0.9417 - val_loss: 0.6482 - val_acc: 0.9168\n",
      "Epoch 213/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9501\n",
      "Epoch 213: val_acc did not improve from 0.91843\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1316 - acc: 0.9501 - val_loss: 0.7712 - val_acc: 0.9136\n",
      "Epoch 214/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9399\n",
      "Epoch 214: val_acc did not improve from 0.91843\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1455 - acc: 0.9403 - val_loss: 0.6610 - val_acc: 0.9075\n",
      "Epoch 215/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9430\n",
      "Epoch 215: val_acc did not improve from 0.91843\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1441 - acc: 0.9431 - val_loss: 0.6785 - val_acc: 0.9148\n",
      "Epoch 216/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9398\n",
      "Epoch 216: val_acc did not improve from 0.91843\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1505 - acc: 0.9399 - val_loss: 0.6695 - val_acc: 0.9127\n",
      "Epoch 217/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1541 - acc: 0.9414\n",
      "Epoch 217: val_acc did not improve from 0.91843\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1541 - acc: 0.9410 - val_loss: 0.6975 - val_acc: 0.9152\n",
      "Epoch 218/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9382\n",
      "Epoch 218: val_acc did not improve from 0.91843\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1529 - acc: 0.9385 - val_loss: 0.6292 - val_acc: 0.9127\n",
      "Epoch 219/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9430\n",
      "Epoch 219: val_acc improved from 0.91843 to 0.91883, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1396 - acc: 0.9429 - val_loss: 0.7514 - val_acc: 0.9188\n",
      "Epoch 220/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9450\n",
      "Epoch 220: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1328 - acc: 0.9449 - val_loss: 0.7609 - val_acc: 0.9115\n",
      "Epoch 221/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9466\n",
      "Epoch 221: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1439 - acc: 0.9469 - val_loss: 0.8481 - val_acc: 0.9140\n",
      "Epoch 222/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1457 - acc: 0.9404\n",
      "Epoch 222: val_acc did not improve from 0.91883\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1457 - acc: 0.9404 - val_loss: 0.8294 - val_acc: 0.9091\n",
      "Epoch 223/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9453\n",
      "Epoch 223: val_acc improved from 0.91883 to 0.92248, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1310 - acc: 0.9453 - val_loss: 0.7793 - val_acc: 0.9225\n",
      "Epoch 224/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9418\n",
      "Epoch 224: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1364 - acc: 0.9421 - val_loss: 0.7931 - val_acc: 0.9156\n",
      "Epoch 225/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9428\n",
      "Epoch 225: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1390 - acc: 0.9432 - val_loss: 0.7577 - val_acc: 0.9087\n",
      "Epoch 226/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1356 - acc: 0.9461\n",
      "Epoch 226: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1356 - acc: 0.9462 - val_loss: 0.7323 - val_acc: 0.9140\n",
      "Epoch 227/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9395\n",
      "Epoch 227: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1455 - acc: 0.9398 - val_loss: 0.7362 - val_acc: 0.9152\n",
      "Epoch 228/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9441\n",
      "Epoch 228: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1329 - acc: 0.9438 - val_loss: 0.8447 - val_acc: 0.9079\n",
      "Epoch 229/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9457\n",
      "Epoch 229: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1356 - acc: 0.9460 - val_loss: 0.7875 - val_acc: 0.9107\n",
      "Epoch 230/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9453\n",
      "Epoch 230: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1387 - acc: 0.9454 - val_loss: 0.7579 - val_acc: 0.9087\n",
      "Epoch 231/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9434\n",
      "Epoch 231: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1408 - acc: 0.9434 - val_loss: 0.8008 - val_acc: 0.9156\n",
      "Epoch 232/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1411 - acc: 0.9432\n",
      "Epoch 232: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1411 - acc: 0.9432 - val_loss: 0.7261 - val_acc: 0.9160\n",
      "Epoch 233/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9459\n",
      "Epoch 233: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1380 - acc: 0.9459 - val_loss: 0.8930 - val_acc: 0.9083\n",
      "Epoch 234/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9459\n",
      "Epoch 234: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1441 - acc: 0.9459 - val_loss: 0.8300 - val_acc: 0.9115\n",
      "Epoch 235/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9438\n",
      "Epoch 235: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1430 - acc: 0.9439 - val_loss: 0.8654 - val_acc: 0.9091\n",
      "Epoch 236/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9436\n",
      "Epoch 236: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1382 - acc: 0.9435 - val_loss: 0.7947 - val_acc: 0.9168\n",
      "Epoch 237/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9457\n",
      "Epoch 237: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1331 - acc: 0.9453 - val_loss: 0.8288 - val_acc: 0.9131\n",
      "Epoch 238/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9461\n",
      "Epoch 238: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1420 - acc: 0.9466 - val_loss: 0.8628 - val_acc: 0.9131\n",
      "Epoch 239/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9446\n",
      "Epoch 239: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1353 - acc: 0.9450 - val_loss: 0.9295 - val_acc: 0.9152\n",
      "Epoch 240/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1411 - acc: 0.9455\n",
      "Epoch 240: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1408 - acc: 0.9457 - val_loss: 0.7650 - val_acc: 0.9136\n",
      "Epoch 241/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9464\n",
      "Epoch 241: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1326 - acc: 0.9467 - val_loss: 0.8978 - val_acc: 0.9107\n",
      "Epoch 242/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9453\n",
      "Epoch 242: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1434 - acc: 0.9450 - val_loss: 0.8020 - val_acc: 0.9164\n",
      "Epoch 243/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9427\n",
      "Epoch 243: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1428 - acc: 0.9428 - val_loss: 0.8076 - val_acc: 0.9184\n",
      "Epoch 244/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9478\n",
      "Epoch 244: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1244 - acc: 0.9478 - val_loss: 0.7393 - val_acc: 0.9136\n",
      "Epoch 245/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9470\n",
      "Epoch 245: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1369 - acc: 0.9469 - val_loss: 0.9110 - val_acc: 0.9136\n",
      "Epoch 246/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9476\n",
      "Epoch 246: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1460 - acc: 0.9477 - val_loss: 0.7654 - val_acc: 0.9164\n",
      "Epoch 247/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9465\n",
      "Epoch 247: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1348 - acc: 0.9469 - val_loss: 0.7936 - val_acc: 0.9140\n",
      "Epoch 248/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1564 - acc: 0.9433\n",
      "Epoch 248: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1554 - acc: 0.9434 - val_loss: 0.7558 - val_acc: 0.9172\n",
      "Epoch 249/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9462\n",
      "Epoch 249: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1277 - acc: 0.9461 - val_loss: 0.7175 - val_acc: 0.9221\n",
      "Epoch 250/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9482\n",
      "Epoch 250: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1314 - acc: 0.9482 - val_loss: 0.7946 - val_acc: 0.9164\n",
      "Epoch 251/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9440\n",
      "Epoch 251: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1300 - acc: 0.9440 - val_loss: 0.7966 - val_acc: 0.9103\n",
      "Epoch 252/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9459\n",
      "Epoch 252: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1306 - acc: 0.9460 - val_loss: 0.8409 - val_acc: 0.9172\n",
      "Epoch 253/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9459\n",
      "Epoch 253: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1315 - acc: 0.9457 - val_loss: 0.8665 - val_acc: 0.9213\n",
      "Epoch 254/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9463\n",
      "Epoch 254: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1306 - acc: 0.9468 - val_loss: 0.9408 - val_acc: 0.9111\n",
      "Epoch 255/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9465\n",
      "Epoch 255: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1331 - acc: 0.9471 - val_loss: 0.9550 - val_acc: 0.9152\n",
      "Epoch 256/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9474\n",
      "Epoch 256: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1306 - acc: 0.9480 - val_loss: 0.9300 - val_acc: 0.9123\n",
      "Epoch 257/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9504\n",
      "Epoch 257: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1297 - acc: 0.9504 - val_loss: 0.8875 - val_acc: 0.9123\n",
      "Epoch 258/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9457\n",
      "Epoch 258: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1268 - acc: 0.9457 - val_loss: 1.0085 - val_acc: 0.9168\n",
      "Epoch 259/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9414\n",
      "Epoch 259: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1545 - acc: 0.9417 - val_loss: 0.7528 - val_acc: 0.9136\n",
      "Epoch 260/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9423\n",
      "Epoch 260: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1492 - acc: 0.9428 - val_loss: 0.8731 - val_acc: 0.9176\n",
      "Epoch 261/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9498\n",
      "Epoch 261: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1339 - acc: 0.9499 - val_loss: 0.8380 - val_acc: 0.9148\n",
      "Epoch 262/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9462\n",
      "Epoch 262: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1253 - acc: 0.9463 - val_loss: 0.9091 - val_acc: 0.9176\n",
      "Epoch 263/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9441\n",
      "Epoch 263: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1511 - acc: 0.9445 - val_loss: 0.8166 - val_acc: 0.9095\n",
      "Epoch 264/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9493\n",
      "Epoch 264: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1364 - acc: 0.9497 - val_loss: 0.8317 - val_acc: 0.9184\n",
      "Epoch 265/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9509\n",
      "Epoch 265: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1328 - acc: 0.9509 - val_loss: 0.9039 - val_acc: 0.9156\n",
      "Epoch 266/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9476\n",
      "Epoch 266: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1396 - acc: 0.9475 - val_loss: 0.7662 - val_acc: 0.9156\n",
      "Epoch 267/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9470\n",
      "Epoch 267: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1338 - acc: 0.9472 - val_loss: 0.7992 - val_acc: 0.9200\n",
      "Epoch 268/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9521\n",
      "Epoch 268: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1206 - acc: 0.9524 - val_loss: 0.9572 - val_acc: 0.9152\n",
      "Epoch 269/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9480\n",
      "Epoch 269: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1285 - acc: 0.9481 - val_loss: 0.8791 - val_acc: 0.9176\n",
      "Epoch 270/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9457\n",
      "Epoch 270: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1410 - acc: 0.9462 - val_loss: 0.8042 - val_acc: 0.9156\n",
      "Epoch 271/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9475\n",
      "Epoch 271: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1371 - acc: 0.9474 - val_loss: 0.8018 - val_acc: 0.9156\n",
      "Epoch 272/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9476\n",
      "Epoch 272: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1269 - acc: 0.9479 - val_loss: 0.8199 - val_acc: 0.9156\n",
      "Epoch 273/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9441\n",
      "Epoch 273: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1327 - acc: 0.9442 - val_loss: 0.7339 - val_acc: 0.9095\n",
      "Epoch 274/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9475\n",
      "Epoch 274: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1334 - acc: 0.9474 - val_loss: 0.7497 - val_acc: 0.9144\n",
      "Epoch 275/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9472\n",
      "Epoch 275: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1279 - acc: 0.9476 - val_loss: 0.8586 - val_acc: 0.9123\n",
      "Epoch 276/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1324 - acc: 0.9470\n",
      "Epoch 276: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1324 - acc: 0.9470 - val_loss: 0.8965 - val_acc: 0.9079\n",
      "Epoch 277/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9494\n",
      "Epoch 277: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1294 - acc: 0.9498 - val_loss: 0.9088 - val_acc: 0.9091\n",
      "Epoch 278/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9511\n",
      "Epoch 278: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1231 - acc: 0.9510 - val_loss: 0.9761 - val_acc: 0.9140\n",
      "Epoch 279/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9486\n",
      "Epoch 279: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1349 - acc: 0.9491 - val_loss: 0.9309 - val_acc: 0.9156\n",
      "Epoch 280/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9471\n",
      "Epoch 280: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1283 - acc: 0.9471 - val_loss: 0.9344 - val_acc: 0.9131\n",
      "Epoch 281/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9469\n",
      "Epoch 281: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1304 - acc: 0.9468 - val_loss: 0.8374 - val_acc: 0.9111\n",
      "Epoch 282/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9502\n",
      "Epoch 282: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1273 - acc: 0.9505 - val_loss: 0.9087 - val_acc: 0.9164\n",
      "Epoch 283/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9475\n",
      "Epoch 283: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1333 - acc: 0.9475 - val_loss: 0.8295 - val_acc: 0.9172\n",
      "Epoch 284/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9503\n",
      "Epoch 284: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1291 - acc: 0.9508 - val_loss: 0.8672 - val_acc: 0.9152\n",
      "Epoch 285/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9519\n",
      "Epoch 285: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1236 - acc: 0.9519 - val_loss: 0.8605 - val_acc: 0.9148\n",
      "Epoch 286/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9476\n",
      "Epoch 286: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1319 - acc: 0.9477 - val_loss: 0.9822 - val_acc: 0.9083\n",
      "Epoch 287/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9506\n",
      "Epoch 287: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1282 - acc: 0.9508 - val_loss: 0.9807 - val_acc: 0.9176\n",
      "Epoch 288/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9481\n",
      "Epoch 288: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1272 - acc: 0.9481 - val_loss: 0.9317 - val_acc: 0.9123\n",
      "Epoch 289/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9483\n",
      "Epoch 289: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1321 - acc: 0.9482 - val_loss: 1.0841 - val_acc: 0.9209\n",
      "Epoch 290/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9497\n",
      "Epoch 290: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1309 - acc: 0.9500 - val_loss: 0.9058 - val_acc: 0.9140\n",
      "Epoch 291/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9523\n",
      "Epoch 291: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1259 - acc: 0.9520 - val_loss: 0.9183 - val_acc: 0.9188\n",
      "Epoch 292/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9482\n",
      "Epoch 292: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1265 - acc: 0.9479 - val_loss: 0.8320 - val_acc: 0.9184\n",
      "Epoch 293/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9497\n",
      "Epoch 293: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1338 - acc: 0.9505 - val_loss: 0.8620 - val_acc: 0.9136\n",
      "Epoch 294/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.9534\n",
      "Epoch 294: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1177 - acc: 0.9536 - val_loss: 0.9223 - val_acc: 0.9160\n",
      "Epoch 295/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9499\n",
      "Epoch 295: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1265 - acc: 0.9498 - val_loss: 0.8485 - val_acc: 0.9136\n",
      "Epoch 296/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9505\n",
      "Epoch 296: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1242 - acc: 0.9505 - val_loss: 0.9161 - val_acc: 0.9221\n",
      "Epoch 297/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9536\n",
      "Epoch 297: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1256 - acc: 0.9540 - val_loss: 0.9975 - val_acc: 0.9148\n",
      "Epoch 298/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9508\n",
      "Epoch 298: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1345 - acc: 0.9512 - val_loss: 0.8512 - val_acc: 0.9172\n",
      "Epoch 299/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9521\n",
      "Epoch 299: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1196 - acc: 0.9520 - val_loss: 0.9709 - val_acc: 0.9188\n",
      "Epoch 300/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9523\n",
      "Epoch 300: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1277 - acc: 0.9524 - val_loss: 0.9205 - val_acc: 0.9140\n",
      "Epoch 301/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9512\n",
      "Epoch 301: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1215 - acc: 0.9513 - val_loss: 1.0840 - val_acc: 0.9123\n",
      "Epoch 302/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9524\n",
      "Epoch 302: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1357 - acc: 0.9522 - val_loss: 1.0018 - val_acc: 0.9119\n",
      "Epoch 303/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9497\n",
      "Epoch 303: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1418 - acc: 0.9498 - val_loss: 0.8575 - val_acc: 0.9164\n",
      "Epoch 304/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9506\n",
      "Epoch 304: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1276 - acc: 0.9511 - val_loss: 0.9859 - val_acc: 0.9200\n",
      "Epoch 305/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9492\n",
      "Epoch 305: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1312 - acc: 0.9499 - val_loss: 0.8885 - val_acc: 0.9144\n",
      "Epoch 306/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9510\n",
      "Epoch 306: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1310 - acc: 0.9513 - val_loss: 0.9370 - val_acc: 0.9144\n",
      "Epoch 307/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9484\n",
      "Epoch 307: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1325 - acc: 0.9486 - val_loss: 1.0727 - val_acc: 0.9188\n",
      "Epoch 308/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9507\n",
      "Epoch 308: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1241 - acc: 0.9508 - val_loss: 0.9766 - val_acc: 0.9196\n",
      "Epoch 309/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9529\n",
      "Epoch 309: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1224 - acc: 0.9530 - val_loss: 1.0420 - val_acc: 0.9152\n",
      "Epoch 310/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9510\n",
      "Epoch 310: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1289 - acc: 0.9513 - val_loss: 0.9317 - val_acc: 0.9148\n",
      "Epoch 311/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9518\n",
      "Epoch 311: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1384 - acc: 0.9515 - val_loss: 0.9054 - val_acc: 0.9148\n",
      "Epoch 312/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9495\n",
      "Epoch 312: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1293 - acc: 0.9496 - val_loss: 1.0359 - val_acc: 0.9131\n",
      "Epoch 313/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9499\n",
      "Epoch 313: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1217 - acc: 0.9502 - val_loss: 0.8416 - val_acc: 0.9168\n",
      "Epoch 314/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9498\n",
      "Epoch 314: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1227 - acc: 0.9499 - val_loss: 0.8199 - val_acc: 0.9192\n",
      "Epoch 315/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.9563\n",
      "Epoch 315: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1176 - acc: 0.9567 - val_loss: 0.9777 - val_acc: 0.9200\n",
      "Epoch 316/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9501\n",
      "Epoch 316: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1213 - acc: 0.9504 - val_loss: 0.9802 - val_acc: 0.9160\n",
      "Epoch 317/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9495\n",
      "Epoch 317: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1257 - acc: 0.9497 - val_loss: 0.9650 - val_acc: 0.9200\n",
      "Epoch 318/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9488\n",
      "Epoch 318: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1359 - acc: 0.9493 - val_loss: 0.8958 - val_acc: 0.9123\n",
      "Epoch 319/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9519\n",
      "Epoch 319: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1201 - acc: 0.9523 - val_loss: 0.8427 - val_acc: 0.9140\n",
      "Epoch 320/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9523\n",
      "Epoch 320: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1334 - acc: 0.9523 - val_loss: 1.0387 - val_acc: 0.9172\n",
      "Epoch 321/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9518\n",
      "Epoch 321: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1223 - acc: 0.9520 - val_loss: 0.9774 - val_acc: 0.9188\n",
      "Epoch 322/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1207 - acc: 0.9537\n",
      "Epoch 322: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1212 - acc: 0.9531 - val_loss: 1.0259 - val_acc: 0.9140\n",
      "Epoch 323/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9524\n",
      "Epoch 323: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1201 - acc: 0.9530 - val_loss: 1.0627 - val_acc: 0.9103\n",
      "Epoch 324/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9520\n",
      "Epoch 324: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1134 - acc: 0.9523 - val_loss: 1.1972 - val_acc: 0.9156\n",
      "Epoch 325/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9543\n",
      "Epoch 325: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1271 - acc: 0.9542 - val_loss: 1.0478 - val_acc: 0.9111\n",
      "Epoch 326/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9505\n",
      "Epoch 326: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1211 - acc: 0.9507 - val_loss: 1.0169 - val_acc: 0.9144\n",
      "Epoch 327/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9519\n",
      "Epoch 327: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1236 - acc: 0.9520 - val_loss: 1.1366 - val_acc: 0.9160\n",
      "Epoch 328/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9513\n",
      "Epoch 328: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1297 - acc: 0.9512 - val_loss: 0.9833 - val_acc: 0.9200\n",
      "Epoch 329/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9528\n",
      "Epoch 329: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1219 - acc: 0.9528 - val_loss: 1.0246 - val_acc: 0.9168\n",
      "Epoch 330/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9513\n",
      "Epoch 330: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1219 - acc: 0.9515 - val_loss: 1.0709 - val_acc: 0.9148\n",
      "Epoch 331/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9529\n",
      "Epoch 331: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1296 - acc: 0.9530 - val_loss: 1.0786 - val_acc: 0.9136\n",
      "Epoch 332/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9511\n",
      "Epoch 332: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1219 - acc: 0.9518 - val_loss: 1.1539 - val_acc: 0.9160\n",
      "Epoch 333/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1443 - acc: 0.9516\n",
      "Epoch 333: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1427 - acc: 0.9518 - val_loss: 1.1235 - val_acc: 0.9172\n",
      "Epoch 334/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9522\n",
      "Epoch 334: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1285 - acc: 0.9522 - val_loss: 1.0979 - val_acc: 0.9188\n",
      "Epoch 335/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9533\n",
      "Epoch 335: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1241 - acc: 0.9530 - val_loss: 1.0225 - val_acc: 0.9119\n",
      "Epoch 336/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9553\n",
      "Epoch 336: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1221 - acc: 0.9555 - val_loss: 0.9977 - val_acc: 0.9168\n",
      "Epoch 337/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9515\n",
      "Epoch 337: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1335 - acc: 0.9517 - val_loss: 0.9581 - val_acc: 0.9196\n",
      "Epoch 338/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9551\n",
      "Epoch 338: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1190 - acc: 0.9558 - val_loss: 1.0659 - val_acc: 0.9184\n",
      "Epoch 339/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9557\n",
      "Epoch 339: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1071 - acc: 0.9557 - val_loss: 1.1009 - val_acc: 0.9148\n",
      "Epoch 340/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9491\n",
      "Epoch 340: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1369 - acc: 0.9494 - val_loss: 1.0452 - val_acc: 0.9188\n",
      "Epoch 341/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9559\n",
      "Epoch 341: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1170 - acc: 0.9560 - val_loss: 1.0749 - val_acc: 0.9196\n",
      "Epoch 342/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1346 - acc: 0.9528\n",
      "Epoch 342: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1340 - acc: 0.9526 - val_loss: 0.9064 - val_acc: 0.9131\n",
      "Epoch 343/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9532\n",
      "Epoch 343: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1211 - acc: 0.9530 - val_loss: 1.0245 - val_acc: 0.9180\n",
      "Epoch 344/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9544\n",
      "Epoch 344: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1145 - acc: 0.9542 - val_loss: 1.0729 - val_acc: 0.9119\n",
      "Epoch 345/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9539\n",
      "Epoch 345: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1186 - acc: 0.9547 - val_loss: 1.0624 - val_acc: 0.9152\n",
      "Epoch 346/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9508\n",
      "Epoch 346: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1332 - acc: 0.9508 - val_loss: 1.0166 - val_acc: 0.9176\n",
      "Epoch 347/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1238 - acc: 0.9530\n",
      "Epoch 347: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1238 - acc: 0.9530 - val_loss: 1.0718 - val_acc: 0.9184\n",
      "Epoch 348/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9530\n",
      "Epoch 348: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1167 - acc: 0.9528 - val_loss: 1.1471 - val_acc: 0.9160\n",
      "Epoch 349/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1399 - acc: 0.9472\n",
      "Epoch 349: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1389 - acc: 0.9477 - val_loss: 1.1084 - val_acc: 0.9152\n",
      "Epoch 350/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9522\n",
      "Epoch 350: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1244 - acc: 0.9525 - val_loss: 1.0607 - val_acc: 0.9127\n",
      "Epoch 351/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9536\n",
      "Epoch 351: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1174 - acc: 0.9540 - val_loss: 1.1115 - val_acc: 0.9160\n",
      "Epoch 352/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9566\n",
      "Epoch 352: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1161 - acc: 0.9567 - val_loss: 1.0043 - val_acc: 0.9099\n",
      "Epoch 353/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9533\n",
      "Epoch 353: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1206 - acc: 0.9532 - val_loss: 1.1006 - val_acc: 0.9156\n",
      "Epoch 354/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9531\n",
      "Epoch 354: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1198 - acc: 0.9530 - val_loss: 1.0699 - val_acc: 0.9119\n",
      "Epoch 355/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9504\n",
      "Epoch 355: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1350 - acc: 0.9506 - val_loss: 1.0306 - val_acc: 0.9091\n",
      "Epoch 356/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9559\n",
      "Epoch 356: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1225 - acc: 0.9567 - val_loss: 1.1532 - val_acc: 0.9188\n",
      "Epoch 357/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9511\n",
      "Epoch 357: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1165 - acc: 0.9513 - val_loss: 1.2951 - val_acc: 0.9127\n",
      "Epoch 358/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9520\n",
      "Epoch 358: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1192 - acc: 0.9528 - val_loss: 1.1166 - val_acc: 0.9136\n",
      "Epoch 359/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9572\n",
      "Epoch 359: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1122 - acc: 0.9571 - val_loss: 1.1181 - val_acc: 0.9107\n",
      "Epoch 360/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9544\n",
      "Epoch 360: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1189 - acc: 0.9545 - val_loss: 1.0451 - val_acc: 0.9184\n",
      "Epoch 361/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9551\n",
      "Epoch 361: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1201 - acc: 0.9550 - val_loss: 1.0347 - val_acc: 0.9188\n",
      "Epoch 362/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9538\n",
      "Epoch 362: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1133 - acc: 0.9538 - val_loss: 1.0142 - val_acc: 0.9176\n",
      "Epoch 363/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9541\n",
      "Epoch 363: val_acc did not improve from 0.92248\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1191 - acc: 0.9540 - val_loss: 1.0745 - val_acc: 0.9196\n",
      "Epoch 364/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9519\n",
      "Epoch 364: val_acc improved from 0.92248 to 0.92573, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1309 - acc: 0.9517 - val_loss: 0.8920 - val_acc: 0.9257\n",
      "Epoch 365/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1146 - acc: 0.9518\n",
      "Epoch 365: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1146 - acc: 0.9518 - val_loss: 0.9646 - val_acc: 0.9160\n",
      "Epoch 366/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9535\n",
      "Epoch 366: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1233 - acc: 0.9539 - val_loss: 1.0821 - val_acc: 0.9172\n",
      "Epoch 367/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9549\n",
      "Epoch 367: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1258 - acc: 0.9548 - val_loss: 1.1315 - val_acc: 0.9144\n",
      "Epoch 368/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9502\n",
      "Epoch 368: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1230 - acc: 0.9506 - val_loss: 0.9922 - val_acc: 0.9213\n",
      "Epoch 369/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9529\n",
      "Epoch 369: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1228 - acc: 0.9529 - val_loss: 1.1470 - val_acc: 0.9188\n",
      "Epoch 370/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9567\n",
      "Epoch 370: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1107 - acc: 0.9566 - val_loss: 1.2173 - val_acc: 0.9168\n",
      "Epoch 371/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9535\n",
      "Epoch 371: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1288 - acc: 0.9540 - val_loss: 1.1856 - val_acc: 0.9140\n",
      "Epoch 372/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9554\n",
      "Epoch 372: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1146 - acc: 0.9561 - val_loss: 1.0821 - val_acc: 0.9172\n",
      "Epoch 373/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9539\n",
      "Epoch 373: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1279 - acc: 0.9536 - val_loss: 1.2266 - val_acc: 0.9184\n",
      "Epoch 374/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9559\n",
      "Epoch 374: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1134 - acc: 0.9560 - val_loss: 1.1845 - val_acc: 0.9144\n",
      "Epoch 375/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9538\n",
      "Epoch 375: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1130 - acc: 0.9546 - val_loss: 1.2376 - val_acc: 0.9205\n",
      "Epoch 376/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9558\n",
      "Epoch 376: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1198 - acc: 0.9562 - val_loss: 1.2393 - val_acc: 0.9188\n",
      "Epoch 377/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9573\n",
      "Epoch 377: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1241 - acc: 0.9576 - val_loss: 1.3165 - val_acc: 0.9148\n",
      "Epoch 378/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9536\n",
      "Epoch 378: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1231 - acc: 0.9535 - val_loss: 1.1923 - val_acc: 0.9156\n",
      "Epoch 379/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9553\n",
      "Epoch 379: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1289 - acc: 0.9551 - val_loss: 1.2225 - val_acc: 0.9160\n",
      "Epoch 380/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9517\n",
      "Epoch 380: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1347 - acc: 0.9518 - val_loss: 1.1682 - val_acc: 0.9176\n",
      "Epoch 381/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1215 - acc: 0.9556\n",
      "Epoch 381: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1215 - acc: 0.9556 - val_loss: 1.1590 - val_acc: 0.9184\n",
      "Epoch 382/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9543\n",
      "Epoch 382: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1161 - acc: 0.9544 - val_loss: 1.2235 - val_acc: 0.9160\n",
      "Epoch 383/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9571\n",
      "Epoch 383: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1124 - acc: 0.9573 - val_loss: 1.1328 - val_acc: 0.9180\n",
      "Epoch 384/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9498\n",
      "Epoch 384: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1214 - acc: 0.9505 - val_loss: 1.0726 - val_acc: 0.9200\n",
      "Epoch 385/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9600\n",
      "Epoch 385: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1118 - acc: 0.9601 - val_loss: 1.4035 - val_acc: 0.9144\n",
      "Epoch 386/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9529\n",
      "Epoch 386: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1229 - acc: 0.9534 - val_loss: 1.2148 - val_acc: 0.9148\n",
      "Epoch 387/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1214 - acc: 0.9538\n",
      "Epoch 387: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1214 - acc: 0.9538 - val_loss: 1.1492 - val_acc: 0.9168\n",
      "Epoch 388/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9557\n",
      "Epoch 388: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1118 - acc: 0.9559 - val_loss: 1.2680 - val_acc: 0.9168\n",
      "Epoch 389/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9566\n",
      "Epoch 389: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1210 - acc: 0.9568 - val_loss: 1.2815 - val_acc: 0.9180\n",
      "Epoch 390/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9560\n",
      "Epoch 390: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1287 - acc: 0.9558 - val_loss: 1.1031 - val_acc: 0.9144\n",
      "Epoch 391/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9547\n",
      "Epoch 391: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1189 - acc: 0.9550 - val_loss: 1.2458 - val_acc: 0.9172\n",
      "Epoch 392/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9586\n",
      "Epoch 392: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1152 - acc: 0.9589 - val_loss: 1.2078 - val_acc: 0.9168\n",
      "Epoch 393/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9564\n",
      "Epoch 393: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1120 - acc: 0.9566 - val_loss: 1.0803 - val_acc: 0.9176\n",
      "Epoch 394/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1248 - acc: 0.9556\n",
      "Epoch 394: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1248 - acc: 0.9556 - val_loss: 1.3081 - val_acc: 0.9200\n",
      "Epoch 395/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9565\n",
      "Epoch 395: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1350 - acc: 0.9566 - val_loss: 1.2423 - val_acc: 0.9229\n",
      "Epoch 396/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9555\n",
      "Epoch 396: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1145 - acc: 0.9558 - val_loss: 1.3045 - val_acc: 0.9172\n",
      "Epoch 397/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9566\n",
      "Epoch 397: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1124 - acc: 0.9566 - val_loss: 1.1601 - val_acc: 0.9148\n",
      "Epoch 398/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9599\n",
      "Epoch 398: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1067 - acc: 0.9595 - val_loss: 1.1842 - val_acc: 0.9200\n",
      "Epoch 399/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9582\n",
      "Epoch 399: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1076 - acc: 0.9580 - val_loss: 1.1897 - val_acc: 0.9148\n",
      "Epoch 400/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9565\n",
      "Epoch 400: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1324 - acc: 0.9564 - val_loss: 1.1638 - val_acc: 0.9131\n",
      "Epoch 401/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9553\n",
      "Epoch 401: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1084 - acc: 0.9556 - val_loss: 1.2363 - val_acc: 0.9192\n",
      "Epoch 402/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9569\n",
      "Epoch 402: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1114 - acc: 0.9571 - val_loss: 1.0272 - val_acc: 0.9205\n",
      "Epoch 403/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9560\n",
      "Epoch 403: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1096 - acc: 0.9561 - val_loss: 1.1423 - val_acc: 0.9192\n",
      "Epoch 404/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9560\n",
      "Epoch 404: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1094 - acc: 0.9563 - val_loss: 1.1557 - val_acc: 0.9209\n",
      "Epoch 405/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9559\n",
      "Epoch 405: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1138 - acc: 0.9560 - val_loss: 1.1738 - val_acc: 0.9205\n",
      "Epoch 406/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9584\n",
      "Epoch 406: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1190 - acc: 0.9582 - val_loss: 1.2843 - val_acc: 0.9172\n",
      "Epoch 407/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9580\n",
      "Epoch 407: val_acc did not improve from 0.92573\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1126 - acc: 0.9582 - val_loss: 1.0091 - val_acc: 0.9148\n",
      "Epoch 408/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9534\n",
      "Epoch 408: val_acc improved from 0.92573 to 0.92735, saving model to train_logs/logs7/FFT_ANN\\4\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1162 - acc: 0.9536 - val_loss: 1.1375 - val_acc: 0.9274\n",
      "Epoch 409/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9580\n",
      "Epoch 409: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1086 - acc: 0.9581 - val_loss: 1.2343 - val_acc: 0.9184\n",
      "Epoch 410/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9587\n",
      "Epoch 410: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1157 - acc: 0.9594 - val_loss: 1.0178 - val_acc: 0.9249\n",
      "Epoch 411/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9579\n",
      "Epoch 411: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1129 - acc: 0.9584 - val_loss: 1.0297 - val_acc: 0.9261\n",
      "Epoch 412/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1095 - acc: 0.9571\n",
      "Epoch 412: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1095 - acc: 0.9571 - val_loss: 0.9732 - val_acc: 0.9192\n",
      "Epoch 413/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9581\n",
      "Epoch 413: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1119 - acc: 0.9580 - val_loss: 1.0932 - val_acc: 0.9229\n",
      "Epoch 414/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9546\n",
      "Epoch 414: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1096 - acc: 0.9551 - val_loss: 1.0022 - val_acc: 0.9172\n",
      "Epoch 415/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9576\n",
      "Epoch 415: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1030 - acc: 0.9577 - val_loss: 1.1583 - val_acc: 0.9196\n",
      "Epoch 416/2000\n",
      "595/616 [===========================>..] - ETA: 0s - loss: 0.1143 - acc: 0.9565\n",
      "Epoch 416: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1130 - acc: 0.9569 - val_loss: 1.1190 - val_acc: 0.9148\n",
      "Epoch 417/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9566\n",
      "Epoch 417: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1121 - acc: 0.9569 - val_loss: 1.2514 - val_acc: 0.9205\n",
      "Epoch 418/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9548\n",
      "Epoch 418: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1204 - acc: 0.9549 - val_loss: 1.1471 - val_acc: 0.9217\n",
      "Epoch 419/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9578\n",
      "Epoch 419: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1154 - acc: 0.9579 - val_loss: 1.0959 - val_acc: 0.9241\n",
      "Epoch 420/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1174 - acc: 0.9547\n",
      "Epoch 420: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1174 - acc: 0.9547 - val_loss: 1.1570 - val_acc: 0.9188\n",
      "Epoch 421/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9598\n",
      "Epoch 421: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1134 - acc: 0.9598 - val_loss: 1.0498 - val_acc: 0.9184\n",
      "Epoch 422/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9566\n",
      "Epoch 422: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1193 - acc: 0.9570 - val_loss: 1.0602 - val_acc: 0.9156\n",
      "Epoch 423/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1035 - acc: 0.9597\n",
      "Epoch 423: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1035 - acc: 0.9597 - val_loss: 1.1187 - val_acc: 0.9209\n",
      "Epoch 424/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1151 - acc: 0.9570\n",
      "Epoch 424: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1151 - acc: 0.9570 - val_loss: 1.1671 - val_acc: 0.9213\n",
      "Epoch 425/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9579\n",
      "Epoch 425: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1253 - acc: 0.9578 - val_loss: 1.2013 - val_acc: 0.9233\n",
      "Epoch 426/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9553\n",
      "Epoch 426: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1265 - acc: 0.9556 - val_loss: 1.2809 - val_acc: 0.9257\n",
      "Epoch 427/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9588\n",
      "Epoch 427: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1192 - acc: 0.9588 - val_loss: 1.4464 - val_acc: 0.9209\n",
      "Epoch 428/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9548\n",
      "Epoch 428: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1326 - acc: 0.9547 - val_loss: 1.3272 - val_acc: 0.9213\n",
      "Epoch 429/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9562\n",
      "Epoch 429: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1099 - acc: 0.9567 - val_loss: 1.2706 - val_acc: 0.9184\n",
      "Epoch 430/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9544\n",
      "Epoch 430: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1205 - acc: 0.9543 - val_loss: 1.1393 - val_acc: 0.9241\n",
      "Epoch 431/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9557\n",
      "Epoch 431: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1140 - acc: 0.9564 - val_loss: 1.3737 - val_acc: 0.9261\n",
      "Epoch 432/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9583\n",
      "Epoch 432: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1068 - acc: 0.9587 - val_loss: 1.3668 - val_acc: 0.9192\n",
      "Epoch 433/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9569\n",
      "Epoch 433: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1122 - acc: 0.9570 - val_loss: 1.4321 - val_acc: 0.9241\n",
      "Epoch 434/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9569\n",
      "Epoch 434: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1125 - acc: 0.9571 - val_loss: 1.4030 - val_acc: 0.9164\n",
      "Epoch 435/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9597\n",
      "Epoch 435: val_acc did not improve from 0.92735\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1034 - acc: 0.9600 - val_loss: 1.4738 - val_acc: 0.9229\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_4 (Reshape)         (None, 80, 1)             0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 80)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               41472     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,057\n",
      "Trainable params: 173,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.5869 - acc: 0.7147\n",
      "Epoch 1: val_acc improved from -inf to 0.76533, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.5850 - acc: 0.7155 - val_loss: 0.4592 - val_acc: 0.7653\n",
      "Epoch 2/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.4740 - acc: 0.7701\n",
      "Epoch 2: val_acc improved from 0.76533 to 0.79740, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4740 - acc: 0.7700 - val_loss: 0.4165 - val_acc: 0.7974\n",
      "Epoch 3/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.4447 - acc: 0.7811\n",
      "Epoch 3: val_acc did not improve from 0.79740\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4424 - acc: 0.7824 - val_loss: 0.4169 - val_acc: 0.7962\n",
      "Epoch 4/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.4264 - acc: 0.7955\n",
      "Epoch 4: val_acc improved from 0.79740 to 0.82095, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4260 - acc: 0.7958 - val_loss: 0.3837 - val_acc: 0.8210\n",
      "Epoch 5/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.4078 - acc: 0.8041\n",
      "Epoch 5: val_acc improved from 0.82095 to 0.82257, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.4076 - acc: 0.8041 - val_loss: 0.3775 - val_acc: 0.8226\n",
      "Epoch 6/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.3992 - acc: 0.8118\n",
      "Epoch 6: val_acc did not improve from 0.82257\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3976 - acc: 0.8123 - val_loss: 0.3811 - val_acc: 0.8140\n",
      "Epoch 7/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.3819 - acc: 0.8173\n",
      "Epoch 7: val_acc improved from 0.82257 to 0.83069, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3807 - acc: 0.8179 - val_loss: 0.3697 - val_acc: 0.8307\n",
      "Epoch 8/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.3787 - acc: 0.8196\n",
      "Epoch 8: val_acc improved from 0.83069 to 0.83110, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3787 - acc: 0.8196 - val_loss: 0.3615 - val_acc: 0.8311\n",
      "Epoch 9/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.3694 - acc: 0.8218\n",
      "Epoch 9: val_acc improved from 0.83110 to 0.83638, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3683 - acc: 0.8224 - val_loss: 0.3459 - val_acc: 0.8364\n",
      "Epoch 10/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.3643 - acc: 0.8322\n",
      "Epoch 10: val_acc improved from 0.83638 to 0.84572, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3627 - acc: 0.8332 - val_loss: 0.3391 - val_acc: 0.8457\n",
      "Epoch 11/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.3536 - acc: 0.8344\n",
      "Epoch 11: val_acc did not improve from 0.84572\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3536 - acc: 0.8344 - val_loss: 0.3375 - val_acc: 0.8437\n",
      "Epoch 12/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8367\n",
      "Epoch 12: val_acc did not improve from 0.84572\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3518 - acc: 0.8377 - val_loss: 0.3336 - val_acc: 0.8392\n",
      "Epoch 13/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.3399 - acc: 0.8405\n",
      "Epoch 13: val_acc improved from 0.84572 to 0.84937, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3393 - acc: 0.8407 - val_loss: 0.3268 - val_acc: 0.8494\n",
      "Epoch 14/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.3391 - acc: 0.8421\n",
      "Epoch 14: val_acc did not improve from 0.84937\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3388 - acc: 0.8423 - val_loss: 0.3258 - val_acc: 0.8494\n",
      "Epoch 15/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.3391 - acc: 0.8455\n",
      "Epoch 15: val_acc improved from 0.84937 to 0.85384, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3392 - acc: 0.8451 - val_loss: 0.3162 - val_acc: 0.8538\n",
      "Epoch 16/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.3236 - acc: 0.8557\n",
      "Epoch 16: val_acc did not improve from 0.85384\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3223 - acc: 0.8560 - val_loss: 0.3282 - val_acc: 0.8514\n",
      "Epoch 17/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.3242 - acc: 0.8512\n",
      "Epoch 17: val_acc did not improve from 0.85384\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3240 - acc: 0.8512 - val_loss: 0.3169 - val_acc: 0.8538\n",
      "Epoch 18/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.3193 - acc: 0.8542\n",
      "Epoch 18: val_acc improved from 0.85384 to 0.85668, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3193 - acc: 0.8543 - val_loss: 0.3162 - val_acc: 0.8567\n",
      "Epoch 19/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.3113 - acc: 0.8563\n",
      "Epoch 19: val_acc improved from 0.85668 to 0.86317, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3113 - acc: 0.8563 - val_loss: 0.3100 - val_acc: 0.8632\n",
      "Epoch 20/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.3070 - acc: 0.8575\n",
      "Epoch 20: val_acc did not improve from 0.86317\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.3071 - acc: 0.8572 - val_loss: 0.3130 - val_acc: 0.8587\n",
      "Epoch 21/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.3110 - acc: 0.8603\n",
      "Epoch 21: val_acc did not improve from 0.86317\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.3093 - acc: 0.8608 - val_loss: 0.3065 - val_acc: 0.8591\n",
      "Epoch 22/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.3005 - acc: 0.8618\n",
      "Epoch 22: val_acc improved from 0.86317 to 0.86439, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.2995 - acc: 0.8620 - val_loss: 0.2985 - val_acc: 0.8644\n",
      "Epoch 23/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2984 - acc: 0.8625\n",
      "Epoch 23: val_acc did not improve from 0.86439\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.2973 - acc: 0.8630 - val_loss: 0.2876 - val_acc: 0.8628\n",
      "Epoch 24/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2960 - acc: 0.8693\n",
      "Epoch 24: val_acc improved from 0.86439 to 0.87251, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2960 - acc: 0.8693 - val_loss: 0.2898 - val_acc: 0.8725\n",
      "Epoch 25/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.2937 - acc: 0.8650\n",
      "Epoch 25: val_acc did not improve from 0.87251\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2928 - acc: 0.8656 - val_loss: 0.3081 - val_acc: 0.8522\n",
      "Epoch 26/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2893 - acc: 0.8652\n",
      "Epoch 26: val_acc did not improve from 0.87251\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2893 - acc: 0.8652 - val_loss: 0.3033 - val_acc: 0.8595\n",
      "Epoch 27/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2840 - acc: 0.8725\n",
      "Epoch 27: val_acc did not improve from 0.87251\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2839 - acc: 0.8725 - val_loss: 0.2797 - val_acc: 0.8713\n",
      "Epoch 28/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2864 - acc: 0.8688\n",
      "Epoch 28: val_acc did not improve from 0.87251\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2856 - acc: 0.8693 - val_loss: 0.2782 - val_acc: 0.8713\n",
      "Epoch 29/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2786 - acc: 0.8746\n",
      "Epoch 29: val_acc did not improve from 0.87251\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2781 - acc: 0.8747 - val_loss: 0.2791 - val_acc: 0.8717\n",
      "Epoch 30/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2872 - acc: 0.8720\n",
      "Epoch 30: val_acc improved from 0.87251 to 0.87860, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2871 - acc: 0.8720 - val_loss: 0.2822 - val_acc: 0.8786\n",
      "Epoch 31/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2804 - acc: 0.8745\n",
      "Epoch 31: val_acc improved from 0.87860 to 0.88063, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2799 - acc: 0.8746 - val_loss: 0.2738 - val_acc: 0.8806\n",
      "Epoch 32/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2713 - acc: 0.8767\n",
      "Epoch 32: val_acc did not improve from 0.88063\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2708 - acc: 0.8767 - val_loss: 0.2856 - val_acc: 0.8713\n",
      "Epoch 33/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2847 - acc: 0.8758\n",
      "Epoch 33: val_acc did not improve from 0.88063\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2836 - acc: 0.8756 - val_loss: 0.2791 - val_acc: 0.8693\n",
      "Epoch 34/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2702 - acc: 0.8799\n",
      "Epoch 34: val_acc did not improve from 0.88063\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2699 - acc: 0.8801 - val_loss: 0.2896 - val_acc: 0.8648\n",
      "Epoch 35/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.2628 - acc: 0.8817\n",
      "Epoch 35: val_acc did not improve from 0.88063\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2622 - acc: 0.8813 - val_loss: 0.2813 - val_acc: 0.8737\n",
      "Epoch 36/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2646 - acc: 0.8814\n",
      "Epoch 36: val_acc did not improve from 0.88063\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2645 - acc: 0.8813 - val_loss: 0.2839 - val_acc: 0.8762\n",
      "Epoch 37/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2669 - acc: 0.8810\n",
      "Epoch 37: val_acc improved from 0.88063 to 0.88104, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2659 - acc: 0.8808 - val_loss: 0.2704 - val_acc: 0.8810\n",
      "Epoch 38/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2578 - acc: 0.8856\n",
      "Epoch 38: val_acc improved from 0.88104 to 0.88307, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2574 - acc: 0.8861 - val_loss: 0.2613 - val_acc: 0.8831\n",
      "Epoch 39/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2596 - acc: 0.8875\n",
      "Epoch 39: val_acc improved from 0.88307 to 0.88591, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2593 - acc: 0.8880 - val_loss: 0.2595 - val_acc: 0.8859\n",
      "Epoch 40/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2546 - acc: 0.8853\n",
      "Epoch 40: val_acc improved from 0.88591 to 0.88632, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2538 - acc: 0.8857 - val_loss: 0.2670 - val_acc: 0.8863\n",
      "Epoch 41/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.2591 - acc: 0.8886\n",
      "Epoch 41: val_acc did not improve from 0.88632\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2575 - acc: 0.8892 - val_loss: 0.2787 - val_acc: 0.8754\n",
      "Epoch 42/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2512 - acc: 0.8919\n",
      "Epoch 42: val_acc improved from 0.88632 to 0.88957, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2502 - acc: 0.8926 - val_loss: 0.2630 - val_acc: 0.8896\n",
      "Epoch 43/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2534 - acc: 0.8875\n",
      "Epoch 43: val_acc did not improve from 0.88957\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2518 - acc: 0.8883 - val_loss: 0.2653 - val_acc: 0.8888\n",
      "Epoch 44/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2528 - acc: 0.8886\n",
      "Epoch 44: val_acc did not improve from 0.88957\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2527 - acc: 0.8884 - val_loss: 0.2686 - val_acc: 0.8831\n",
      "Epoch 45/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2477 - acc: 0.8931\n",
      "Epoch 45: val_acc improved from 0.88957 to 0.89200, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2474 - acc: 0.8931 - val_loss: 0.2467 - val_acc: 0.8920\n",
      "Epoch 46/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2505 - acc: 0.8936\n",
      "Epoch 46: val_acc did not improve from 0.89200\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.2504 - acc: 0.8931 - val_loss: 0.2839 - val_acc: 0.8685\n",
      "Epoch 47/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2395 - acc: 0.8965\n",
      "Epoch 47: val_acc did not improve from 0.89200\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.2383 - acc: 0.8970 - val_loss: 0.2585 - val_acc: 0.8892\n",
      "Epoch 48/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2417 - acc: 0.8931\n",
      "Epoch 48: val_acc did not improve from 0.89200\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2417 - acc: 0.8931 - val_loss: 0.2619 - val_acc: 0.8843\n",
      "Epoch 49/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2479 - acc: 0.8900\n",
      "Epoch 49: val_acc did not improve from 0.89200\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2470 - acc: 0.8903 - val_loss: 0.2620 - val_acc: 0.8867\n",
      "Epoch 50/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2338 - acc: 0.8974\n",
      "Epoch 50: val_acc did not improve from 0.89200\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2337 - acc: 0.8976 - val_loss: 0.2800 - val_acc: 0.8766\n",
      "Epoch 51/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2403 - acc: 0.8957\n",
      "Epoch 51: val_acc improved from 0.89200 to 0.89687, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2405 - acc: 0.8955 - val_loss: 0.2411 - val_acc: 0.8969\n",
      "Epoch 52/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2392 - acc: 0.9000\n",
      "Epoch 52: val_acc did not improve from 0.89687\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2377 - acc: 0.9008 - val_loss: 0.2537 - val_acc: 0.8928\n",
      "Epoch 53/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2307 - acc: 0.8987\n",
      "Epoch 53: val_acc did not improve from 0.89687\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2307 - acc: 0.8987 - val_loss: 0.2623 - val_acc: 0.8831\n",
      "Epoch 54/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2383 - acc: 0.8993\n",
      "Epoch 54: val_acc did not improve from 0.89687\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2378 - acc: 0.8995 - val_loss: 0.2539 - val_acc: 0.8908\n",
      "Epoch 55/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2309 - acc: 0.9025\n",
      "Epoch 55: val_acc did not improve from 0.89687\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2300 - acc: 0.9029 - val_loss: 0.2550 - val_acc: 0.8920\n",
      "Epoch 56/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2415 - acc: 0.8938\n",
      "Epoch 56: val_acc did not improve from 0.89687\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.2415 - acc: 0.8938 - val_loss: 0.2567 - val_acc: 0.8928\n",
      "Epoch 57/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2312 - acc: 0.9006\n",
      "Epoch 57: val_acc did not improve from 0.89687\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2304 - acc: 0.9010 - val_loss: 0.2540 - val_acc: 0.8920\n",
      "Epoch 58/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2324 - acc: 0.8981\n",
      "Epoch 58: val_acc did not improve from 0.89687\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2321 - acc: 0.8983 - val_loss: 0.2611 - val_acc: 0.8904\n",
      "Epoch 59/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2343 - acc: 0.9029\n",
      "Epoch 59: val_acc improved from 0.89687 to 0.89931, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2332 - acc: 0.9032 - val_loss: 0.2496 - val_acc: 0.8993\n",
      "Epoch 60/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2272 - acc: 0.9004\n",
      "Epoch 60: val_acc did not improve from 0.89931\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.2270 - acc: 0.9004 - val_loss: 0.2507 - val_acc: 0.8879\n",
      "Epoch 61/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2245 - acc: 0.9039\n",
      "Epoch 61: val_acc did not improve from 0.89931\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2246 - acc: 0.9038 - val_loss: 0.2461 - val_acc: 0.8892\n",
      "Epoch 62/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9015\n",
      "Epoch 62: val_acc did not improve from 0.89931\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2280 - acc: 0.9014 - val_loss: 0.2609 - val_acc: 0.8916\n",
      "Epoch 63/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2268 - acc: 0.9048\n",
      "Epoch 63: val_acc did not improve from 0.89931\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2277 - acc: 0.9045 - val_loss: 0.2507 - val_acc: 0.8965\n",
      "Epoch 64/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.2254 - acc: 0.9041\n",
      "Epoch 64: val_acc did not improve from 0.89931\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2252 - acc: 0.9041 - val_loss: 0.2476 - val_acc: 0.8944\n",
      "Epoch 65/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9053\n",
      "Epoch 65: val_acc did not improve from 0.89931\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2161 - acc: 0.9053 - val_loss: 0.2481 - val_acc: 0.8981\n",
      "Epoch 66/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2192 - acc: 0.9059\n",
      "Epoch 66: val_acc did not improve from 0.89931\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2176 - acc: 0.9066 - val_loss: 0.2576 - val_acc: 0.8924\n",
      "Epoch 67/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2165 - acc: 0.9056\n",
      "Epoch 67: val_acc did not improve from 0.89931\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2156 - acc: 0.9061 - val_loss: 0.2728 - val_acc: 0.8867\n",
      "Epoch 68/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9082\n",
      "Epoch 68: val_acc improved from 0.89931 to 0.90093, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2103 - acc: 0.9080 - val_loss: 0.2510 - val_acc: 0.9009\n",
      "Epoch 69/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.2197 - acc: 0.9055\n",
      "Epoch 69: val_acc did not improve from 0.90093\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2197 - acc: 0.9055 - val_loss: 0.2570 - val_acc: 0.8969\n",
      "Epoch 70/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.2119 - acc: 0.9103\n",
      "Epoch 70: val_acc did not improve from 0.90093\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2118 - acc: 0.9105 - val_loss: 0.2565 - val_acc: 0.8920\n",
      "Epoch 71/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.2139 - acc: 0.9110\n",
      "Epoch 71: val_acc did not improve from 0.90093\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2131 - acc: 0.9115 - val_loss: 0.2721 - val_acc: 0.8965\n",
      "Epoch 72/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2193 - acc: 0.9084\n",
      "Epoch 72: val_acc did not improve from 0.90093\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2191 - acc: 0.9085 - val_loss: 0.2541 - val_acc: 0.8997\n",
      "Epoch 73/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9055\n",
      "Epoch 73: val_acc did not improve from 0.90093\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2123 - acc: 0.9055 - val_loss: 0.2575 - val_acc: 0.8989\n",
      "Epoch 74/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.2124 - acc: 0.9080\n",
      "Epoch 74: val_acc did not improve from 0.90093\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2113 - acc: 0.9083 - val_loss: 0.2531 - val_acc: 0.8952\n",
      "Epoch 75/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2082 - acc: 0.9108\n",
      "Epoch 75: val_acc improved from 0.90093 to 0.90134, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2080 - acc: 0.9108 - val_loss: 0.2550 - val_acc: 0.9013\n",
      "Epoch 76/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.2117 - acc: 0.9093\n",
      "Epoch 76: val_acc did not improve from 0.90134\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2103 - acc: 0.9100 - val_loss: 0.2540 - val_acc: 0.8952\n",
      "Epoch 77/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.2114 - acc: 0.9136\n",
      "Epoch 77: val_acc did not improve from 0.90134\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2113 - acc: 0.9136 - val_loss: 0.2439 - val_acc: 0.8997\n",
      "Epoch 78/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2186 - acc: 0.9088\n",
      "Epoch 78: val_acc did not improve from 0.90134\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2183 - acc: 0.9090 - val_loss: 0.2476 - val_acc: 0.8993\n",
      "Epoch 79/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9131\n",
      "Epoch 79: val_acc did not improve from 0.90134\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2096 - acc: 0.9131 - val_loss: 0.2475 - val_acc: 0.8944\n",
      "Epoch 80/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9108\n",
      "Epoch 80: val_acc did not improve from 0.90134\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2077 - acc: 0.9112 - val_loss: 0.2655 - val_acc: 0.8940\n",
      "Epoch 81/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2115 - acc: 0.9096\n",
      "Epoch 81: val_acc did not improve from 0.90134\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2106 - acc: 0.9097 - val_loss: 0.2681 - val_acc: 0.8985\n",
      "Epoch 82/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9093\n",
      "Epoch 82: val_acc did not improve from 0.90134\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2102 - acc: 0.9094 - val_loss: 0.2567 - val_acc: 0.8985\n",
      "Epoch 83/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.2057 - acc: 0.9133\n",
      "Epoch 83: val_acc improved from 0.90134 to 0.90418, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2054 - acc: 0.9135 - val_loss: 0.2475 - val_acc: 0.9042\n",
      "Epoch 84/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.2024 - acc: 0.9132\n",
      "Epoch 84: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2011 - acc: 0.9130 - val_loss: 0.2605 - val_acc: 0.9038\n",
      "Epoch 85/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9172\n",
      "Epoch 85: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.2015 - acc: 0.9180 - val_loss: 0.2517 - val_acc: 0.9034\n",
      "Epoch 86/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1998 - acc: 0.9109\n",
      "Epoch 86: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1992 - acc: 0.9110 - val_loss: 0.2574 - val_acc: 0.8989\n",
      "Epoch 87/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.2014 - acc: 0.9117\n",
      "Epoch 87: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2001 - acc: 0.9122 - val_loss: 0.2510 - val_acc: 0.8993\n",
      "Epoch 88/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9119\n",
      "Epoch 88: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.2012 - acc: 0.9121 - val_loss: 0.2628 - val_acc: 0.8948\n",
      "Epoch 89/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.2001 - acc: 0.9141\n",
      "Epoch 89: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.2001 - acc: 0.9140 - val_loss: 0.2577 - val_acc: 0.8989\n",
      "Epoch 90/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9156\n",
      "Epoch 90: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1963 - acc: 0.9158 - val_loss: 0.2556 - val_acc: 0.9013\n",
      "Epoch 91/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1949 - acc: 0.9150\n",
      "Epoch 91: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1949 - acc: 0.9150 - val_loss: 0.2937 - val_acc: 0.8920\n",
      "Epoch 92/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9178\n",
      "Epoch 92: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 3s 6ms/step - loss: 0.1972 - acc: 0.9180 - val_loss: 0.2579 - val_acc: 0.8985\n",
      "Epoch 93/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.2038 - acc: 0.9152\n",
      "Epoch 93: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.2027 - acc: 0.9156 - val_loss: 0.2637 - val_acc: 0.9042\n",
      "Epoch 94/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9194\n",
      "Epoch 94: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1924 - acc: 0.9194 - val_loss: 0.2750 - val_acc: 0.8965\n",
      "Epoch 95/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9182\n",
      "Epoch 95: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1978 - acc: 0.9181 - val_loss: 0.2721 - val_acc: 0.8969\n",
      "Epoch 96/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1987 - acc: 0.9164\n",
      "Epoch 96: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1987 - acc: 0.9166 - val_loss: 0.2518 - val_acc: 0.9038\n",
      "Epoch 97/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1921 - acc: 0.9175\n",
      "Epoch 97: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1918 - acc: 0.9176 - val_loss: 0.2788 - val_acc: 0.9030\n",
      "Epoch 98/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9196\n",
      "Epoch 98: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1898 - acc: 0.9199 - val_loss: 0.2668 - val_acc: 0.9022\n",
      "Epoch 99/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1911 - acc: 0.9182\n",
      "Epoch 99: val_acc did not improve from 0.90418\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1912 - acc: 0.9181 - val_loss: 0.2786 - val_acc: 0.9034\n",
      "Epoch 100/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1898 - acc: 0.9158\n",
      "Epoch 100: val_acc improved from 0.90418 to 0.90743, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1890 - acc: 0.9163 - val_loss: 0.2503 - val_acc: 0.9074\n",
      "Epoch 101/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1879 - acc: 0.9230\n",
      "Epoch 101: val_acc did not improve from 0.90743\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1872 - acc: 0.9232 - val_loss: 0.2576 - val_acc: 0.9066\n",
      "Epoch 102/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9186\n",
      "Epoch 102: val_acc improved from 0.90743 to 0.90905, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1883 - acc: 0.9187 - val_loss: 0.2498 - val_acc: 0.9091\n",
      "Epoch 103/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9191\n",
      "Epoch 103: val_acc did not improve from 0.90905\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1911 - acc: 0.9190 - val_loss: 0.2651 - val_acc: 0.9062\n",
      "Epoch 104/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1895 - acc: 0.9203\n",
      "Epoch 104: val_acc improved from 0.90905 to 0.91027, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1888 - acc: 0.9206 - val_loss: 0.2504 - val_acc: 0.9103\n",
      "Epoch 105/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1929 - acc: 0.9193\n",
      "Epoch 105: val_acc improved from 0.91027 to 0.91108, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1918 - acc: 0.9198 - val_loss: 0.2375 - val_acc: 0.9111\n",
      "Epoch 106/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9204\n",
      "Epoch 106: val_acc did not improve from 0.91108\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1926 - acc: 0.9204 - val_loss: 0.2560 - val_acc: 0.9103\n",
      "Epoch 107/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1881 - acc: 0.9254\n",
      "Epoch 107: val_acc did not improve from 0.91108\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1876 - acc: 0.9254 - val_loss: 0.2534 - val_acc: 0.9001\n",
      "Epoch 108/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1943 - acc: 0.9188\n",
      "Epoch 108: val_acc did not improve from 0.91108\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1935 - acc: 0.9187 - val_loss: 0.2563 - val_acc: 0.9013\n",
      "Epoch 109/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9204\n",
      "Epoch 109: val_acc did not improve from 0.91108\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1883 - acc: 0.9206 - val_loss: 0.2456 - val_acc: 0.9099\n",
      "Epoch 110/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9224\n",
      "Epoch 110: val_acc did not improve from 0.91108\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1794 - acc: 0.9228 - val_loss: 0.2560 - val_acc: 0.9050\n",
      "Epoch 111/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1971 - acc: 0.9228\n",
      "Epoch 111: val_acc did not improve from 0.91108\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1966 - acc: 0.9230 - val_loss: 0.2745 - val_acc: 0.9078\n",
      "Epoch 112/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1837 - acc: 0.9244\n",
      "Epoch 112: val_acc did not improve from 0.91108\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1830 - acc: 0.9248 - val_loss: 0.2771 - val_acc: 0.8997\n",
      "Epoch 113/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9255\n",
      "Epoch 113: val_acc did not improve from 0.91108\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1811 - acc: 0.9256 - val_loss: 0.2529 - val_acc: 0.9062\n",
      "Epoch 114/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1813 - acc: 0.9252\n",
      "Epoch 114: val_acc did not improve from 0.91108\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1811 - acc: 0.9252 - val_loss: 0.2482 - val_acc: 0.9111\n",
      "Epoch 115/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9233\n",
      "Epoch 115: val_acc improved from 0.91108 to 0.91190, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1792 - acc: 0.9239 - val_loss: 0.2572 - val_acc: 0.9119\n",
      "Epoch 116/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9252\n",
      "Epoch 116: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1802 - acc: 0.9253 - val_loss: 0.2564 - val_acc: 0.9091\n",
      "Epoch 117/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1903 - acc: 0.9208\n",
      "Epoch 117: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1893 - acc: 0.9212 - val_loss: 0.2584 - val_acc: 0.9038\n",
      "Epoch 118/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1812 - acc: 0.9245\n",
      "Epoch 118: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1812 - acc: 0.9244 - val_loss: 0.2689 - val_acc: 0.9034\n",
      "Epoch 119/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1736 - acc: 0.9258\n",
      "Epoch 119: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1733 - acc: 0.9259 - val_loss: 0.2536 - val_acc: 0.9107\n",
      "Epoch 120/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9305\n",
      "Epoch 120: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1697 - acc: 0.9303 - val_loss: 0.2583 - val_acc: 0.9070\n",
      "Epoch 121/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1837 - acc: 0.9228\n",
      "Epoch 121: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1843 - acc: 0.9226 - val_loss: 0.2733 - val_acc: 0.8993\n",
      "Epoch 122/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9227\n",
      "Epoch 122: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1835 - acc: 0.9225 - val_loss: 0.2926 - val_acc: 0.8896\n",
      "Epoch 123/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9282\n",
      "Epoch 123: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1730 - acc: 0.9283 - val_loss: 0.2766 - val_acc: 0.9066\n",
      "Epoch 124/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1844 - acc: 0.9228\n",
      "Epoch 124: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1836 - acc: 0.9231 - val_loss: 0.2665 - val_acc: 0.9091\n",
      "Epoch 125/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9245\n",
      "Epoch 125: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1802 - acc: 0.9246 - val_loss: 0.2609 - val_acc: 0.9017\n",
      "Epoch 126/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9281\n",
      "Epoch 126: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1725 - acc: 0.9286 - val_loss: 0.2857 - val_acc: 0.9062\n",
      "Epoch 127/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9264\n",
      "Epoch 127: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1739 - acc: 0.9268 - val_loss: 0.2690 - val_acc: 0.9107\n",
      "Epoch 128/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1817 - acc: 0.9281\n",
      "Epoch 128: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1816 - acc: 0.9281 - val_loss: 0.2615 - val_acc: 0.8985\n",
      "Epoch 129/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1767 - acc: 0.9257\n",
      "Epoch 129: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1763 - acc: 0.9257 - val_loss: 0.2685 - val_acc: 0.9070\n",
      "Epoch 130/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9298\n",
      "Epoch 130: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1714 - acc: 0.9298 - val_loss: 0.2604 - val_acc: 0.9070\n",
      "Epoch 131/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1711 - acc: 0.9283\n",
      "Epoch 131: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1705 - acc: 0.9286 - val_loss: 0.2695 - val_acc: 0.8977\n",
      "Epoch 132/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1730 - acc: 0.9298\n",
      "Epoch 132: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1721 - acc: 0.9298 - val_loss: 0.2450 - val_acc: 0.9095\n",
      "Epoch 133/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1765 - acc: 0.9239\n",
      "Epoch 133: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1764 - acc: 0.9239 - val_loss: 0.2663 - val_acc: 0.9046\n",
      "Epoch 134/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1738 - acc: 0.9275\n",
      "Epoch 134: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1737 - acc: 0.9277 - val_loss: 0.2575 - val_acc: 0.9070\n",
      "Epoch 135/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9314\n",
      "Epoch 135: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1729 - acc: 0.9313 - val_loss: 0.2770 - val_acc: 0.9074\n",
      "Epoch 136/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1684 - acc: 0.9304\n",
      "Epoch 136: val_acc did not improve from 0.91190\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1678 - acc: 0.9305 - val_loss: 0.2729 - val_acc: 0.9042\n",
      "Epoch 137/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1686 - acc: 0.9296\n",
      "Epoch 137: val_acc improved from 0.91190 to 0.91474, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1684 - acc: 0.9297 - val_loss: 0.2628 - val_acc: 0.9147\n",
      "Epoch 138/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1796 - acc: 0.9282\n",
      "Epoch 138: val_acc did not improve from 0.91474\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1789 - acc: 0.9287 - val_loss: 0.2629 - val_acc: 0.9062\n",
      "Epoch 139/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9284\n",
      "Epoch 139: val_acc did not improve from 0.91474\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1739 - acc: 0.9292 - val_loss: 0.2730 - val_acc: 0.9103\n",
      "Epoch 140/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.9303\n",
      "Epoch 140: val_acc did not improve from 0.91474\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1722 - acc: 0.9304 - val_loss: 0.2630 - val_acc: 0.9058\n",
      "Epoch 141/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1639 - acc: 0.9322\n",
      "Epoch 141: val_acc improved from 0.91474 to 0.91555, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1636 - acc: 0.9324 - val_loss: 0.2640 - val_acc: 0.9156\n",
      "Epoch 142/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1713 - acc: 0.9307\n",
      "Epoch 142: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1703 - acc: 0.9312 - val_loss: 0.2748 - val_acc: 0.9139\n",
      "Epoch 143/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9327\n",
      "Epoch 143: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1677 - acc: 0.9327 - val_loss: 0.2907 - val_acc: 0.9107\n",
      "Epoch 144/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1711 - acc: 0.9300\n",
      "Epoch 144: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1704 - acc: 0.9302 - val_loss: 0.2891 - val_acc: 0.9046\n",
      "Epoch 145/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1707 - acc: 0.9288\n",
      "Epoch 145: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1703 - acc: 0.9290 - val_loss: 0.3011 - val_acc: 0.9042\n",
      "Epoch 146/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9306\n",
      "Epoch 146: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1683 - acc: 0.9309 - val_loss: 0.2934 - val_acc: 0.9017\n",
      "Epoch 147/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1719 - acc: 0.9270\n",
      "Epoch 147: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.1717 - acc: 0.9272 - val_loss: 0.2867 - val_acc: 0.9078\n",
      "Epoch 148/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9303\n",
      "Epoch 148: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1669 - acc: 0.9304 - val_loss: 0.2893 - val_acc: 0.9034\n",
      "Epoch 149/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9296\n",
      "Epoch 149: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1699 - acc: 0.9300 - val_loss: 0.2913 - val_acc: 0.9062\n",
      "Epoch 150/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1706 - acc: 0.9339\n",
      "Epoch 150: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1701 - acc: 0.9341 - val_loss: 0.2871 - val_acc: 0.9091\n",
      "Epoch 151/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1634 - acc: 0.9336\n",
      "Epoch 151: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1634 - acc: 0.9336 - val_loss: 0.2680 - val_acc: 0.9127\n",
      "Epoch 152/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1700 - acc: 0.9314\n",
      "Epoch 152: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1702 - acc: 0.9314 - val_loss: 0.2929 - val_acc: 0.9099\n",
      "Epoch 153/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1721 - acc: 0.9300\n",
      "Epoch 153: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1719 - acc: 0.9300 - val_loss: 0.2972 - val_acc: 0.9058\n",
      "Epoch 154/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1652 - acc: 0.9307\n",
      "Epoch 154: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1645 - acc: 0.9308 - val_loss: 0.2960 - val_acc: 0.9086\n",
      "Epoch 155/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9325\n",
      "Epoch 155: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1599 - acc: 0.9328 - val_loss: 0.2854 - val_acc: 0.9099\n",
      "Epoch 156/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1592 - acc: 0.9337\n",
      "Epoch 156: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1593 - acc: 0.9336 - val_loss: 0.3183 - val_acc: 0.9103\n",
      "Epoch 157/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1612 - acc: 0.9351\n",
      "Epoch 157: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1608 - acc: 0.9354 - val_loss: 0.2963 - val_acc: 0.9017\n",
      "Epoch 158/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9375\n",
      "Epoch 158: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1588 - acc: 0.9376 - val_loss: 0.3108 - val_acc: 0.9082\n",
      "Epoch 159/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9323\n",
      "Epoch 159: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1660 - acc: 0.9321 - val_loss: 0.2948 - val_acc: 0.9127\n",
      "Epoch 160/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9316\n",
      "Epoch 160: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1649 - acc: 0.9316 - val_loss: 0.2972 - val_acc: 0.9050\n",
      "Epoch 161/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9319\n",
      "Epoch 161: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1672 - acc: 0.9321 - val_loss: 0.2789 - val_acc: 0.9147\n",
      "Epoch 162/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9377\n",
      "Epoch 162: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1614 - acc: 0.9375 - val_loss: 0.2627 - val_acc: 0.9111\n",
      "Epoch 163/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9334\n",
      "Epoch 163: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1616 - acc: 0.9333 - val_loss: 0.2872 - val_acc: 0.9107\n",
      "Epoch 164/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1617 - acc: 0.9336\n",
      "Epoch 164: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1616 - acc: 0.9336 - val_loss: 0.2801 - val_acc: 0.9062\n",
      "Epoch 165/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9339\n",
      "Epoch 165: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1576 - acc: 0.9341 - val_loss: 0.2750 - val_acc: 0.9127\n",
      "Epoch 166/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1625 - acc: 0.9328\n",
      "Epoch 166: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1629 - acc: 0.9330 - val_loss: 0.3032 - val_acc: 0.9111\n",
      "Epoch 167/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1646 - acc: 0.9353\n",
      "Epoch 167: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1645 - acc: 0.9352 - val_loss: 0.2916 - val_acc: 0.9070\n",
      "Epoch 168/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9349\n",
      "Epoch 168: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1699 - acc: 0.9350 - val_loss: 0.3288 - val_acc: 0.9078\n",
      "Epoch 169/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1641 - acc: 0.9379\n",
      "Epoch 169: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1635 - acc: 0.9381 - val_loss: 0.2870 - val_acc: 0.9099\n",
      "Epoch 170/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9370\n",
      "Epoch 170: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1575 - acc: 0.9372 - val_loss: 0.2745 - val_acc: 0.9111\n",
      "Epoch 171/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9314\n",
      "Epoch 171: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1719 - acc: 0.9315 - val_loss: 0.3108 - val_acc: 0.9058\n",
      "Epoch 172/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1628 - acc: 0.9352\n",
      "Epoch 172: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1621 - acc: 0.9353 - val_loss: 0.2982 - val_acc: 0.9111\n",
      "Epoch 173/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1628 - acc: 0.9330\n",
      "Epoch 173: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1619 - acc: 0.9334 - val_loss: 0.3201 - val_acc: 0.9086\n",
      "Epoch 174/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9372\n",
      "Epoch 174: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1499 - acc: 0.9376 - val_loss: 0.2970 - val_acc: 0.9127\n",
      "Epoch 175/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9364\n",
      "Epoch 175: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1576 - acc: 0.9369 - val_loss: 0.2947 - val_acc: 0.9082\n",
      "Epoch 176/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1592 - acc: 0.9324\n",
      "Epoch 176: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1590 - acc: 0.9323 - val_loss: 0.3076 - val_acc: 0.9086\n",
      "Epoch 177/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9404\n",
      "Epoch 177: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1495 - acc: 0.9405 - val_loss: 0.3087 - val_acc: 0.9127\n",
      "Epoch 178/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1564 - acc: 0.9351\n",
      "Epoch 178: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1563 - acc: 0.9351 - val_loss: 0.3314 - val_acc: 0.9095\n",
      "Epoch 179/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9369\n",
      "Epoch 179: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1595 - acc: 0.9373 - val_loss: 0.3099 - val_acc: 0.9131\n",
      "Epoch 180/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1646 - acc: 0.9329\n",
      "Epoch 180: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1645 - acc: 0.9324 - val_loss: 0.3136 - val_acc: 0.9127\n",
      "Epoch 181/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1565 - acc: 0.9398\n",
      "Epoch 181: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1550 - acc: 0.9401 - val_loss: 0.3238 - val_acc: 0.9086\n",
      "Epoch 182/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9318\n",
      "Epoch 182: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1667 - acc: 0.9323 - val_loss: 0.3198 - val_acc: 0.9086\n",
      "Epoch 183/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9375\n",
      "Epoch 183: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1546 - acc: 0.9375 - val_loss: 0.3029 - val_acc: 0.9111\n",
      "Epoch 184/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9360\n",
      "Epoch 184: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.1654 - acc: 0.9362 - val_loss: 0.3285 - val_acc: 0.9070\n",
      "Epoch 185/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9383\n",
      "Epoch 185: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 6ms/step - loss: 0.1429 - acc: 0.9384 - val_loss: 0.3432 - val_acc: 0.9099\n",
      "Epoch 186/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9369\n",
      "Epoch 186: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1534 - acc: 0.9371 - val_loss: 0.3164 - val_acc: 0.9078\n",
      "Epoch 187/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1511 - acc: 0.9396\n",
      "Epoch 187: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1507 - acc: 0.9398 - val_loss: 0.3406 - val_acc: 0.9091\n",
      "Epoch 188/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9342\n",
      "Epoch 188: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1562 - acc: 0.9344 - val_loss: 0.3396 - val_acc: 0.9066\n",
      "Epoch 189/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1633 - acc: 0.9378\n",
      "Epoch 189: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1626 - acc: 0.9380 - val_loss: 0.3217 - val_acc: 0.9074\n",
      "Epoch 190/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9354\n",
      "Epoch 190: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1600 - acc: 0.9359 - val_loss: 0.3028 - val_acc: 0.9058\n",
      "Epoch 191/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1571 - acc: 0.9369\n",
      "Epoch 191: val_acc did not improve from 0.91555\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1564 - acc: 0.9375 - val_loss: 0.3540 - val_acc: 0.9058\n",
      "Epoch 192/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9339\n",
      "Epoch 192: val_acc improved from 0.91555 to 0.91677, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1658 - acc: 0.9339 - val_loss: 0.2822 - val_acc: 0.9168\n",
      "Epoch 193/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9406\n",
      "Epoch 193: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1429 - acc: 0.9408 - val_loss: 0.3431 - val_acc: 0.9107\n",
      "Epoch 194/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1718 - acc: 0.9325\n",
      "Epoch 194: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1714 - acc: 0.9325 - val_loss: 0.3229 - val_acc: 0.9009\n",
      "Epoch 195/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1582 - acc: 0.9366\n",
      "Epoch 195: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1565 - acc: 0.9373 - val_loss: 0.3166 - val_acc: 0.9034\n",
      "Epoch 196/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9386\n",
      "Epoch 196: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1568 - acc: 0.9390 - val_loss: 0.2700 - val_acc: 0.9160\n",
      "Epoch 197/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9409\n",
      "Epoch 197: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1458 - acc: 0.9414 - val_loss: 0.2906 - val_acc: 0.9107\n",
      "Epoch 198/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9407\n",
      "Epoch 198: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1491 - acc: 0.9409 - val_loss: 0.2905 - val_acc: 0.9111\n",
      "Epoch 199/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9374\n",
      "Epoch 199: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1600 - acc: 0.9375 - val_loss: 0.3068 - val_acc: 0.8973\n",
      "Epoch 200/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9355\n",
      "Epoch 200: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1505 - acc: 0.9359 - val_loss: 0.3125 - val_acc: 0.9070\n",
      "Epoch 201/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1567 - acc: 0.9387\n",
      "Epoch 201: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1559 - acc: 0.9390 - val_loss: 0.2919 - val_acc: 0.9046\n",
      "Epoch 202/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9406\n",
      "Epoch 202: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1443 - acc: 0.9406 - val_loss: 0.3011 - val_acc: 0.9107\n",
      "Epoch 203/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9388\n",
      "Epoch 203: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1553 - acc: 0.9389 - val_loss: 0.2990 - val_acc: 0.9042\n",
      "Epoch 204/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1545 - acc: 0.9386\n",
      "Epoch 204: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1544 - acc: 0.9387 - val_loss: 0.3025 - val_acc: 0.9095\n",
      "Epoch 205/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1479 - acc: 0.9370\n",
      "Epoch 205: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.1478 - acc: 0.9369 - val_loss: 0.3147 - val_acc: 0.9099\n",
      "Epoch 206/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1593 - acc: 0.9359\n",
      "Epoch 206: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.1590 - acc: 0.9360 - val_loss: 0.3429 - val_acc: 0.9086\n",
      "Epoch 207/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1662 - acc: 0.9383\n",
      "Epoch 207: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1653 - acc: 0.9384 - val_loss: 0.3147 - val_acc: 0.9119\n",
      "Epoch 208/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1544 - acc: 0.9416\n",
      "Epoch 208: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1537 - acc: 0.9418 - val_loss: 0.3240 - val_acc: 0.9103\n",
      "Epoch 209/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9400\n",
      "Epoch 209: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1533 - acc: 0.9401 - val_loss: 0.3222 - val_acc: 0.9115\n",
      "Epoch 210/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9410\n",
      "Epoch 210: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1440 - acc: 0.9411 - val_loss: 0.3128 - val_acc: 0.9086\n",
      "Epoch 211/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9380\n",
      "Epoch 211: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.1579 - acc: 0.9384 - val_loss: 0.2901 - val_acc: 0.9119\n",
      "Epoch 212/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9372\n",
      "Epoch 212: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1486 - acc: 0.9372 - val_loss: 0.3192 - val_acc: 0.9156\n",
      "Epoch 213/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1453 - acc: 0.9399\n",
      "Epoch 213: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1449 - acc: 0.9399 - val_loss: 0.3011 - val_acc: 0.9119\n",
      "Epoch 214/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9407\n",
      "Epoch 214: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1412 - acc: 0.9406 - val_loss: 0.3753 - val_acc: 0.9091\n",
      "Epoch 215/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9410\n",
      "Epoch 215: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1449 - acc: 0.9407 - val_loss: 0.3464 - val_acc: 0.9078\n",
      "Epoch 216/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9444\n",
      "Epoch 216: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1438 - acc: 0.9451 - val_loss: 0.3498 - val_acc: 0.9078\n",
      "Epoch 217/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9434\n",
      "Epoch 217: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1510 - acc: 0.9436 - val_loss: 0.3779 - val_acc: 0.9058\n",
      "Epoch 218/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9391\n",
      "Epoch 218: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1539 - acc: 0.9397 - val_loss: 0.3347 - val_acc: 0.9151\n",
      "Epoch 219/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1392 - acc: 0.9411\n",
      "Epoch 219: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1392 - acc: 0.9411 - val_loss: 0.3597 - val_acc: 0.9115\n",
      "Epoch 220/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9421\n",
      "Epoch 220: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1447 - acc: 0.9427 - val_loss: 0.2971 - val_acc: 0.9111\n",
      "Epoch 221/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9441\n",
      "Epoch 221: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1394 - acc: 0.9442 - val_loss: 0.3239 - val_acc: 0.9066\n",
      "Epoch 222/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9406\n",
      "Epoch 222: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1432 - acc: 0.9413 - val_loss: 0.3425 - val_acc: 0.9082\n",
      "Epoch 223/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9407\n",
      "Epoch 223: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1516 - acc: 0.9411 - val_loss: 0.3440 - val_acc: 0.9143\n",
      "Epoch 224/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9414\n",
      "Epoch 224: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1450 - acc: 0.9418 - val_loss: 0.3097 - val_acc: 0.9147\n",
      "Epoch 225/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9421\n",
      "Epoch 225: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1417 - acc: 0.9425 - val_loss: 0.3101 - val_acc: 0.9099\n",
      "Epoch 226/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9405\n",
      "Epoch 226: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1439 - acc: 0.9416 - val_loss: 0.3296 - val_acc: 0.9123\n",
      "Epoch 227/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9392\n",
      "Epoch 227: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1606 - acc: 0.9392 - val_loss: 0.3165 - val_acc: 0.9070\n",
      "Epoch 228/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9373\n",
      "Epoch 228: val_acc did not improve from 0.91677\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1511 - acc: 0.9378 - val_loss: 0.2821 - val_acc: 0.9139\n",
      "Epoch 229/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9424\n",
      "Epoch 229: val_acc improved from 0.91677 to 0.91799, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1377 - acc: 0.9425 - val_loss: 0.2800 - val_acc: 0.9180\n",
      "Epoch 230/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9427\n",
      "Epoch 230: val_acc did not improve from 0.91799\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1457 - acc: 0.9426 - val_loss: 0.2937 - val_acc: 0.9127\n",
      "Epoch 231/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9477\n",
      "Epoch 231: val_acc did not improve from 0.91799\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1396 - acc: 0.9483 - val_loss: 0.2952 - val_acc: 0.9115\n",
      "Epoch 232/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9405\n",
      "Epoch 232: val_acc did not improve from 0.91799\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1493 - acc: 0.9412 - val_loss: 0.2881 - val_acc: 0.9135\n",
      "Epoch 233/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9404\n",
      "Epoch 233: val_acc did not improve from 0.91799\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1490 - acc: 0.9404 - val_loss: 0.3186 - val_acc: 0.9139\n",
      "Epoch 234/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9430\n",
      "Epoch 234: val_acc did not improve from 0.91799\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1415 - acc: 0.9430 - val_loss: 0.3062 - val_acc: 0.9082\n",
      "Epoch 235/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9435\n",
      "Epoch 235: val_acc improved from 0.91799 to 0.91839, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1386 - acc: 0.9436 - val_loss: 0.2952 - val_acc: 0.9184\n",
      "Epoch 236/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9416\n",
      "Epoch 236: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1417 - acc: 0.9418 - val_loss: 0.2994 - val_acc: 0.9107\n",
      "Epoch 237/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1511 - acc: 0.9399\n",
      "Epoch 237: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1509 - acc: 0.9400 - val_loss: 0.3350 - val_acc: 0.9078\n",
      "Epoch 238/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1671 - acc: 0.9427\n",
      "Epoch 238: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1671 - acc: 0.9427 - val_loss: 0.3268 - val_acc: 0.9123\n",
      "Epoch 239/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9424\n",
      "Epoch 239: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1440 - acc: 0.9429 - val_loss: 0.3418 - val_acc: 0.9135\n",
      "Epoch 240/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9400\n",
      "Epoch 240: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1429 - acc: 0.9403 - val_loss: 0.2958 - val_acc: 0.9156\n",
      "Epoch 241/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9426\n",
      "Epoch 241: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1394 - acc: 0.9431 - val_loss: 0.3552 - val_acc: 0.9022\n",
      "Epoch 242/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9422\n",
      "Epoch 242: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1398 - acc: 0.9426 - val_loss: 0.3290 - val_acc: 0.9107\n",
      "Epoch 243/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9403\n",
      "Epoch 243: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1421 - acc: 0.9409 - val_loss: 0.3283 - val_acc: 0.9172\n",
      "Epoch 244/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9419\n",
      "Epoch 244: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1356 - acc: 0.9424 - val_loss: 0.3168 - val_acc: 0.9115\n",
      "Epoch 245/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1485 - acc: 0.9438\n",
      "Epoch 245: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1471 - acc: 0.9442 - val_loss: 0.3162 - val_acc: 0.9119\n",
      "Epoch 246/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9449\n",
      "Epoch 246: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1442 - acc: 0.9452 - val_loss: 0.3034 - val_acc: 0.9143\n",
      "Epoch 247/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9456\n",
      "Epoch 247: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1402 - acc: 0.9460 - val_loss: 0.3404 - val_acc: 0.9086\n",
      "Epoch 248/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9440\n",
      "Epoch 248: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1431 - acc: 0.9442 - val_loss: 0.3181 - val_acc: 0.9086\n",
      "Epoch 249/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9435\n",
      "Epoch 249: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1349 - acc: 0.9437 - val_loss: 0.3759 - val_acc: 0.9135\n",
      "Epoch 250/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1461 - acc: 0.9379\n",
      "Epoch 250: val_acc did not improve from 0.91839\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1455 - acc: 0.9384 - val_loss: 0.3435 - val_acc: 0.9143\n",
      "Epoch 251/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9475\n",
      "Epoch 251: val_acc improved from 0.91839 to 0.91961, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1314 - acc: 0.9474 - val_loss: 0.3256 - val_acc: 0.9196\n",
      "Epoch 252/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9461\n",
      "Epoch 252: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1402 - acc: 0.9465 - val_loss: 0.3076 - val_acc: 0.9164\n",
      "Epoch 253/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9424\n",
      "Epoch 253: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1488 - acc: 0.9425 - val_loss: 0.3145 - val_acc: 0.9115\n",
      "Epoch 254/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1446 - acc: 0.9419\n",
      "Epoch 254: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1436 - acc: 0.9424 - val_loss: 0.3047 - val_acc: 0.9123\n",
      "Epoch 255/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1411 - acc: 0.9463\n",
      "Epoch 255: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1413 - acc: 0.9461 - val_loss: 0.3103 - val_acc: 0.9164\n",
      "Epoch 256/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1461 - acc: 0.9448\n",
      "Epoch 256: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1461 - acc: 0.9448 - val_loss: 0.3019 - val_acc: 0.9135\n",
      "Epoch 257/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9451\n",
      "Epoch 257: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1357 - acc: 0.9453 - val_loss: 0.2982 - val_acc: 0.9099\n",
      "Epoch 258/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9463\n",
      "Epoch 258: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1375 - acc: 0.9468 - val_loss: 0.3167 - val_acc: 0.9095\n",
      "Epoch 259/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9449\n",
      "Epoch 259: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.1514 - acc: 0.9450 - val_loss: 0.3338 - val_acc: 0.9131\n",
      "Epoch 260/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9445\n",
      "Epoch 260: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1449 - acc: 0.9446 - val_loss: 0.3647 - val_acc: 0.9151\n",
      "Epoch 261/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9438\n",
      "Epoch 261: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1446 - acc: 0.9439 - val_loss: 0.3040 - val_acc: 0.9164\n",
      "Epoch 262/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9458\n",
      "Epoch 262: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1347 - acc: 0.9460 - val_loss: 0.3374 - val_acc: 0.9119\n",
      "Epoch 263/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9485\n",
      "Epoch 263: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1283 - acc: 0.9486 - val_loss: 0.3571 - val_acc: 0.9123\n",
      "Epoch 264/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9439\n",
      "Epoch 264: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1369 - acc: 0.9441 - val_loss: 0.3539 - val_acc: 0.9046\n",
      "Epoch 265/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9434\n",
      "Epoch 265: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1471 - acc: 0.9436 - val_loss: 0.3118 - val_acc: 0.9119\n",
      "Epoch 266/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9482\n",
      "Epoch 266: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1400 - acc: 0.9482 - val_loss: 0.3491 - val_acc: 0.9086\n",
      "Epoch 267/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9457\n",
      "Epoch 267: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.1339 - acc: 0.9455 - val_loss: 0.3711 - val_acc: 0.9107\n",
      "Epoch 268/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9432\n",
      "Epoch 268: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1444 - acc: 0.9433 - val_loss: 0.3564 - val_acc: 0.9017\n",
      "Epoch 269/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1321 - acc: 0.9468\n",
      "Epoch 269: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1321 - acc: 0.9468 - val_loss: 0.3240 - val_acc: 0.9164\n",
      "Epoch 270/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9462\n",
      "Epoch 270: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1379 - acc: 0.9464 - val_loss: 0.3606 - val_acc: 0.9066\n",
      "Epoch 271/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9451\n",
      "Epoch 271: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1432 - acc: 0.9455 - val_loss: 0.3490 - val_acc: 0.9099\n",
      "Epoch 272/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1399 - acc: 0.9483\n",
      "Epoch 272: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1393 - acc: 0.9487 - val_loss: 0.3481 - val_acc: 0.9038\n",
      "Epoch 273/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9494\n",
      "Epoch 273: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1350 - acc: 0.9494 - val_loss: 0.3670 - val_acc: 0.9119\n",
      "Epoch 274/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9459\n",
      "Epoch 274: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1438 - acc: 0.9459 - val_loss: 0.3399 - val_acc: 0.9095\n",
      "Epoch 275/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9432\n",
      "Epoch 275: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1409 - acc: 0.9435 - val_loss: 0.3244 - val_acc: 0.9151\n",
      "Epoch 276/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9461\n",
      "Epoch 276: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1306 - acc: 0.9462 - val_loss: 0.3433 - val_acc: 0.9147\n",
      "Epoch 277/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9458\n",
      "Epoch 277: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1435 - acc: 0.9456 - val_loss: 0.3280 - val_acc: 0.9095\n",
      "Epoch 278/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9434\n",
      "Epoch 278: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1393 - acc: 0.9437 - val_loss: 0.3161 - val_acc: 0.9123\n",
      "Epoch 279/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9446\n",
      "Epoch 279: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1352 - acc: 0.9447 - val_loss: 0.2979 - val_acc: 0.9180\n",
      "Epoch 280/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1398 - acc: 0.9444\n",
      "Epoch 280: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1399 - acc: 0.9443 - val_loss: 0.3417 - val_acc: 0.9135\n",
      "Epoch 281/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9406\n",
      "Epoch 281: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1522 - acc: 0.9409 - val_loss: 0.3182 - val_acc: 0.9086\n",
      "Epoch 282/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9469\n",
      "Epoch 282: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1267 - acc: 0.9472 - val_loss: 0.3835 - val_acc: 0.9074\n",
      "Epoch 283/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9460\n",
      "Epoch 283: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1319 - acc: 0.9467 - val_loss: 0.3558 - val_acc: 0.9070\n",
      "Epoch 284/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9481\n",
      "Epoch 284: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1345 - acc: 0.9485 - val_loss: 0.3785 - val_acc: 0.9103\n",
      "Epoch 285/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9482\n",
      "Epoch 285: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1351 - acc: 0.9485 - val_loss: 0.3553 - val_acc: 0.9135\n",
      "Epoch 286/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9473\n",
      "Epoch 286: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1338 - acc: 0.9476 - val_loss: 0.3467 - val_acc: 0.9139\n",
      "Epoch 287/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9463\n",
      "Epoch 287: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1395 - acc: 0.9462 - val_loss: 0.3544 - val_acc: 0.9062\n",
      "Epoch 288/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9482\n",
      "Epoch 288: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1257 - acc: 0.9481 - val_loss: 0.3716 - val_acc: 0.9119\n",
      "Epoch 289/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9533\n",
      "Epoch 289: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1247 - acc: 0.9535 - val_loss: 0.4183 - val_acc: 0.9119\n",
      "Epoch 290/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9463\n",
      "Epoch 290: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1377 - acc: 0.9462 - val_loss: 0.3397 - val_acc: 0.9115\n",
      "Epoch 291/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9494\n",
      "Epoch 291: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1301 - acc: 0.9495 - val_loss: 0.3264 - val_acc: 0.9188\n",
      "Epoch 292/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1340 - acc: 0.9474\n",
      "Epoch 292: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1340 - acc: 0.9474 - val_loss: 0.3430 - val_acc: 0.9188\n",
      "Epoch 293/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9455\n",
      "Epoch 293: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1325 - acc: 0.9457 - val_loss: 0.4013 - val_acc: 0.9119\n",
      "Epoch 294/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9482\n",
      "Epoch 294: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1263 - acc: 0.9487 - val_loss: 0.3760 - val_acc: 0.9115\n",
      "Epoch 295/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9500\n",
      "Epoch 295: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1353 - acc: 0.9499 - val_loss: 0.3928 - val_acc: 0.9180\n",
      "Epoch 296/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9491\n",
      "Epoch 296: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1281 - acc: 0.9492 - val_loss: 0.3569 - val_acc: 0.9184\n",
      "Epoch 297/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9510\n",
      "Epoch 297: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1275 - acc: 0.9510 - val_loss: 0.3976 - val_acc: 0.9127\n",
      "Epoch 298/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1419 - acc: 0.9498\n",
      "Epoch 298: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1419 - acc: 0.9498 - val_loss: 0.4160 - val_acc: 0.9091\n",
      "Epoch 299/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9490\n",
      "Epoch 299: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1382 - acc: 0.9491 - val_loss: 0.3526 - val_acc: 0.9188\n",
      "Epoch 300/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9497\n",
      "Epoch 300: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1271 - acc: 0.9498 - val_loss: 0.3511 - val_acc: 0.9168\n",
      "Epoch 301/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9474\n",
      "Epoch 301: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1379 - acc: 0.9473 - val_loss: 0.4099 - val_acc: 0.9176\n",
      "Epoch 302/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9487\n",
      "Epoch 302: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1252 - acc: 0.9485 - val_loss: 0.4660 - val_acc: 0.9123\n",
      "Epoch 303/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9463\n",
      "Epoch 303: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1453 - acc: 0.9466 - val_loss: 0.3646 - val_acc: 0.9115\n",
      "Epoch 304/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9482\n",
      "Epoch 304: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1261 - acc: 0.9487 - val_loss: 0.4045 - val_acc: 0.9123\n",
      "Epoch 305/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9455\n",
      "Epoch 305: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1423 - acc: 0.9460 - val_loss: 0.3897 - val_acc: 0.9147\n",
      "Epoch 306/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9471\n",
      "Epoch 306: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1302 - acc: 0.9474 - val_loss: 0.3880 - val_acc: 0.9184\n",
      "Epoch 307/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9498\n",
      "Epoch 307: val_acc did not improve from 0.91961\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1313 - acc: 0.9502 - val_loss: 0.4305 - val_acc: 0.9115\n",
      "Epoch 308/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9463\n",
      "Epoch 308: val_acc improved from 0.91961 to 0.92002, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1397 - acc: 0.9466 - val_loss: 0.3700 - val_acc: 0.9200\n",
      "Epoch 309/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9447\n",
      "Epoch 309: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1356 - acc: 0.9449 - val_loss: 0.3705 - val_acc: 0.9046\n",
      "Epoch 310/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9490\n",
      "Epoch 310: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1279 - acc: 0.9493 - val_loss: 0.3678 - val_acc: 0.9164\n",
      "Epoch 311/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9508\n",
      "Epoch 311: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1349 - acc: 0.9513 - val_loss: 0.3389 - val_acc: 0.9160\n",
      "Epoch 312/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9516\n",
      "Epoch 312: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1391 - acc: 0.9514 - val_loss: 0.4328 - val_acc: 0.9151\n",
      "Epoch 313/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9483\n",
      "Epoch 313: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1291 - acc: 0.9484 - val_loss: 0.3779 - val_acc: 0.9115\n",
      "Epoch 314/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9502\n",
      "Epoch 314: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1292 - acc: 0.9507 - val_loss: 0.3754 - val_acc: 0.9160\n",
      "Epoch 315/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9479\n",
      "Epoch 315: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1335 - acc: 0.9480 - val_loss: 0.3624 - val_acc: 0.9131\n",
      "Epoch 316/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9522\n",
      "Epoch 316: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1313 - acc: 0.9520 - val_loss: 0.3644 - val_acc: 0.9111\n",
      "Epoch 317/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1240 - acc: 0.9490\n",
      "Epoch 317: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1240 - acc: 0.9490 - val_loss: 0.3597 - val_acc: 0.9131\n",
      "Epoch 318/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9499\n",
      "Epoch 318: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 3s 4ms/step - loss: 0.1362 - acc: 0.9502 - val_loss: 0.3441 - val_acc: 0.9164\n",
      "Epoch 319/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9488\n",
      "Epoch 319: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1325 - acc: 0.9492 - val_loss: 0.3650 - val_acc: 0.9143\n",
      "Epoch 320/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9495\n",
      "Epoch 320: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1342 - acc: 0.9495 - val_loss: 0.3821 - val_acc: 0.9143\n",
      "Epoch 321/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9521\n",
      "Epoch 321: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1182 - acc: 0.9523 - val_loss: 0.3810 - val_acc: 0.9103\n",
      "Epoch 322/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1322 - acc: 0.9486\n",
      "Epoch 322: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1335 - acc: 0.9485 - val_loss: 0.3527 - val_acc: 0.9196\n",
      "Epoch 323/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9487\n",
      "Epoch 323: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1378 - acc: 0.9489 - val_loss: 0.3427 - val_acc: 0.9151\n",
      "Epoch 324/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9521\n",
      "Epoch 324: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1239 - acc: 0.9522 - val_loss: 0.3669 - val_acc: 0.9086\n",
      "Epoch 325/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9471\n",
      "Epoch 325: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1279 - acc: 0.9473 - val_loss: 0.3260 - val_acc: 0.9095\n",
      "Epoch 326/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9493\n",
      "Epoch 326: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1255 - acc: 0.9491 - val_loss: 0.3291 - val_acc: 0.9164\n",
      "Epoch 327/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9493\n",
      "Epoch 327: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1309 - acc: 0.9495 - val_loss: 0.3665 - val_acc: 0.9168\n",
      "Epoch 328/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9506\n",
      "Epoch 328: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1253 - acc: 0.9507 - val_loss: 0.3884 - val_acc: 0.9188\n",
      "Epoch 329/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9472\n",
      "Epoch 329: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1307 - acc: 0.9474 - val_loss: 0.3193 - val_acc: 0.9200\n",
      "Epoch 330/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9506\n",
      "Epoch 330: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1471 - acc: 0.9506 - val_loss: 0.3355 - val_acc: 0.9168\n",
      "Epoch 331/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9497\n",
      "Epoch 331: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1260 - acc: 0.9497 - val_loss: 0.3454 - val_acc: 0.9131\n",
      "Epoch 332/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9525\n",
      "Epoch 332: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1249 - acc: 0.9526 - val_loss: 0.3653 - val_acc: 0.9176\n",
      "Epoch 333/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9504\n",
      "Epoch 333: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1224 - acc: 0.9502 - val_loss: 0.3657 - val_acc: 0.9151\n",
      "Epoch 334/2000\n",
      "594/616 [===========================>..] - ETA: 0s - loss: 0.1318 - acc: 0.9502\n",
      "Epoch 334: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1299 - acc: 0.9508 - val_loss: 0.3683 - val_acc: 0.9168\n",
      "Epoch 335/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1263 - acc: 0.9483\n",
      "Epoch 335: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1263 - acc: 0.9483 - val_loss: 0.3987 - val_acc: 0.9074\n",
      "Epoch 336/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9497\n",
      "Epoch 336: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1258 - acc: 0.9497 - val_loss: 0.3740 - val_acc: 0.9123\n",
      "Epoch 337/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9511\n",
      "Epoch 337: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1249 - acc: 0.9514 - val_loss: 0.3940 - val_acc: 0.9127\n",
      "Epoch 338/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9492\n",
      "Epoch 338: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1331 - acc: 0.9497 - val_loss: 0.3780 - val_acc: 0.9135\n",
      "Epoch 339/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9541\n",
      "Epoch 339: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1304 - acc: 0.9544 - val_loss: 0.4216 - val_acc: 0.9188\n",
      "Epoch 340/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9542\n",
      "Epoch 340: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1268 - acc: 0.9543 - val_loss: 0.4107 - val_acc: 0.9180\n",
      "Epoch 341/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9512\n",
      "Epoch 341: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1229 - acc: 0.9520 - val_loss: 0.3657 - val_acc: 0.9168\n",
      "Epoch 342/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9517\n",
      "Epoch 342: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1298 - acc: 0.9518 - val_loss: 0.3655 - val_acc: 0.9074\n",
      "Epoch 343/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9498\n",
      "Epoch 343: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1334 - acc: 0.9500 - val_loss: 0.3354 - val_acc: 0.9156\n",
      "Epoch 344/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9477\n",
      "Epoch 344: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1336 - acc: 0.9478 - val_loss: 0.4048 - val_acc: 0.9172\n",
      "Epoch 345/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9517\n",
      "Epoch 345: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1204 - acc: 0.9512 - val_loss: 0.3604 - val_acc: 0.9127\n",
      "Epoch 346/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9529\n",
      "Epoch 346: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1311 - acc: 0.9530 - val_loss: 0.3662 - val_acc: 0.9119\n",
      "Epoch 347/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9529\n",
      "Epoch 347: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1217 - acc: 0.9530 - val_loss: 0.3480 - val_acc: 0.9156\n",
      "Epoch 348/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9499\n",
      "Epoch 348: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1357 - acc: 0.9501 - val_loss: 0.3566 - val_acc: 0.9135\n",
      "Epoch 349/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9506\n",
      "Epoch 349: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1331 - acc: 0.9507 - val_loss: 0.3247 - val_acc: 0.9151\n",
      "Epoch 350/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9489\n",
      "Epoch 350: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1324 - acc: 0.9489 - val_loss: 0.3504 - val_acc: 0.9143\n",
      "Epoch 351/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9525\n",
      "Epoch 351: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1143 - acc: 0.9529 - val_loss: 0.3695 - val_acc: 0.9156\n",
      "Epoch 352/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9483\n",
      "Epoch 352: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1283 - acc: 0.9485 - val_loss: 0.3955 - val_acc: 0.9099\n",
      "Epoch 353/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1274 - acc: 0.9498\n",
      "Epoch 353: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1274 - acc: 0.9498 - val_loss: 0.3566 - val_acc: 0.9164\n",
      "Epoch 354/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9490\n",
      "Epoch 354: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1285 - acc: 0.9489 - val_loss: 0.3343 - val_acc: 0.9147\n",
      "Epoch 355/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9547\n",
      "Epoch 355: val_acc did not improve from 0.92002\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1204 - acc: 0.9550 - val_loss: 0.3233 - val_acc: 0.9139\n",
      "Epoch 356/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9477\n",
      "Epoch 356: val_acc improved from 0.92002 to 0.92205, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1252 - acc: 0.9478 - val_loss: 0.3425 - val_acc: 0.9220\n",
      "Epoch 357/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9540\n",
      "Epoch 357: val_acc did not improve from 0.92205\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1279 - acc: 0.9542 - val_loss: 0.4270 - val_acc: 0.9164\n",
      "Epoch 358/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9513\n",
      "Epoch 358: val_acc did not improve from 0.92205\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1369 - acc: 0.9514 - val_loss: 0.3944 - val_acc: 0.9168\n",
      "Epoch 359/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9511\n",
      "Epoch 359: val_acc did not improve from 0.92205\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1364 - acc: 0.9512 - val_loss: 0.3673 - val_acc: 0.9176\n",
      "Epoch 360/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9490\n",
      "Epoch 360: val_acc did not improve from 0.92205\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1308 - acc: 0.9491 - val_loss: 0.3651 - val_acc: 0.9151\n",
      "Epoch 361/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9524\n",
      "Epoch 361: val_acc did not improve from 0.92205\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1245 - acc: 0.9523 - val_loss: 0.3668 - val_acc: 0.9164\n",
      "Epoch 362/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9492\n",
      "Epoch 362: val_acc did not improve from 0.92205\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1241 - acc: 0.9493 - val_loss: 0.3748 - val_acc: 0.9147\n",
      "Epoch 363/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9531\n",
      "Epoch 363: val_acc did not improve from 0.92205\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1218 - acc: 0.9532 - val_loss: 0.3845 - val_acc: 0.9204\n",
      "Epoch 364/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9543\n",
      "Epoch 364: val_acc did not improve from 0.92205\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1127 - acc: 0.9545 - val_loss: 0.3758 - val_acc: 0.9143\n",
      "Epoch 365/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9548\n",
      "Epoch 365: val_acc did not improve from 0.92205\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1235 - acc: 0.9550 - val_loss: 0.3982 - val_acc: 0.9099\n",
      "Epoch 366/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1335 - acc: 0.9502\n",
      "Epoch 366: val_acc did not improve from 0.92205\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1335 - acc: 0.9502 - val_loss: 0.3460 - val_acc: 0.9184\n",
      "Epoch 367/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9489\n",
      "Epoch 367: val_acc did not improve from 0.92205\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1276 - acc: 0.9495 - val_loss: 0.3323 - val_acc: 0.9184\n",
      "Epoch 368/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9542\n",
      "Epoch 368: val_acc did not improve from 0.92205\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1176 - acc: 0.9542 - val_loss: 0.3885 - val_acc: 0.9188\n",
      "Epoch 369/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9533\n",
      "Epoch 369: val_acc improved from 0.92205 to 0.92286, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1205 - acc: 0.9534 - val_loss: 0.3624 - val_acc: 0.9229\n",
      "Epoch 370/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9556\n",
      "Epoch 370: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1168 - acc: 0.9558 - val_loss: 0.3822 - val_acc: 0.9156\n",
      "Epoch 371/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9519\n",
      "Epoch 371: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1308 - acc: 0.9521 - val_loss: 0.3529 - val_acc: 0.9200\n",
      "Epoch 372/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9523\n",
      "Epoch 372: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1323 - acc: 0.9524 - val_loss: 0.3488 - val_acc: 0.9135\n",
      "Epoch 373/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9550\n",
      "Epoch 373: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1306 - acc: 0.9553 - val_loss: 0.3487 - val_acc: 0.9184\n",
      "Epoch 374/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9513\n",
      "Epoch 374: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1218 - acc: 0.9516 - val_loss: 0.3639 - val_acc: 0.9151\n",
      "Epoch 375/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9512\n",
      "Epoch 375: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1166 - acc: 0.9513 - val_loss: 0.3637 - val_acc: 0.9135\n",
      "Epoch 376/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9529\n",
      "Epoch 376: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1379 - acc: 0.9530 - val_loss: 0.3686 - val_acc: 0.9216\n",
      "Epoch 377/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9548\n",
      "Epoch 377: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1220 - acc: 0.9550 - val_loss: 0.3845 - val_acc: 0.9123\n",
      "Epoch 378/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9579\n",
      "Epoch 378: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 0.1147 - acc: 0.9585 - val_loss: 0.3518 - val_acc: 0.9225\n",
      "Epoch 379/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9513\n",
      "Epoch 379: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1225 - acc: 0.9520 - val_loss: 0.3753 - val_acc: 0.9156\n",
      "Epoch 380/2000\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.1266 - acc: 0.9518\n",
      "Epoch 380: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1266 - acc: 0.9518 - val_loss: 0.3702 - val_acc: 0.9188\n",
      "Epoch 381/2000\n",
      "609/616 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9546\n",
      "Epoch 381: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1219 - acc: 0.9548 - val_loss: 0.3722 - val_acc: 0.9208\n",
      "Epoch 382/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1191 - acc: 0.9552\n",
      "Epoch 382: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1191 - acc: 0.9548 - val_loss: 0.3500 - val_acc: 0.9225\n",
      "Epoch 383/2000\n",
      "606/616 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9509\n",
      "Epoch 383: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1314 - acc: 0.9513 - val_loss: 0.3635 - val_acc: 0.9135\n",
      "Epoch 384/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9519\n",
      "Epoch 384: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1298 - acc: 0.9521 - val_loss: 0.3451 - val_acc: 0.9188\n",
      "Epoch 385/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9493\n",
      "Epoch 385: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1385 - acc: 0.9498 - val_loss: 0.4021 - val_acc: 0.9147\n",
      "Epoch 386/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9521\n",
      "Epoch 386: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1240 - acc: 0.9521 - val_loss: 0.5394 - val_acc: 0.9086\n",
      "Epoch 387/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9490\n",
      "Epoch 387: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1407 - acc: 0.9497 - val_loss: 0.4302 - val_acc: 0.9127\n",
      "Epoch 388/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9517\n",
      "Epoch 388: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1334 - acc: 0.9517 - val_loss: 0.3812 - val_acc: 0.9196\n",
      "Epoch 389/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9505\n",
      "Epoch 389: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1214 - acc: 0.9505 - val_loss: 0.3946 - val_acc: 0.9160\n",
      "Epoch 390/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9510\n",
      "Epoch 390: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1288 - acc: 0.9511 - val_loss: 0.3529 - val_acc: 0.9156\n",
      "Epoch 391/2000\n",
      "614/616 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9543\n",
      "Epoch 391: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1193 - acc: 0.9544 - val_loss: 0.4088 - val_acc: 0.9160\n",
      "Epoch 392/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9556\n",
      "Epoch 392: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1281 - acc: 0.9562 - val_loss: 0.3835 - val_acc: 0.9176\n",
      "Epoch 393/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9532\n",
      "Epoch 393: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1184 - acc: 0.9534 - val_loss: 0.4317 - val_acc: 0.9188\n",
      "Epoch 394/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9560\n",
      "Epoch 394: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1149 - acc: 0.9560 - val_loss: 0.4342 - val_acc: 0.9168\n",
      "Epoch 395/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9505\n",
      "Epoch 395: val_acc did not improve from 0.92286\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1202 - acc: 0.9509 - val_loss: 0.3895 - val_acc: 0.9160\n",
      "Epoch 396/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9568\n",
      "Epoch 396: val_acc improved from 0.92286 to 0.92326, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1176 - acc: 0.9573 - val_loss: 0.3525 - val_acc: 0.9233\n",
      "Epoch 397/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9524\n",
      "Epoch 397: val_acc did not improve from 0.92326\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1237 - acc: 0.9522 - val_loss: 0.3375 - val_acc: 0.9220\n",
      "Epoch 398/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9539\n",
      "Epoch 398: val_acc did not improve from 0.92326\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1298 - acc: 0.9535 - val_loss: 0.3712 - val_acc: 0.9164\n",
      "Epoch 399/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9534\n",
      "Epoch 399: val_acc did not improve from 0.92326\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1295 - acc: 0.9537 - val_loss: 0.3409 - val_acc: 0.9139\n",
      "Epoch 400/2000\n",
      "599/616 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9540\n",
      "Epoch 400: val_acc did not improve from 0.92326\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1271 - acc: 0.9542 - val_loss: 0.3517 - val_acc: 0.9200\n",
      "Epoch 401/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9502\n",
      "Epoch 401: val_acc did not improve from 0.92326\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1270 - acc: 0.9510 - val_loss: 0.3765 - val_acc: 0.9188\n",
      "Epoch 402/2000\n",
      "596/616 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9548\n",
      "Epoch 402: val_acc did not improve from 0.92326\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1211 - acc: 0.9545 - val_loss: 0.3164 - val_acc: 0.9139\n",
      "Epoch 403/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9550\n",
      "Epoch 403: val_acc did not improve from 0.92326\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1186 - acc: 0.9553 - val_loss: 0.3639 - val_acc: 0.9135\n",
      "Epoch 404/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9573\n",
      "Epoch 404: val_acc improved from 0.92326 to 0.92448, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1105 - acc: 0.9573 - val_loss: 0.3160 - val_acc: 0.9245\n",
      "Epoch 405/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9556\n",
      "Epoch 405: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1151 - acc: 0.9557 - val_loss: 0.3491 - val_acc: 0.9200\n",
      "Epoch 406/2000\n",
      "600/616 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9533\n",
      "Epoch 406: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1131 - acc: 0.9533 - val_loss: 0.3240 - val_acc: 0.9237\n",
      "Epoch 407/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9520\n",
      "Epoch 407: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1241 - acc: 0.9524 - val_loss: 0.3365 - val_acc: 0.9168\n",
      "Epoch 408/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9528\n",
      "Epoch 408: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1321 - acc: 0.9531 - val_loss: 0.3416 - val_acc: 0.9151\n",
      "Epoch 409/2000\n",
      "598/616 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9538\n",
      "Epoch 409: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1229 - acc: 0.9533 - val_loss: 0.3521 - val_acc: 0.9237\n",
      "Epoch 410/2000\n",
      "608/616 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9549\n",
      "Epoch 410: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1143 - acc: 0.9553 - val_loss: 0.3554 - val_acc: 0.9168\n",
      "Epoch 411/2000\n",
      "604/616 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9555\n",
      "Epoch 411: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1149 - acc: 0.9554 - val_loss: 0.4104 - val_acc: 0.9143\n",
      "Epoch 412/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9565\n",
      "Epoch 412: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1251 - acc: 0.9567 - val_loss: 0.3710 - val_acc: 0.9168\n",
      "Epoch 413/2000\n",
      "611/616 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9554\n",
      "Epoch 413: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1204 - acc: 0.9555 - val_loss: 0.3591 - val_acc: 0.9208\n",
      "Epoch 414/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9543\n",
      "Epoch 414: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1281 - acc: 0.9540 - val_loss: 0.3401 - val_acc: 0.9233\n",
      "Epoch 415/2000\n",
      "605/616 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9564\n",
      "Epoch 415: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1306 - acc: 0.9563 - val_loss: 0.3321 - val_acc: 0.9180\n",
      "Epoch 416/2000\n",
      "610/616 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9556\n",
      "Epoch 416: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1145 - acc: 0.9560 - val_loss: 0.4042 - val_acc: 0.9176\n",
      "Epoch 417/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9566\n",
      "Epoch 417: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1118 - acc: 0.9568 - val_loss: 0.4300 - val_acc: 0.9107\n",
      "Epoch 418/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9566\n",
      "Epoch 418: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1151 - acc: 0.9565 - val_loss: 0.3688 - val_acc: 0.9164\n",
      "Epoch 419/2000\n",
      "602/616 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9554\n",
      "Epoch 419: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1225 - acc: 0.9559 - val_loss: 0.3795 - val_acc: 0.9123\n",
      "Epoch 420/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9549\n",
      "Epoch 420: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1151 - acc: 0.9548 - val_loss: 0.3822 - val_acc: 0.9196\n",
      "Epoch 421/2000\n",
      "603/616 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9569\n",
      "Epoch 421: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1222 - acc: 0.9571 - val_loss: 0.3822 - val_acc: 0.9216\n",
      "Epoch 422/2000\n",
      "597/616 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9569\n",
      "Epoch 422: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1145 - acc: 0.9573 - val_loss: 0.4028 - val_acc: 0.9200\n",
      "Epoch 423/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9539\n",
      "Epoch 423: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1102 - acc: 0.9540 - val_loss: 0.4534 - val_acc: 0.9139\n",
      "Epoch 424/2000\n",
      "607/616 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9516\n",
      "Epoch 424: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 3ms/step - loss: 0.1236 - acc: 0.9516 - val_loss: 0.4237 - val_acc: 0.9143\n",
      "Epoch 425/2000\n",
      "612/616 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9555\n",
      "Epoch 425: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1109 - acc: 0.9556 - val_loss: 0.3869 - val_acc: 0.9204\n",
      "Epoch 426/2000\n",
      "613/616 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9528\n",
      "Epoch 426: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1218 - acc: 0.9529 - val_loss: 0.4011 - val_acc: 0.9143\n",
      "Epoch 427/2000\n",
      "615/616 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9552\n",
      "Epoch 427: val_acc did not improve from 0.92448\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1213 - acc: 0.9553 - val_loss: 0.3758 - val_acc: 0.9192\n",
      "Epoch 428/2000\n",
      "601/616 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9545\n",
      "Epoch 428: val_acc improved from 0.92448 to 0.92489, saving model to train_logs/logs7/FFT_ANN\\5\\best_model.h5\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 0.1203 - acc: 0.9546 - val_loss: 0.3376 - val_acc: 0.9249\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.6136 - acc: 0.9179\n"
     ]
    }
   ],
   "source": [
    "for log_dir in log_dirs:\n",
    "    recap = pd.DataFrame(columns=range(1, 6))\n",
    "    training_time = pd.DataFrame(columns=[f'CPU_Time_{i}' for i in range(1, 6)] + [f'Wall_Time_{i}' for i in range(1, 6)])\n",
    "    \n",
    "\n",
    "    train_temp_dir = train_dir\n",
    "    train = tf.data.Dataset.load(train_temp_dir)\n",
    "    flattened_train = train.unbatch()\n",
    "    \n",
    "    train_data = list(flattened_train.as_numpy_iterator())\n",
    "    train_size = len(train_data)\n",
    "    # print(train_data[0].shape)\n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(train_data), 1):\n",
    "        train_fold_data = ([train_data[i][0] for i in train_index], [train_data[i][1] for i in train_index])\n",
    "        val_fold_data = ([train_data[i][0] for i in val_index], [train_data[i][1] for i in val_index])\n",
    "        \n",
    "        train_fold = tf.data.Dataset.from_tensor_slices(train_fold_data).batch(16)\n",
    "        val_fold = tf.data.Dataset.from_tensor_slices(val_fold_data).batch(16)\n",
    "        \n",
    "        log_path = os.path.join(log_dir, str(fold))\n",
    "        \n",
    "        model = create_model()\n",
    "        model.summary()\n",
    "        \n",
    "        model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['acc'])\n",
    "        \n",
    "        cpu_start = time.process_time()\n",
    "        wt_start = time.time()\n",
    "        \n",
    "        history = model.fit(train_fold, epochs=epochs, validation_data=val_fold, callbacks=myCallbacks(log_path))\n",
    "        \n",
    "        wt_end = time.time()\n",
    "        cpu_end = time.process_time()\n",
    "        wall_time = wt_end - wt_start\n",
    "        cpu_time = cpu_end - cpu_start\n",
    "        \n",
    "        training_time.loc[f'CPU_Time_{fold}'] = cpu_time\n",
    "        training_time.loc[f'Wall_Time_{fold}'] = wall_time\n",
    "        \n",
    "        recap.loc[fold] = history.history['acc'][-1]\n",
    "    \n",
    "    # Evaluate on the test dataset after cross-validation\n",
    "    test_temp_dir = test_dir\n",
    "    test_ds = tf.data.Dataset.load(test_temp_dir)\n",
    "    results = model.evaluate(test_ds, callbacks=myCallbacks(log_path))\n",
    "    \n",
    "    recap[f'test'] = results[1]\n",
    "    \n",
    "    log_recap_dir = os.path.join(log_dir, 'Recap')\n",
    "    if not os.path.exists(log_recap_dir):\n",
    "        os.makedirs(log_recap_dir)\n",
    "    \n",
    "    recap.to_csv(os.path.join(log_recap_dir, 'recap.csv'))\n",
    "    training_time.to_csv(os.path.join(log_recap_dir, 'Training_time.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Best Model\n",
    "test_dir = \"datasets/tf_batch/fft/segment_1 seconds/test\"\n",
    "test_ds = tf.data.Dataset.load(test_dir)\n",
    "model_dir = [f\"train_logs/logs7/FFT_ANN/{i}/best_model.h5\" for i in range(1,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_test = test_ds.unbatch()\n",
    "test_data = list(flattened_test.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_value = np.array([test_data[i][0] for i in range(len(test_data))])\n",
    "test_data_label = np.array([test_data[i][1] for i in range(len(test_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3080, 80)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_value.reshape(test_data_value.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 1ms/step - loss: 0.8566 - acc: 0.9269\n",
      "0.8566104769706726 0.926948070526123\n",
      "97/97 [==============================] - 0s 1ms/step\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.7647 - acc: 0.9231\n",
      "0.7647488713264465 0.9230519533157349\n",
      "97/97 [==============================] - 0s 1ms/step\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.8536 - acc: 0.9162\n",
      "0.8535622954368591 0.9162337779998779\n",
      "97/97 [==============================] - 0s 1ms/step\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5396 - acc: 0.9221\n",
      "0.5395732522010803 0.9220778942108154\n",
      "97/97 [==============================] - 0s 1ms/step\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.6136 - acc: 0.9179\n",
      "0.6135910153388977 0.9178571701049805\n",
      "97/97 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i, model_path in enumerate(model_dir):\n",
    "    model = keras.models.load_model(model_path)\n",
    "    loss, acc = model.evaluate(test_ds)\n",
    "    print(loss, acc)\n",
    "    pred = model.predict(test_data_value.reshape(test_data_value.shape[0], -1 ))\n",
    "    results.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62991303, 0.65858334, 0.64691746, ..., 0.64113957, 0.64485747,\n",
       "       0.62906283], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].reshape(results[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAHHCAYAAAB+wBhMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcGElEQVR4nO3deVgV1f8H8PeA7HBZVDZFcBcUtNAMV/y64JJpWpYr7htumIqWC2qJaSVa5pprmGbuWv7EfcMFFTVFEtTAZDEJEI3t3vn9QUzegCvXe3Fu+H49zzw5Z86cOXO7wsfPOXNGEEVRBBEREZGBMpK7A0RERESaMFghIiIig8ZghYiIiAwagxUiIiIyaAxWiIiIyKAxWCEiIiKDxmCFiIiIDBqDFSIiIjJoDFaIiIjIoDFYIYMnCAJCQ0Pl7sYrLzs7G8OHD4ezszMEQcCkSZPk7lK5Gjx4MDw8PF7oXH9/f/j7+z+3noeHBwYPHvxC1yjNwYMH0aRJE5ibm0MQBGRkZJT53NDQUAiCUKa6/HtJLxODlVfchg0bIAiCtFWqVAnVqlXD4MGD8fvvv8vdvRKdPXsWoaGhWv0QLomHh4favT+75eTkACj++Ty7TZ8+Hf7+/qUef3Yr6w/1Pn36QBAEhISElHj8+PHjUpuXLl0qdnzw4MGwtrZWKyvqY/fu3YvVv3fvHgRBwOeff/7cvi1YsAAbNmzAmDFjsHnzZgwcOLBM90Qvz6NHj9CnTx9YWFhg+fLl2Lx5M6ysrGTrT1JSEubOnYs33ngD9vb2qFKlCvz9/XH48GHZ+kT/TZXk7gAZhnnz5qFmzZrIycnBuXPnsGHDBpw+fRq//PILzM3N5e6emrNnz2Lu3LkYPHgw7OzsdGqrSZMm+PDDD4uVm5qaqu0XfT7PatSoEdq3b4/hw4dLZRcvXsSyZcvw0UcfwdPTUyr38fF5bl+ysrKwb98+eHh44Pvvv8fChQs1/is3NDQU+/bte267Rfbv349Lly7B19e3zOc86+jRo3jzzTcxZ86cFzqfiouLi4ORkf7+zXjx4kU8fvwY8+fPR4cOHfTW7ovas2cPPvvsM/Ts2ROBgYEoKCjApk2b0LFjR6xbtw5DhgyRu4v0H8FghQAAXbp0QdOmTQEAw4cPR5UqVfDZZ59h79696NOnj8y9Kz/VqlXDgAEDnlvv2c9HE3NzcyxbtgwdO3Ys0zDAs3bs2AGlUol169bhf//7H06ePIm2bduWWLdJkybYv38/Ll++jNdff/25bdeoUQOPHz/G3LlzsXfvXq36VSQtLQ1eXl4vdG5JCgoKoFKpigWGrxIzMzO9tpeWlgYAOgfx+tKuXTskJiaiSpUqUtno0aPRpEkTzJ49m8EKlRmHgahErVu3BgAkJCSold+6dQvvvvsuHBwcYG5ujqZNmxb75Zefn4+5c+eibt26MDc3R+XKldGqVStERkZKdUob03/ePIHQ0FBMnToVAFCzZk1pSOTevXsAgD/++AO3bt3C06dPX+Cu5RUREYGOHTuiXbt28PT0RERERKl1x48fD3t7+zIPL9nY2CA4OBj79u3D5cuXtepX0dDT3bt3ceDAgWKfeVpaGoYNGwYnJyeYm5ujcePG2Lhxo1obzw43hYeHo3bt2jAzM8PNmzdLva4gCBg3bhy2b98OLy8vWFhYwM/PD9evXwcArFq1CnXq1IG5uTn8/f2l/jxr+/bt8PX1hYWFBapUqYIBAwaUOLy5e/duNGrUCObm5mjUqBF27dpVYp9UKhXCw8PRsGFDmJubw8nJCaNGjcKff/5Zxk9T3b/nrBQNO545cwaTJ09G1apVYWVlhXfeeQcPHz7U2Ja/vz8CAwMBAM2aNYMgCGptl/Wz+Lfc3FwEBwejatWqsLGxwdtvv4379++X6f4aNmyoFqgAhQFa165dcf/+fTx+/LhM7RAxWKESFf3gt7e3l8pu3LiBN998E7GxsZg+fTq++OILWFlZoWfPnmo/3ENDQzF37ly0a9cOX3/9NT7++GPUqFFD61+SJenVqxf69u0LAFiyZAk2b96MzZs3o2rVqgCAr7/+Gp6enrhw4UKZ2svPz8cff/yhtpUU6GRmZharp08PHjzAsWPHpHvr27cvfvzxR+Tl5ZVYX6FQaB18TJw4UasAp4inpyc2b96MKlWqoEmTJmqf+V9//QV/f39s3rwZ/fv3x+LFi2Fra4vBgwdj6dKlxdpav349vvrqK4wcORJffPEFHBwcNF771KlT+PDDDxEYGIjQ0FDExsbirbfewvLly7Fs2TKMHTsWU6dORVRUFIYOHap27oYNG9CnTx8YGxsjLCwMI0aMwM6dO9GqVSu1+U6HDh1C7969IQgCwsLC0LNnTwwZMgTR0dHF+jNq1ChMnToVLVu2xNKlSzFkyBBEREQgICAA+fn5Wn2umowfPx5Xr17FnDlzMGbMGOzbtw/jxo3TeM7HH3+MkSNHAigctty8eTNGjRql1WdRkuHDhyM8PBydOnXCwoULYWJigm7duul0fykpKbC0tISlpaVO7dArRKRX2vr160UA4uHDh8WHDx+KSUlJ4o8//ihWrVpVNDMzE5OSkqS67du3F729vcWcnBypTKVSiS1atBDr1q0rlTVu3Fjs1q2bxuu2bdtWbNu2bbHywMBA0d3dXa0MgDhnzhxpf/HixSIA8e7du8XOnzNnjghAPHbsmMbri6Iouru7iwCKbc9eq+jzKWkryfbt28t8/Wd9/vnnooWFhZiVlSWKoij++uuvIgBx165davWOHTsmAhC3b98uZmRkiPb29uLbb78tHQ8MDBStrKzUzmnbtq3YsGFDURRFce7cuSIA8dKlS6IoiuLdu3dFAOLixYuf20d3d/di/1/Dw8NFAOJ3330nleXl5Yl+fn6itbW1dD9F11EoFGJaWlqZPhMAopmZmdr/51WrVokARGdnZ6ltURTFGTNmqH0n8vLyREdHR7FRo0biX3/9JdXbv3+/CECcPXu2VNakSRPRxcVFzMjIkMoOHTokAlD7Lp46dUoEIEZERKj18+DBg8XKS/t+/5u7u7sYGBgo7Rd93zp06CCqVCqpPDg4WDQ2NlbrY0mKzr948aJUps1nUfT3p0hMTIwIQBw7dqzadfr161fs70pZ3b59WzQ3NxcHDhyo9bn06mJmhQAAHTp0QNWqVeHm5oZ3330XVlZW2Lt3L6pXrw4ASE9Px9GjR9GnTx88fvxYyi48evQIAQEBuH37tpRStrOzw40bN3D79u2Xfh+hoaEQRbHM80WaN2+OyMhItW3QoEHF6i1fvrxYPX2KiIhAt27dYGNjAwCoW7cufH19NQ4F2draYtKkSdi7dy+uXLlSpusUZVfmzp2rl37/9NNPcHZ2ljJCAGBiYoIJEyYgOzsbJ06cUKvfu3dvKQtWFu3bt1cbFmzevLnUTtFn9Wz5nTt3AADR0dFIS0vD2LFj1SaId+vWDQ0aNMCBAwcAAMnJyYiJiUFgYCBsbW2leh07diw2P2f79u2wtbVFx44d1TJsvr6+sLa2xrFjx8p8X88zcuRItcnVrVu3hlKpxG+//aZ1W2X9LEry008/AQAmTJigVv6ij60/ffoU7733HiwsLLBw4cIXaoNeTZxgSwAKfxnXq1cPmZmZWLduHU6ePKk2+S8+Ph6iKGLWrFmYNWtWiW2kpaWhWrVqmDdvHnr06IF69eqhUaNG6Ny5MwYOHFimJ2JetipVqpTpqYk33nijTBNsX0RsbCyuXLmCQYMGIT4+Xir39/fH8uXLkZWVBYVCUeK5EydOxJIlSxAaGoo9e/Y891pFAc6cOXNw5coVtWG+F/Hbb7+hbt26xZ5oKXoS6t+/XP/9RNXz1KhRQ22/KKBwc3Mrsbxo7kjRdevXr1+szQYNGuD06dNq9erWrVusXv369dWG2G7fvo3MzEw4OjqW2Neiya368O/7Lvr/9CJzY8r6WZR2rpGREWrXrq1WXlJbz6NUKvHBBx/g5s2b+Pnnn+Hq6qp1G/TqYrBCANR/Gffs2ROtWrVCv379EBcXB2tra6hUKgDAlClTEBAQUGIbderUAQC0adMGCQkJ2LNnDw4dOoS1a9diyZIlWLlypfSYryAIEEWxWBtKpbI8bs+gfffddwCA4OBgBAcHFzu+Y8eOUp+aKAo+QkNDtcquLFmyBHPnzkV4ePgL9/tFWFhYaFXf2NhYq/KSvlP6olKp4OjoWGq2S5uM0fPIcX/lbcSIEdi/fz8iIiLwv//9T+7u0H8MgxUqpmgSXtEE2enTp6NWrVoAClP8ZclEODg4YMiQIRgyZAiys7PRpk0bhIaGSsGKvb29lLJ/VlnS3GVdYfO/QBRFbNmyBe3atcPYsWOLHZ8/fz4iIiI0PuI5adIkhIeHY+7cuWV6ZPXZAKfo6ZEX5e7ujmvXrkGlUqllV27duiUdl0PRdePi4or9YoyLi5OOF/23pCHLuLg4tf3atWvj8OHDaNmypdZBl5zK+lmUdq5KpUJCQoJaNuXfn83zTJ06FevXr0d4eLjakCFRWXHOCpXI398fb7zxBsLDw5GTkwNHR0f4+/tj1apVSE5OLlb/2ccqHz16pHbM2toaderUQW5urlRWu3Zt3Lp1S+28q1ev4syZM8/tW9GKnCU9xfBfe3T5zJkzuHfvHoYMGYJ333232Pb+++/j2LFjePDgQaltFAUfe/bsQUxMTJmuO2nSJNjZ2WHevHk69b9r165ISUnBtm3bpLKCggJ89dVXsLa2LnWdmPLWtGlTODo6YuXKlWrfu59//hmxsbHS0ywuLi5o0qQJNm7ciMzMTKleZGRksceq+/TpA6VSifnz5xe7XkFBgc4rKpeXsn4WJenSpQsAYNmyZWrl2mTkFi9ejM8//xwfffQRJk6cqF3nif7GzAqVaurUqXjvvfewYcMGjB49GsuXL0erVq3g7e2NESNGoFatWkhNTUVUVBTu37+Pq1evAgC8vLzg7+8PX19fODg4IDo6Gj/++KPao5dDhw7Fl19+iYCAAAwbNgxpaWlYuXIlGjZsiKysLI39KlqB9eOPP8YHH3wAExMTdO/eHVZWVvj6668xd+5cHDt2TOtF2eQQEREBY2PjUn9hvP322/j444+xdetWTJ48udR2ioZ2rl69Wqbl1W1tbTFx4kSdJ9qOHDkSq1atwuDBg3Hp0iV4eHjgxx9/xJkzZxAeHq42CfZlMjExwWeffYYhQ4agbdu26Nu3L1JTU7F06VJ4eHioDbeFhYWhW7duaNWqFYYOHYr09HR89dVXaNiwIbKzs6V6bdu2xahRoxAWFoaYmBh06tQJJiYmuH37NrZv346lS5fi3XffleN2NdLms/i3Jk2aoG/fvvjmm2+QmZmJFi1a4MiRI2pzqzTZtWsXpk2bhrp168LT01Ma8izSsWNHODk56XR/9GpgZoVK1atXL9SuXRuff/45lEolvLy8EB0djW7dumHDhg0ICgrCypUrYWRkhNmzZ0vnTZgwAffu3UNYWBgmTJiAEydO4JNPPsEXX3wh1fH09MSmTZuQmZmJyZMnY+/evdi8eXOZVmNt1qwZ5s+fj6tXr2Lw4MHo27fvcxfMMkT5+fnYvn07WrRoUep6I40aNULNmjWL/ZD/Nzs7O62f0Jg0aZLaEzAvwsLCAsePH0f//v2xceNGfPjhh0hPT8f69etl/1f04MGDsW3bNuTl5SEkJASrVq3CO++8g9OnT6sNl3Xu3Bnbt2+HUqnEjBkzsHPnTqxfv77ECdUrV67E6tWrkZaWho8++ggzZszA0aNHMWDAALRs2fIl3p12yvpZlGTdunWYMGECDh48iGnTpiE/P1/jE0TPKvoHzO3btzFw4MBiW2xsrK63Rq8IQfwvz9giIiKiCo+ZFSIiIjJoDFaIiIjIoDFYISIiIoPGYIWIiIgMGoMVIiIiMmgMVoiIiMigcVG4cqRSqfDgwQPY2NhUqCXiiYheFaIo4vHjx3B1dS32wk59ycnJQV5enl7aMjU1VXu7dkXBYKUcPXjwoNjbYYmI6L8nKSkJ1atX13u7OTk5qOlujZQ0/bzE1dnZGXfv3q1wAQuDlXJUtNR4vRGzYWxasb44REVcNt2QuwtE5aZAzMfJ7B/K7dUReXl5SElT4rdLHlDY6Ja5yXqsgrvvPeTl5ZUpWAkLC8POnTtx69YtWFhYoEWLFvjss8/UXlqZk5ODDz/8EFu3bkVubi4CAgLwzTffqL0mITExEWPGjMGxY8dgbW2NwMBAhIWFoVKlf0KM48ePY/Lkybhx4wbc3Nwwc+ZMDB48uMz3xmClHBUN/RibmsPYjMEKVUyVBFO5u0BU7sp7KN/aRoC1jW7XUEG780+cOIGgoCA0a9YMBQUF+Oijj9CpUyfcvHlTesdYcHAwDhw4gO3bt8PW1hbjxo1Dr169pJfOKpVKdOvWDc7Ozjh79iySk5MxaNAgmJiYYMGCBQCAu3fvolu3bhg9ejQiIiJw5MgRDB8+HC4uLggICChTX7ncfjnKysqCra0tPIMWMFihCst17XW5u0BUbgrEPBx9HIHMzEwoFAq9t1/0eyItzl0vmRXH+r+9cF8fPnwIR0dHnDhxAm3atEFmZiaqVq2KLVu2SC/pvHXrFjw9PREVFYU333wTP//8M9566y08ePBAyrasXLkSISEhePjwIUxNTRESEoIDBw7gl19+ka71wQcfICMjAwcPHixT3/g0EBERkcxUEPWyAYUB0LNbbm5umfqQmZkJANKLVS9duoT8/Hx06NBBqtOgQQPUqFEDUVFRAICoqCh4e3urDQsFBAQgKysLN27ckOo820ZRnaI2yoLBChERUQXi5uYGW1tbaQsLC3vuOSqVCpMmTULLli3RqFEjAEBKSgpMTU2LvZnbyckJKSkpUp1nA5Wi40XHNNXJysrCX3/9VaZ74pwVIiIimamggkoPbQCFTy49OwxkZmb23HODgoLwyy+/4PTp0zr2onwwWCEiIpKZUhSh1HEKadH5CoVCqzkr48aNw/79+3Hy5Em1x7OdnZ2Rl5eHjIwMtexKamoqnJ2dpToXLlxQay81NVU6VvTforJn6ygUClhYWJSpjxwGIiIiegWJoohx48Zh165dOHr0KGrWrKl23NfXFyYmJjhy5IhUFhcXh8TERPj5+QEA/Pz8cP36daSlpUl1IiMjoVAo4OXlJdV5to2iOkVtlAUzK0RERDJ7doKsLm1oIygoCFu2bMGePXtgY2MjzTGxtbWFhYUFbG1tMWzYMEyePBkODg5QKBQYP348/Pz88OabbwIAOnXqBC8vLwwcOBCLFi1CSkoKZs6ciaCgIGn4afTo0fj6668xbdo0DB06FEePHsUPP/yAAwcOlLmvDFaIiIhkpoII5UsOVlasWAEA8Pf3Vytfv369tGDbkiVLYGRkhN69e6stClfE2NgY+/fvx5gxY+Dn5wcrKysEBgZi3rx5Up2aNWviwIEDCA4OxtKlS1G9enWsXbu2zGusAFxnpVxxnRV6FXCdFarIXtY6K3dvucBGx3VWHj9WoWaD5HLrq5yYWSEiIpKZHMNA/yUMVoiIiGSmz6eBKiI+DUREREQGjZkVIiIiman+3nRto6JisEJERCQzpR6eBtL1fEPGYIWIiEhmSrFw07WNiopzVoiIiMigMbNCREQkM85Z0YzBChERkcxUEKCEoHMbFRWHgYiIiMigMbNCREQkM5VYuOnaRkXFYIWIiEhmSj0MA+l6viHjMBAREREZNGZWiIiIZMbMimYMVoiIiGSmEgWoRB2fBtLxfEPGYSAiIiIyaMysEBERyYzDQJoxWCEiIpKZEkZQ6jjYodRTXwwRgxUiIiKZiXqYsyJyzgoRERGRPJhZISIikhnnrGjGYIWIiEhmStEISlHHOSsVeLl9DgMRERGRQWNmhYiISGYqCFDpmD9QoeKmVhisEBERyYxzVjTjMBAREREZNGZWiIiIZKafCbYcBiIiIqJyUjhnRccXGXIYiIiIiEgezKwQERHJTKWHdwPxaSAiIiIqN5yzohmDFSIiIpmpYMR1VjTgnBUiIiIyaMysEBERyUwpClCKOi4Kp+P5hozBChERkcyUephgq+QwEBEREZE8mFkhIiKSmUo0gkrHp4FUFfhpIGZWiIiIZFY0DKTrpo2TJ0+ie/fucHV1hSAI2L17t9pxQRBK3BYvXizV8fDwKHZ84cKFau1cu3YNrVu3hrm5Odzc3LBo0SKtPx8GK0RERK+gJ0+eoHHjxli+fHmJx5OTk9W2devWQRAE9O7dW63evHnz1OqNHz9eOpaVlYVOnTrB3d0dly5dwuLFixEaGorVq1dr1VcOAxEREclMBd2f5lFpWb9Lly7o0qVLqcednZ3V9vfs2YN27dqhVq1aauU2NjbF6haJiIhAXl4e1q1bB1NTUzRs2BAxMTH48ssvMXLkyDL3lZkVIiIimRUtCqfrBhRmM57dcnNzde5famoqDhw4gGHDhhU7tnDhQlSuXBmvvfYaFi9ejIKCAulYVFQU2rRpA1NTU6ksICAAcXFx+PPPP8t8fQYrREREFYibmxtsbW2lLSwsTOc2N27cCBsbG/Tq1UutfMKECdi6dSuOHTuGUaNGYcGCBZg2bZp0PCUlBU5OTmrnFO2npKSU+focBiIiIpKZft4NVHh+UlISFAqFVG5mZqZTuwCwbt069O/fH+bm5mrlkydPlv7s4+MDU1NTjBo1CmFhYXq5bhEGK0RERDJTQYAKus5ZKTxfoVCoBSu6OnXqFOLi4rBt27bn1m3evDkKCgpw79491K9fH87OzkhNTVWrU7Rf2jyXknAYiIiISGZFmRVdt/Lw7bffwtfXF40bN35u3ZiYGBgZGcHR0REA4Ofnh5MnTyI/P1+qExkZifr168Pe3r7MfWCwQkRE9ArKzs5GTEwMYmJiAAB3795FTEwMEhMTpTpZWVnYvn07hg8fXuz8qKgohIeH4+rVq7hz5w4iIiIQHByMAQMGSIFIv379YGpqimHDhuHGjRvYtm0bli5dqjZ8VBYcBiIiIpKZft4NpN350dHRaNeunbRfFEAEBgZiw4YNAICtW7dCFEX07du32PlmZmbYunUrQkNDkZubi5o1ayI4OFgtELG1tcWhQ4cQFBQEX19fVKlSBbNnz9bqsWWAwQoREZHsVKIAla7rrGh5vr+/P8TnLNE/cuTIUgOL119/HefOnXvudXx8fHDq1Cmt+vZvHAYiIiIig8bMChERkcxUehgGUlXg/AODFSIiIpnp563LFTdYqbh3RkRERBUCMytEREQyU0KAUsdF4XQ935AxWCEiIpIZh4E0q7h3RkRERBUCMytEREQyU0L3YRylfrpikBisEBERyYzDQJoxWCEiIpKZPl5EWF4vMjQEFffOiIiIqEJgZoWIiEhmIgSodJyzIvLRZSIiIiovHAbSrOLeGREREVUIzKwQERHJTCUKUIm6DePoer4hY7BCREQkM6Ue3rqs6/mGrOLeGREREVUIzKwQERHJjMNAmjFYISIikpkKRlDpONih6/mGrOLeGREREVUIzKwQERHJTCkKUOo4jKPr+YaMwQoREZHMOGdFMwYrREREMhP18NZlkSvYEhEREcmDmRUiIiKZKSFAqeOLCHU935AxWCEiIpKZStR9zolK1FNnDBCHgYiIiMigMbOiBQ8PD0yaNAmTJk2SuyuvDCNBhTEtotHN61dUtnqKh0+ssPeX+lgd5Qv8nfJsX/cO3mtyA55OD2FnkYs+G99DXFoVtXbWvr8HzWo8UCvbHuOFTyLbvqxbISpVo6aZeHfYfdRp9ASVHfMwb6wnoo5Ulo5PDvsVHXulqZ0TfcoOs4Y3Uitr1jYd/YISUbP+U+TlCrh+0Rbzg7xeyj2QblR6mGCr6/mGjMEKGbQhb1zBe01uYNbP/0PCH/bwcn6IeV2OITvXFFsu+wAALEzyceW+C/7vVm2Edj5Rals/XvXEN2fekPZz8vn1J8NgbqnEnThrHNrhhFnLb5VY5+JJeyyZUVfaz89T/8XUstMfmDg/HhuWuOPqOTsYG4twr/ekXPtN+qOCAJWOc050Pd+QVaif1nl5eTA1NZW7G6RHTaql4ni8B07dcQcAPMhSoIvnbTRy+edfmftv1gcAuCqyNLaVk18Jj55Yll9niV5Q9EkHRJ900FgnP0/An3+U/PPNyFjE6I/vYO1iDxz60VkqT0zg950qBllzRv7+/pgwYQKmTZsGBwcHODs7IzQ0VDqemJiIHj16wNraGgqFAn369EFqaqp0PDQ0FE2aNMHatWtRs2ZNmJubAwAEQcCqVavw1ltvwdLSEp6enoiKikJ8fDz8/f1hZWWFFi1aICEhQWorISEBPXr0gJOTE6ytrdGsWTMcPnz4pX0WVLKY353whvvvcLfPAADUq/oHXquWgtN3amjdVlev2zgetB47Bm/FhNbnYF4pX8+9JSo/Pm9k4vuz57Hm4CWMC42Hjd0/3986Xtmo4pwHUSXg611XEHHqPOatuQH3usys/FcUrWCr61ZRyT7AtXHjRlhZWeH8+fNYtGgR5s2bh8jISKhUKvTo0QPp6ek4ceIEIiMjcefOHbz//vtq58fHx2PHjh3YuXMnYmJipPL58+dj0KBBiImJQYMGDdCvXz+MGjUKM2bMQHR0NERRxLhx46T62dnZ6Nq1K44cOYIrV66gc+fO6N69OxITE1/WR0ElWHf+dfzfrTrYPex7RE9ehW2B2/HdJR/8FFtPq3Z+jq2Ljw+0x/Btb+Pb86/jrYa/YkG3I+XUayL9unTKHp+H1MOMwY2wbrEHvJtlYv6aGzAyKnz8w8UtBwDQf1wivl/hhjmjGyI7sxI+23wd1rYMyv8Liuas6LpVVLIPA/n4+GDOnDkAgLp16+Lrr7/GkSOFv0SuX7+Ou3fvws3NDQCwadMmNGzYEBcvXkSzZs0AFA79bNq0CVWrVlVrd8iQIejTpw8AICQkBH5+fpg1axYCAgIAABMnTsSQIUOk+o0bN0bjxo2l/fnz52PXrl3Yu3evWlCjSW5uLnJzc6X9rCzNwxL0fAEN4tHV81fM2N8B8X84oIHjH5j6vzN4mG2JfTcalLmdHdf+mWQY/0dl/PHEEmve34fqdpm4n2FbHl0n0psTP/3z8+3er1a4G2eF9Uei4fNGJmLO2UH4O2jZttINZw4VTi5fMqMuNp+8gNad/8DP21xk6TeRvsgehvn4+Kjtu7i4IC0tDbGxsXBzc5MCFQDw8vKCnZ0dYmNjpTJ3d/digcq/23VycgIAeHt7q5Xl5ORIAUV2djamTJkCT09P2NnZwdraGrGxsVplVsLCwmBrayttz/adXkxw2yisu/A6Dt6qi/g/KmP/zfr4LroxhjW/olO715MLvxM17DL10U2ilyrlvjky0yvBxf0vAED6w8K5LIkJFlKd/HwjJCeZw9Elt8Q2yLCoIEjvB3rhrQJPsJU9WDExMVHbFwQBKpWqzOdbWVk9t11BEEotK7rWlClTsGvXLixYsACnTp1CTEwMvL29kZeXV+a+zJgxA5mZmdKWlJRU5nOpZOYmBcUWOlKKAowE3VY/qu/4BwDg4ZOSvz9EhqyKUy5s7AqkICX+F2vk5QqoVvMvqY5xJRWcquUi7YG5XN0kLYh/Pw2kyyZW4GBF9mGg0nh6eiIpKQlJSUlShuLmzZvIyMiAl5f+1w04c+YMBg8ejHfeeQdAYabl3r17WrVhZmYGMzMzvfftVXYiwQMj3ryMlCwbJPxhjwZOf2Bg06vYc/2fISCFeQ5cFNmoalU4mdDj78m4fzyxxKMnlqhul4munrdx6o47Mv8yQ92qjzD1f2cRneSC2w8rl3RZopfK3FIJ1xr/BBpO1XNQq0E2HmdWwuNME/Qfl4gz/1cZ6X+YwtUtB0On3sWD38xx+ZQ9AODpk0r4aasLBo5PxB/JZkh9YIZ3h/0OADh1sEqJ1yTDwrcua2awwUqHDh3g7e2N/v37Izw8HAUFBRg7dizatm2Lpk2b6v16devWxc6dO9G9e3cIgoBZs2ZpleGh8rHwcCsEtbqAjzqchIPlX3j4xAo/XvXCqrP/fAf8a9/D/K7HpP1Fb0cCAFacaYqVZ5shX2mM5u730d/3GixMCpDy2BqHf62FNVG+L/1+iEpSt9FjLNr8i7Q/6qO7AIDInY74OrQ2atZ7gg4902BlU4D0NFNcPmOHTUvdkZ//T3J87SIPKAsETFn0K8zMVbh11QbTAxshO8tgf8yTzE6ePInFixfj0qVLSE5Oxq5du9CzZ0/p+ODBg7Fx40a1cwICAnDw4EFpPz09HePHj8e+fftgZGSE3r17Y+nSpbC2tpbqXLt2DUFBQbh48SKqVq2K8ePHY9q0aVr11WC/xYIgYM+ePRg/fjzatGkDIyMjdO7cGV999VW5XO/LL7/E0KFD0aJFC1SpUgUhISGcIGsAnuabYvGxVlh8rFWpdfbeaIC9Gibbpj62xrCtPcuhd0T6cf2CHbrUL/07PvNfK9WWRFlghLWLamLtopr67Bq9JHKsYPvkyRM0btwYQ4cORa9evUqs07lzZ6xfv17a//foQf/+/ZGcnIzIyEjk5+djyJAhGDlyJLZs2QKg8EGTTp06oUOHDli5ciWuX7+OoUOHws7ODiNHjixzXwVRFCvwq4/klZWVBVtbW3gGLYCxGceNqWJyXXtd7i4QlZsCMQ9HH0cgMzMTCoVC7+0X/Z7ocWgoTKx0W9Q0/0ke9nRa90J9FQShxMxKRkYGdu/eXeI5sbGx8PLywsWLF6URj4MHD6Jr1664f/8+XF1dsWLFCnz88cdISUmRFm2dPn06du/ejVu3Sl6tuSSyT7AlIiIi/cnKylLbnl1SQ1vHjx+Ho6Mj6tevjzFjxuDRo0fSsaioKNjZ2alNzejQoQOMjIxw/vx5qU6bNm3UVpcPCAhAXFwc/vzzzzL3g8EKERGRzHR9EujZdwu5ubmpLaMRFhb2Qn3q3LkzNm3ahCNHjuCzzz7DiRMn0KVLFyiVSgBASkoKHB0d1c6pVKkSHBwckJKSItUpWj6kSNF+UZ2yMNg5K0RERK8KfT4NlJSUpDYM9KJPqX7wwQfSn729veHj44PatWvj+PHjaN++vU591RYzK0RERBWIQqFQ2/S1pEatWrVQpUoVxMfHAwCcnZ2RlpamVqegoADp6elwdnaW6jz7Tj8A0n5RnbJgsEJERCQznVev1UNm5nnu37+PR48ewcWl8PUNfn5+yMjIwKVLl6Q6R48ehUqlQvPmzaU6J0+eRH7+P++oioyMRP369WFvb1/mazNYISIikpkcwUp2djZiYmKklwDfvXsXMTExSExMRHZ2NqZOnYpz587h3r17OHLkCHr06IE6depI79jz9PRE586dMWLECFy4cAFnzpzBuHHj8MEHH8DV1RUA0K9fP5iammLYsGG4ceMGtm3bhqVLl2Ly5Mla9ZXBChER0SsoOjoar732Gl577TUAwOTJk/Haa69h9uzZMDY2xrVr1/D222+jXr16GDZsGHx9fXHq1Cm1YaWIiAg0aNAA7du3R9euXdGqVSusXr1aOm5ra4tDhw7h7t278PX1xYcffojZs2drtcYKwAm2REREspNjuX1/f39oWmrt//7v/57bhoODg7QAXGl8fHxw6tQprfr2bwxWiIiIZCYCOr81uSKv8MpghYiISGZ8kaFmnLNCREREBo2ZFSIiIpkxs6IZgxUiIiKZMVjRjMNAREREZNCYWSEiIpIZMyuaMVghIiKSmSgKEHUMNnQ935BxGIiIiIgMGjMrREREMlNB0HlROF3PN2QMVoiIiGTGOSuacRiIiIiIDBozK0RERDLjBFvNGKwQERHJjMNAmjFYISIikhkzK5pxzgoREREZNGZWiIiIZCbqYRioImdWGKwQERHJTAQgirq3UVFxGIiIiIgMGjMrREREMlNBgMAVbEvFYIWIiEhmfBpIMw4DERERkUFjZoWIiEhmKlGAwEXhSsVghYiISGaiqIengSrw40AcBiIiIiKDxswKERGRzDjBVjMGK0RERDJjsKIZgxUiIiKZcYKtZpyzQkRERAaNmRUiIiKZ8WkgzRisEBERyawwWNF1zoqeOmOAOAxEREREBo2ZFSIiIpnxaSDNGKwQERHJTPx707WNiorDQERERGTQmFkhIiKSGYeBNGOwQkREJDeOA2nEYSAiIiK5/Z1Z0WWDlpmVkydPonv37nB1dYUgCNi9e7d0LD8/HyEhIfD29oaVlRVcXV0xaNAgPHjwQK0NDw8PCIKgti1cuFCtzrVr19C6dWuYm5vDzc0NixYt0vrjYbBCRET0Cnry5AkaN26M5cuXFzv29OlTXL58GbNmzcLly5exc+dOxMXF4e233y5Wd968eUhOTpa28ePHS8eysrLQqVMnuLu749KlS1i8eDFCQ0OxevVqrfrKYSAiIiKZybGCbZcuXdClS5cSj9na2iIyMlKt7Ouvv8Ybb7yBxMRE1KhRQyq3sbGBs7Nzie1EREQgLy8P69atg6mpKRo2bIiYmBh8+eWXGDlyZJn7yswKERGRzHQdAnp2gm5WVpbalpubq5c+ZmZmQhAE2NnZqZUvXLgQlStXxmuvvYbFixejoKBAOhYVFYU2bdrA1NRUKgsICEBcXBz+/PPPMl+bwQoREVEF4ubmBltbW2kLCwvTuc2cnByEhISgb9++UCgUUvmECROwdetWHDt2DKNGjcKCBQswbdo06XhKSgqcnJzU2iraT0lJKfP1OQxEREQktxeYIFtiGwCSkpLUAgozMzOdms3Pz0efPn0giiJWrFihdmzy5MnSn318fGBqaopRo0YhLCxM5+s+i8EKERGRzPQ5Z0WhUKgFK7ooClR+++03HD169LntNm/eHAUFBbh37x7q168PZ2dnpKamqtUp2i9tnktJOAxERERExRQFKrdv38bhw4dRuXLl554TExMDIyMjODo6AgD8/Pxw8uRJ5OfnS3UiIyNRv3592Nvbl7kvzKwQERHJTYZF4bKzsxEfHy/t3717FzExMXBwcICLiwveffddXL58Gfv374dSqZTmmDg4OMDU1BRRUVE4f/482rVrBxsbG0RFRSE4OBgDBgyQApF+/fph7ty5GDZsGEJCQvDLL79g6dKlWLJkiVZ9LVOwsnfv3jI3WNIz2ERERFQ6OZbbj46ORrt27aT9ovkngYGBCA0NlX73N2nSRO28Y8eOwd/fH2ZmZti6dStCQ0ORm5uLmjVrIjg4WG0ei62tLQ4dOoSgoCD4+vqiSpUqmD17tlaPLQNlDFZ69uxZpsYEQYBSqdSqA0RERPTy+fv7Q9QwUUbTMQB4/fXXce7cuedex8fHB6dOndK6f88qU7CiUql0uggRERE9RwV+t4+udJqzkpOTA3Nzc331hYiI6JXEty5rpvXTQEqlEvPnz0e1atVgbW2NO3fuAABmzZqFb7/9Vu8dJCIiqvBEPW0VlNbByqeffooNGzZg0aJFasvnNmrUCGvXrtVr54iIiIi0DlY2bdqE1atXo3///jA2NpbKGzdujFu3bum1c0RERK8GQU9bxaT1nJXff/8dderUKVauUqnUFn0hIiKiMpJhnZX/Eq0zK15eXiU+gvTjjz/itdde00uniIiIiIponVmZPXs2AgMD8fvvv0OlUmHnzp2Ii4vDpk2bsH///vLoIxERUcXGzIpGWmdWevTogX379uHw4cOwsrLC7NmzERsbi3379qFjx47l0UciIqKKreity7puFdQLrbPSunVrREZG6rsvRERERMW88KJw0dHRiI2NBVA4j8XX11dvnSIiInqViGLhpmsbFZXWwcr9+/fRt29fnDlzBnZ2dgCAjIwMtGjRAlu3bkX16tX13UciIqKKjXNWNNJ6zsrw4cORn5+P2NhYpKenIz09HbGxsVCpVBg+fHh59JGIiIheYVpnVk6cOIGzZ8+ifv36Uln9+vXx1VdfoXXr1nrtHBER0StBHxNkOcH2H25ubiUu/qZUKuHq6qqXThEREb1KBLFw07WNikrrYaDFixdj/PjxiI6Olsqio6MxceJEfP7553rtHBER0SuBLzLUqEyZFXt7ewjCP+mlJ0+eoHnz5qhUqfD0goICVKpUCUOHDkXPnj3LpaNERET0aipTsBIeHl7O3SAiInqFcc6KRmUKVgIDA8u7H0RERK8uPrqs0QsvCgcAOTk5yMvLUytTKBQ6dYiIiIjoWVpPsH3y5AnGjRsHR0dHWFlZwd7eXm0jIiIiLXGCrUZaByvTpk3D0aNHsWLFCpiZmWHt2rWYO3cuXF1dsWnTpvLoIxERUcXGYEUjrYeB9u3bh02bNsHf3x9DhgxB69atUadOHbi7uyMiIgL9+/cvj34SERHRK0rrzEp6ejpq1aoFoHB+Snp6OgCgVatWOHnypH57R0RE9CooehpI162C0jpYqVWrFu7evQsAaNCgAX744QcAhRmXohcbEhERUdkVrWCr61ZRaR2sDBkyBFevXgUATJ8+HcuXL4e5uTmCg4MxdepUvXeQiIiIXm1az1kJDg6W/tyhQwfcunULly5dQp06deDj46PXzhEREb0SuM6KRjqtswIA7u7ucHd310dfiIiIiIopU7CybNmyMjc4YcKEF+4MERHRq0iAHt66rJeeGKYyBStLliwpU2OCIDBYISIiIr0qU7BS9PQPvRin5edRSTCRuxtE5eLnBzFyd4Go3GQ9VsG+3ku4EF9kqJHOc1aIiIhIR5xgq5HWjy4TERERvUzMrBAREcmNmRWNGKwQERHJTB8r0HIFWyIiIiKZvFCwcurUKQwYMAB+fn74/fffAQCbN2/G6dOn9do5IiKiV4Kop00LJ0+eRPfu3eHq6gpBELB79271LokiZs+eDRcXF1hYWKBDhw64ffu2Wp309HT0798fCoUCdnZ2GDZsGLKzs9XqXLt2Da1bt4a5uTnc3NywaNEi7TqKFwhWduzYgYCAAFhYWODKlSvIzc0FAGRmZmLBggVad4CIiOiVJ0Ow8uTJEzRu3BjLly8v8fiiRYuwbNkyrFy5EufPn4eVlRUCAgKQk5Mj1enfvz9u3LiByMhI7N+/HydPnsTIkSOl41lZWejUqRPc3d1x6dIlLF68GKGhoVi9erVWfdU6WPnkk0+wcuVKrFmzBiYm/6wd0rJlS1y+fFnb5oiIiEgGXbp0wSeffIJ33nmn2DFRFBEeHo6ZM2eiR48e8PHxwaZNm/DgwQMpAxMbG4uDBw9i7dq1aN68OVq1aoWvvvoKW7duxYMHDwAAERERyMvLw7p169CwYUN88MEHmDBhAr788kut+qp1sBIXF4c2bdoUK7e1tUVGRoa2zREREb3yiibY6roBhdmMZ7eiERBt3L17FykpKejQoYNUZmtri+bNmyMqKgoAEBUVBTs7OzRt2lSq06FDBxgZGeH8+fNSnTZt2sDU1FSqExAQgLi4OPz5559l7o/WwYqzszPi4+OLlZ8+fRq1atXStjkiIiIqWsFW1w2Am5sbbG1tpS0sLEzr7qSkpAAAnJyc1MqdnJykYykpKXB0dFQ7XqlSJTg4OKjVKamNZ69RFlo/ujxixAhMnDgR69atgyAIePDgAaKiojBlyhTMmjVL2+aIiIhIj+usJCUlQaFQSMVmZmY6Niw/rYOV6dOnQ6VSoX379nj69CnatGkDMzMzTJkyBePHjy+PPhIREVEZKRQKtWDlRTg7OwMAUlNT4eLiIpWnpqaiSZMmUp20tDS18woKCpCeni6d7+zsjNTUVLU6RftFdcpC62EgQRDw8ccfIz09Hb/88gvOnTuHhw8fYv78+do2RURERNDvnBV9qFmzJpydnXHkyBGpLCsrC+fPn4efnx8AwM/PDxkZGbh06ZJU5+jRo1CpVGjevLlU5+TJk8jPz5fqREZGon79+rC3ty9zf154UThTU1N4eXnhjTfegLW19Ys2Q0RERDI8upydnY2YmBjExMQAKJxUGxMTg8TERAiCgEmTJuGTTz7B3r17cf36dQwaNAiurq7o2bMnAMDT0xOdO3fGiBEjcOHCBZw5cwbjxo3DBx98AFdXVwBAv379YGpqimHDhuHGjRvYtm0bli5dismTJ2vVV62Hgdq1awdBKP011EePHtW2SSIiInrJoqOj0a5dO2m/KIAIDAzEhg0bMG3aNDx58gQjR45ERkYGWrVqhYMHD8Lc3Fw6JyIiAuPGjUP79u1hZGSE3r17Y9myZdJxW1tbHDp0CEFBQfD19UWVKlUwe/ZstbVYykLrYKVorKpIfn4+YmJi8MsvvyAwMFDb5oiIiEgfwzhanu/v7w9RLP0kQRAwb948zJs3r9Q6Dg4O2LJli8br+Pj44NSpU9p17l+0DlaWLFlSYnloaGixJXaJiIioDPjWZY309iLDAQMGYN26dfpqjoiIiAjAC2RWShMVFaU2jkVERERlxMyKRloHK7169VLbF0URycnJiI6O5qJwREREL0Afjx7r89FlQ6N1sGJra6u2b2RkhPr162PevHno1KmT3jpGREREBGgZrCiVSgwZMgTe3t5aLeZCRERE9KK0mmBrbGyMTp068e3KRERE+iTDonD/JVo/DdSoUSPcuXOnPPpCRET0SjK05fYNjdbByieffIIpU6Zg//79SE5ORlZWltpGREREpE9lnrMyb948fPjhh+jatSsA4O2331Zbdl8URQiCAKVSqf9eEhERVXQVODOiqzIHK3PnzsXo0aNx7Nix8uwPERHRq4frrGhU5mCl6P0Bbdu2LbfOEBEREf2bVo8ua3rbMhEREb0YLgqnmVbBSr169Z4bsKSnp+vUISIiolcOh4E00ipYmTt3brEVbImIiIjKk1bBygcffABHR8fy6gsREdEricNAmpU5WOF8FSIionLCYSCNyrwoXNHTQEREREQvU5kzKyqVqjz7QURE9OpiZkUjreasEBERkf5xzopmDFaIiIjkxsyKRlq/yJCIiIjoZWJmhYiISG7MrGjEYIWIiEhmnLOiGYeBiIiIyKAxs0JERCQ3DgNpxGCFiIhIZhwG0ozDQERERGTQmFkhIiKSG4eBNGKwQkREJDcGKxpxGIiIiIgMGjMrREREMhP+3nRto6JisEJERCQ3DgNpxGCFiIhIZnx0WTPOWSEiIiKDxswKERGR3DgMpBEzK0RERIZA1HHTkoeHBwRBKLYFBQUBAPz9/YsdGz16tFobiYmJ6NatGywtLeHo6IipU6eioKDghW5fE2ZWiIiIXkEXL16EUqmU9n/55Rd07NgR7733nlQ2YsQIzJs3T9q3tLSU/qxUKtGtWzc4Ozvj7NmzSE5OxqBBg2BiYoIFCxbota8MVoiIiGQmxwTbqlWrqu0vXLgQtWvXRtu2baUyS0tLODs7l3j+oUOHcPPmTRw+fBhOTk5o0qQJ5s+fj5CQEISGhsLU1FTreygNh4GIiIjkpusQkI5zXvLy8vDdd99h6NChEIR/VmyJiIhAlSpV0KhRI8yYMQNPnz6VjkVFRcHb2xtOTk5SWUBAALKysnDjxo0X70wJmFkhIiKqQLKystT2zczMYGZmpvGc3bt3IyMjA4MHD5bK+vXrB3d3d7i6uuLatWsICQlBXFwcdu7cCQBISUlRC1QASPspKSl6uJN/MFghIiKSmT6Hgdzc3NTK58yZg9DQUI3nfvvtt+jSpQtcXV2lspEjR0p/9vb2houLC9q3b4+EhATUrl1bt85qicEKERGR3PT46HJSUhIUCoVU/Lysym+//YbDhw9LGZPSNG/eHAAQHx+P2rVrw9nZGRcuXFCrk5qaCgClznN5UZyzQkREVIEoFAq17XnByvr16+Ho6Ihu3bpprBcTEwMAcHFxAQD4+fnh+vXrSEtLk+pERkZCoVDAy8tLt5v4F2ZWiIiIZCbXcvsqlQrr169HYGAgKlX6JyRISEjAli1b0LVrV1SuXBnXrl1DcHAw2rRpAx8fHwBAp06d4OXlhYEDB2LRokVISUnBzJkzERQU9NwASVsMVoiIiOQm0wq2hw8fRmJiIoYOHapWbmpqisOHDyM8PBxPnjyBm5sbevfujZkzZ0p1jI2NsX//fowZMwZ+fn6wsrJCYGCg2ros+sJghYiISG4yBSudOnWCKBY/0c3NDSdOnHju+e7u7vjpp5+0v7CWOGeFiIiIDBozK0RERDKTa87KfwWDFSIiIrnxrcsacRiIiIiIDBozK0RERDITRBFCCRNdtW2jomKwQkREJDcOA2nEYSAiIiIyaMysEBERyYxPA2nGYIWIiEhuHAbSiMNAREREZNCYWSEiIpIZh4E0Y7BCREQkNw4DacRghYiISGbMrGjGOStERERk0JhZISIikhuHgTRisEJERGQAKvIwjq44DEREREQGjZkVIiIiuYli4aZrGxUUgxUiIiKZ8WkgzTgMRERERAaNmRUiIiK58WkgjRisEBERyUxQFW66tlFRcRiIiIiIDFqFzqx4eHhg0qRJmDRpktxdIT0yMhIx4MMUtO+dAfuq+XiUaoLIHxywJdwRgAAAaNklA90GPUJd77+gcFBiTMd6uHPDQt6OEwHY+pUjzvxkh6R4M5iaq+DV9CmGffwAbnVypTp5OQJWz3XF8b32yM8V4Ov/GOPD7sO+agEAIOGGOX742gm/XLBC1p+V4FQ9D90G/YF3hv+hdq2jO+3xwzeOeHDHDFYKJZq2y8KIWQ+gcFC+1HumMuAwkEYVIrOyYcMG2NnZFSu/ePEiRo4c+fI7ROWqT1Aa3gp8hOUfV8OItg3w7acueG9sGnoM++cHtbmlCjcuWOHbBS4y9pSouGtR1ug++A+E77+NsK0JUBYAH/WtjZyn//w4XhlaDecibTFz1T18vjMe6akmmDfMQzoef80SdlUKEPL1b1h97Bb6TkzF+gWu2LOuilTnxgUrLJ5QA50/eITVx2/h41X3EBdjifCpbi/zdqmMip4G0nWrqCp0ZqVq1apyd4HKgVfTJ4j6P1tcOKIAAKTeN0W7nhmo3+SpVOfIDgcAgFP1PFn6SFSaBVvuqO1/GJ6I9729cfuaBbzffIInWUb4v+8dMH35b2jSKhsAMPnLRIxo64nYS5bw9H2KgL7pam24uOchNtoSZ362RY+hhUH7zUuWcHLLQ8+/sy3ONfLQbcAj/PCN40u4S9Ia11nRyCAyKwcPHkSrVq1gZ2eHypUr46233kJCQgIA4Pjx4xAEARkZGVL9mJgYCIKAe/fu4fjx4xgyZAgyMzMhCAIEQUBoaCiAwmGg8PBwAIAoiggNDUWNGjVgZmYGV1dXTJgwQWrTw8MDn3zyCQYNGgRra2u4u7tj7969ePjwIXr06AFra2v4+PggOjr6ZX0sVIqb0VZo0uoxqtUqTJvX8voLDd94gotHFTL3jEh7T7KMAQA2doVDM7evWaIg3wivtc6W6tSomwvHanmIvWRVejuPjaU2AMDL9ykePjDBhSM2EEXgz4eVcOqAHZr9L6uc7oSo/BhEsPLkyRNMnjwZ0dHROHLkCIyMjPDOO+9ApXr+1OYWLVogPDwcCoUCycnJSE5OxpQpU4rV27FjB5YsWYJVq1bh9u3b2L17N7y9vdXqLFmyBC1btsSVK1fQrVs3DBw4EIMGDcKAAQNw+fJl1K5dG4MGDYJYSvSam5uLrKwstY30b9vXjjixxw5rT97Cgd+uYvmhX7FrTRUc22Uvd9eItKJSASvnVEPDZtnwaJADAEhPqwQTUxWsbdXnldhVzUd6WsnJ8BsXLXFirz269n8klTV84wlCvv4NC0Z7oJt7Y3zQuBGsbJQYt+B++d0QvTAOA2lmEMNAvXv3Vttft24dqlatips3bz73XFNTU9ja2kIQBDg7O5daLzExEc7OzujQoQNMTExQo0YNvPHGG2p1unbtilGjRgEAZs+ejRUrVqBZs2Z47733AAAhISHw8/NDampqidcKCwvD3Llzn9tn0k2btzPwv14ZWBhUA7/FmaN2w78weu4DPEo1weHtDnJ3j6jMvv6oOn67ZYEvdt9+4Tbu3TLH3CG1MGByCnz9H0vlv/1qhhWzq6N/cGF5epoJ1s53xbIQN0z+Mkkf3Sd94gRbjQwis3L79m307dsXtWrVgkKhgIeHB4DCAENf3nvvPfz111+oVasWRowYgV27dqGgoECtjo+Pj/RnJycnAFDLvhSVpaWllXiNGTNmIDMzU9qSkvgDoTyMmJX8d3bFHvduWeDIDgfsXFMVH4wv+f8LkSH6+qNqOB+pwKIf41HVNV8qd3AsQH6eEbIzjdXqZzw0gYOj+s+s3341Q0if2ugy4A/0m5SqdmzbV05o2OwJ3hv7ELW8ctDU/zHGLbiP/9taGY9SDeLfqURlZhDBSvfu3ZGeno41a9bg/PnzOH/+PAAgLy8PRkaFXXx26CU/P7/EdjRxc3NDXFwcvvnmG1hYWGDs2LFo06aNWlsmJibSnwVBKLWstOEpMzMzKBQKtY30z8xcBfFf/wtUSkCoyDlQqjBEsTBQOXvQFou2x8O5hvok8Lo+T1HJRIUrp62lsqR4M6T9bgpP3ydS2b04c0x7tw46vpeOIdNTil0n5y+jYn8njIz/3udfFYPDYSDNZA+vHz16hLi4OKxZswatW7cGAJw+fVo6XvRET3JyMuztC+ckxMTEqLVhamoKpfL56wZYWFige/fu6N69O4KCgtCgQQNcv34dr7/+up7uhl6Gc5EKfDAhDWm/mxYOAzX6C71GPcShrf8MAdnYFaBqtXxUdioMRt1qF84H+DOtEv58aFJiu0Qvw9cfVcexXfYIXX8HFtYqaR6KlY0SZhYirBQqBPRNx+rQarCxU8LKRonlH1eHp+8TePoWPvF275Y5pr1XG039H6PXqIdSG0bGIuwqF/4sfLNjFsKnumHfxmw09X+M9FQTrJxTDfVfe4LKzgUld47kw6eBNJI9WLG3t0flypWxevVquLi4IDExEdOnT5eO16lTB25ubggNDcWnn36KX3/9FV988YVaGx4eHsjOzsaRI0fQuHFjWFpawtLSUq3Ohg0boFQq0bx5c1haWuK7776DhYUF3N3dX8p9kv58M7MaAqelYFzYfdhVLsCjVBP8tLkyIpY4SXXe7JSFKeH/DMN9tLJwSHHzF0747ovS5zYRlbf9GwvXQpnau65a+YdLEtHp/cJHkkeH/g4jQcT8ER7IzxUKh3DC/pkYe2q/HTIfmeDIDgfpMX2g8FH9TRcK5/p1ej8df2UbYe/6KlgztxqsbJVo0vIxhn2cXN63SKR3sgcrRkZG2Lp1KyZMmIBGjRqhfv36WLZsGfz9/QEUDsN8//33GDNmDHx8fNCsWTN88skn0qRXoPCJoNGjR+P999/Ho0ePMGfOHOnx5SJ2dnZYuHAhJk+eDKVSCW9vb+zbtw+VK1d+iXdL+vDXE2OsnFMNK+dUK7VO5A8OiPyBk23J8Pzfg5jn1jE1FzEu7HeMC/u9xOMDp6Rg4JTiQz//1mPYH2qLJZLh0scwTkUeBhLE0p7DJZ1lZWXB1tYW/uiBSgKHHqhiKssvX6L/qqzHKtjXu4PMzMxymYdY9HvCr/M8VDIx16mtgvwcRB2cXW59lZNBTLAlIiIiKo3sw0BERESvOg4DacbMChERkdxUon42LYSGhkqvqSnaGjRoIB3PyclBUFAQKleuDGtra/Tu3Rupqerr+SQmJqJbt26wtLSEo6Mjpk6dWmwNM31gZoWIiEhuMq1g27BhQxw+fFjar1Tpn7AgODgYBw4cwPbt22Fra4tx48ahV69eOHPmDABAqVSiW7ducHZ2xtmzZ5GcnIxBgwbBxMQECxYs0PFm1DFYISIiekVVqlSpxNfHZGZm4ttvv8WWLVvwv//9DwCwfv16eHp64ty5c3jzzTdx6NAh3Lx5E4cPH4aTkxOaNGmC+fPnIyQkBKGhoTA1NdVbPzkMREREJDMBeljB9u+2/v1C3dzc3FKve/v2bbi6uqJWrVro37+/9JqbS5cuIT8/Hx06dJDqNmjQADVq1EBUVBQAICoqCt7e3tKraAAgICAAWVlZuHHjhl4/HwYrREREcitawVbXDYWvl7G1tZW2sLCwEi/ZvHlzbNiwAQcPHsSKFStw9+5dtG7dGo8fP0ZKSgpMTU1hZ2endo6TkxNSUgrX+ElJSVELVIqOFx3TJw4DERERVSBJSUlq66yYmZmVWK9Lly7Sn318fNC8eXO4u7vjhx9+gIWFRbn3UxvMrBAREclMny8y/PcLdUsLVv7Nzs4O9erVQ3x8PJydnZGXl4eMjAy1OqmpqdIcF2dn52JPBxXtlzQPRhcMVoiIiOQm6mnTQXZ2NhISEuDi4gJfX1+YmJjgyJEj0vG4uDgkJibCz88PAODn54fr168jLS1NqhMZGQmFQgEvLy/dOvMvHAYiIiJ6BU2ZMgXdu3eHu7s7Hjx4gDlz5sDY2Bh9+/aFra0thg0bhsmTJ8PBwQEKhQLjx4+Hn58f3nzzTQBAp06d4OXlhYEDB2LRokVISUnBzJkzERQUVOZsTlkxWCEiIpKZIIoQdHxVn7bn379/H3379sWjR49QtWpVtGrVCufOnUPVqlUBAEuWLIGRkRF69+6N3NxcBAQE4JtvvpHONzY2xv79+zFmzBj4+fnBysoKgYGBmDdvnk73URIGK0RERHJT/b3p2oYWtm7dqvG4ubk5li9fjuXLl5dax93dHT/99JN2F34BnLNCREREBo2ZFSIiIpnJMQz0X8JghYiISG4yvRvov4LBChERkdyeWYFWpzYqKM5ZISIiIoPGzAoREZHMnl2BVpc2KioGK0RERHLjMJBGHAYiIiIig8bMChERkcwEVeGmaxsVFYMVIiIiuXEYSCMOAxEREZFBY2aFiIhIblwUTiMGK0RERDLjcvuacRiIiIiIDBozK0RERHLjBFuNGKwQERHJTQSg66PHFTdWYbBCREQkN85Z0YxzVoiIiMigMbNCREQkNxF6mLOil54YJAYrREREcuMEW404DEREREQGjZkVIiIiuakACHpoo4JisEJERCQzPg2kGYeBiIiIyKAxs0JERCQ3TrDViMEKERGR3BisaMRhICIiIjJozKwQERHJjZkVjRisEBERyY2PLmvEYIWIiEhmfHRZM85ZISIiIoPGzAoREZHcOGdFIwYrREREclOJgKBjsKGquMEKh4GIiIjIoDGzQkREJDcOA2nEYIWIiEh2eghWUHGDFQ4DERERvYLCwsLQrFkz2NjYwNHRET179kRcXJxaHX9/fwiCoLaNHj1arU5iYiK6desGS0tLODo6YurUqSgoKNBrX5lZISIikpsMw0AnTpxAUFAQmjVrhoKCAnz00Ufo1KkTbt68CSsrK6neiBEjMG/ePGnf0tJS+rNSqUS3bt3g7OyMs2fPIjk5GYMGDYKJiQkWLFig2/08g8EKERGR3FQidB7G0fJpoIMHD6rtb9iwAY6Ojrh06RLatGkjlVtaWsLZ2bnENg4dOoSbN2/i8OHDcHJyQpMmTTB//nyEhIQgNDQUpqam2t9HCTgMRERERMjMzAQAODg4qJVHRESgSpUqaNSoEWbMmIGnT59Kx6KiouDt7Q0nJyepLCAgAFlZWbhx44be+sbMChERkdxEVeGmaxsAsrKy1IrNzMxgZmam8VSVSoVJkyahZcuWaNSokVTer18/uLu7w9XVFdeuXUNISAji4uKwc+dOAEBKSopaoAJA2k9JSdHtfp7BYIWIiEhuepyz4ubmplY8Z84chIaGajw1KCgIv/zyC06fPq1WPnLkSOnP3t7ecHFxQfv27ZGQkIDatWvr1l8tMFghIiKSmx7nrCQlJUGhUEjFz8uqjBs3Dvv378fJkydRvXp1jXWbN28OAIiPj0ft2rXh7OyMCxcuqNVJTU0FgFLnubwIzlkhIiKqQBQKhdpWWrAiiiLGjRuHXbt24ejRo6hZs+Zz246JiQEAuLi4AAD8/Pxw/fp1pKWlSXUiIyOhUCjg5eWl+838jZkVIiIiucnw6HJQUBC2bNmCPXv2wMbGRppjYmtrCwsLCyQkJGDLli3o2rUrKleujGvXriE4OBht2rSBj48PAKBTp07w8vLCwIEDsWjRIqSkpGDmzJkICgp6bkZHG8ysEBERyU3EPwHLC2/aXXLFihXIzMyEv78/XFxcpG3btm0AAFNTUxw+fBidOnVCgwYN8OGHH6J3797Yt2+f1IaxsTH2798PY2Nj+Pn5YcCAARg0aJDauiz6wMwKERHRK0h8TibGzc0NJ06ceG477u7u+Omnn/TVrRIxWCEiIpIbX2SoEYMVIiIiualUAHRcZ0Wl4/kGjHNWiIiIyKAxs0JERCQ3DgNpxGCFiIhIbgxWNOIwEBERERk0ZlaIiIjkpsfl9isiBitEREQyE0UVRB3fuqzr+YaMwQoREZHcRFH3zAjnrBARERHJg5kVIiIiuYl6mLNSgTMrDFaIiIjkplIBgo5zTirwnBUOAxEREZFBY2aFiIhIbhwG0ojBChERkcxElQqijsNAFfnRZQ4DERERkUFjZoWIiEhuHAbSiMEKERGR3FQiIDBYKQ2HgYiIiMigMbNCREQkN1EEoOs6KxU3s8JghYiISGaiSoSo4zCQyGCFiIiIyo2ogu6ZFT66TERERCQLZlaIiIhkxmEgzRisEBERyY3DQBoxWClHRVFuAfJ1XuuHyFBlPa64PyCJsrILv9/lnbXQx++JAuTrpzMGiMFKOXr8+DEA4DR+krknROXHvp7cPSAqf48fP4atra3e2zU1NYWzszNOp+jn94SzszNMTU310pYhEcSKPMglM5VKhQcPHsDGxgaCIMjdnQovKysLbm5uSEpKgkKhkLs7RHrH7/jLJ4oiHj9+DFdXVxgZlc8zKTk5OcjLy9NLW6ampjA3N9dLW4aEmZVyZGRkhOrVq8vdjVeOQqHgD3Kq0Pgdf7nKI6PyLHNz8woZYOgTH10mIiIig8ZghYiIiAwagxWqMMzMzDBnzhyYmZnJ3RWicsHvOL2qOMGWiIiIDBozK0RERGTQGKwQERGRQWOwQkRERAaNwQrRc3h4eCA8PFzubhAB4PeRXk0MVoiIDNCGDRtgZ2dXrPzixYsYOXLky+8QkYy4gi395+Xl5VXId2EQlaRq1apyd4HopWNmhV46f39/TJgwAdOmTYODgwOcnZ0RGhoqHU9MTESPHj1gbW0NhUKBPn36IDU1VToeGhqKJk2aYO3atahZs6a0TLUgCFi1ahXeeustWFpawtPTE1FRUYiPj4e/vz+srKzQokULJCQkSG0lJCSgR48ecHJygrW1NZo1a4bDhw+/tM+CKq6DBw+iVatWsLOzQ+XKlfHWW29J373jx49DEARkZGRI9WNiYiAIAu7du4fjx49jyJAhyMzMhCAIEARB+jvy7DCQKIoIDQ1FjRo1YGZmBldXV0yYMEFq08PDA5988gkGDRoEa2truLu7Y+/evXj48KH0d8zHxwfR0dEv62MheiEMVkgWGzduhJWVFc6fP49FixZh3rx5iIyMhEqlQo8ePZCeno4TJ04gMjISd+7cwfvvv692fnx8PHbs2IGdO3ciJiZGKp8/fz4GDRqEmJgYNGjQAP369cOoUaMwY8YMREdHQxRFjBs3TqqfnZ2Nrl274siRI7hy5Qo6d+6M7t27IzEx8WV9FFRBPXnyBJMnT0Z0dDSOHDkCIyMjvPPOO1CpVM89t0WLFggPD4dCoUBycjKSk5MxZcqUYvV27NiBJUuWYNWqVbh9+zZ2794Nb29vtTpLlixBy5YtceXKFXTr1g0DBw7EoEGDMGDAAFy+fBm1a9fGoEGDwCW3yKCJRC9Z27ZtxVatWqmVNWvWTAwJCREPHTokGhsbi4mJidKxGzduiADECxcuiKIoinPmzBFNTEzEtLQ0tTYAiDNnzpT2o6KiRADit99+K5V9//33orm5ucb+NWzYUPzqq6+kfXd3d3HJkiVa3yfRsx4+fCgCEK9fvy4eO3ZMBCD++eef0vErV66IAMS7d++KoiiK69evF21tbYu18+z38YsvvhDr1asn5uXllXhNd3d3ccCAAdJ+cnKyCECcNWuWVFb09yQ5OVnneyQqL8yskCx8fHzU9l1cXJCWlobY2Fi4ubnBzc1NOubl5QU7OzvExsZKZe7u7iWO3T/brpOTEwCo/UvTyckJOTk5yMrKAlCYWZkyZQo8PT1hZ2cHa2trxMbGMrNCOrt9+zb69u2LWrVqQaFQwMPDAwD0+t1677338Ndff6FWrVoYMWIEdu3ahYKCArU6Zfk7AQBpaWl66xeRvjFYIVmYmJio7QuCUKb0eBErK6vntisIQqllRdeaMmUKdu3ahQULFuDUqVOIiYmBt7c38vLyytwXopJ0794d6enpWLNmDc6fP4/z588DKJwQbmRU+KNXfGboJT8/X+truLm5IS4uDt988w0sLCwwduxYtGnTRq0tbf9OEBkiBitkUDw9PZGUlISkpCSp7ObNm8jIyICXl5fer3fmzBkMHjwY77zzDry9veHs7Ix79+7p/Tr0ann06BHi4uIwc+ZMtG/fHp6envjzzz+l40VZweTkZKns2blXAGBqagqlUvnca1lYWKB79+5YtmwZjh8/jqioKFy/fl0/N0JkIPjoMhmUDh06wNvbG/3790d4eDgKCgowduxYtG3bFk2bNtX79erWrYudO3eie/fuEAQBs2bN4r8wSWf29vaoXLkyVq9eDRcXFyQmJmL69OnS8Tp16sDNzQ2hoaH49NNP8euvv+KLL75Qa8PDwwPZ2dk4cuQIGjduDEtLS1haWqrV2bBhA5RKJZo3bw5LS0t89913sLCwgLu7+0u5T6KXhZkVMiiCIGDPnj2wt7dHmzZt0KFDB9SqVQvbtm0rl+t9+eWXsLe3R4sWLdC9e3cEBATg9ddfL5dr0avDyMgIW7duxaVLl9CoUSMEBwdj8eLF0nETExN8//33uHXrFnx8fPDZZ5/hk08+UWujRYsWGD16NN5//31UrVoVixYtKnYdOzs7rFmzBi1btoSPjw8OHz6Mffv2oXLlyuV+j0QvkyCKfF6NiIiIDBczK0RERGTQGKwQERGRQWOwQkRERAaNwQoREREZNAYrREREZNAYrBAREZFBY7BCREREBo3BClEFN3jwYPTs2VPa9/f3x6RJk156P44fPw5BEJCRkVFqHUEQsHv37jK3GRoaiiZNmujUr3v37kEQhGLL3ROR4WCwQiSDwYMHQxAECIIAU1NT1KlTB/PmzSv2xtzysHPnTsyfP79MdcsSYBARlTe+G4hIJp07d8b69euRm5uLn376CUFBQTAxMcGMGTOK1c3Ly4Opqaleruvg4KCXdoiIXhZmVohkYmZmBmdnZ7i7u2PMmDHo0KED9u7dC+CfoZtPP/0Urq6uqF+/PgAgKSkJffr0gZ2dHRwcHNCjRw+1t0QrlUpMnjwZdnZ2qFy5MqZNm4Z/v1Hj38NAubm5CAkJgZubG8zMzFCnTh18++23uHfvHtq1aweg8MV8giBg8ODBAACVSoWwsDDUrFkTFhYWaNy4MX788Ue16/z000+oV68eLCws0K5duxd6m3VISAjq1asHS0tL1KpVC7NmzUJ+fn6xeqtWrYKbmxssLS3Rp08fZGZmqh1fu3YtPD09YW5ujgYNGuCbb77Rui9EJB8GK0QGwsLCAnl5edL+kSNHEBcXh8jISOzfvx/5+fkICAiAjY0NTp06hTNnzsDa2hqdO3eWzvviiy+wYcMGrFu3DqdPn0Z6ejp27dql8bqDBg3C999/j2XLliE2NharVq2CtbU13NzcsGPHDgBAXFwckpOTsXTpUgBAWFgYNm3ahJUrV+LGjRsIDg7GgAEDcOLECQCFQVWvXr3QvXt3xMTEYPjw4WpvHS4rGxsbbNiwATdv3sTSpUuxZs0aLFmyRK1OfHw8fvjhB+zbtw8HDx7ElStXMHbsWOl4REQEZs+ejU8//RSxsbFYsGABZs2ahY0bN2rdHyKSiUhEL11gYKDYo0cPURRFUaVSiZGRkaKZmZk4ZcoU6biTk5OYm5srnbN582axfv36okqlkspyc3NFCwsL8f/+7/9EURRFFxcXcdGiRdLx/Px8sXr16tK1RFEU27ZtK06cOFEURVGMi4sTAYiRkZEl9vPYsWMiAPHPP/+UynJyckRLS0vx7NmzanWHDRsm9u3bVxRFUZwxY4bo5eWldjwkJKRYW/8GQNy1a1epxxcvXiz6+vpK+3PmzBGNjY3F+/fvS2U///yzaGRkJCYnJ4uiKIq1a9cWt2zZotbO/PnzRT8/P1EURfHu3bsiAPHKlSulXpeI5MU5K0Qy2b9/P6ytrZGfnw+VSoV+/fohNDRUOu7t7a02T+Xq1auIj4+HjY2NWjs5OTlISEhAZmYmkpOT0bx5c+lYpUqV0LRp02JDQUViYmJgbGyMtm3blrnf8fHxePr0KTp27KhWnpeXh9deew0AEBsbq9YPAPDz8yvzNYps27YNy5YtQ0JCArKzs1FQUACFQqFWp0aNGqhWrZradVQqFeLi4mBjY4OEhAQMGzYMI0aMkOoUFBTA1tZW6/4QkTwYrBDJpF27dlixYgVMTU3h6uqKSpXU/zpaWVmp7WdnZ8PX1xcRERHF2qpateoL9cHCwkLrc7KzswEABw4cUAsSgMJ5OPoSFRWF/v37Y+7cuQgICICtrS22bt2KL774Quu+rlmzpljwZGxsrLe+ElH5YrBCJBMrKyvUqVOnzPVff/11bNu2DY6OjsWyC0VcXFxw/vx5tGnTBkBhBuHSpUt4/fXXS6zv7e0NlUqFEydOoEOHDsWOF2V2lEqlVObl5QUzMzMkJiaWmpHx9PSUJgsXOXfu3PNv8hlnz56Fu7s7Pv74Y6nst99+K1YvMTERDx48gKurq3QdIyMj1K9fH05OTnB1dcWdO3fQv39/ra5PRIaDE2yJ/iP69++PKlWqoEePHjh16hTu3r2L48ePY8KECbh//z4AYOLEiVi4cCF2796NW7duYezYsRrXSPHw8EBgYCCGDh2K3bt3S23+8MMPAAB3d3cIgoD9+/fj4cOHyM7Oho2NDaZMmYLg4GBs3LgRCQkJuHz5Mr766itp0uro0aNx+/ZtTJ06FXFxcdiyZQs2bNig1f3WrVsXiYmJ2Lp1KxISErBs2bISJwubm5sjMDAQV69exalTpzBhwgT06dMHzs7OAIC5c+ciLCwMy5Ytw6+//orr169j/fr1+PLLL7XqDxHJh8EK0X+EpaUlTp48iRo1aqBXr17w9PTEsGHDkJOTI2VaPvzwQwwcOBCBgYHw8/ODjY0N3nnnHY3trlixAu+++y7Gjh2LBg0aYMSIEXjy5AkAoFq1apg7dy6mT58OJycnjBs3DgAwf/58zJo1C2FhYfD09ETnzp1x4MAB1KxZE0DhPJIdO3Zg9+7daNy4MVauXIkFCxZodb9vv/02goODMW7cODRp0gRnz57FrFmzitWrU6cOevXqha5du6JTp07w8fFRezR5+PDhWLt2LdavXw9vb2+0bdsWGzZskPpKRIZPEEubeUdERERkAJhZISIiIoPGYIWIiIgMGoMVIiIiMmgMVoiIiMigMVghIiIig8ZghYiIiAwagxUiIiIyaAxWiIiIyKAxWCEiIiKDxmCFiIiIDBqDFSIiIjJoDFaIiIjIoP0/A4HQFcE4/gUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "for i, res in enumerate(results, 1):\n",
    "    pred = np.round(res.reshape(res.shape[0])).astype(bool)\n",
    "    confusion_matrix = metrics.confusion_matrix(test_data_label, pred)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['normal', 'autism'])\n",
    "    cm_display.plot()\n",
    "    plt.title(f\"Result: FFT ANN for model in fold {i}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: FFT ANN for model in fold 1\n",
      "Precision: 0.9250902527075813\n",
      "Recall: 0.9720246562351825\n",
      "Accuracy: 0.926948051948052\n",
      "F1-score: 0.9479768786127167\n",
      "\n",
      "\n",
      "Result: FFT ANN for model in fold 2\n",
      "Precision: 0.9285714285714286\n",
      "Recall: 0.9615931721194879\n",
      "Accuracy: 0.923051948051948\n",
      "F1-score: 0.9447938504542279\n",
      "\n",
      "\n",
      "Result: FFT ANN for model in fold 3\n",
      "Precision: 0.9314685314685315\n",
      "Recall: 0.9473684210526315\n",
      "Accuracy: 0.9162337662337663\n",
      "F1-score: 0.9393511988716502\n",
      "\n",
      "\n",
      "Result: FFT ANN for model in fold 4\n",
      "Precision: 0.9276887871853547\n",
      "Recall: 0.9611190137505927\n",
      "Accuracy: 0.922077922077922\n",
      "F1-score: 0.9441080577550071\n",
      "\n",
      "\n",
      "Result: FFT ANN for model in fold 5\n",
      "Precision: 0.9268629254829807\n",
      "Recall: 0.9554291133238502\n",
      "Accuracy: 0.9178571428571428\n",
      "F1-score: 0.9409292551949568\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, res in enumerate(results, 1):\n",
    "    pred = np.round(res.reshape(res.shape[0])).astype(bool)\n",
    "    test_data_label = test_data_label.astype(bool)  \n",
    "\n",
    "    print(f\"Result: FFT ANN for model in fold {i}\")\n",
    "\n",
    "    TP = np.sum((test_data_label == True) & (pred == True))\n",
    "    FP = np.sum((test_data_label == False) & (pred == True))\n",
    "    TN = np.sum((test_data_label == False) & (pred == False))\n",
    "    FN = np.sum((test_data_label == True) & (pred == False))  \n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1-score: {f1_score}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
