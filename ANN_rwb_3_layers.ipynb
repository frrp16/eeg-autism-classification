{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing, model_selection\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(directory, lag, excluded_name=[]):\n",
    "    data = pd.DataFrame(columns=['data', 'label'])\n",
    "    for foldername in os.listdir(directory):        \n",
    "        folder = os.path.join(directory, foldername)\n",
    "        # print(folder)\n",
    "        if str(lag) in folder:\n",
    "            # print(os.listdir(folder))\n",
    "            for name in os.listdir(folder):\n",
    "                if name in excluded_name:\n",
    "                    # print(name)\n",
    "                    continue\n",
    "                filename = os.path.join(folder, name)\n",
    "                # print(filename)\n",
    "                for files in os.listdir(filename):\n",
    "                    rel_path = os.path.join(filename, files)\n",
    "                    # print(rel_path)\n",
    "                    temp_label = folder\n",
    "                    if \"autism\" in temp_label:\n",
    "                        label = 'autism'\n",
    "                    else:\n",
    "                        label = 'normal'\n",
    "\n",
    "                    temp_data = pd.DataFrame(columns=['data', 'label'], index=[0])\n",
    "\n",
    "                    rwb = np.load(rel_path)\n",
    "                    rwb.astype(np.float64).reshape(-1,1)\n",
    "                                    \n",
    "                    temp_data.loc[0, \"data\"] = rwb\n",
    "                    temp_data['label'] = label\n",
    "                    data = pd.concat([data, temp_data], ignore_index=True)\n",
    "    label_map = {\"autism\": 1, \"normal\": 0}\n",
    "    data['label_map'] = data['label'].map(label_map)      \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_value(data):\n",
    "    series_list = np.vstack(data[\"data\"].values)\n",
    "    labels_list = data[\"label_map\"].values    \n",
    "    missing_indices = np.where(np.isnan(series_list).any(axis=1))[0]\n",
    "\n",
    "    clean_data = data.drop(index=data.index[missing_indices])\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(data, des_path):\n",
    "    if not os.path.exists(des_path):\n",
    "        os.makedirs(des_path)\n",
    "    data.save(des_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(data, train_split: float):\n",
    "    train_x, test_x, train_y, test_y = model_selection.train_test_split(\n",
    "        data['data'],\n",
    "        data[['label', 'label_map']],\n",
    "        train_size=train_split,\n",
    "        stratify=data['label_map']\n",
    "    )\n",
    "\n",
    "    train_df = pd.DataFrame(columns=['data', 'label', 'label_map'])\n",
    "    test_df = pd.DataFrame(columns=['data', 'label', 'label_map'])\n",
    "\n",
    "    train_df[\"data\"] = train_x\n",
    "    train_df[['label', 'label_map']] = train_y\n",
    "\n",
    "    test_df[\"data\"] = test_x\n",
    "    test_df[['label', 'label_map']] = test_y\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data):\n",
    "    # loading extracted feature & label\n",
    "    # x = get_dataset(path, lag, excluded_name)\n",
    "\n",
    "    # scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    series_list = np.vstack(data[\"data\"].values)\n",
    "\n",
    "    # series_list = series_list.reshape(-1, 366, 1)\n",
    "\n",
    "    labels_list = data[\"label_map\"].values\n",
    "        \n",
    "    # y = keras.utils.to_categorical(y[0])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((series_list,labels_list))\n",
    "    dataset = dataset.shuffle(len(labels_list))\n",
    "\n",
    "    # train_size = int(train_split * len(labels_list))  \n",
    "    # test_size = len(labels_list) - train_size  \n",
    "\n",
    "    # train_dataset = dataset.take(train_size)\n",
    "    # test_dataset = dataset.skip(train_size)\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"datasets/features/rwb/segment_1 seconds\"\n",
    "\n",
    "train_dir = \"datasets/tf_batch/rwb/segment_1 seconds/train\"\n",
    "test_dir = \"datasets/tf_batch/rwb/segment_1 seconds/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15434, 3)\n",
      "(14618, 3)\n",
      "train:  (11694, 3)\n",
      "test:  (2924, 3)\n"
     ]
    }
   ],
   "source": [
    "excluded = [\"zyad\"]\n",
    "train_split = 0.8\n",
    "LAG = [256]\n",
    "\n",
    "for lag in LAG:\n",
    "    data = get_dataset(data_dir, lag, excluded)\n",
    "    print(data.shape)\n",
    "    data = remove_missing_value(data)\n",
    "    print(data.shape)\n",
    "    train_data, test_data = get_train_test(data, train_split)\n",
    "    print(\"train: \", train_data.shape)\n",
    "    print(\"test: \", test_data.shape)\n",
    "    train_batch = get_batch(train_data)\n",
    "    test_batch = get_batch(test_data)\n",
    "    tf.data.Dataset.save(train_batch, f\"{train_dir}_{lag}\")\n",
    "    tf.data.Dataset.save(test_batch, f\"{test_dir}_{lag}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "signal = np.load(\"datasets/features/rwb/segment_1 seconds/normal_256/amer/Amer_segment_1.csv_bispectrum.npy\")\n",
    "\n",
    "# Extract the signal values from the DataFrame\n",
    "\n",
    "# Create a time axis for the signal\n",
    "t = range(len(signal))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# Plot the signal\n",
    "ax.plot(t, signal)\n",
    "ax.set_xlabel('Time (samples)')\n",
    "ax.set_ylabel('Signal amplitude')\n",
    "ax.set_title('Signal plot')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Input(shape=(96,)))\n",
    "    model.add(layers.Reshape((96, 1)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(256, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myCallbacks(log_dir):\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='acc',\n",
    "    patience=50,\n",
    "    mode='max')\n",
    "    model_path = os.path.join(log_dir,'best_model.h5')\n",
    "    mc = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "    return [tensorboard_callback, early_stopping, mc]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [256]\n",
    "# folds = ['train_1', 'test_1', 'epoch_1', 'train_2', 'test_2', 'epoch_2']\n",
    "time_measured = ['Wall_Time_1', 'CPU_Time_1', 'Wall_Time_2', 'CPU_Time_2']\n",
    "epochs = 2000\n",
    "log_dirs = [f\"train_logs/logs7/RWB_ANN_512_256_512_RMSprop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 96, 1)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               49664     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 313,089\n",
      "Trainable params: 313,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 1.5960 - acc: 0.5973\n",
      "Epoch 1: val_acc improved from -inf to 0.66781, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 4s 10ms/step - loss: 1.5865 - acc: 0.5973 - val_loss: 0.6476 - val_acc: 0.6678\n",
      "Epoch 2/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.6989 - acc: 0.6365\n",
      "Epoch 2: val_acc improved from 0.66781 to 0.71056, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.6985 - acc: 0.6363 - val_loss: 0.5830 - val_acc: 0.7106\n",
      "Epoch 3/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.6174 - acc: 0.6876\n",
      "Epoch 3: val_acc improved from 0.71056 to 0.72424, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.6181 - acc: 0.6863 - val_loss: 0.5663 - val_acc: 0.7242\n",
      "Epoch 4/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5905 - acc: 0.7055\n",
      "Epoch 4: val_acc improved from 0.72424 to 0.73065, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5904 - acc: 0.7056 - val_loss: 0.5630 - val_acc: 0.7307\n",
      "Epoch 5/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5834 - acc: 0.7130\n",
      "Epoch 5: val_acc improved from 0.73065 to 0.73792, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.5834 - acc: 0.7130 - val_loss: 0.5588 - val_acc: 0.7379\n",
      "Epoch 6/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5713 - acc: 0.7230\n",
      "Epoch 6: val_acc improved from 0.73792 to 0.74434, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5714 - acc: 0.7227 - val_loss: 0.5623 - val_acc: 0.7443\n",
      "Epoch 7/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.7222\n",
      "Epoch 7: val_acc improved from 0.74434 to 0.74476, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5648 - acc: 0.7218 - val_loss: 0.5691 - val_acc: 0.7448\n",
      "Epoch 8/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5600 - acc: 0.7224\n",
      "Epoch 8: val_acc improved from 0.74476 to 0.74904, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5602 - acc: 0.7224 - val_loss: 0.5341 - val_acc: 0.7490\n",
      "Epoch 9/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5483 - acc: 0.7373\n",
      "Epoch 9: val_acc did not improve from 0.74904\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5483 - acc: 0.7371 - val_loss: 0.5403 - val_acc: 0.7465\n",
      "Epoch 10/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5451 - acc: 0.7380\n",
      "Epoch 10: val_acc improved from 0.74904 to 0.75631, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5446 - acc: 0.7375 - val_loss: 0.5265 - val_acc: 0.7563\n",
      "Epoch 11/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5480 - acc: 0.7340\n",
      "Epoch 11: val_acc did not improve from 0.75631\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.5480 - acc: 0.7337 - val_loss: 0.5641 - val_acc: 0.7456\n",
      "Epoch 12/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5560 - acc: 0.7384\n",
      "Epoch 12: val_acc did not improve from 0.75631\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5557 - acc: 0.7382 - val_loss: 0.5528 - val_acc: 0.7516\n",
      "Epoch 13/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5411 - acc: 0.7409\n",
      "Epoch 13: val_acc improved from 0.75631 to 0.75759, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5409 - acc: 0.7409 - val_loss: 0.5347 - val_acc: 0.7576\n",
      "Epoch 14/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5364 - acc: 0.7418\n",
      "Epoch 14: val_acc improved from 0.75759 to 0.75930, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5360 - acc: 0.7414 - val_loss: 0.5309 - val_acc: 0.7593\n",
      "Epoch 15/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5372 - acc: 0.7453\n",
      "Epoch 15: val_acc did not improve from 0.75930\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5366 - acc: 0.7456 - val_loss: 0.5285 - val_acc: 0.7572\n",
      "Epoch 16/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5347 - acc: 0.7411\n",
      "Epoch 16: val_acc did not improve from 0.75930\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5345 - acc: 0.7412 - val_loss: 0.5085 - val_acc: 0.7452\n",
      "Epoch 17/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5303 - acc: 0.7484\n",
      "Epoch 17: val_acc did not improve from 0.75930\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5301 - acc: 0.7479 - val_loss: 0.5322 - val_acc: 0.7559\n",
      "Epoch 18/2000\n",
      "286/293 [============================>.] - ETA: 0s - loss: 0.5284 - acc: 0.7489\n",
      "Epoch 18: val_acc did not improve from 0.75930\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5285 - acc: 0.7480 - val_loss: 0.5137 - val_acc: 0.7559\n",
      "Epoch 19/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5339 - acc: 0.7485\n",
      "Epoch 19: val_acc improved from 0.75930 to 0.76699, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5334 - acc: 0.7486 - val_loss: 0.5135 - val_acc: 0.7670\n",
      "Epoch 20/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5272 - acc: 0.7554\n",
      "Epoch 20: val_acc did not improve from 0.76699\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5264 - acc: 0.7552 - val_loss: 0.5034 - val_acc: 0.7589\n",
      "Epoch 21/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5298 - acc: 0.7501\n",
      "Epoch 21: val_acc did not improve from 0.76699\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5290 - acc: 0.7494 - val_loss: 0.5155 - val_acc: 0.7567\n",
      "Epoch 22/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5222 - acc: 0.7536\n",
      "Epoch 22: val_acc did not improve from 0.76699\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5217 - acc: 0.7531 - val_loss: 0.5320 - val_acc: 0.7490\n",
      "Epoch 23/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5248 - acc: 0.7506\n",
      "Epoch 23: val_acc did not improve from 0.76699\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5242 - acc: 0.7507 - val_loss: 0.5309 - val_acc: 0.7610\n",
      "Epoch 24/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5573 - acc: 0.7488\n",
      "Epoch 24: val_acc did not improve from 0.76699\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5570 - acc: 0.7489 - val_loss: 0.5073 - val_acc: 0.7593\n",
      "Epoch 25/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5273 - acc: 0.7513\n",
      "Epoch 25: val_acc did not improve from 0.76699\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5269 - acc: 0.7513 - val_loss: 0.5100 - val_acc: 0.7542\n",
      "Epoch 26/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5319 - acc: 0.7565\n",
      "Epoch 26: val_acc improved from 0.76699 to 0.77341, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5309 - acc: 0.7569 - val_loss: 0.5157 - val_acc: 0.7734\n",
      "Epoch 27/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5214 - acc: 0.7568\n",
      "Epoch 27: val_acc improved from 0.77341 to 0.77640, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5217 - acc: 0.7566 - val_loss: 0.5505 - val_acc: 0.7764\n",
      "Epoch 28/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5430 - acc: 0.7574\n",
      "Epoch 28: val_acc did not improve from 0.77640\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5421 - acc: 0.7569 - val_loss: 0.5197 - val_acc: 0.7708\n",
      "Epoch 29/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5235 - acc: 0.7595\n",
      "Epoch 29: val_acc did not improve from 0.77640\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5230 - acc: 0.7596 - val_loss: 0.5218 - val_acc: 0.7644\n",
      "Epoch 30/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5388 - acc: 0.7570\n",
      "Epoch 30: val_acc did not improve from 0.77640\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5380 - acc: 0.7571 - val_loss: 0.5291 - val_acc: 0.7764\n",
      "Epoch 31/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5264 - acc: 0.7611\n",
      "Epoch 31: val_acc did not improve from 0.77640\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5253 - acc: 0.7614 - val_loss: 0.5322 - val_acc: 0.7687\n",
      "Epoch 32/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5507 - acc: 0.7577\n",
      "Epoch 32: val_acc did not improve from 0.77640\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5501 - acc: 0.7577 - val_loss: 0.5064 - val_acc: 0.7636\n",
      "Epoch 33/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5349 - acc: 0.7581\n",
      "Epoch 33: val_acc did not improve from 0.77640\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5349 - acc: 0.7581 - val_loss: 0.5274 - val_acc: 0.7597\n",
      "Epoch 34/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5355 - acc: 0.7586\n",
      "Epoch 34: val_acc did not improve from 0.77640\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5350 - acc: 0.7582 - val_loss: 0.5160 - val_acc: 0.7567\n",
      "Epoch 35/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5186 - acc: 0.7641\n",
      "Epoch 35: val_acc did not improve from 0.77640\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5184 - acc: 0.7642 - val_loss: 0.5094 - val_acc: 0.7760\n",
      "Epoch 36/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5224 - acc: 0.7702\n",
      "Epoch 36: val_acc did not improve from 0.77640\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5215 - acc: 0.7704 - val_loss: 0.5418 - val_acc: 0.7738\n",
      "Epoch 37/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5202 - acc: 0.7679\n",
      "Epoch 37: val_acc did not improve from 0.77640\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5195 - acc: 0.7673 - val_loss: 0.5231 - val_acc: 0.7670\n",
      "Epoch 38/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5248 - acc: 0.7624\n",
      "Epoch 38: val_acc improved from 0.77640 to 0.77811, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5257 - acc: 0.7619 - val_loss: 0.5347 - val_acc: 0.7781\n",
      "Epoch 39/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5224 - acc: 0.7651\n",
      "Epoch 39: val_acc did not improve from 0.77811\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5216 - acc: 0.7647 - val_loss: 0.5085 - val_acc: 0.7614\n",
      "Epoch 40/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5190 - acc: 0.7652\n",
      "Epoch 40: val_acc improved from 0.77811 to 0.77939, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5173 - acc: 0.7654 - val_loss: 0.5474 - val_acc: 0.7794\n",
      "Epoch 41/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5219 - acc: 0.7631\n",
      "Epoch 41: val_acc improved from 0.77939 to 0.78025, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5219 - acc: 0.7631 - val_loss: 0.5287 - val_acc: 0.7802\n",
      "Epoch 42/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5285 - acc: 0.7676\n",
      "Epoch 42: val_acc improved from 0.78025 to 0.78452, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5285 - acc: 0.7676 - val_loss: 0.5308 - val_acc: 0.7845\n",
      "Epoch 43/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5246 - acc: 0.7667\n",
      "Epoch 43: val_acc did not improve from 0.78452\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5237 - acc: 0.7662 - val_loss: 0.5329 - val_acc: 0.7687\n",
      "Epoch 44/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5310 - acc: 0.7673\n",
      "Epoch 44: val_acc did not improve from 0.78452\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5310 - acc: 0.7673 - val_loss: 0.5197 - val_acc: 0.7734\n",
      "Epoch 45/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5256 - acc: 0.7700\n",
      "Epoch 45: val_acc did not improve from 0.78452\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5247 - acc: 0.7701 - val_loss: 0.5315 - val_acc: 0.7755\n",
      "Epoch 46/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5196 - acc: 0.7726\n",
      "Epoch 46: val_acc did not improve from 0.78452\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5188 - acc: 0.7728 - val_loss: 0.5047 - val_acc: 0.7696\n",
      "Epoch 47/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5203 - acc: 0.7712\n",
      "Epoch 47: val_acc did not improve from 0.78452\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5198 - acc: 0.7714 - val_loss: 0.5259 - val_acc: 0.7687\n",
      "Epoch 48/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5307 - acc: 0.7688\n",
      "Epoch 48: val_acc did not improve from 0.78452\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5298 - acc: 0.7691 - val_loss: 0.4974 - val_acc: 0.7657\n",
      "Epoch 49/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5444 - acc: 0.7704\n",
      "Epoch 49: val_acc improved from 0.78452 to 0.78581, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5433 - acc: 0.7709 - val_loss: 0.5038 - val_acc: 0.7858\n",
      "Epoch 50/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5258 - acc: 0.7674\n",
      "Epoch 50: val_acc did not improve from 0.78581\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5248 - acc: 0.7677 - val_loss: 0.5013 - val_acc: 0.7781\n",
      "Epoch 51/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5229 - acc: 0.7764\n",
      "Epoch 51: val_acc did not improve from 0.78581\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5220 - acc: 0.7768 - val_loss: 0.4999 - val_acc: 0.7721\n",
      "Epoch 52/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5121 - acc: 0.7791\n",
      "Epoch 52: val_acc did not improve from 0.78581\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5117 - acc: 0.7792 - val_loss: 0.5155 - val_acc: 0.7828\n",
      "Epoch 53/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5166 - acc: 0.7727\n",
      "Epoch 53: val_acc did not improve from 0.78581\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5163 - acc: 0.7728 - val_loss: 0.5022 - val_acc: 0.7815\n",
      "Epoch 54/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5120 - acc: 0.7772\n",
      "Epoch 54: val_acc did not improve from 0.78581\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5113 - acc: 0.7777 - val_loss: 0.5288 - val_acc: 0.7781\n",
      "Epoch 55/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5099 - acc: 0.7757\n",
      "Epoch 55: val_acc improved from 0.78581 to 0.78709, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5088 - acc: 0.7755 - val_loss: 0.5326 - val_acc: 0.7871\n",
      "Epoch 56/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5218 - acc: 0.7754\n",
      "Epoch 56: val_acc did not improve from 0.78709\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5215 - acc: 0.7754 - val_loss: 0.5252 - val_acc: 0.7726\n",
      "Epoch 57/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5111 - acc: 0.7784\n",
      "Epoch 57: val_acc improved from 0.78709 to 0.78880, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5103 - acc: 0.7785 - val_loss: 0.5051 - val_acc: 0.7888\n",
      "Epoch 58/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5170 - acc: 0.7786\n",
      "Epoch 58: val_acc did not improve from 0.78880\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5167 - acc: 0.7786 - val_loss: 0.5072 - val_acc: 0.7832\n",
      "Epoch 59/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5196 - acc: 0.7756\n",
      "Epoch 59: val_acc did not improve from 0.78880\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5176 - acc: 0.7757 - val_loss: 0.5040 - val_acc: 0.7734\n",
      "Epoch 60/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5045 - acc: 0.7817\n",
      "Epoch 60: val_acc did not improve from 0.78880\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5043 - acc: 0.7817 - val_loss: 0.4997 - val_acc: 0.7700\n",
      "Epoch 61/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4953 - acc: 0.7808\n",
      "Epoch 61: val_acc improved from 0.78880 to 0.79307, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 9s 32ms/step - loss: 0.4947 - acc: 0.7809 - val_loss: 0.4925 - val_acc: 0.7931\n",
      "Epoch 62/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5193 - acc: 0.7830\n",
      "Epoch 62: val_acc improved from 0.79307 to 0.79607, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5193 - acc: 0.7830 - val_loss: 0.5063 - val_acc: 0.7961\n",
      "Epoch 63/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5049 - acc: 0.7841\n",
      "Epoch 63: val_acc did not improve from 0.79607\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5046 - acc: 0.7842 - val_loss: 0.5167 - val_acc: 0.7794\n",
      "Epoch 64/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4938 - acc: 0.7834\n",
      "Epoch 64: val_acc did not improve from 0.79607\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4938 - acc: 0.7834 - val_loss: 0.4892 - val_acc: 0.7884\n",
      "Epoch 65/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4973 - acc: 0.7867\n",
      "Epoch 65: val_acc did not improve from 0.79607\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4973 - acc: 0.7867 - val_loss: 0.5059 - val_acc: 0.7935\n",
      "Epoch 66/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5072 - acc: 0.7829\n",
      "Epoch 66: val_acc did not improve from 0.79607\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5061 - acc: 0.7831 - val_loss: 0.4873 - val_acc: 0.7888\n",
      "Epoch 67/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5013 - acc: 0.7869\n",
      "Epoch 67: val_acc did not improve from 0.79607\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5036 - acc: 0.7866 - val_loss: 0.4962 - val_acc: 0.7862\n",
      "Epoch 68/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5087 - acc: 0.7865\n",
      "Epoch 68: val_acc did not improve from 0.79607\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5076 - acc: 0.7864 - val_loss: 0.4853 - val_acc: 0.7871\n",
      "Epoch 69/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4876 - acc: 0.7887\n",
      "Epoch 69: val_acc did not improve from 0.79607\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4878 - acc: 0.7890 - val_loss: 0.4805 - val_acc: 0.7901\n",
      "Epoch 70/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5061 - acc: 0.7849\n",
      "Epoch 70: val_acc did not improve from 0.79607\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5061 - acc: 0.7849 - val_loss: 0.4891 - val_acc: 0.7867\n",
      "Epoch 71/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5114 - acc: 0.7824\n",
      "Epoch 71: val_acc did not improve from 0.79607\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5103 - acc: 0.7826 - val_loss: 0.5105 - val_acc: 0.7931\n",
      "Epoch 72/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5012 - acc: 0.7859\n",
      "Epoch 72: val_acc did not improve from 0.79607\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5007 - acc: 0.7857 - val_loss: 0.4983 - val_acc: 0.7717\n",
      "Epoch 73/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4978 - acc: 0.7922\n",
      "Epoch 73: val_acc did not improve from 0.79607\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4972 - acc: 0.7923 - val_loss: 0.4854 - val_acc: 0.7649\n",
      "Epoch 74/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4966 - acc: 0.7875\n",
      "Epoch 74: val_acc improved from 0.79607 to 0.79820, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4953 - acc: 0.7877 - val_loss: 0.4856 - val_acc: 0.7982\n",
      "Epoch 75/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4976 - acc: 0.7929\n",
      "Epoch 75: val_acc did not improve from 0.79820\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4965 - acc: 0.7925 - val_loss: 0.4927 - val_acc: 0.7939\n",
      "Epoch 76/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5104 - acc: 0.7861\n",
      "Epoch 76: val_acc did not improve from 0.79820\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5101 - acc: 0.7863 - val_loss: 0.4695 - val_acc: 0.7973\n",
      "Epoch 77/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5058 - acc: 0.7927\n",
      "Epoch 77: val_acc did not improve from 0.79820\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5057 - acc: 0.7927 - val_loss: 0.4961 - val_acc: 0.7781\n",
      "Epoch 78/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5087 - acc: 0.7947\n",
      "Epoch 78: val_acc did not improve from 0.79820\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5079 - acc: 0.7943 - val_loss: 0.4750 - val_acc: 0.7841\n",
      "Epoch 79/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5022 - acc: 0.7911\n",
      "Epoch 79: val_acc did not improve from 0.79820\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5019 - acc: 0.7912 - val_loss: 0.4833 - val_acc: 0.7811\n",
      "Epoch 80/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5233 - acc: 0.7856\n",
      "Epoch 80: val_acc did not improve from 0.79820\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5233 - acc: 0.7856 - val_loss: 0.4736 - val_acc: 0.7747\n",
      "Epoch 81/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5004 - acc: 0.7955\n",
      "Epoch 81: val_acc did not improve from 0.79820\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5007 - acc: 0.7955 - val_loss: 0.4933 - val_acc: 0.7815\n",
      "Epoch 82/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4840 - acc: 0.7918\n",
      "Epoch 82: val_acc did not improve from 0.79820\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4837 - acc: 0.7920 - val_loss: 0.5039 - val_acc: 0.7858\n",
      "Epoch 83/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4901 - acc: 0.7939\n",
      "Epoch 83: val_acc did not improve from 0.79820\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4881 - acc: 0.7938 - val_loss: 0.4792 - val_acc: 0.7935\n",
      "Epoch 84/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4862 - acc: 0.7912\n",
      "Epoch 84: val_acc did not improve from 0.79820\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4850 - acc: 0.7911 - val_loss: 0.4886 - val_acc: 0.7862\n",
      "Epoch 85/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4849 - acc: 0.7956\n",
      "Epoch 85: val_acc did not improve from 0.79820\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4841 - acc: 0.7952 - val_loss: 0.4904 - val_acc: 0.7790\n",
      "Epoch 86/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4980 - acc: 0.7937\n",
      "Epoch 86: val_acc did not improve from 0.79820\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4977 - acc: 0.7935 - val_loss: 0.4735 - val_acc: 0.7700\n",
      "Epoch 87/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4863 - acc: 0.7954\n",
      "Epoch 87: val_acc improved from 0.79820 to 0.81445, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4860 - acc: 0.7955 - val_loss: 0.4828 - val_acc: 0.8145\n",
      "Epoch 88/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4877 - acc: 0.7951\n",
      "Epoch 88: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4877 - acc: 0.7951 - val_loss: 0.4966 - val_acc: 0.7897\n",
      "Epoch 89/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4846 - acc: 0.7961\n",
      "Epoch 89: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4837 - acc: 0.7965 - val_loss: 0.4863 - val_acc: 0.7901\n",
      "Epoch 90/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4986 - acc: 0.7892\n",
      "Epoch 90: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4972 - acc: 0.7892 - val_loss: 0.4858 - val_acc: 0.7931\n",
      "Epoch 91/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4929 - acc: 0.8001\n",
      "Epoch 91: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4928 - acc: 0.8000 - val_loss: 0.4790 - val_acc: 0.7850\n",
      "Epoch 92/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5052 - acc: 0.7977\n",
      "Epoch 92: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5048 - acc: 0.7978 - val_loss: 0.4637 - val_acc: 0.7948\n",
      "Epoch 93/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4854 - acc: 0.7967\n",
      "Epoch 93: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4855 - acc: 0.7966 - val_loss: 0.4665 - val_acc: 0.8055\n",
      "Epoch 94/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4743 - acc: 0.7986\n",
      "Epoch 94: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4722 - acc: 0.7993 - val_loss: 0.4824 - val_acc: 0.8102\n",
      "Epoch 95/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5027 - acc: 0.7981\n",
      "Epoch 95: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4997 - acc: 0.7986 - val_loss: 0.4828 - val_acc: 0.7991\n",
      "Epoch 96/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4890 - acc: 0.7984\n",
      "Epoch 96: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4881 - acc: 0.7988 - val_loss: 0.4779 - val_acc: 0.7999\n",
      "Epoch 97/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5084 - acc: 0.7960\n",
      "Epoch 97: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5069 - acc: 0.7957 - val_loss: 0.4708 - val_acc: 0.7879\n",
      "Epoch 98/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5085 - acc: 0.7973\n",
      "Epoch 98: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5075 - acc: 0.7973 - val_loss: 0.4718 - val_acc: 0.8055\n",
      "Epoch 99/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4721 - acc: 0.8016\n",
      "Epoch 99: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4706 - acc: 0.8016 - val_loss: 0.4736 - val_acc: 0.7914\n",
      "Epoch 100/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4962 - acc: 0.7966\n",
      "Epoch 100: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4956 - acc: 0.7965 - val_loss: 0.4587 - val_acc: 0.7909\n",
      "Epoch 101/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5028 - acc: 0.7972\n",
      "Epoch 101: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5025 - acc: 0.7973 - val_loss: 0.4618 - val_acc: 0.8093\n",
      "Epoch 102/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4820 - acc: 0.7968\n",
      "Epoch 102: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4801 - acc: 0.7968 - val_loss: 0.4732 - val_acc: 0.7909\n",
      "Epoch 103/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4755 - acc: 0.7966\n",
      "Epoch 103: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4743 - acc: 0.7968 - val_loss: 0.4824 - val_acc: 0.7935\n",
      "Epoch 104/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4802 - acc: 0.7981\n",
      "Epoch 104: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4795 - acc: 0.7980 - val_loss: 0.4666 - val_acc: 0.7935\n",
      "Epoch 105/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4817 - acc: 0.7987\n",
      "Epoch 105: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4815 - acc: 0.7983 - val_loss: 0.4856 - val_acc: 0.7973\n",
      "Epoch 106/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4895 - acc: 0.8010\n",
      "Epoch 106: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4912 - acc: 0.8011 - val_loss: 0.4635 - val_acc: 0.7995\n",
      "Epoch 107/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4813 - acc: 0.7946\n",
      "Epoch 107: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4796 - acc: 0.7948 - val_loss: 0.4668 - val_acc: 0.7914\n",
      "Epoch 108/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4889 - acc: 0.8005\n",
      "Epoch 108: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4881 - acc: 0.8002 - val_loss: 0.4596 - val_acc: 0.7837\n",
      "Epoch 109/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4873 - acc: 0.7957\n",
      "Epoch 109: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4855 - acc: 0.7958 - val_loss: 0.4607 - val_acc: 0.7879\n",
      "Epoch 110/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4780 - acc: 0.7989\n",
      "Epoch 110: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4766 - acc: 0.7990 - val_loss: 0.4599 - val_acc: 0.7884\n",
      "Epoch 111/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4631 - acc: 0.8016\n",
      "Epoch 111: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4631 - acc: 0.8016 - val_loss: 0.4516 - val_acc: 0.7926\n",
      "Epoch 112/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5059 - acc: 0.7973\n",
      "Epoch 112: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5056 - acc: 0.7974 - val_loss: 0.4829 - val_acc: 0.7773\n",
      "Epoch 113/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4890 - acc: 0.8019\n",
      "Epoch 113: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4881 - acc: 0.8025 - val_loss: 0.4520 - val_acc: 0.8059\n",
      "Epoch 114/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4748 - acc: 0.8011\n",
      "Epoch 114: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4743 - acc: 0.8010 - val_loss: 0.4547 - val_acc: 0.7820\n",
      "Epoch 115/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4856 - acc: 0.7990\n",
      "Epoch 115: val_acc improved from 0.81445 to 0.81573, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4847 - acc: 0.7993 - val_loss: 0.4633 - val_acc: 0.8157\n",
      "Epoch 116/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4900 - acc: 0.8010\n",
      "Epoch 116: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4880 - acc: 0.8010 - val_loss: 0.4545 - val_acc: 0.7991\n",
      "Epoch 117/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4755 - acc: 0.7984\n",
      "Epoch 117: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4793 - acc: 0.7985 - val_loss: 0.4620 - val_acc: 0.7884\n",
      "Epoch 118/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4979 - acc: 0.7944\n",
      "Epoch 118: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4976 - acc: 0.7945 - val_loss: 0.4495 - val_acc: 0.7935\n",
      "Epoch 119/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4604 - acc: 0.8000\n",
      "Epoch 119: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4604 - acc: 0.8000 - val_loss: 0.4627 - val_acc: 0.8097\n",
      "Epoch 120/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4699 - acc: 0.8053\n",
      "Epoch 120: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4699 - acc: 0.8053 - val_loss: 0.4831 - val_acc: 0.8076\n",
      "Epoch 121/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4764 - acc: 0.8001\n",
      "Epoch 121: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4764 - acc: 0.8001 - val_loss: 0.4470 - val_acc: 0.8025\n",
      "Epoch 122/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4804 - acc: 0.8041\n",
      "Epoch 122: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4787 - acc: 0.8044 - val_loss: 0.4512 - val_acc: 0.8033\n",
      "Epoch 123/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4714 - acc: 0.8029\n",
      "Epoch 123: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4708 - acc: 0.8029 - val_loss: 0.4614 - val_acc: 0.7850\n",
      "Epoch 124/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4706 - acc: 0.8080\n",
      "Epoch 124: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4706 - acc: 0.8080 - val_loss: 0.4496 - val_acc: 0.7999\n",
      "Epoch 125/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4765 - acc: 0.8079\n",
      "Epoch 125: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4748 - acc: 0.8078 - val_loss: 0.4596 - val_acc: 0.8097\n",
      "Epoch 126/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4788 - acc: 0.8081\n",
      "Epoch 126: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4788 - acc: 0.8081 - val_loss: 0.4613 - val_acc: 0.8093\n",
      "Epoch 127/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4634 - acc: 0.8061\n",
      "Epoch 127: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 6s 19ms/step - loss: 0.4630 - acc: 0.8061 - val_loss: 0.4569 - val_acc: 0.7841\n",
      "Epoch 128/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4653 - acc: 0.8073\n",
      "Epoch 128: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4640 - acc: 0.8074 - val_loss: 0.4595 - val_acc: 0.7986\n",
      "Epoch 129/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4993 - acc: 0.8033\n",
      "Epoch 129: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4989 - acc: 0.8032 - val_loss: 0.4644 - val_acc: 0.8021\n",
      "Epoch 130/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4819 - acc: 0.8005\n",
      "Epoch 130: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4800 - acc: 0.8005 - val_loss: 0.4643 - val_acc: 0.7982\n",
      "Epoch 131/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4659 - acc: 0.8089\n",
      "Epoch 131: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4656 - acc: 0.8090 - val_loss: 0.4456 - val_acc: 0.8050\n",
      "Epoch 132/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4811 - acc: 0.8021\n",
      "Epoch 132: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4796 - acc: 0.8025 - val_loss: 0.4495 - val_acc: 0.7948\n",
      "Epoch 133/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4868 - acc: 0.8039\n",
      "Epoch 133: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4862 - acc: 0.8040 - val_loss: 0.4513 - val_acc: 0.7914\n",
      "Epoch 134/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4764 - acc: 0.8068\n",
      "Epoch 134: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4754 - acc: 0.8072 - val_loss: 0.4532 - val_acc: 0.8097\n",
      "Epoch 135/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4848 - acc: 0.8061\n",
      "Epoch 135: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4825 - acc: 0.8063 - val_loss: 0.4460 - val_acc: 0.8063\n",
      "Epoch 136/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4715 - acc: 0.8062\n",
      "Epoch 136: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4713 - acc: 0.8062 - val_loss: 0.4494 - val_acc: 0.8106\n",
      "Epoch 137/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4439 - acc: 0.8038\n",
      "Epoch 137: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4428 - acc: 0.8037 - val_loss: 0.4481 - val_acc: 0.8115\n",
      "Epoch 138/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4874 - acc: 0.8015\n",
      "Epoch 138: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4870 - acc: 0.8016 - val_loss: 0.4671 - val_acc: 0.7969\n",
      "Epoch 139/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4767 - acc: 0.8055\n",
      "Epoch 139: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4758 - acc: 0.8052 - val_loss: 0.4635 - val_acc: 0.7841\n",
      "Epoch 140/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4739 - acc: 0.8086\n",
      "Epoch 140: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4730 - acc: 0.8088 - val_loss: 0.4624 - val_acc: 0.7931\n",
      "Epoch 141/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4847 - acc: 0.8029\n",
      "Epoch 141: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4845 - acc: 0.8030 - val_loss: 0.4632 - val_acc: 0.7965\n",
      "Epoch 142/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4694 - acc: 0.7999\n",
      "Epoch 142: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4687 - acc: 0.7999 - val_loss: 0.4530 - val_acc: 0.8115\n",
      "Epoch 143/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4670 - acc: 0.8020\n",
      "Epoch 143: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4666 - acc: 0.8017 - val_loss: 0.4537 - val_acc: 0.7888\n",
      "Epoch 144/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4858 - acc: 0.8059\n",
      "Epoch 144: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4839 - acc: 0.8057 - val_loss: 0.4433 - val_acc: 0.7901\n",
      "Epoch 145/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4633 - acc: 0.8087\n",
      "Epoch 145: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4626 - acc: 0.8089 - val_loss: 0.4651 - val_acc: 0.8119\n",
      "Epoch 146/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4858 - acc: 0.8047\n",
      "Epoch 146: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4843 - acc: 0.8048 - val_loss: 0.4604 - val_acc: 0.8149\n",
      "Epoch 147/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4953 - acc: 0.8113\n",
      "Epoch 147: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4936 - acc: 0.8115 - val_loss: 0.4557 - val_acc: 0.8003\n",
      "Epoch 148/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4898 - acc: 0.8076\n",
      "Epoch 148: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5323 - acc: 0.8078 - val_loss: 0.4618 - val_acc: 0.7875\n",
      "Epoch 149/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4744 - acc: 0.8038\n",
      "Epoch 149: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4729 - acc: 0.8038 - val_loss: 0.4602 - val_acc: 0.8063\n",
      "Epoch 150/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4669 - acc: 0.8034\n",
      "Epoch 150: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4669 - acc: 0.8034 - val_loss: 0.4569 - val_acc: 0.7815\n",
      "Epoch 151/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4715 - acc: 0.8050\n",
      "Epoch 151: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4712 - acc: 0.8050 - val_loss: 0.4470 - val_acc: 0.8046\n",
      "Epoch 152/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8044\n",
      "Epoch 152: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4674 - acc: 0.8045 - val_loss: 0.4676 - val_acc: 0.7901\n",
      "Epoch 153/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5073 - acc: 0.8067\n",
      "Epoch 153: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5073 - acc: 0.8067 - val_loss: 0.4557 - val_acc: 0.8136\n",
      "Epoch 154/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4762 - acc: 0.8092\n",
      "Epoch 154: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4747 - acc: 0.8094 - val_loss: 0.4701 - val_acc: 0.7944\n",
      "Epoch 155/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4820 - acc: 0.8091\n",
      "Epoch 155: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4802 - acc: 0.8089 - val_loss: 0.4538 - val_acc: 0.8093\n",
      "Epoch 156/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4989 - acc: 0.8089\n",
      "Epoch 156: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4968 - acc: 0.8089 - val_loss: 0.4496 - val_acc: 0.8132\n",
      "Epoch 157/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4795 - acc: 0.8093\n",
      "Epoch 157: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4792 - acc: 0.8091 - val_loss: 0.4660 - val_acc: 0.7914\n",
      "Epoch 158/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5105 - acc: 0.8089\n",
      "Epoch 158: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5082 - acc: 0.8094 - val_loss: 0.4451 - val_acc: 0.8021\n",
      "Epoch 159/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4653 - acc: 0.8128\n",
      "Epoch 159: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4642 - acc: 0.8131 - val_loss: 0.4500 - val_acc: 0.8106\n",
      "Epoch 160/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4540 - acc: 0.8093\n",
      "Epoch 160: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4532 - acc: 0.8093 - val_loss: 0.4564 - val_acc: 0.7939\n",
      "Epoch 161/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4916 - acc: 0.8096\n",
      "Epoch 161: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4913 - acc: 0.8096 - val_loss: 0.4551 - val_acc: 0.7918\n",
      "Epoch 162/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4735 - acc: 0.8128\n",
      "Epoch 162: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5100 - acc: 0.8129 - val_loss: 0.4538 - val_acc: 0.8136\n",
      "Epoch 163/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4727 - acc: 0.8096\n",
      "Epoch 163: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4725 - acc: 0.8096 - val_loss: 0.4408 - val_acc: 0.8003\n",
      "Epoch 164/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4608 - acc: 0.8124\n",
      "Epoch 164: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4588 - acc: 0.8124 - val_loss: 0.4571 - val_acc: 0.8123\n",
      "Epoch 165/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4703 - acc: 0.8111\n",
      "Epoch 165: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4697 - acc: 0.8112 - val_loss: 0.4648 - val_acc: 0.7858\n",
      "Epoch 166/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4868 - acc: 0.8120\n",
      "Epoch 166: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4865 - acc: 0.8120 - val_loss: 0.4475 - val_acc: 0.7862\n",
      "Epoch 167/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4697 - acc: 0.8142\n",
      "Epoch 167: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4693 - acc: 0.8139 - val_loss: 0.4548 - val_acc: 0.7926\n",
      "Epoch 168/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4866 - acc: 0.8053\n",
      "Epoch 168: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4859 - acc: 0.8056 - val_loss: 0.4468 - val_acc: 0.7931\n",
      "Epoch 169/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4571 - acc: 0.8103\n",
      "Epoch 169: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4697 - acc: 0.8103 - val_loss: 0.4576 - val_acc: 0.7995\n",
      "Epoch 170/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4835 - acc: 0.8095\n",
      "Epoch 170: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4826 - acc: 0.8095 - val_loss: 0.4395 - val_acc: 0.8038\n",
      "Epoch 171/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4612 - acc: 0.8091\n",
      "Epoch 171: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4607 - acc: 0.8089 - val_loss: 0.4462 - val_acc: 0.7935\n",
      "Epoch 172/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4741 - acc: 0.8151\n",
      "Epoch 172: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4738 - acc: 0.8152 - val_loss: 0.4613 - val_acc: 0.7969\n",
      "Epoch 173/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4885 - acc: 0.8103\n",
      "Epoch 173: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4951 - acc: 0.8103 - val_loss: 0.4511 - val_acc: 0.8119\n",
      "Epoch 174/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4652 - acc: 0.8111\n",
      "Epoch 174: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4652 - acc: 0.8111 - val_loss: 0.4404 - val_acc: 0.7948\n",
      "Epoch 175/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4792 - acc: 0.8106\n",
      "Epoch 175: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4792 - acc: 0.8106 - val_loss: 0.4540 - val_acc: 0.8123\n",
      "Epoch 176/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4697 - acc: 0.8084\n",
      "Epoch 176: val_acc did not improve from 0.81573\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4694 - acc: 0.8086 - val_loss: 0.4659 - val_acc: 0.7884\n",
      "Epoch 177/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4794 - acc: 0.8063\n",
      "Epoch 177: val_acc improved from 0.81573 to 0.81744, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4769 - acc: 0.8066 - val_loss: 0.4534 - val_acc: 0.8174\n",
      "Epoch 178/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4644 - acc: 0.8079\n",
      "Epoch 178: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4625 - acc: 0.8081 - val_loss: 0.4336 - val_acc: 0.8059\n",
      "Epoch 179/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8116\n",
      "Epoch 179: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4577 - acc: 0.8118 - val_loss: 0.4345 - val_acc: 0.8157\n",
      "Epoch 180/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4723 - acc: 0.8109\n",
      "Epoch 180: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4706 - acc: 0.8112 - val_loss: 0.4525 - val_acc: 0.8102\n",
      "Epoch 181/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4522 - acc: 0.8117\n",
      "Epoch 181: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4515 - acc: 0.8115 - val_loss: 0.4600 - val_acc: 0.8080\n",
      "Epoch 182/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5403 - acc: 0.8142\n",
      "Epoch 182: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5365 - acc: 0.8141 - val_loss: 0.4347 - val_acc: 0.8145\n",
      "Epoch 183/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4711 - acc: 0.8110\n",
      "Epoch 183: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4703 - acc: 0.8112 - val_loss: 0.4382 - val_acc: 0.7794\n",
      "Epoch 184/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4698 - acc: 0.8135\n",
      "Epoch 184: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4699 - acc: 0.8135 - val_loss: 0.4617 - val_acc: 0.8119\n",
      "Epoch 185/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4470 - acc: 0.8149\n",
      "Epoch 185: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4668 - acc: 0.8152 - val_loss: 0.4455 - val_acc: 0.8072\n",
      "Epoch 186/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4853 - acc: 0.8144\n",
      "Epoch 186: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4850 - acc: 0.8144 - val_loss: 0.4354 - val_acc: 0.7935\n",
      "Epoch 187/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4860 - acc: 0.8105\n",
      "Epoch 187: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4850 - acc: 0.8106 - val_loss: 0.4368 - val_acc: 0.8050\n",
      "Epoch 188/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4680 - acc: 0.8178\n",
      "Epoch 188: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4657 - acc: 0.8185 - val_loss: 0.4315 - val_acc: 0.8170\n",
      "Epoch 189/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4698 - acc: 0.8128\n",
      "Epoch 189: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4673 - acc: 0.8137 - val_loss: 0.4288 - val_acc: 0.8097\n",
      "Epoch 190/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4920 - acc: 0.8194\n",
      "Epoch 190: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4897 - acc: 0.8192 - val_loss: 0.4429 - val_acc: 0.7820\n",
      "Epoch 191/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4962 - acc: 0.8120\n",
      "Epoch 191: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 5s 17ms/step - loss: 0.4953 - acc: 0.8121 - val_loss: 0.4407 - val_acc: 0.7879\n",
      "Epoch 192/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4524 - acc: 0.8108\n",
      "Epoch 192: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4523 - acc: 0.8107 - val_loss: 0.4430 - val_acc: 0.7738\n",
      "Epoch 193/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4511 - acc: 0.8156\n",
      "Epoch 193: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4493 - acc: 0.8160 - val_loss: 0.4290 - val_acc: 0.8068\n",
      "Epoch 194/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4540 - acc: 0.8130\n",
      "Epoch 194: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4518 - acc: 0.8130 - val_loss: 0.4407 - val_acc: 0.8063\n",
      "Epoch 195/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4793 - acc: 0.8151\n",
      "Epoch 195: val_acc improved from 0.81744 to 0.82428, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4782 - acc: 0.8145 - val_loss: 0.4231 - val_acc: 0.8243\n",
      "Epoch 196/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4708 - acc: 0.8112\n",
      "Epoch 196: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4699 - acc: 0.8113 - val_loss: 0.4468 - val_acc: 0.7815\n",
      "Epoch 197/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4442 - acc: 0.8104\n",
      "Epoch 197: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4435 - acc: 0.8106 - val_loss: 0.4433 - val_acc: 0.8033\n",
      "Epoch 198/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4768 - acc: 0.8081\n",
      "Epoch 198: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4749 - acc: 0.8080 - val_loss: 0.4354 - val_acc: 0.8123\n",
      "Epoch 199/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4459 - acc: 0.8145\n",
      "Epoch 199: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4506 - acc: 0.8146 - val_loss: 0.4440 - val_acc: 0.8230\n",
      "Epoch 200/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4877 - acc: 0.8094\n",
      "Epoch 200: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4865 - acc: 0.8100 - val_loss: 0.4352 - val_acc: 0.8166\n",
      "Epoch 201/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4851 - acc: 0.8086\n",
      "Epoch 201: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4839 - acc: 0.8088 - val_loss: 0.4387 - val_acc: 0.7969\n",
      "Epoch 202/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4675 - acc: 0.8122\n",
      "Epoch 202: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4661 - acc: 0.8124 - val_loss: 0.4368 - val_acc: 0.8127\n",
      "Epoch 203/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4410 - acc: 0.8167\n",
      "Epoch 203: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4427 - acc: 0.8165 - val_loss: 0.4411 - val_acc: 0.7914\n",
      "Epoch 204/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4795 - acc: 0.8085\n",
      "Epoch 204: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4786 - acc: 0.8088 - val_loss: 0.4390 - val_acc: 0.7918\n",
      "Epoch 205/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4855 - acc: 0.8157\n",
      "Epoch 205: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4855 - acc: 0.8157 - val_loss: 0.4229 - val_acc: 0.8085\n",
      "Epoch 206/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4843 - acc: 0.8120\n",
      "Epoch 206: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4843 - acc: 0.8120 - val_loss: 0.4484 - val_acc: 0.7879\n",
      "Epoch 207/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4585 - acc: 0.8087\n",
      "Epoch 207: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4579 - acc: 0.8090 - val_loss: 0.4296 - val_acc: 0.8204\n",
      "Epoch 208/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4553 - acc: 0.8098\n",
      "Epoch 208: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4553 - acc: 0.8098 - val_loss: 0.4507 - val_acc: 0.7922\n",
      "Epoch 209/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4491 - acc: 0.8190\n",
      "Epoch 209: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4484 - acc: 0.8189 - val_loss: 0.4417 - val_acc: 0.7875\n",
      "Epoch 210/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4769 - acc: 0.8129\n",
      "Epoch 210: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4753 - acc: 0.8127 - val_loss: 0.4492 - val_acc: 0.7905\n",
      "Epoch 211/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.8156\n",
      "Epoch 211: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4598 - acc: 0.8157 - val_loss: 0.4275 - val_acc: 0.8050\n",
      "Epoch 212/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4995 - acc: 0.8164\n",
      "Epoch 212: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4973 - acc: 0.8168 - val_loss: 0.4265 - val_acc: 0.8089\n",
      "Epoch 213/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4526 - acc: 0.8208\n",
      "Epoch 213: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4513 - acc: 0.8210 - val_loss: 0.4391 - val_acc: 0.8217\n",
      "Epoch 214/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4658 - acc: 0.8193\n",
      "Epoch 214: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4654 - acc: 0.8196 - val_loss: 0.4415 - val_acc: 0.8200\n",
      "Epoch 215/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4623 - acc: 0.8120\n",
      "Epoch 215: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4614 - acc: 0.8120 - val_loss: 0.4333 - val_acc: 0.8042\n",
      "Epoch 216/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4776 - acc: 0.8136\n",
      "Epoch 216: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4754 - acc: 0.8134 - val_loss: 0.4367 - val_acc: 0.7969\n",
      "Epoch 217/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5424 - acc: 0.8173\n",
      "Epoch 217: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5420 - acc: 0.8174 - val_loss: 0.4375 - val_acc: 0.7884\n",
      "Epoch 218/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4534 - acc: 0.8139\n",
      "Epoch 218: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4532 - acc: 0.8140 - val_loss: 0.4423 - val_acc: 0.7944\n",
      "Epoch 219/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4679 - acc: 0.8169\n",
      "Epoch 219: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4656 - acc: 0.8168 - val_loss: 0.4552 - val_acc: 0.7828\n",
      "Epoch 220/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4442 - acc: 0.8220\n",
      "Epoch 220: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4440 - acc: 0.8220 - val_loss: 0.4403 - val_acc: 0.7926\n",
      "Epoch 221/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4547 - acc: 0.8211\n",
      "Epoch 221: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4535 - acc: 0.8212 - val_loss: 0.4467 - val_acc: 0.8033\n",
      "Epoch 222/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5053 - acc: 0.8149\n",
      "Epoch 222: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5208 - acc: 0.8154 - val_loss: 0.4410 - val_acc: 0.8209\n",
      "Epoch 223/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.8246\n",
      "Epoch 223: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4779 - acc: 0.8238 - val_loss: 0.4318 - val_acc: 0.8080\n",
      "Epoch 224/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4725 - acc: 0.8124\n",
      "Epoch 224: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4707 - acc: 0.8125 - val_loss: 0.4409 - val_acc: 0.8153\n",
      "Epoch 225/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4495 - acc: 0.8188\n",
      "Epoch 225: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4482 - acc: 0.8189 - val_loss: 0.4246 - val_acc: 0.8140\n",
      "Epoch 226/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4777 - acc: 0.8211\n",
      "Epoch 226: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4773 - acc: 0.8212 - val_loss: 0.4283 - val_acc: 0.8063\n",
      "Epoch 227/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4382 - acc: 0.8179\n",
      "Epoch 227: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4374 - acc: 0.8179 - val_loss: 0.4326 - val_acc: 0.8145\n",
      "Epoch 228/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4629 - acc: 0.8217\n",
      "Epoch 228: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4619 - acc: 0.8220 - val_loss: 0.4242 - val_acc: 0.8123\n",
      "Epoch 229/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4542 - acc: 0.8216\n",
      "Epoch 229: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4539 - acc: 0.8217 - val_loss: 0.4391 - val_acc: 0.8021\n",
      "Epoch 230/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4716 - acc: 0.8171\n",
      "Epoch 230: val_acc did not improve from 0.82428\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4716 - acc: 0.8171 - val_loss: 0.4442 - val_acc: 0.8076\n",
      "Epoch 231/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4621 - acc: 0.8180\n",
      "Epoch 231: val_acc improved from 0.82428 to 0.82557, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4611 - acc: 0.8183 - val_loss: 0.4333 - val_acc: 0.8256\n",
      "Epoch 232/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4471 - acc: 0.8187\n",
      "Epoch 232: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4468 - acc: 0.8188 - val_loss: 0.4266 - val_acc: 0.8042\n",
      "Epoch 233/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4536 - acc: 0.8163\n",
      "Epoch 233: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4526 - acc: 0.8166 - val_loss: 0.4291 - val_acc: 0.7973\n",
      "Epoch 234/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4456 - acc: 0.8155\n",
      "Epoch 234: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4447 - acc: 0.8157 - val_loss: 0.4288 - val_acc: 0.8097\n",
      "Epoch 235/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4596 - acc: 0.8143\n",
      "Epoch 235: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4593 - acc: 0.8144 - val_loss: 0.4334 - val_acc: 0.7918\n",
      "Epoch 236/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4712 - acc: 0.8138\n",
      "Epoch 236: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4703 - acc: 0.8139 - val_loss: 0.4329 - val_acc: 0.8097\n",
      "Epoch 237/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8198\n",
      "Epoch 237: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4653 - acc: 0.8198 - val_loss: 0.4527 - val_acc: 0.8042\n",
      "Epoch 238/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4845 - acc: 0.8144\n",
      "Epoch 238: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4824 - acc: 0.8143 - val_loss: 0.4377 - val_acc: 0.7956\n",
      "Epoch 239/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4664 - acc: 0.8146\n",
      "Epoch 239: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4656 - acc: 0.8150 - val_loss: 0.4389 - val_acc: 0.7961\n",
      "Epoch 240/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4766 - acc: 0.8209\n",
      "Epoch 240: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4759 - acc: 0.8208 - val_loss: 0.4348 - val_acc: 0.8016\n",
      "Epoch 241/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4629 - acc: 0.8166\n",
      "Epoch 241: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4621 - acc: 0.8166 - val_loss: 0.4390 - val_acc: 0.8059\n",
      "Epoch 242/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4705 - acc: 0.8155\n",
      "Epoch 242: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4705 - acc: 0.8155 - val_loss: 0.4294 - val_acc: 0.8063\n",
      "Epoch 243/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4777 - acc: 0.8181\n",
      "Epoch 243: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4763 - acc: 0.8175 - val_loss: 0.4280 - val_acc: 0.8033\n",
      "Epoch 244/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4469 - acc: 0.8172\n",
      "Epoch 244: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4466 - acc: 0.8174 - val_loss: 0.4374 - val_acc: 0.8204\n",
      "Epoch 245/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4751 - acc: 0.8112\n",
      "Epoch 245: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4741 - acc: 0.8114 - val_loss: 0.4395 - val_acc: 0.8050\n",
      "Epoch 246/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4609 - acc: 0.8097\n",
      "Epoch 246: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4608 - acc: 0.8096 - val_loss: 0.4415 - val_acc: 0.7879\n",
      "Epoch 247/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4808 - acc: 0.8182\n",
      "Epoch 247: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4797 - acc: 0.8182 - val_loss: 0.4531 - val_acc: 0.7867\n",
      "Epoch 248/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4963 - acc: 0.8130\n",
      "Epoch 248: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4933 - acc: 0.8130 - val_loss: 0.4500 - val_acc: 0.8089\n",
      "Epoch 249/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4787 - acc: 0.8178\n",
      "Epoch 249: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4777 - acc: 0.8180 - val_loss: 0.4268 - val_acc: 0.8162\n",
      "Epoch 250/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4830 - acc: 0.8181\n",
      "Epoch 250: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4826 - acc: 0.8182 - val_loss: 0.4419 - val_acc: 0.7926\n",
      "Epoch 251/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5042 - acc: 0.8189\n",
      "Epoch 251: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5038 - acc: 0.8190 - val_loss: 0.4257 - val_acc: 0.8076\n",
      "Epoch 252/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4563 - acc: 0.8216\n",
      "Epoch 252: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4559 - acc: 0.8217 - val_loss: 0.4293 - val_acc: 0.7897\n",
      "Epoch 253/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4868 - acc: 0.8215\n",
      "Epoch 253: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.4864 - acc: 0.8216 - val_loss: 0.4218 - val_acc: 0.8059\n",
      "Epoch 254/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4723 - acc: 0.8173\n",
      "Epoch 254: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4720 - acc: 0.8174 - val_loss: 0.4202 - val_acc: 0.8097\n",
      "Epoch 255/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4573 - acc: 0.8166\n",
      "Epoch 255: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4563 - acc: 0.8170 - val_loss: 0.4319 - val_acc: 0.7892\n",
      "Epoch 256/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4547 - acc: 0.8219\n",
      "Epoch 256: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4529 - acc: 0.8218 - val_loss: 0.4222 - val_acc: 0.8247\n",
      "Epoch 257/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4589 - acc: 0.8185\n",
      "Epoch 257: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4583 - acc: 0.8188 - val_loss: 0.4348 - val_acc: 0.8097\n",
      "Epoch 258/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4603 - acc: 0.8208\n",
      "Epoch 258: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4601 - acc: 0.8208 - val_loss: 0.4468 - val_acc: 0.7764\n",
      "Epoch 259/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4663 - acc: 0.8220\n",
      "Epoch 259: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4646 - acc: 0.8221 - val_loss: 0.4375 - val_acc: 0.8123\n",
      "Epoch 260/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4731 - acc: 0.8159\n",
      "Epoch 260: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4720 - acc: 0.8164 - val_loss: 0.4230 - val_acc: 0.8170\n",
      "Epoch 261/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5342 - acc: 0.8134\n",
      "Epoch 261: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5342 - acc: 0.8134 - val_loss: 0.4298 - val_acc: 0.8068\n",
      "Epoch 262/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4812 - acc: 0.8214\n",
      "Epoch 262: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4802 - acc: 0.8217 - val_loss: 0.4324 - val_acc: 0.8042\n",
      "Epoch 263/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4711 - acc: 0.8234\n",
      "Epoch 263: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4707 - acc: 0.8236 - val_loss: 0.4530 - val_acc: 0.8140\n",
      "Epoch 264/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4902 - acc: 0.8175\n",
      "Epoch 264: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4902 - acc: 0.8175 - val_loss: 0.4371 - val_acc: 0.7909\n",
      "Epoch 265/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4596 - acc: 0.8213\n",
      "Epoch 265: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4596 - acc: 0.8213 - val_loss: 0.4439 - val_acc: 0.7973\n",
      "Epoch 266/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4847 - acc: 0.8219\n",
      "Epoch 266: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4830 - acc: 0.8219 - val_loss: 0.4369 - val_acc: 0.7948\n",
      "Epoch 267/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4758 - acc: 0.8187\n",
      "Epoch 267: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4758 - acc: 0.8187 - val_loss: 0.4381 - val_acc: 0.8050\n",
      "Epoch 268/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4599 - acc: 0.8248\n",
      "Epoch 268: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4590 - acc: 0.8251 - val_loss: 0.4315 - val_acc: 0.7961\n",
      "Epoch 269/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4321 - acc: 0.8228\n",
      "Epoch 269: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4301 - acc: 0.8230 - val_loss: 0.4248 - val_acc: 0.8119\n",
      "Epoch 270/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4786 - acc: 0.8150\n",
      "Epoch 270: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4776 - acc: 0.8152 - val_loss: 0.4271 - val_acc: 0.8123\n",
      "Epoch 271/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4721 - acc: 0.8207\n",
      "Epoch 271: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4706 - acc: 0.8208 - val_loss: 0.4312 - val_acc: 0.8050\n",
      "Epoch 272/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4589 - acc: 0.8191\n",
      "Epoch 272: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4589 - acc: 0.8190 - val_loss: 0.4351 - val_acc: 0.7939\n",
      "Epoch 273/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4701 - acc: 0.8162\n",
      "Epoch 273: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4701 - acc: 0.8162 - val_loss: 0.4457 - val_acc: 0.8038\n",
      "Epoch 274/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4691 - acc: 0.8191\n",
      "Epoch 274: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4667 - acc: 0.8193 - val_loss: 0.4293 - val_acc: 0.8204\n",
      "Epoch 275/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4455 - acc: 0.8224\n",
      "Epoch 275: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4455 - acc: 0.8224 - val_loss: 0.4324 - val_acc: 0.7978\n",
      "Epoch 276/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4734 - acc: 0.8216\n",
      "Epoch 276: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4727 - acc: 0.8215 - val_loss: 0.4426 - val_acc: 0.8187\n",
      "Epoch 277/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4427 - acc: 0.8183\n",
      "Epoch 277: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4474 - acc: 0.8182 - val_loss: 0.4252 - val_acc: 0.8119\n",
      "Epoch 278/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8277\n",
      "Epoch 278: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4588 - acc: 0.8278 - val_loss: 0.4303 - val_acc: 0.8093\n",
      "Epoch 279/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4464 - acc: 0.8259\n",
      "Epoch 279: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 7s 22ms/step - loss: 0.4464 - acc: 0.8259 - val_loss: 0.4317 - val_acc: 0.8153\n",
      "Epoch 280/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4482 - acc: 0.8294\n",
      "Epoch 280: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4465 - acc: 0.8296 - val_loss: 0.4303 - val_acc: 0.8106\n",
      "Epoch 281/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4718 - acc: 0.8180\n",
      "Epoch 281: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4708 - acc: 0.8181 - val_loss: 0.4359 - val_acc: 0.8072\n",
      "Epoch 282/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4906 - acc: 0.8202\n",
      "Epoch 282: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4896 - acc: 0.8200 - val_loss: 0.4257 - val_acc: 0.7858\n",
      "Epoch 283/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4639 - acc: 0.8236\n",
      "Epoch 283: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4626 - acc: 0.8236 - val_loss: 0.4322 - val_acc: 0.8008\n",
      "Epoch 284/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4485 - acc: 0.8247\n",
      "Epoch 284: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4476 - acc: 0.8246 - val_loss: 0.4342 - val_acc: 0.7952\n",
      "Epoch 285/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4694 - acc: 0.8204\n",
      "Epoch 285: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4681 - acc: 0.8203 - val_loss: 0.4204 - val_acc: 0.8080\n",
      "Epoch 286/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4797 - acc: 0.8233\n",
      "Epoch 286: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4797 - acc: 0.8233 - val_loss: 0.4253 - val_acc: 0.8085\n",
      "Epoch 287/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4594 - acc: 0.8264\n",
      "Epoch 287: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4583 - acc: 0.8265 - val_loss: 0.4342 - val_acc: 0.8076\n",
      "Epoch 288/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4715 - acc: 0.8229\n",
      "Epoch 288: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4699 - acc: 0.8231 - val_loss: 0.4292 - val_acc: 0.7978\n",
      "Epoch 289/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4557 - acc: 0.8182\n",
      "Epoch 289: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.4548 - acc: 0.8179 - val_loss: 0.4704 - val_acc: 0.7850\n",
      "Epoch 290/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4671 - acc: 0.8214\n",
      "Epoch 290: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4659 - acc: 0.8214 - val_loss: 0.4365 - val_acc: 0.7999\n",
      "Epoch 291/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4617 - acc: 0.8205\n",
      "Epoch 291: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4617 - acc: 0.8205 - val_loss: 0.4407 - val_acc: 0.7935\n",
      "Epoch 292/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4660 - acc: 0.8220\n",
      "Epoch 292: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4660 - acc: 0.8216 - val_loss: 0.4498 - val_acc: 0.7973\n",
      "Epoch 293/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4598 - acc: 0.8201\n",
      "Epoch 293: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4595 - acc: 0.8203 - val_loss: 0.4520 - val_acc: 0.8055\n",
      "Epoch 294/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4733 - acc: 0.8143\n",
      "Epoch 294: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4730 - acc: 0.8144 - val_loss: 0.4348 - val_acc: 0.8106\n",
      "Epoch 295/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4567 - acc: 0.8191\n",
      "Epoch 295: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4554 - acc: 0.8192 - val_loss: 0.4526 - val_acc: 0.7982\n",
      "Epoch 296/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4552 - acc: 0.8208\n",
      "Epoch 296: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4542 - acc: 0.8212 - val_loss: 0.4348 - val_acc: 0.8213\n",
      "Epoch 297/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4519 - acc: 0.8244\n",
      "Epoch 297: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4501 - acc: 0.8243 - val_loss: 0.5185 - val_acc: 0.7884\n",
      "Epoch 298/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4716 - acc: 0.8230\n",
      "Epoch 298: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4696 - acc: 0.8235 - val_loss: 0.4287 - val_acc: 0.8132\n",
      "Epoch 299/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4916 - acc: 0.8189\n",
      "Epoch 299: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4907 - acc: 0.8190 - val_loss: 0.4480 - val_acc: 0.7820\n",
      "Epoch 300/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4827 - acc: 0.8139\n",
      "Epoch 300: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.4816 - acc: 0.8139 - val_loss: 0.4328 - val_acc: 0.7837\n",
      "Epoch 301/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4634 - acc: 0.8239\n",
      "Epoch 301: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4634 - acc: 0.8239 - val_loss: 0.4312 - val_acc: 0.8059\n",
      "Epoch 302/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4828 - acc: 0.8197\n",
      "Epoch 302: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4814 - acc: 0.8200 - val_loss: 0.4466 - val_acc: 0.8025\n",
      "Epoch 303/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4657 - acc: 0.8232\n",
      "Epoch 303: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4644 - acc: 0.8233 - val_loss: 0.4229 - val_acc: 0.8110\n",
      "Epoch 304/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4564 - acc: 0.8218\n",
      "Epoch 304: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4542 - acc: 0.8220 - val_loss: 0.4334 - val_acc: 0.8110\n",
      "Epoch 305/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5045 - acc: 0.8202\n",
      "Epoch 305: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5033 - acc: 0.8205 - val_loss: 0.4347 - val_acc: 0.8055\n",
      "Epoch 306/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4877 - acc: 0.8296\n",
      "Epoch 306: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4856 - acc: 0.8296 - val_loss: 0.4273 - val_acc: 0.8140\n",
      "Epoch 307/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4617 - acc: 0.8186\n",
      "Epoch 307: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4617 - acc: 0.8186 - val_loss: 0.4433 - val_acc: 0.7832\n",
      "Epoch 308/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4650 - acc: 0.8227\n",
      "Epoch 308: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 5s 18ms/step - loss: 0.4640 - acc: 0.8221 - val_loss: 0.4281 - val_acc: 0.8097\n",
      "Epoch 309/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4427 - acc: 0.8311\n",
      "Epoch 309: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4418 - acc: 0.8307 - val_loss: 0.4304 - val_acc: 0.7978\n",
      "Epoch 310/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4961 - acc: 0.8237\n",
      "Epoch 310: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4941 - acc: 0.8241 - val_loss: 0.4283 - val_acc: 0.8115\n",
      "Epoch 311/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5023 - acc: 0.8197\n",
      "Epoch 311: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5019 - acc: 0.8196 - val_loss: 0.4261 - val_acc: 0.7969\n",
      "Epoch 312/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4726 - acc: 0.8264\n",
      "Epoch 312: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4723 - acc: 0.8265 - val_loss: 0.4236 - val_acc: 0.7986\n",
      "Epoch 313/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4452 - acc: 0.8189\n",
      "Epoch 313: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4452 - acc: 0.8189 - val_loss: 0.4292 - val_acc: 0.8085\n",
      "Epoch 314/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4499 - acc: 0.8237\n",
      "Epoch 314: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4498 - acc: 0.8230 - val_loss: 0.4467 - val_acc: 0.7982\n",
      "Epoch 315/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4695 - acc: 0.8208\n",
      "Epoch 315: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4695 - acc: 0.8208 - val_loss: 0.4287 - val_acc: 0.8063\n",
      "Epoch 316/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4898 - acc: 0.8216\n",
      "Epoch 316: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4898 - acc: 0.8216 - val_loss: 0.4219 - val_acc: 0.8140\n",
      "Epoch 317/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4653 - acc: 0.8269\n",
      "Epoch 317: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4651 - acc: 0.8270 - val_loss: 0.4324 - val_acc: 0.8076\n",
      "Epoch 318/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4703 - acc: 0.8272\n",
      "Epoch 318: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4703 - acc: 0.8272 - val_loss: 0.4326 - val_acc: 0.8183\n",
      "Epoch 319/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4446 - acc: 0.8221\n",
      "Epoch 319: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4439 - acc: 0.8218 - val_loss: 0.4646 - val_acc: 0.7879\n",
      "Epoch 320/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4760 - acc: 0.8228\n",
      "Epoch 320: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4736 - acc: 0.8230 - val_loss: 0.4305 - val_acc: 0.8055\n",
      "Epoch 321/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8268\n",
      "Epoch 321: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4576 - acc: 0.8266 - val_loss: 0.4385 - val_acc: 0.8021\n",
      "Epoch 322/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4821 - acc: 0.8248\n",
      "Epoch 322: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 6s 21ms/step - loss: 0.4802 - acc: 0.8244 - val_loss: 0.4121 - val_acc: 0.8162\n",
      "Epoch 323/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4441 - acc: 0.8191\n",
      "Epoch 323: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4435 - acc: 0.8190 - val_loss: 0.4392 - val_acc: 0.7854\n",
      "Epoch 324/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5122 - acc: 0.8213\n",
      "Epoch 324: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5103 - acc: 0.8210 - val_loss: 0.4467 - val_acc: 0.8145\n",
      "Epoch 325/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5104 - acc: 0.8276\n",
      "Epoch 325: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5104 - acc: 0.8276 - val_loss: 0.4370 - val_acc: 0.7901\n",
      "Epoch 326/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4364 - acc: 0.8233\n",
      "Epoch 326: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4364 - acc: 0.8233 - val_loss: 0.4327 - val_acc: 0.8089\n",
      "Epoch 327/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4942 - acc: 0.8232\n",
      "Epoch 327: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4934 - acc: 0.8231 - val_loss: 0.4490 - val_acc: 0.7905\n",
      "Epoch 328/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4794 - acc: 0.8205\n",
      "Epoch 328: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4791 - acc: 0.8206 - val_loss: 0.4387 - val_acc: 0.8153\n",
      "Epoch 329/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4785 - acc: 0.8218\n",
      "Epoch 329: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4766 - acc: 0.8218 - val_loss: 0.4246 - val_acc: 0.8119\n",
      "Epoch 330/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4376 - acc: 0.8269\n",
      "Epoch 330: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4371 - acc: 0.8268 - val_loss: 0.4312 - val_acc: 0.8200\n",
      "Epoch 331/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4636 - acc: 0.8227\n",
      "Epoch 331: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4626 - acc: 0.8226 - val_loss: 0.4338 - val_acc: 0.8204\n",
      "Epoch 332/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4628 - acc: 0.8162\n",
      "Epoch 332: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4617 - acc: 0.8161 - val_loss: 0.4285 - val_acc: 0.8157\n",
      "Epoch 333/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4523 - acc: 0.8259\n",
      "Epoch 333: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 5s 17ms/step - loss: 0.4521 - acc: 0.8260 - val_loss: 0.4390 - val_acc: 0.8230\n",
      "Epoch 334/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4924 - acc: 0.8294\n",
      "Epoch 334: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4892 - acc: 0.8295 - val_loss: 0.4337 - val_acc: 0.8230\n",
      "Epoch 335/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4747 - acc: 0.8208\n",
      "Epoch 335: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4737 - acc: 0.8211 - val_loss: 0.4470 - val_acc: 0.7922\n",
      "Epoch 336/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5030 - acc: 0.8255\n",
      "Epoch 336: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5016 - acc: 0.8251 - val_loss: 0.4488 - val_acc: 0.7931\n",
      "Epoch 337/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4965 - acc: 0.8272\n",
      "Epoch 337: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4944 - acc: 0.8273 - val_loss: 0.4128 - val_acc: 0.8209\n",
      "Epoch 338/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4187 - acc: 0.8279\n",
      "Epoch 338: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 7s 22ms/step - loss: 0.4185 - acc: 0.8280 - val_loss: 0.4267 - val_acc: 0.8059\n",
      "Epoch 339/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4522 - acc: 0.8239\n",
      "Epoch 339: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4506 - acc: 0.8239 - val_loss: 0.4583 - val_acc: 0.7802\n",
      "Epoch 340/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5402 - acc: 0.8277\n",
      "Epoch 340: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5384 - acc: 0.8275 - val_loss: 0.4464 - val_acc: 0.7931\n",
      "Epoch 341/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4611 - acc: 0.8273\n",
      "Epoch 341: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4598 - acc: 0.8269 - val_loss: 0.4351 - val_acc: 0.8055\n",
      "Epoch 342/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4279 - acc: 0.8341\n",
      "Epoch 342: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4279 - acc: 0.8341 - val_loss: 0.4452 - val_acc: 0.7931\n",
      "Epoch 343/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4640 - acc: 0.8232\n",
      "Epoch 343: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4632 - acc: 0.8233 - val_loss: 0.4463 - val_acc: 0.7965\n",
      "Epoch 344/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4683 - acc: 0.8241\n",
      "Epoch 344: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4667 - acc: 0.8241 - val_loss: 0.4378 - val_acc: 0.8085\n",
      "Epoch 345/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4406 - acc: 0.8287\n",
      "Epoch 345: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4395 - acc: 0.8283 - val_loss: 0.4212 - val_acc: 0.8072\n",
      "Epoch 346/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4785 - acc: 0.8237\n",
      "Epoch 346: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4781 - acc: 0.8238 - val_loss: 0.4380 - val_acc: 0.8243\n",
      "Epoch 347/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4516 - acc: 0.8269\n",
      "Epoch 347: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4507 - acc: 0.8270 - val_loss: 0.4646 - val_acc: 0.8187\n",
      "Epoch 348/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4525 - acc: 0.8279\n",
      "Epoch 348: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4513 - acc: 0.8281 - val_loss: 0.4418 - val_acc: 0.8093\n",
      "Epoch 349/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5293 - acc: 0.8263\n",
      "Epoch 349: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5274 - acc: 0.8264 - val_loss: 0.4260 - val_acc: 0.8089\n",
      "Epoch 350/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4708 - acc: 0.8217\n",
      "Epoch 350: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4690 - acc: 0.8219 - val_loss: 0.4339 - val_acc: 0.8042\n",
      "Epoch 351/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4425 - acc: 0.8192\n",
      "Epoch 351: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4420 - acc: 0.8189 - val_loss: 0.4350 - val_acc: 0.7986\n",
      "Epoch 352/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4488 - acc: 0.8268\n",
      "Epoch 352: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4483 - acc: 0.8266 - val_loss: 0.4456 - val_acc: 0.8012\n",
      "Epoch 353/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4523 - acc: 0.8202\n",
      "Epoch 353: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4519 - acc: 0.8203 - val_loss: 0.4473 - val_acc: 0.8085\n",
      "Epoch 354/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4562 - acc: 0.8248\n",
      "Epoch 354: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4546 - acc: 0.8250 - val_loss: 0.4672 - val_acc: 0.8221\n",
      "Epoch 355/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8242\n",
      "Epoch 355: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4575 - acc: 0.8245 - val_loss: 0.4434 - val_acc: 0.8050\n",
      "Epoch 356/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5191 - acc: 0.8222\n",
      "Epoch 356: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5168 - acc: 0.8221 - val_loss: 0.4337 - val_acc: 0.8072\n",
      "Epoch 357/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5336 - acc: 0.8253\n",
      "Epoch 357: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5317 - acc: 0.8248 - val_loss: 0.4480 - val_acc: 0.7914\n",
      "Epoch 358/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4987 - acc: 0.8219\n",
      "Epoch 358: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4987 - acc: 0.8219 - val_loss: 0.4361 - val_acc: 0.8063\n",
      "Epoch 359/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4407 - acc: 0.8286\n",
      "Epoch 359: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4388 - acc: 0.8291 - val_loss: 0.4399 - val_acc: 0.8226\n",
      "Epoch 360/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8243\n",
      "Epoch 360: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4584 - acc: 0.8244 - val_loss: 0.4394 - val_acc: 0.7944\n",
      "Epoch 361/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4825 - acc: 0.8250\n",
      "Epoch 361: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4817 - acc: 0.8250 - val_loss: 0.4415 - val_acc: 0.8110\n",
      "Epoch 362/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4474 - acc: 0.8300\n",
      "Epoch 362: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4474 - acc: 0.8300 - val_loss: 0.4510 - val_acc: 0.8140\n",
      "Epoch 363/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4264 - acc: 0.8242\n",
      "Epoch 363: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4264 - acc: 0.8242 - val_loss: 0.4250 - val_acc: 0.8157\n",
      "Epoch 364/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4663 - acc: 0.8279\n",
      "Epoch 364: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4662 - acc: 0.8277 - val_loss: 0.4437 - val_acc: 0.7952\n",
      "Epoch 365/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4637 - acc: 0.8256\n",
      "Epoch 365: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4609 - acc: 0.8264 - val_loss: 0.4403 - val_acc: 0.8076\n",
      "Epoch 366/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4601 - acc: 0.8259\n",
      "Epoch 366: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4596 - acc: 0.8259 - val_loss: 0.4298 - val_acc: 0.8076\n",
      "Epoch 367/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4480 - acc: 0.8314\n",
      "Epoch 367: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4468 - acc: 0.8313 - val_loss: 0.4304 - val_acc: 0.8068\n",
      "Epoch 368/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4553 - acc: 0.8267\n",
      "Epoch 368: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4538 - acc: 0.8268 - val_loss: 0.4321 - val_acc: 0.8136\n",
      "Epoch 369/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4627 - acc: 0.8218\n",
      "Epoch 369: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4611 - acc: 0.8218 - val_loss: 0.4351 - val_acc: 0.8055\n",
      "Epoch 370/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4452 - acc: 0.8207\n",
      "Epoch 370: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4452 - acc: 0.8207 - val_loss: 0.4459 - val_acc: 0.8012\n",
      "Epoch 371/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4631 - acc: 0.8257\n",
      "Epoch 371: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4631 - acc: 0.8257 - val_loss: 0.4488 - val_acc: 0.7973\n",
      "Epoch 372/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4482 - acc: 0.8321\n",
      "Epoch 372: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4491 - acc: 0.8309 - val_loss: 0.4593 - val_acc: 0.7871\n",
      "Epoch 373/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4928 - acc: 0.8236\n",
      "Epoch 373: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4913 - acc: 0.8236 - val_loss: 0.4507 - val_acc: 0.8055\n",
      "Epoch 374/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4564 - acc: 0.8207\n",
      "Epoch 374: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4555 - acc: 0.8206 - val_loss: 0.4594 - val_acc: 0.8003\n",
      "Epoch 375/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4458 - acc: 0.8258\n",
      "Epoch 375: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4458 - acc: 0.8255 - val_loss: 0.4602 - val_acc: 0.8256\n",
      "Epoch 376/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.8280\n",
      "Epoch 376: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4604 - acc: 0.8278 - val_loss: 0.4461 - val_acc: 0.8055\n",
      "Epoch 377/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4722 - acc: 0.8280\n",
      "Epoch 377: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4722 - acc: 0.8280 - val_loss: 0.4284 - val_acc: 0.8217\n",
      "Epoch 378/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4706 - acc: 0.8264\n",
      "Epoch 378: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4706 - acc: 0.8264 - val_loss: 0.4324 - val_acc: 0.8174\n",
      "Epoch 379/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4546 - acc: 0.8220\n",
      "Epoch 379: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4535 - acc: 0.8222 - val_loss: 0.4404 - val_acc: 0.8055\n",
      "Epoch 380/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4527 - acc: 0.8320\n",
      "Epoch 380: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4522 - acc: 0.8320 - val_loss: 0.4320 - val_acc: 0.8102\n",
      "Epoch 381/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4623 - acc: 0.8257\n",
      "Epoch 381: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4604 - acc: 0.8254 - val_loss: 0.4366 - val_acc: 0.8033\n",
      "Epoch 382/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4550 - acc: 0.8263\n",
      "Epoch 382: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4547 - acc: 0.8263 - val_loss: 0.4342 - val_acc: 0.8166\n",
      "Epoch 383/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4603 - acc: 0.8299\n",
      "Epoch 383: val_acc did not improve from 0.82557\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4603 - acc: 0.8299 - val_loss: 0.4382 - val_acc: 0.8012\n",
      "Epoch 384/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4364 - acc: 0.8298\n",
      "Epoch 384: val_acc improved from 0.82557 to 0.82685, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4349 - acc: 0.8298 - val_loss: 0.4312 - val_acc: 0.8268\n",
      "Epoch 385/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4657 - acc: 0.8266\n",
      "Epoch 385: val_acc did not improve from 0.82685\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4643 - acc: 0.8262 - val_loss: 0.4589 - val_acc: 0.7884\n",
      "Epoch 386/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5100 - acc: 0.8255\n",
      "Epoch 386: val_acc did not improve from 0.82685\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5101 - acc: 0.8251 - val_loss: 0.4496 - val_acc: 0.8162\n",
      "Epoch 387/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4582 - acc: 0.8218\n",
      "Epoch 387: val_acc did not improve from 0.82685\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4582 - acc: 0.8218 - val_loss: 0.4244 - val_acc: 0.8251\n",
      "Epoch 388/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8236\n",
      "Epoch 388: val_acc did not improve from 0.82685\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4635 - acc: 0.8239 - val_loss: 0.4310 - val_acc: 0.8196\n",
      "Epoch 389/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4362 - acc: 0.8329\n",
      "Epoch 389: val_acc did not improve from 0.82685\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4357 - acc: 0.8329 - val_loss: 0.4583 - val_acc: 0.7879\n",
      "Epoch 390/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4701 - acc: 0.8265\n",
      "Epoch 390: val_acc did not improve from 0.82685\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4687 - acc: 0.8265 - val_loss: 0.4506 - val_acc: 0.7991\n",
      "Epoch 391/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8336\n",
      "Epoch 391: val_acc improved from 0.82685 to 0.82856, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/1/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4458 - acc: 0.8339 - val_loss: 0.4505 - val_acc: 0.8286\n",
      "Epoch 392/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.8275\n",
      "Epoch 392: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4497 - acc: 0.8277 - val_loss: 0.4389 - val_acc: 0.8003\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_1 (Reshape)         (None, 96, 1)             0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               49664     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 313,089\n",
      "Trainable params: 313,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 1.5943 - acc: 0.6165\n",
      "Epoch 1: val_acc improved from -inf to 0.47841, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 4s 10ms/step - loss: 1.5852 - acc: 0.6159 - val_loss: 0.6952 - val_acc: 0.4784\n",
      "Epoch 2/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.6925 - acc: 0.6433\n",
      "Epoch 2: val_acc improved from 0.47841 to 0.70842, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.6927 - acc: 0.6433 - val_loss: 0.6235 - val_acc: 0.7084\n",
      "Epoch 3/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.6141 - acc: 0.6877\n",
      "Epoch 3: val_acc improved from 0.70842 to 0.71142, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.6151 - acc: 0.6871 - val_loss: 0.5926 - val_acc: 0.7114\n",
      "Epoch 4/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5917 - acc: 0.7088\n",
      "Epoch 4: val_acc improved from 0.71142 to 0.71697, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5924 - acc: 0.7077 - val_loss: 0.5918 - val_acc: 0.7170\n",
      "Epoch 5/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5792 - acc: 0.7117\n",
      "Epoch 5: val_acc improved from 0.71697 to 0.72210, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5802 - acc: 0.7106 - val_loss: 0.5830 - val_acc: 0.7221\n",
      "Epoch 6/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5761 - acc: 0.7191\n",
      "Epoch 6: val_acc improved from 0.72210 to 0.72467, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5765 - acc: 0.7182 - val_loss: 0.5608 - val_acc: 0.7247\n",
      "Epoch 7/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5669 - acc: 0.7231\n",
      "Epoch 7: val_acc improved from 0.72467 to 0.73194, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5674 - acc: 0.7227 - val_loss: 0.5761 - val_acc: 0.7319\n",
      "Epoch 8/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5595 - acc: 0.7288\n",
      "Epoch 8: val_acc improved from 0.73194 to 0.73536, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5594 - acc: 0.7287 - val_loss: 0.5565 - val_acc: 0.7354\n",
      "Epoch 9/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5593 - acc: 0.7326\n",
      "Epoch 9: val_acc did not improve from 0.73536\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5591 - acc: 0.7324 - val_loss: 0.5446 - val_acc: 0.7272\n",
      "Epoch 10/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5491 - acc: 0.7332\n",
      "Epoch 10: val_acc improved from 0.73536 to 0.74391, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5491 - acc: 0.7332 - val_loss: 0.5426 - val_acc: 0.7439\n",
      "Epoch 11/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5560 - acc: 0.7323\n",
      "Epoch 11: val_acc did not improve from 0.74391\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5560 - acc: 0.7323 - val_loss: 0.5543 - val_acc: 0.7336\n",
      "Epoch 12/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5460 - acc: 0.7403\n",
      "Epoch 12: val_acc did not improve from 0.74391\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5459 - acc: 0.7402 - val_loss: 0.5491 - val_acc: 0.7418\n",
      "Epoch 13/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5525 - acc: 0.7403\n",
      "Epoch 13: val_acc did not improve from 0.74391\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5525 - acc: 0.7402 - val_loss: 0.5497 - val_acc: 0.7383\n",
      "Epoch 14/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5420 - acc: 0.7407\n",
      "Epoch 14: val_acc did not improve from 0.74391\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5425 - acc: 0.7398 - val_loss: 0.5492 - val_acc: 0.7336\n",
      "Epoch 15/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5404 - acc: 0.7396\n",
      "Epoch 15: val_acc improved from 0.74391 to 0.74989, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5402 - acc: 0.7397 - val_loss: 0.5586 - val_acc: 0.7499\n",
      "Epoch 16/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5452 - acc: 0.7436\n",
      "Epoch 16: val_acc did not improve from 0.74989\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5452 - acc: 0.7436 - val_loss: 0.5276 - val_acc: 0.7422\n",
      "Epoch 17/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5498 - acc: 0.7413\n",
      "Epoch 17: val_acc improved from 0.74989 to 0.75417, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5498 - acc: 0.7412 - val_loss: 0.5428 - val_acc: 0.7542\n",
      "Epoch 18/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5411 - acc: 0.7464\n",
      "Epoch 18: val_acc did not improve from 0.75417\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5409 - acc: 0.7466 - val_loss: 0.5421 - val_acc: 0.7383\n",
      "Epoch 19/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5357 - acc: 0.7453\n",
      "Epoch 19: val_acc did not improve from 0.75417\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5361 - acc: 0.7443 - val_loss: 0.5269 - val_acc: 0.7418\n",
      "Epoch 20/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5321 - acc: 0.7468\n",
      "Epoch 20: val_acc did not improve from 0.75417\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5321 - acc: 0.7464 - val_loss: 0.5357 - val_acc: 0.7512\n",
      "Epoch 21/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5308 - acc: 0.7565\n",
      "Epoch 21: val_acc improved from 0.75417 to 0.75631, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5311 - acc: 0.7554 - val_loss: 0.5441 - val_acc: 0.7563\n",
      "Epoch 22/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5485 - acc: 0.7468\n",
      "Epoch 22: val_acc did not improve from 0.75631\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5484 - acc: 0.7466 - val_loss: 0.5412 - val_acc: 0.7490\n",
      "Epoch 23/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5528 - acc: 0.7476\n",
      "Epoch 23: val_acc improved from 0.75631 to 0.75673, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5526 - acc: 0.7476 - val_loss: 0.5210 - val_acc: 0.7567\n",
      "Epoch 24/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5417 - acc: 0.7522\n",
      "Epoch 24: val_acc did not improve from 0.75673\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5416 - acc: 0.7522 - val_loss: 0.5272 - val_acc: 0.7478\n",
      "Epoch 25/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5335 - acc: 0.7559\n",
      "Epoch 25: val_acc did not improve from 0.75673\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5334 - acc: 0.7559 - val_loss: 0.5361 - val_acc: 0.7490\n",
      "Epoch 26/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5284 - acc: 0.7539\n",
      "Epoch 26: val_acc did not improve from 0.75673\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5282 - acc: 0.7540 - val_loss: 0.5326 - val_acc: 0.7503\n",
      "Epoch 27/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5313 - acc: 0.7512\n",
      "Epoch 27: val_acc did not improve from 0.75673\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5312 - acc: 0.7511 - val_loss: 0.5425 - val_acc: 0.7405\n",
      "Epoch 28/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5426 - acc: 0.7537\n",
      "Epoch 28: val_acc did not improve from 0.75673\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5421 - acc: 0.7534 - val_loss: 0.5266 - val_acc: 0.7478\n",
      "Epoch 29/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5383 - acc: 0.7573\n",
      "Epoch 29: val_acc improved from 0.75673 to 0.75973, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5378 - acc: 0.7573 - val_loss: 0.5298 - val_acc: 0.7597\n",
      "Epoch 30/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5365 - acc: 0.7582\n",
      "Epoch 30: val_acc did not improve from 0.75973\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5363 - acc: 0.7580 - val_loss: 0.5253 - val_acc: 0.7465\n",
      "Epoch 31/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5304 - acc: 0.7570\n",
      "Epoch 31: val_acc did not improve from 0.75973\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5314 - acc: 0.7560 - val_loss: 0.5438 - val_acc: 0.7448\n",
      "Epoch 32/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5318 - acc: 0.7597\n",
      "Epoch 32: val_acc improved from 0.75973 to 0.77127, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5316 - acc: 0.7598 - val_loss: 0.5290 - val_acc: 0.7713\n",
      "Epoch 33/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5333 - acc: 0.7628\n",
      "Epoch 33: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5332 - acc: 0.7629 - val_loss: 0.5543 - val_acc: 0.7657\n",
      "Epoch 34/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5334 - acc: 0.7615\n",
      "Epoch 34: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5329 - acc: 0.7610 - val_loss: 0.5433 - val_acc: 0.7546\n",
      "Epoch 35/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5261 - acc: 0.7639\n",
      "Epoch 35: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5259 - acc: 0.7638 - val_loss: 0.5273 - val_acc: 0.7546\n",
      "Epoch 36/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5237 - acc: 0.7657\n",
      "Epoch 36: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5234 - acc: 0.7650 - val_loss: 0.5218 - val_acc: 0.7589\n",
      "Epoch 37/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5225 - acc: 0.7643\n",
      "Epoch 37: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5229 - acc: 0.7630 - val_loss: 0.5228 - val_acc: 0.7465\n",
      "Epoch 38/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5355 - acc: 0.7651\n",
      "Epoch 38: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5347 - acc: 0.7647 - val_loss: 0.5176 - val_acc: 0.7653\n",
      "Epoch 39/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5301 - acc: 0.7659\n",
      "Epoch 39: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5301 - acc: 0.7659 - val_loss: 0.5366 - val_acc: 0.7644\n",
      "Epoch 40/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5417 - acc: 0.7637\n",
      "Epoch 40: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5415 - acc: 0.7637 - val_loss: 0.5252 - val_acc: 0.7563\n",
      "Epoch 41/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5084 - acc: 0.7690\n",
      "Epoch 41: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5090 - acc: 0.7681 - val_loss: 0.5447 - val_acc: 0.7537\n",
      "Epoch 42/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5146 - acc: 0.7680\n",
      "Epoch 42: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5151 - acc: 0.7672 - val_loss: 0.5211 - val_acc: 0.7439\n",
      "Epoch 43/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5268 - acc: 0.7622\n",
      "Epoch 43: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5268 - acc: 0.7622 - val_loss: 0.5269 - val_acc: 0.7576\n",
      "Epoch 44/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5218 - acc: 0.7689\n",
      "Epoch 44: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5214 - acc: 0.7687 - val_loss: 0.5431 - val_acc: 0.7593\n",
      "Epoch 45/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5263 - acc: 0.7649\n",
      "Epoch 45: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5314 - acc: 0.7638 - val_loss: 0.5201 - val_acc: 0.7533\n",
      "Epoch 46/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5161 - acc: 0.7643\n",
      "Epoch 46: val_acc did not improve from 0.77127\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5160 - acc: 0.7641 - val_loss: 0.5359 - val_acc: 0.7503\n",
      "Epoch 47/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5170 - acc: 0.7723\n",
      "Epoch 47: val_acc improved from 0.77127 to 0.77982, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5170 - acc: 0.7723 - val_loss: 0.5400 - val_acc: 0.7798\n",
      "Epoch 48/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5281 - acc: 0.7703\n",
      "Epoch 48: val_acc did not improve from 0.77982\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5281 - acc: 0.7692 - val_loss: 0.5438 - val_acc: 0.7555\n",
      "Epoch 49/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5149 - acc: 0.7696\n",
      "Epoch 49: val_acc did not improve from 0.77982\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.5152 - acc: 0.7689 - val_loss: 0.5316 - val_acc: 0.7649\n",
      "Epoch 50/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5310 - acc: 0.7707\n",
      "Epoch 50: val_acc did not improve from 0.77982\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.5305 - acc: 0.7705 - val_loss: 0.5195 - val_acc: 0.7691\n",
      "Epoch 51/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5228 - acc: 0.7667\n",
      "Epoch 51: val_acc did not improve from 0.77982\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5226 - acc: 0.7668 - val_loss: 0.5339 - val_acc: 0.7563\n",
      "Epoch 52/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5070 - acc: 0.7795\n",
      "Epoch 52: val_acc did not improve from 0.77982\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.5071 - acc: 0.7787 - val_loss: 0.5382 - val_acc: 0.7760\n",
      "Epoch 53/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5270 - acc: 0.7677\n",
      "Epoch 53: val_acc did not improve from 0.77982\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5271 - acc: 0.7666 - val_loss: 0.5298 - val_acc: 0.7708\n",
      "Epoch 54/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5159 - acc: 0.7709\n",
      "Epoch 54: val_acc did not improve from 0.77982\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5159 - acc: 0.7709 - val_loss: 0.5118 - val_acc: 0.7661\n",
      "Epoch 55/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5068 - acc: 0.7805\n",
      "Epoch 55: val_acc improved from 0.77982 to 0.79478, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5063 - acc: 0.7800 - val_loss: 0.5230 - val_acc: 0.7948\n",
      "Epoch 56/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5111 - acc: 0.7727\n",
      "Epoch 56: val_acc did not improve from 0.79478\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5109 - acc: 0.7728 - val_loss: 0.5530 - val_acc: 0.7627\n",
      "Epoch 57/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5346 - acc: 0.7753\n",
      "Epoch 57: val_acc did not improve from 0.79478\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5344 - acc: 0.7743 - val_loss: 0.5205 - val_acc: 0.7678\n",
      "Epoch 58/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5049 - acc: 0.7836\n",
      "Epoch 58: val_acc did not improve from 0.79478\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5056 - acc: 0.7833 - val_loss: 0.5270 - val_acc: 0.7777\n",
      "Epoch 59/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5147 - acc: 0.7809\n",
      "Epoch 59: val_acc did not improve from 0.79478\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5149 - acc: 0.7802 - val_loss: 0.5390 - val_acc: 0.7614\n",
      "Epoch 60/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5110 - acc: 0.7749\n",
      "Epoch 60: val_acc did not improve from 0.79478\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5116 - acc: 0.7737 - val_loss: 0.5270 - val_acc: 0.7678\n",
      "Epoch 61/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5145 - acc: 0.7759\n",
      "Epoch 61: val_acc did not improve from 0.79478\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5145 - acc: 0.7759 - val_loss: 0.5205 - val_acc: 0.7892\n",
      "Epoch 62/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5231 - acc: 0.7748\n",
      "Epoch 62: val_acc did not improve from 0.79478\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5230 - acc: 0.7741 - val_loss: 0.5258 - val_acc: 0.7602\n",
      "Epoch 63/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5190 - acc: 0.7789\n",
      "Epoch 63: val_acc did not improve from 0.79478\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5192 - acc: 0.7786 - val_loss: 0.5373 - val_acc: 0.7764\n",
      "Epoch 64/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5073 - acc: 0.7835\n",
      "Epoch 64: val_acc improved from 0.79478 to 0.79649, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5073 - acc: 0.7835 - val_loss: 0.5308 - val_acc: 0.7965\n",
      "Epoch 65/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5058 - acc: 0.7823\n",
      "Epoch 65: val_acc did not improve from 0.79649\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5067 - acc: 0.7813 - val_loss: 0.5365 - val_acc: 0.7785\n",
      "Epoch 66/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5003 - acc: 0.7832\n",
      "Epoch 66: val_acc did not improve from 0.79649\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5000 - acc: 0.7831 - val_loss: 0.5277 - val_acc: 0.7884\n",
      "Epoch 67/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5064 - acc: 0.7836\n",
      "Epoch 67: val_acc did not improve from 0.79649\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5062 - acc: 0.7836 - val_loss: 0.5424 - val_acc: 0.7914\n",
      "Epoch 68/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5118 - acc: 0.7846\n",
      "Epoch 68: val_acc did not improve from 0.79649\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5112 - acc: 0.7848 - val_loss: 0.5211 - val_acc: 0.7730\n",
      "Epoch 69/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4982 - acc: 0.7818\n",
      "Epoch 69: val_acc did not improve from 0.79649\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4982 - acc: 0.7818 - val_loss: 0.5412 - val_acc: 0.7704\n",
      "Epoch 70/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4935 - acc: 0.7861\n",
      "Epoch 70: val_acc did not improve from 0.79649\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4933 - acc: 0.7852 - val_loss: 0.5535 - val_acc: 0.7815\n",
      "Epoch 71/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4893 - acc: 0.7887\n",
      "Epoch 71: val_acc did not improve from 0.79649\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4894 - acc: 0.7878 - val_loss: 0.5279 - val_acc: 0.7717\n",
      "Epoch 72/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4961 - acc: 0.7839\n",
      "Epoch 72: val_acc did not improve from 0.79649\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4960 - acc: 0.7831 - val_loss: 0.5473 - val_acc: 0.7828\n",
      "Epoch 73/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5068 - acc: 0.7888\n",
      "Epoch 73: val_acc did not improve from 0.79649\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5064 - acc: 0.7880 - val_loss: 0.5298 - val_acc: 0.7781\n",
      "Epoch 74/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5061 - acc: 0.7830\n",
      "Epoch 74: val_acc did not improve from 0.79649\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5059 - acc: 0.7826 - val_loss: 0.5162 - val_acc: 0.7696\n",
      "Epoch 75/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5028 - acc: 0.7904\n",
      "Epoch 75: val_acc did not improve from 0.79649\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5028 - acc: 0.7904 - val_loss: 0.5068 - val_acc: 0.7901\n",
      "Epoch 76/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5059 - acc: 0.7901\n",
      "Epoch 76: val_acc improved from 0.79649 to 0.80077, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5052 - acc: 0.7894 - val_loss: 0.5565 - val_acc: 0.8008\n",
      "Epoch 77/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4916 - acc: 0.7864\n",
      "Epoch 77: val_acc did not improve from 0.80077\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4916 - acc: 0.7864 - val_loss: 0.5269 - val_acc: 0.7743\n",
      "Epoch 78/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4898 - acc: 0.7884\n",
      "Epoch 78: val_acc did not improve from 0.80077\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4893 - acc: 0.7878 - val_loss: 0.5447 - val_acc: 0.7922\n",
      "Epoch 79/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4942 - acc: 0.7857\n",
      "Epoch 79: val_acc did not improve from 0.80077\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4948 - acc: 0.7846 - val_loss: 0.5329 - val_acc: 0.7734\n",
      "Epoch 80/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4992 - acc: 0.7905\n",
      "Epoch 80: val_acc did not improve from 0.80077\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4985 - acc: 0.7907 - val_loss: 0.5286 - val_acc: 0.8008\n",
      "Epoch 81/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4892 - acc: 0.7949\n",
      "Epoch 81: val_acc did not improve from 0.80077\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4885 - acc: 0.7940 - val_loss: 0.5319 - val_acc: 0.7862\n",
      "Epoch 82/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5071 - acc: 0.7905\n",
      "Epoch 82: val_acc did not improve from 0.80077\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5069 - acc: 0.7906 - val_loss: 0.5399 - val_acc: 0.7700\n",
      "Epoch 83/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5202 - acc: 0.7902\n",
      "Epoch 83: val_acc did not improve from 0.80077\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5199 - acc: 0.7904 - val_loss: 0.5114 - val_acc: 0.7790\n",
      "Epoch 84/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4861 - acc: 0.7917\n",
      "Epoch 84: val_acc did not improve from 0.80077\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4855 - acc: 0.7914 - val_loss: 0.5247 - val_acc: 0.7969\n",
      "Epoch 85/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4831 - acc: 0.7925\n",
      "Epoch 85: val_acc improved from 0.80077 to 0.80248, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4825 - acc: 0.7920 - val_loss: 0.5124 - val_acc: 0.8025\n",
      "Epoch 86/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5061 - acc: 0.7932\n",
      "Epoch 86: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5061 - acc: 0.7932 - val_loss: 0.5462 - val_acc: 0.7961\n",
      "Epoch 87/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5182 - acc: 0.7959\n",
      "Epoch 87: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5182 - acc: 0.7959 - val_loss: 0.5124 - val_acc: 0.7871\n",
      "Epoch 88/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4821 - acc: 0.7955\n",
      "Epoch 88: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4822 - acc: 0.7944 - val_loss: 0.5493 - val_acc: 0.7879\n",
      "Epoch 89/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4959 - acc: 0.7943\n",
      "Epoch 89: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4957 - acc: 0.7937 - val_loss: 0.5356 - val_acc: 0.7897\n",
      "Epoch 90/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4961 - acc: 0.7882\n",
      "Epoch 90: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4958 - acc: 0.7880 - val_loss: 0.5433 - val_acc: 0.7931\n",
      "Epoch 91/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4923 - acc: 0.7891\n",
      "Epoch 91: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4921 - acc: 0.7891 - val_loss: 0.5222 - val_acc: 0.7965\n",
      "Epoch 92/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4995 - acc: 0.7978\n",
      "Epoch 92: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4989 - acc: 0.7971 - val_loss: 0.4850 - val_acc: 0.7815\n",
      "Epoch 93/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4749 - acc: 0.7960\n",
      "Epoch 93: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4747 - acc: 0.7956 - val_loss: 0.5156 - val_acc: 0.7773\n",
      "Epoch 94/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4821 - acc: 0.7953\n",
      "Epoch 94: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4821 - acc: 0.7953 - val_loss: 0.4893 - val_acc: 0.7973\n",
      "Epoch 95/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4951 - acc: 0.7976\n",
      "Epoch 95: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5045 - acc: 0.7972 - val_loss: 0.4924 - val_acc: 0.7961\n",
      "Epoch 96/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4867 - acc: 0.7972\n",
      "Epoch 96: val_acc improved from 0.80248 to 0.80590, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4862 - acc: 0.7971 - val_loss: 0.5023 - val_acc: 0.8059\n",
      "Epoch 97/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4730 - acc: 0.8001\n",
      "Epoch 97: val_acc improved from 0.80590 to 0.80718, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4725 - acc: 0.8004 - val_loss: 0.5362 - val_acc: 0.8072\n",
      "Epoch 98/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4696 - acc: 0.7979\n",
      "Epoch 98: val_acc did not improve from 0.80718\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4696 - acc: 0.7979 - val_loss: 0.5139 - val_acc: 0.7815\n",
      "Epoch 99/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4886 - acc: 0.7951\n",
      "Epoch 99: val_acc did not improve from 0.80718\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4885 - acc: 0.7952 - val_loss: 0.5246 - val_acc: 0.7965\n",
      "Epoch 100/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4970 - acc: 0.7968\n",
      "Epoch 100: val_acc improved from 0.80718 to 0.81531, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4965 - acc: 0.7965 - val_loss: 0.5370 - val_acc: 0.8153\n",
      "Epoch 101/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4918 - acc: 0.7984\n",
      "Epoch 101: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4918 - acc: 0.7984 - val_loss: 0.5173 - val_acc: 0.8008\n",
      "Epoch 102/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4920 - acc: 0.7951\n",
      "Epoch 102: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4919 - acc: 0.7950 - val_loss: 0.5200 - val_acc: 0.7837\n",
      "Epoch 103/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4753 - acc: 0.7969\n",
      "Epoch 103: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4753 - acc: 0.7969 - val_loss: 0.5101 - val_acc: 0.7850\n",
      "Epoch 104/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5186 - acc: 0.7984\n",
      "Epoch 104: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5180 - acc: 0.7987 - val_loss: 0.5058 - val_acc: 0.8025\n",
      "Epoch 105/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5218 - acc: 0.7967\n",
      "Epoch 105: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5209 - acc: 0.7963 - val_loss: 0.5133 - val_acc: 0.8003\n",
      "Epoch 106/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4653 - acc: 0.8005\n",
      "Epoch 106: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4647 - acc: 0.8001 - val_loss: 0.5091 - val_acc: 0.8110\n",
      "Epoch 107/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4605 - acc: 0.8046\n",
      "Epoch 107: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4601 - acc: 0.8041 - val_loss: 0.5149 - val_acc: 0.8042\n",
      "Epoch 108/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4735 - acc: 0.8008\n",
      "Epoch 108: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4730 - acc: 0.8003 - val_loss: 0.5225 - val_acc: 0.8012\n",
      "Epoch 109/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4694 - acc: 0.8026\n",
      "Epoch 109: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4694 - acc: 0.8026 - val_loss: 0.5070 - val_acc: 0.7961\n",
      "Epoch 110/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4691 - acc: 0.8028\n",
      "Epoch 110: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4686 - acc: 0.8025 - val_loss: 0.4713 - val_acc: 0.8063\n",
      "Epoch 111/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4785 - acc: 0.7994\n",
      "Epoch 111: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4776 - acc: 0.7991 - val_loss: 0.5052 - val_acc: 0.7986\n",
      "Epoch 112/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4717 - acc: 0.8025\n",
      "Epoch 112: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4725 - acc: 0.8021 - val_loss: 0.5135 - val_acc: 0.8050\n",
      "Epoch 113/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4775 - acc: 0.7985\n",
      "Epoch 113: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4775 - acc: 0.7985 - val_loss: 0.4965 - val_acc: 0.7982\n",
      "Epoch 114/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4708 - acc: 0.8072\n",
      "Epoch 114: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4703 - acc: 0.8072 - val_loss: 0.5364 - val_acc: 0.7926\n",
      "Epoch 115/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4522 - acc: 0.8001\n",
      "Epoch 115: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4514 - acc: 0.8003 - val_loss: 0.5301 - val_acc: 0.8076\n",
      "Epoch 116/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5183 - acc: 0.8012\n",
      "Epoch 116: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5162 - acc: 0.8009 - val_loss: 0.5043 - val_acc: 0.8097\n",
      "Epoch 117/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4885 - acc: 0.8068\n",
      "Epoch 117: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4880 - acc: 0.8064 - val_loss: 0.5225 - val_acc: 0.7969\n",
      "Epoch 118/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4758 - acc: 0.8008\n",
      "Epoch 118: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4755 - acc: 0.8004 - val_loss: 0.5412 - val_acc: 0.8080\n",
      "Epoch 119/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4644 - acc: 0.7953\n",
      "Epoch 119: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4644 - acc: 0.7952 - val_loss: 0.5130 - val_acc: 0.7845\n",
      "Epoch 120/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4839 - acc: 0.8034\n",
      "Epoch 120: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4849 - acc: 0.8028 - val_loss: 0.5269 - val_acc: 0.8093\n",
      "Epoch 121/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4920 - acc: 0.8039\n",
      "Epoch 121: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4912 - acc: 0.8041 - val_loss: 0.5017 - val_acc: 0.7995\n",
      "Epoch 122/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4950 - acc: 0.8055\n",
      "Epoch 122: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4946 - acc: 0.8058 - val_loss: 0.5024 - val_acc: 0.7991\n",
      "Epoch 123/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.8083\n",
      "Epoch 123: val_acc did not improve from 0.81531\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4689 - acc: 0.8075 - val_loss: 0.5330 - val_acc: 0.7969\n",
      "Epoch 124/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4696 - acc: 0.8080\n",
      "Epoch 124: val_acc improved from 0.81531 to 0.81744, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4695 - acc: 0.8073 - val_loss: 0.5334 - val_acc: 0.8174\n",
      "Epoch 125/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4859 - acc: 0.8101\n",
      "Epoch 125: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4844 - acc: 0.8096 - val_loss: 0.5167 - val_acc: 0.8050\n",
      "Epoch 126/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4850 - acc: 0.8062\n",
      "Epoch 126: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4857 - acc: 0.8057 - val_loss: 0.4862 - val_acc: 0.8145\n",
      "Epoch 127/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4711 - acc: 0.8058\n",
      "Epoch 127: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4759 - acc: 0.8056 - val_loss: 0.5279 - val_acc: 0.8038\n",
      "Epoch 128/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4720 - acc: 0.8113\n",
      "Epoch 128: val_acc did not improve from 0.81744\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4720 - acc: 0.8108 - val_loss: 0.5351 - val_acc: 0.7991\n",
      "Epoch 129/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4820 - acc: 0.8077\n",
      "Epoch 129: val_acc improved from 0.81744 to 0.81958, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4810 - acc: 0.8081 - val_loss: 0.5110 - val_acc: 0.8196\n",
      "Epoch 130/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4752 - acc: 0.8023\n",
      "Epoch 130: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4751 - acc: 0.8020 - val_loss: 0.5085 - val_acc: 0.7820\n",
      "Epoch 131/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4657 - acc: 0.8084\n",
      "Epoch 131: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4660 - acc: 0.8072 - val_loss: 0.5047 - val_acc: 0.7965\n",
      "Epoch 132/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4621 - acc: 0.8096\n",
      "Epoch 132: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4609 - acc: 0.8095 - val_loss: 0.5335 - val_acc: 0.8063\n",
      "Epoch 133/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4768 - acc: 0.8063\n",
      "Epoch 133: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4759 - acc: 0.8066 - val_loss: 0.5275 - val_acc: 0.7969\n",
      "Epoch 134/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5248 - acc: 0.8104\n",
      "Epoch 134: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5241 - acc: 0.8107 - val_loss: 0.5148 - val_acc: 0.8119\n",
      "Epoch 135/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4832 - acc: 0.8097\n",
      "Epoch 135: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4843 - acc: 0.8090 - val_loss: 0.5167 - val_acc: 0.7909\n",
      "Epoch 136/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.8069\n",
      "Epoch 136: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4581 - acc: 0.8063 - val_loss: 0.5132 - val_acc: 0.7978\n",
      "Epoch 137/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8140\n",
      "Epoch 137: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4638 - acc: 0.8136 - val_loss: 0.5457 - val_acc: 0.7944\n",
      "Epoch 138/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4960 - acc: 0.8043\n",
      "Epoch 138: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4955 - acc: 0.8045 - val_loss: 0.5436 - val_acc: 0.7999\n",
      "Epoch 139/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4657 - acc: 0.8095\n",
      "Epoch 139: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4662 - acc: 0.8086 - val_loss: 0.5262 - val_acc: 0.7969\n",
      "Epoch 140/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4705 - acc: 0.8127\n",
      "Epoch 140: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4700 - acc: 0.8126 - val_loss: 0.4743 - val_acc: 0.8021\n",
      "Epoch 141/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4561 - acc: 0.8045\n",
      "Epoch 141: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4554 - acc: 0.8041 - val_loss: 0.5102 - val_acc: 0.8093\n",
      "Epoch 142/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4827 - acc: 0.8071\n",
      "Epoch 142: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4818 - acc: 0.8068 - val_loss: 0.5060 - val_acc: 0.8102\n",
      "Epoch 143/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4473 - acc: 0.8060\n",
      "Epoch 143: val_acc did not improve from 0.81958\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4481 - acc: 0.8057 - val_loss: 0.4935 - val_acc: 0.8050\n",
      "Epoch 144/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4632 - acc: 0.8035\n",
      "Epoch 144: val_acc improved from 0.81958 to 0.82343, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4624 - acc: 0.8029 - val_loss: 0.5219 - val_acc: 0.8234\n",
      "Epoch 145/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4551 - acc: 0.8142\n",
      "Epoch 145: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4548 - acc: 0.8140 - val_loss: 0.5413 - val_acc: 0.8042\n",
      "Epoch 146/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4769 - acc: 0.8032\n",
      "Epoch 146: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4769 - acc: 0.8032 - val_loss: 0.5064 - val_acc: 0.7982\n",
      "Epoch 147/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4678 - acc: 0.8121\n",
      "Epoch 147: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4677 - acc: 0.8111 - val_loss: 0.5194 - val_acc: 0.7952\n",
      "Epoch 148/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4730 - acc: 0.8057\n",
      "Epoch 148: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4721 - acc: 0.8050 - val_loss: 0.5380 - val_acc: 0.7944\n",
      "Epoch 149/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4606 - acc: 0.8069\n",
      "Epoch 149: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4602 - acc: 0.8063 - val_loss: 0.5081 - val_acc: 0.7969\n",
      "Epoch 150/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4522 - acc: 0.8135\n",
      "Epoch 150: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4704 - acc: 0.8128 - val_loss: 0.5451 - val_acc: 0.8123\n",
      "Epoch 151/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4628 - acc: 0.8121\n",
      "Epoch 151: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4624 - acc: 0.8120 - val_loss: 0.5154 - val_acc: 0.7973\n",
      "Epoch 152/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4510 - acc: 0.8145\n",
      "Epoch 152: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4508 - acc: 0.8146 - val_loss: 0.5362 - val_acc: 0.7978\n",
      "Epoch 153/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4644 - acc: 0.8113\n",
      "Epoch 153: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4640 - acc: 0.8107 - val_loss: 0.5346 - val_acc: 0.7965\n",
      "Epoch 154/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4602 - acc: 0.8075\n",
      "Epoch 154: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4595 - acc: 0.8077 - val_loss: 0.5745 - val_acc: 0.8119\n",
      "Epoch 155/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4694 - acc: 0.8093\n",
      "Epoch 155: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4694 - acc: 0.8093 - val_loss: 0.5009 - val_acc: 0.8042\n",
      "Epoch 156/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4538 - acc: 0.8141\n",
      "Epoch 156: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5032 - acc: 0.8137 - val_loss: 0.5114 - val_acc: 0.7986\n",
      "Epoch 157/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4640 - acc: 0.8127\n",
      "Epoch 157: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4638 - acc: 0.8129 - val_loss: 0.5127 - val_acc: 0.8213\n",
      "Epoch 158/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4487 - acc: 0.8127\n",
      "Epoch 158: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4478 - acc: 0.8123 - val_loss: 0.5199 - val_acc: 0.8033\n",
      "Epoch 159/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4669 - acc: 0.8149\n",
      "Epoch 159: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4665 - acc: 0.8149 - val_loss: 0.5133 - val_acc: 0.8059\n",
      "Epoch 160/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4633 - acc: 0.8162\n",
      "Epoch 160: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4631 - acc: 0.8164 - val_loss: 0.5096 - val_acc: 0.8055\n",
      "Epoch 161/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4525 - acc: 0.8151\n",
      "Epoch 161: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4527 - acc: 0.8146 - val_loss: 0.5112 - val_acc: 0.7995\n",
      "Epoch 162/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.8148\n",
      "Epoch 162: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4609 - acc: 0.8143 - val_loss: 0.5135 - val_acc: 0.7926\n",
      "Epoch 163/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5107 - acc: 0.8131\n",
      "Epoch 163: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5105 - acc: 0.8131 - val_loss: 0.5090 - val_acc: 0.7879\n",
      "Epoch 164/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4715 - acc: 0.8110\n",
      "Epoch 164: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4691 - acc: 0.8114 - val_loss: 0.5405 - val_acc: 0.8072\n",
      "Epoch 165/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4702 - acc: 0.8100\n",
      "Epoch 165: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4702 - acc: 0.8100 - val_loss: 0.5342 - val_acc: 0.7858\n",
      "Epoch 166/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4520 - acc: 0.8152\n",
      "Epoch 166: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4514 - acc: 0.8151 - val_loss: 0.5121 - val_acc: 0.8136\n",
      "Epoch 167/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4993 - acc: 0.8078\n",
      "Epoch 167: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4993 - acc: 0.8078 - val_loss: 0.5295 - val_acc: 0.7696\n",
      "Epoch 168/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4696 - acc: 0.8127\n",
      "Epoch 168: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4679 - acc: 0.8126 - val_loss: 0.4992 - val_acc: 0.8192\n",
      "Epoch 169/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.8094\n",
      "Epoch 169: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4611 - acc: 0.8091 - val_loss: 0.5232 - val_acc: 0.8174\n",
      "Epoch 170/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4806 - acc: 0.8089\n",
      "Epoch 170: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4794 - acc: 0.8084 - val_loss: 0.5003 - val_acc: 0.7905\n",
      "Epoch 171/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4675 - acc: 0.8114\n",
      "Epoch 171: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4672 - acc: 0.8117 - val_loss: 0.5438 - val_acc: 0.8132\n",
      "Epoch 172/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4860 - acc: 0.8140\n",
      "Epoch 172: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4846 - acc: 0.8134 - val_loss: 0.5006 - val_acc: 0.8085\n",
      "Epoch 173/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4516 - acc: 0.8207\n",
      "Epoch 173: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4506 - acc: 0.8202 - val_loss: 0.5508 - val_acc: 0.7901\n",
      "Epoch 174/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4722 - acc: 0.8160\n",
      "Epoch 174: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4716 - acc: 0.8160 - val_loss: 0.5094 - val_acc: 0.7875\n",
      "Epoch 175/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4768 - acc: 0.8125\n",
      "Epoch 175: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4752 - acc: 0.8125 - val_loss: 0.5394 - val_acc: 0.8213\n",
      "Epoch 176/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4593 - acc: 0.8128\n",
      "Epoch 176: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4593 - acc: 0.8128 - val_loss: 0.5243 - val_acc: 0.8038\n",
      "Epoch 177/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4660 - acc: 0.8165\n",
      "Epoch 177: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4655 - acc: 0.8166 - val_loss: 0.5357 - val_acc: 0.7926\n",
      "Epoch 178/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4589 - acc: 0.8108\n",
      "Epoch 178: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4590 - acc: 0.8098 - val_loss: 0.4838 - val_acc: 0.7794\n",
      "Epoch 179/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4809 - acc: 0.8115\n",
      "Epoch 179: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4981 - acc: 0.8105 - val_loss: 0.5057 - val_acc: 0.7743\n",
      "Epoch 180/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4568 - acc: 0.8191\n",
      "Epoch 180: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4552 - acc: 0.8185 - val_loss: 0.5045 - val_acc: 0.8183\n",
      "Epoch 181/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4714 - acc: 0.8141\n",
      "Epoch 181: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4708 - acc: 0.8143 - val_loss: 0.5309 - val_acc: 0.8132\n",
      "Epoch 182/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4523 - acc: 0.8195\n",
      "Epoch 182: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4523 - acc: 0.8195 - val_loss: 0.4894 - val_acc: 0.8085\n",
      "Epoch 183/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4791 - acc: 0.8102\n",
      "Epoch 183: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4787 - acc: 0.8100 - val_loss: 0.5438 - val_acc: 0.8003\n",
      "Epoch 184/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.8108\n",
      "Epoch 184: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4576 - acc: 0.8111 - val_loss: 0.5061 - val_acc: 0.8110\n",
      "Epoch 185/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4715 - acc: 0.8146\n",
      "Epoch 185: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4711 - acc: 0.8142 - val_loss: 0.5310 - val_acc: 0.8119\n",
      "Epoch 186/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4605 - acc: 0.8113\n",
      "Epoch 186: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4603 - acc: 0.8109 - val_loss: 0.5302 - val_acc: 0.8072\n",
      "Epoch 187/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4638 - acc: 0.8134\n",
      "Epoch 187: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4630 - acc: 0.8130 - val_loss: 0.5237 - val_acc: 0.8042\n",
      "Epoch 188/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4775 - acc: 0.8150\n",
      "Epoch 188: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4767 - acc: 0.8152 - val_loss: 0.5031 - val_acc: 0.8204\n",
      "Epoch 189/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5419 - acc: 0.8160\n",
      "Epoch 189: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5411 - acc: 0.8152 - val_loss: 0.4809 - val_acc: 0.7824\n",
      "Epoch 190/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4719 - acc: 0.8116\n",
      "Epoch 190: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4735 - acc: 0.8109 - val_loss: 0.5408 - val_acc: 0.7922\n",
      "Epoch 191/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4695 - acc: 0.8182\n",
      "Epoch 191: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4794 - acc: 0.8176 - val_loss: 0.5634 - val_acc: 0.8068\n",
      "Epoch 192/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4712 - acc: 0.8171\n",
      "Epoch 192: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4702 - acc: 0.8173 - val_loss: 0.5538 - val_acc: 0.8102\n",
      "Epoch 193/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4858 - acc: 0.8161\n",
      "Epoch 193: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4855 - acc: 0.8161 - val_loss: 0.5055 - val_acc: 0.7879\n",
      "Epoch 194/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4897 - acc: 0.8179\n",
      "Epoch 194: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.5204 - acc: 0.8172 - val_loss: 0.5269 - val_acc: 0.8038\n",
      "Epoch 195/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4688 - acc: 0.8096\n",
      "Epoch 195: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4674 - acc: 0.8098 - val_loss: 0.5310 - val_acc: 0.8068\n",
      "Epoch 196/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4531 - acc: 0.8157\n",
      "Epoch 196: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4531 - acc: 0.8157 - val_loss: 0.5268 - val_acc: 0.8230\n",
      "Epoch 197/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4657 - acc: 0.8146\n",
      "Epoch 197: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4657 - acc: 0.8146 - val_loss: 0.5397 - val_acc: 0.8140\n",
      "Epoch 198/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4631 - acc: 0.8115\n",
      "Epoch 198: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4626 - acc: 0.8110 - val_loss: 0.5157 - val_acc: 0.8102\n",
      "Epoch 199/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4613 - acc: 0.8168\n",
      "Epoch 199: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4610 - acc: 0.8168 - val_loss: 0.5013 - val_acc: 0.7982\n",
      "Epoch 200/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5263 - acc: 0.8120\n",
      "Epoch 200: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5235 - acc: 0.8118 - val_loss: 0.5392 - val_acc: 0.8021\n",
      "Epoch 201/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4463 - acc: 0.8161\n",
      "Epoch 201: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4464 - acc: 0.8155 - val_loss: 0.5157 - val_acc: 0.8025\n",
      "Epoch 202/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4431 - acc: 0.8135\n",
      "Epoch 202: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4419 - acc: 0.8133 - val_loss: 0.5572 - val_acc: 0.7948\n",
      "Epoch 203/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4961 - acc: 0.8140\n",
      "Epoch 203: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4943 - acc: 0.8140 - val_loss: 0.5042 - val_acc: 0.8072\n",
      "Epoch 204/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4493 - acc: 0.8175\n",
      "Epoch 204: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4489 - acc: 0.8176 - val_loss: 0.4932 - val_acc: 0.8038\n",
      "Epoch 205/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4732 - acc: 0.8152\n",
      "Epoch 205: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4723 - acc: 0.8150 - val_loss: 0.4809 - val_acc: 0.8115\n",
      "Epoch 206/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5134 - acc: 0.8138\n",
      "Epoch 206: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5117 - acc: 0.8134 - val_loss: 0.4738 - val_acc: 0.8102\n",
      "Epoch 207/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4575 - acc: 0.8127\n",
      "Epoch 207: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4571 - acc: 0.8121 - val_loss: 0.5370 - val_acc: 0.7939\n",
      "Epoch 208/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4691 - acc: 0.8184\n",
      "Epoch 208: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4685 - acc: 0.8177 - val_loss: 0.5360 - val_acc: 0.7845\n",
      "Epoch 209/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4746 - acc: 0.8121\n",
      "Epoch 209: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4734 - acc: 0.8120 - val_loss: 0.4836 - val_acc: 0.8157\n",
      "Epoch 210/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4989 - acc: 0.8162\n",
      "Epoch 210: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4970 - acc: 0.8164 - val_loss: 0.5044 - val_acc: 0.8157\n",
      "Epoch 211/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4603 - acc: 0.8151\n",
      "Epoch 211: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4596 - acc: 0.8151 - val_loss: 0.5009 - val_acc: 0.8076\n",
      "Epoch 212/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4745 - acc: 0.8131\n",
      "Epoch 212: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4745 - acc: 0.8131 - val_loss: 0.4888 - val_acc: 0.8187\n",
      "Epoch 213/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4452 - acc: 0.8211\n",
      "Epoch 213: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4446 - acc: 0.8211 - val_loss: 0.4891 - val_acc: 0.8097\n",
      "Epoch 214/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4700 - acc: 0.8222\n",
      "Epoch 214: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5031 - acc: 0.8217 - val_loss: 0.5123 - val_acc: 0.8080\n",
      "Epoch 215/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4356 - acc: 0.8188\n",
      "Epoch 215: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4356 - acc: 0.8188 - val_loss: 0.4786 - val_acc: 0.8106\n",
      "Epoch 216/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4562 - acc: 0.8181\n",
      "Epoch 216: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4555 - acc: 0.8174 - val_loss: 0.5020 - val_acc: 0.8038\n",
      "Epoch 217/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4835 - acc: 0.8193\n",
      "Epoch 217: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4835 - acc: 0.8193 - val_loss: 0.5108 - val_acc: 0.8072\n",
      "Epoch 218/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4795 - acc: 0.8187\n",
      "Epoch 218: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4788 - acc: 0.8187 - val_loss: 0.4934 - val_acc: 0.7982\n",
      "Epoch 219/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4680 - acc: 0.8195\n",
      "Epoch 219: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4679 - acc: 0.8188 - val_loss: 0.4846 - val_acc: 0.8033\n",
      "Epoch 220/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4506 - acc: 0.8180\n",
      "Epoch 220: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4506 - acc: 0.8180 - val_loss: 0.5083 - val_acc: 0.8110\n",
      "Epoch 221/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4555 - acc: 0.8177\n",
      "Epoch 221: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4550 - acc: 0.8174 - val_loss: 0.5196 - val_acc: 0.8072\n",
      "Epoch 222/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4540 - acc: 0.8181\n",
      "Epoch 222: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4538 - acc: 0.8182 - val_loss: 0.5081 - val_acc: 0.8106\n",
      "Epoch 223/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4537 - acc: 0.8211\n",
      "Epoch 223: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4534 - acc: 0.8203 - val_loss: 0.4810 - val_acc: 0.8093\n",
      "Epoch 224/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4521 - acc: 0.8236\n",
      "Epoch 224: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4519 - acc: 0.8231 - val_loss: 0.5207 - val_acc: 0.7991\n",
      "Epoch 225/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4477 - acc: 0.8177\n",
      "Epoch 225: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4477 - acc: 0.8177 - val_loss: 0.5004 - val_acc: 0.8076\n",
      "Epoch 226/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4500 - acc: 0.8176\n",
      "Epoch 226: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4497 - acc: 0.8176 - val_loss: 0.5061 - val_acc: 0.7978\n",
      "Epoch 227/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4746 - acc: 0.8194\n",
      "Epoch 227: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4738 - acc: 0.8193 - val_loss: 0.5004 - val_acc: 0.8136\n",
      "Epoch 228/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4723 - acc: 0.8171\n",
      "Epoch 228: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4723 - acc: 0.8164 - val_loss: 0.4867 - val_acc: 0.8063\n",
      "Epoch 229/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4771 - acc: 0.8178\n",
      "Epoch 229: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4748 - acc: 0.8179 - val_loss: 0.4933 - val_acc: 0.8123\n",
      "Epoch 230/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4586 - acc: 0.8224\n",
      "Epoch 230: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4583 - acc: 0.8223 - val_loss: 0.5165 - val_acc: 0.8217\n",
      "Epoch 231/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4485 - acc: 0.8189\n",
      "Epoch 231: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4485 - acc: 0.8189 - val_loss: 0.5085 - val_acc: 0.8016\n",
      "Epoch 232/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4648 - acc: 0.8194\n",
      "Epoch 232: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4886 - acc: 0.8191 - val_loss: 0.4990 - val_acc: 0.8059\n",
      "Epoch 233/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4891 - acc: 0.8168\n",
      "Epoch 233: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4888 - acc: 0.8169 - val_loss: 0.4827 - val_acc: 0.8059\n",
      "Epoch 234/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4631 - acc: 0.8187\n",
      "Epoch 234: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4662 - acc: 0.8184 - val_loss: 0.4993 - val_acc: 0.7995\n",
      "Epoch 235/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4400 - acc: 0.8290\n",
      "Epoch 235: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4394 - acc: 0.8286 - val_loss: 0.4764 - val_acc: 0.8097\n",
      "Epoch 236/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.8232\n",
      "Epoch 236: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4609 - acc: 0.8224 - val_loss: 0.4985 - val_acc: 0.7986\n",
      "Epoch 237/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4722 - acc: 0.8230\n",
      "Epoch 237: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4718 - acc: 0.8224 - val_loss: 0.5066 - val_acc: 0.8068\n",
      "Epoch 238/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4467 - acc: 0.8233\n",
      "Epoch 238: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4458 - acc: 0.8232 - val_loss: 0.4878 - val_acc: 0.8025\n",
      "Epoch 239/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4567 - acc: 0.8201\n",
      "Epoch 239: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4563 - acc: 0.8197 - val_loss: 0.4864 - val_acc: 0.7999\n",
      "Epoch 240/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4470 - acc: 0.8214\n",
      "Epoch 240: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4465 - acc: 0.8211 - val_loss: 0.5340 - val_acc: 0.7897\n",
      "Epoch 241/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4527 - acc: 0.8167\n",
      "Epoch 241: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4533 - acc: 0.8168 - val_loss: 0.4955 - val_acc: 0.8140\n",
      "Epoch 242/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4666 - acc: 0.8205\n",
      "Epoch 242: val_acc did not improve from 0.82343\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4649 - acc: 0.8207 - val_loss: 0.4992 - val_acc: 0.8187\n",
      "Epoch 243/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.8220\n",
      "Epoch 243: val_acc improved from 0.82343 to 0.82984, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/2/256/best_model.h5\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4611 - acc: 0.8221 - val_loss: 0.4958 - val_acc: 0.8298\n",
      "Epoch 244/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4652 - acc: 0.8190\n",
      "Epoch 244: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4647 - acc: 0.8184 - val_loss: 0.4841 - val_acc: 0.8149\n",
      "Epoch 245/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8218\n",
      "Epoch 245: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4413 - acc: 0.8211 - val_loss: 0.4845 - val_acc: 0.7973\n",
      "Epoch 246/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4515 - acc: 0.8233\n",
      "Epoch 246: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4513 - acc: 0.8228 - val_loss: 0.5203 - val_acc: 0.8003\n",
      "Epoch 247/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.8227\n",
      "Epoch 247: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4676 - acc: 0.8228 - val_loss: 0.4744 - val_acc: 0.8076\n",
      "Epoch 248/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4556 - acc: 0.8174\n",
      "Epoch 248: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4544 - acc: 0.8173 - val_loss: 0.4724 - val_acc: 0.8102\n",
      "Epoch 249/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4543 - acc: 0.8259\n",
      "Epoch 249: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4543 - acc: 0.8259 - val_loss: 0.4714 - val_acc: 0.8021\n",
      "Epoch 250/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4436 - acc: 0.8190\n",
      "Epoch 250: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4427 - acc: 0.8186 - val_loss: 0.4797 - val_acc: 0.8008\n",
      "Epoch 251/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4957 - acc: 0.8183\n",
      "Epoch 251: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4933 - acc: 0.8184 - val_loss: 0.4494 - val_acc: 0.8068\n",
      "Epoch 252/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4522 - acc: 0.8181\n",
      "Epoch 252: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4519 - acc: 0.8182 - val_loss: 0.4754 - val_acc: 0.8192\n",
      "Epoch 253/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4689 - acc: 0.8224\n",
      "Epoch 253: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4677 - acc: 0.8221 - val_loss: 0.5012 - val_acc: 0.7991\n",
      "Epoch 254/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4584 - acc: 0.8175\n",
      "Epoch 254: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4578 - acc: 0.8172 - val_loss: 0.4935 - val_acc: 0.8080\n",
      "Epoch 255/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4556 - acc: 0.8218\n",
      "Epoch 255: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4542 - acc: 0.8216 - val_loss: 0.5030 - val_acc: 0.8050\n",
      "Epoch 256/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4488 - acc: 0.8207\n",
      "Epoch 256: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4483 - acc: 0.8204 - val_loss: 0.4895 - val_acc: 0.8183\n",
      "Epoch 257/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4694 - acc: 0.8225\n",
      "Epoch 257: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4688 - acc: 0.8224 - val_loss: 0.4588 - val_acc: 0.8192\n",
      "Epoch 258/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4417 - acc: 0.8259\n",
      "Epoch 258: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4415 - acc: 0.8258 - val_loss: 0.5002 - val_acc: 0.7982\n",
      "Epoch 259/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4479 - acc: 0.8245\n",
      "Epoch 259: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4495 - acc: 0.8236 - val_loss: 0.4967 - val_acc: 0.8230\n",
      "Epoch 260/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4839 - acc: 0.8295\n",
      "Epoch 260: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4837 - acc: 0.8295 - val_loss: 0.5064 - val_acc: 0.8127\n",
      "Epoch 261/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.8253\n",
      "Epoch 261: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4618 - acc: 0.8252 - val_loss: 0.4906 - val_acc: 0.8166\n",
      "Epoch 262/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4422 - acc: 0.8250\n",
      "Epoch 262: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4422 - acc: 0.8250 - val_loss: 0.5111 - val_acc: 0.7948\n",
      "Epoch 263/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4659 - acc: 0.8188\n",
      "Epoch 263: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4658 - acc: 0.8186 - val_loss: 0.5057 - val_acc: 0.8187\n",
      "Epoch 264/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4556 - acc: 0.8208\n",
      "Epoch 264: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4552 - acc: 0.8206 - val_loss: 0.4938 - val_acc: 0.8025\n",
      "Epoch 265/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8185\n",
      "Epoch 265: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4408 - acc: 0.8185 - val_loss: 0.4840 - val_acc: 0.7905\n",
      "Epoch 266/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4809 - acc: 0.8241\n",
      "Epoch 266: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4806 - acc: 0.8241 - val_loss: 0.4797 - val_acc: 0.7905\n",
      "Epoch 267/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4527 - acc: 0.8244\n",
      "Epoch 267: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4520 - acc: 0.8241 - val_loss: 0.4967 - val_acc: 0.8127\n",
      "Epoch 268/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4586 - acc: 0.8221\n",
      "Epoch 268: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4576 - acc: 0.8217 - val_loss: 0.4749 - val_acc: 0.8033\n",
      "Epoch 269/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4486 - acc: 0.8233\n",
      "Epoch 269: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 5s 12ms/step - loss: 0.4484 - acc: 0.8232 - val_loss: 0.4658 - val_acc: 0.8260\n",
      "Epoch 270/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4493 - acc: 0.8268\n",
      "Epoch 270: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4485 - acc: 0.8265 - val_loss: 0.4810 - val_acc: 0.8085\n",
      "Epoch 271/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4393 - acc: 0.8231\n",
      "Epoch 271: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4595 - acc: 0.8231 - val_loss: 0.4872 - val_acc: 0.8072\n",
      "Epoch 272/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4516 - acc: 0.8282\n",
      "Epoch 272: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4499 - acc: 0.8283 - val_loss: 0.5103 - val_acc: 0.7961\n",
      "Epoch 273/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4497 - acc: 0.8242\n",
      "Epoch 273: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4497 - acc: 0.8242 - val_loss: 0.5145 - val_acc: 0.8281\n",
      "Epoch 274/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4707 - acc: 0.8237\n",
      "Epoch 274: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4707 - acc: 0.8237 - val_loss: 0.4989 - val_acc: 0.7837\n",
      "Epoch 275/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4608 - acc: 0.8214\n",
      "Epoch 275: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4601 - acc: 0.8214 - val_loss: 0.4976 - val_acc: 0.8102\n",
      "Epoch 276/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4576 - acc: 0.8237\n",
      "Epoch 276: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4570 - acc: 0.8232 - val_loss: 0.4821 - val_acc: 0.8068\n",
      "Epoch 277/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4570 - acc: 0.8228\n",
      "Epoch 277: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4565 - acc: 0.8227 - val_loss: 0.4935 - val_acc: 0.8268\n",
      "Epoch 278/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4612 - acc: 0.8175\n",
      "Epoch 278: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4605 - acc: 0.8173 - val_loss: 0.5090 - val_acc: 0.8251\n",
      "Epoch 279/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4529 - acc: 0.8231\n",
      "Epoch 279: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4529 - acc: 0.8230 - val_loss: 0.5129 - val_acc: 0.7794\n",
      "Epoch 280/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4510 - acc: 0.8237\n",
      "Epoch 280: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4502 - acc: 0.8235 - val_loss: 0.4893 - val_acc: 0.8166\n",
      "Epoch 281/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.8212\n",
      "Epoch 281: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4690 - acc: 0.8213 - val_loss: 0.5087 - val_acc: 0.8157\n",
      "Epoch 282/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4821 - acc: 0.8245\n",
      "Epoch 282: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4817 - acc: 0.8246 - val_loss: 0.5037 - val_acc: 0.8140\n",
      "Epoch 283/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4624 - acc: 0.8263\n",
      "Epoch 283: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4613 - acc: 0.8260 - val_loss: 0.5121 - val_acc: 0.8106\n",
      "Epoch 284/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4444 - acc: 0.8277\n",
      "Epoch 284: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4441 - acc: 0.8272 - val_loss: 0.4830 - val_acc: 0.8162\n",
      "Epoch 285/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4622 - acc: 0.8258\n",
      "Epoch 285: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.4618 - acc: 0.8253 - val_loss: 0.4737 - val_acc: 0.8209\n",
      "Epoch 286/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5473 - acc: 0.8244\n",
      "Epoch 286: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5461 - acc: 0.8246 - val_loss: 0.4782 - val_acc: 0.8251\n",
      "Epoch 287/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4724 - acc: 0.8280\n",
      "Epoch 287: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4712 - acc: 0.8277 - val_loss: 0.5380 - val_acc: 0.8243\n",
      "Epoch 288/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4767 - acc: 0.8216\n",
      "Epoch 288: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 5s 19ms/step - loss: 0.4765 - acc: 0.8214 - val_loss: 0.4877 - val_acc: 0.8042\n",
      "Epoch 289/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4543 - acc: 0.8245\n",
      "Epoch 289: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4547 - acc: 0.8238 - val_loss: 0.5143 - val_acc: 0.7926\n",
      "Epoch 290/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4729 - acc: 0.8290\n",
      "Epoch 290: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4723 - acc: 0.8292 - val_loss: 0.4726 - val_acc: 0.8072\n",
      "Epoch 291/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4487 - acc: 0.8256\n",
      "Epoch 291: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4484 - acc: 0.8257 - val_loss: 0.4772 - val_acc: 0.8076\n",
      "Epoch 292/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4548 - acc: 0.8246\n",
      "Epoch 292: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4548 - acc: 0.8246 - val_loss: 0.4955 - val_acc: 0.7922\n",
      "Epoch 293/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4561 - acc: 0.8259\n",
      "Epoch 293: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4561 - acc: 0.8259 - val_loss: 0.5109 - val_acc: 0.7986\n",
      "Epoch 294/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4667 - acc: 0.8241\n",
      "Epoch 294: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4657 - acc: 0.8238 - val_loss: 0.4960 - val_acc: 0.8021\n",
      "Epoch 295/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4639 - acc: 0.8285\n",
      "Epoch 295: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4639 - acc: 0.8277 - val_loss: 0.4600 - val_acc: 0.8059\n",
      "Epoch 296/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4241 - acc: 0.8258\n",
      "Epoch 296: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4255 - acc: 0.8250 - val_loss: 0.5183 - val_acc: 0.8042\n",
      "Epoch 297/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4873 - acc: 0.8211\n",
      "Epoch 297: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4873 - acc: 0.8211 - val_loss: 0.4771 - val_acc: 0.8110\n",
      "Epoch 298/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4365 - acc: 0.8272\n",
      "Epoch 298: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4355 - acc: 0.8269 - val_loss: 0.4888 - val_acc: 0.8153\n",
      "Epoch 299/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4704 - acc: 0.8262\n",
      "Epoch 299: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4702 - acc: 0.8254 - val_loss: 0.5213 - val_acc: 0.7858\n",
      "Epoch 300/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4795 - acc: 0.8258\n",
      "Epoch 300: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4792 - acc: 0.8258 - val_loss: 0.5124 - val_acc: 0.7884\n",
      "Epoch 301/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4392 - acc: 0.8292\n",
      "Epoch 301: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4392 - acc: 0.8292 - val_loss: 0.4917 - val_acc: 0.7986\n",
      "Epoch 302/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4528 - acc: 0.8284\n",
      "Epoch 302: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4538 - acc: 0.8279 - val_loss: 0.4929 - val_acc: 0.8106\n",
      "Epoch 303/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4547 - acc: 0.8249\n",
      "Epoch 303: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4570 - acc: 0.8243 - val_loss: 0.4741 - val_acc: 0.8247\n",
      "Epoch 304/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4687 - acc: 0.8285\n",
      "Epoch 304: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4675 - acc: 0.8275 - val_loss: 0.4895 - val_acc: 0.7991\n",
      "Epoch 305/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4757 - acc: 0.8277\n",
      "Epoch 305: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4749 - acc: 0.8280 - val_loss: 0.4747 - val_acc: 0.7978\n",
      "Epoch 306/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4639 - acc: 0.8308\n",
      "Epoch 306: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4635 - acc: 0.8300 - val_loss: 0.5028 - val_acc: 0.7969\n",
      "Epoch 307/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4517 - acc: 0.8238\n",
      "Epoch 307: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4517 - acc: 0.8238 - val_loss: 0.5137 - val_acc: 0.7879\n",
      "Epoch 308/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4873 - acc: 0.8198\n",
      "Epoch 308: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4873 - acc: 0.8198 - val_loss: 0.4643 - val_acc: 0.8157\n",
      "Epoch 309/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4457 - acc: 0.8267\n",
      "Epoch 309: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4457 - acc: 0.8267 - val_loss: 0.4935 - val_acc: 0.8050\n",
      "Epoch 310/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4528 - acc: 0.8291\n",
      "Epoch 310: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4517 - acc: 0.8288 - val_loss: 0.4735 - val_acc: 0.8123\n",
      "Epoch 311/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4860 - acc: 0.8207\n",
      "Epoch 311: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4858 - acc: 0.8208 - val_loss: 0.4802 - val_acc: 0.7820\n",
      "Epoch 312/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4317 - acc: 0.8270\n",
      "Epoch 312: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4461 - acc: 0.8266 - val_loss: 0.4854 - val_acc: 0.8174\n",
      "Epoch 313/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4362 - acc: 0.8356\n",
      "Epoch 313: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4362 - acc: 0.8356 - val_loss: 0.5556 - val_acc: 0.8093\n",
      "Epoch 314/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4692 - acc: 0.8256\n",
      "Epoch 314: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4691 - acc: 0.8250 - val_loss: 0.5166 - val_acc: 0.7961\n",
      "Epoch 315/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4302 - acc: 0.8278\n",
      "Epoch 315: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4299 - acc: 0.8275 - val_loss: 0.5010 - val_acc: 0.8145\n",
      "Epoch 316/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4885 - acc: 0.8272\n",
      "Epoch 316: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4887 - acc: 0.8266 - val_loss: 0.4954 - val_acc: 0.7944\n",
      "Epoch 317/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4729 - acc: 0.8273\n",
      "Epoch 317: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4726 - acc: 0.8270 - val_loss: 0.4749 - val_acc: 0.8042\n",
      "Epoch 318/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4960 - acc: 0.8298\n",
      "Epoch 318: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4960 - acc: 0.8298 - val_loss: 0.4891 - val_acc: 0.8008\n",
      "Epoch 319/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4521 - acc: 0.8294\n",
      "Epoch 319: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4521 - acc: 0.8286 - val_loss: 0.5013 - val_acc: 0.8132\n",
      "Epoch 320/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4478 - acc: 0.8244\n",
      "Epoch 320: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4483 - acc: 0.8239 - val_loss: 0.5172 - val_acc: 0.8110\n",
      "Epoch 321/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4413 - acc: 0.8281\n",
      "Epoch 321: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4418 - acc: 0.8278 - val_loss: 0.4538 - val_acc: 0.8076\n",
      "Epoch 322/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4671 - acc: 0.8293\n",
      "Epoch 322: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4670 - acc: 0.8292 - val_loss: 0.5162 - val_acc: 0.8080\n",
      "Epoch 323/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4822 - acc: 0.8225\n",
      "Epoch 323: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4812 - acc: 0.8229 - val_loss: 0.4944 - val_acc: 0.8085\n",
      "Epoch 324/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4621 - acc: 0.8202\n",
      "Epoch 324: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4614 - acc: 0.8202 - val_loss: 0.4927 - val_acc: 0.8115\n",
      "Epoch 325/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4552 - acc: 0.8246\n",
      "Epoch 325: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 6s 19ms/step - loss: 0.4552 - acc: 0.8246 - val_loss: 0.4706 - val_acc: 0.8102\n",
      "Epoch 326/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4386 - acc: 0.8281\n",
      "Epoch 326: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4383 - acc: 0.8282 - val_loss: 0.4904 - val_acc: 0.8059\n",
      "Epoch 327/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4500 - acc: 0.8299\n",
      "Epoch 327: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4503 - acc: 0.8292 - val_loss: 0.4880 - val_acc: 0.8102\n",
      "Epoch 328/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4729 - acc: 0.8234\n",
      "Epoch 328: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4852 - acc: 0.8231 - val_loss: 0.4840 - val_acc: 0.8230\n",
      "Epoch 329/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4166 - acc: 0.8337\n",
      "Epoch 329: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4166 - acc: 0.8336 - val_loss: 0.5293 - val_acc: 0.8106\n",
      "Epoch 330/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4566 - acc: 0.8170\n",
      "Epoch 330: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4773 - acc: 0.8169 - val_loss: 0.4968 - val_acc: 0.8093\n",
      "Epoch 331/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4399 - acc: 0.8313\n",
      "Epoch 331: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4396 - acc: 0.8304 - val_loss: 0.4725 - val_acc: 0.8213\n",
      "Epoch 332/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5214 - acc: 0.8257\n",
      "Epoch 332: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5209 - acc: 0.8252 - val_loss: 0.4917 - val_acc: 0.8115\n",
      "Epoch 333/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4468 - acc: 0.8268\n",
      "Epoch 333: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4468 - acc: 0.8268 - val_loss: 0.4777 - val_acc: 0.8102\n",
      "Epoch 334/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4447 - acc: 0.8284\n",
      "Epoch 334: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4446 - acc: 0.8280 - val_loss: 0.4923 - val_acc: 0.7999\n",
      "Epoch 335/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4549 - acc: 0.8264\n",
      "Epoch 335: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4546 - acc: 0.8258 - val_loss: 0.5125 - val_acc: 0.8145\n",
      "Epoch 336/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8258\n",
      "Epoch 336: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4663 - acc: 0.8250 - val_loss: 0.4719 - val_acc: 0.8097\n",
      "Epoch 337/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4909 - acc: 0.8270\n",
      "Epoch 337: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4909 - acc: 0.8270 - val_loss: 0.5145 - val_acc: 0.8097\n",
      "Epoch 338/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4514 - acc: 0.8256\n",
      "Epoch 338: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4512 - acc: 0.8254 - val_loss: 0.4862 - val_acc: 0.8085\n",
      "Epoch 339/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4553 - acc: 0.8273\n",
      "Epoch 339: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4544 - acc: 0.8272 - val_loss: 0.5114 - val_acc: 0.8174\n",
      "Epoch 340/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4933 - acc: 0.8289\n",
      "Epoch 340: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4922 - acc: 0.8288 - val_loss: 0.5268 - val_acc: 0.8149\n",
      "Epoch 341/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4447 - acc: 0.8253\n",
      "Epoch 341: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4452 - acc: 0.8248 - val_loss: 0.5420 - val_acc: 0.8123\n",
      "Epoch 342/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4631 - acc: 0.8264\n",
      "Epoch 342: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4629 - acc: 0.8264 - val_loss: 0.5325 - val_acc: 0.8055\n",
      "Epoch 343/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4724 - acc: 0.8283\n",
      "Epoch 343: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4758 - acc: 0.8281 - val_loss: 0.5072 - val_acc: 0.8192\n",
      "Epoch 344/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4565 - acc: 0.8215\n",
      "Epoch 344: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4563 - acc: 0.8215 - val_loss: 0.5022 - val_acc: 0.7965\n",
      "Epoch 345/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4314 - acc: 0.8274\n",
      "Epoch 345: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4312 - acc: 0.8272 - val_loss: 0.5065 - val_acc: 0.8029\n",
      "Epoch 346/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4384 - acc: 0.8277\n",
      "Epoch 346: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4384 - acc: 0.8277 - val_loss: 0.4887 - val_acc: 0.8016\n",
      "Epoch 347/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4369 - acc: 0.8287\n",
      "Epoch 347: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4362 - acc: 0.8286 - val_loss: 0.4993 - val_acc: 0.8221\n",
      "Epoch 348/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5128 - acc: 0.8274\n",
      "Epoch 348: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5121 - acc: 0.8268 - val_loss: 0.5428 - val_acc: 0.8063\n",
      "Epoch 349/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5134 - acc: 0.8288\n",
      "Epoch 349: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5119 - acc: 0.8283 - val_loss: 0.5064 - val_acc: 0.8093\n",
      "Epoch 350/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5056 - acc: 0.8276\n",
      "Epoch 350: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.5056 - acc: 0.8276 - val_loss: 0.4892 - val_acc: 0.7991\n",
      "Epoch 351/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4444 - acc: 0.8301\n",
      "Epoch 351: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4444 - acc: 0.8301 - val_loss: 0.5161 - val_acc: 0.8174\n",
      "Epoch 352/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8207\n",
      "Epoch 352: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4642 - acc: 0.8199 - val_loss: 0.4943 - val_acc: 0.7952\n",
      "Epoch 353/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4537 - acc: 0.8343\n",
      "Epoch 353: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4530 - acc: 0.8343 - val_loss: 0.4993 - val_acc: 0.8187\n",
      "Epoch 354/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4332 - acc: 0.8302\n",
      "Epoch 354: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4330 - acc: 0.8300 - val_loss: 0.4701 - val_acc: 0.8119\n",
      "Epoch 355/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4960 - acc: 0.8291\n",
      "Epoch 355: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4960 - acc: 0.8291 - val_loss: 0.4931 - val_acc: 0.7918\n",
      "Epoch 356/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5045 - acc: 0.8266\n",
      "Epoch 356: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5045 - acc: 0.8266 - val_loss: 0.4794 - val_acc: 0.7961\n",
      "Epoch 357/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4598 - acc: 0.8317\n",
      "Epoch 357: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4579 - acc: 0.8316 - val_loss: 0.4872 - val_acc: 0.8132\n",
      "Epoch 358/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4585 - acc: 0.8263\n",
      "Epoch 358: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4577 - acc: 0.8259 - val_loss: 0.4754 - val_acc: 0.8021\n",
      "Epoch 359/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4944 - acc: 0.8240\n",
      "Epoch 359: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4938 - acc: 0.8234 - val_loss: 0.4694 - val_acc: 0.8145\n",
      "Epoch 360/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4352 - acc: 0.8291\n",
      "Epoch 360: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4342 - acc: 0.8293 - val_loss: 0.5090 - val_acc: 0.8200\n",
      "Epoch 361/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4442 - acc: 0.8266\n",
      "Epoch 361: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4440 - acc: 0.8266 - val_loss: 0.5215 - val_acc: 0.8050\n",
      "Epoch 362/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5054 - acc: 0.8312\n",
      "Epoch 362: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5043 - acc: 0.8314 - val_loss: 0.5326 - val_acc: 0.8217\n",
      "Epoch 363/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4426 - acc: 0.8297\n",
      "Epoch 363: val_acc did not improve from 0.82984\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4423 - acc: 0.8299 - val_loss: 0.5074 - val_acc: 0.8260\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_2 (Reshape)         (None, 96, 1)             0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               49664     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 313,089\n",
      "Trainable params: 313,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 1.6163 - acc: 0.5885\n",
      "Epoch 1: val_acc improved from -inf to 0.70457, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 4s 11ms/step - loss: 1.6077 - acc: 0.5877 - val_loss: 0.6229 - val_acc: 0.7046\n",
      "Epoch 2/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.6963 - acc: 0.6457\n",
      "Epoch 2: val_acc improved from 0.70457 to 0.71355, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.6963 - acc: 0.6453 - val_loss: 0.5758 - val_acc: 0.7136\n",
      "Epoch 3/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.6212 - acc: 0.6854\n",
      "Epoch 3: val_acc improved from 0.71355 to 0.72424, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.6214 - acc: 0.6848 - val_loss: 0.5620 - val_acc: 0.7242\n",
      "Epoch 4/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5937 - acc: 0.7082\n",
      "Epoch 4: val_acc improved from 0.72424 to 0.72467, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5938 - acc: 0.7082 - val_loss: 0.5659 - val_acc: 0.7247\n",
      "Epoch 5/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5829 - acc: 0.7107\n",
      "Epoch 5: val_acc improved from 0.72467 to 0.73407, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5830 - acc: 0.7107 - val_loss: 0.5422 - val_acc: 0.7341\n",
      "Epoch 6/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5721 - acc: 0.7238\n",
      "Epoch 6: val_acc improved from 0.73407 to 0.74049, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5716 - acc: 0.7236 - val_loss: 0.5212 - val_acc: 0.7405\n",
      "Epoch 7/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5644 - acc: 0.7241\n",
      "Epoch 7: val_acc improved from 0.74049 to 0.74562, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5646 - acc: 0.7234 - val_loss: 0.5179 - val_acc: 0.7456\n",
      "Epoch 8/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5610 - acc: 0.7263\n",
      "Epoch 8: val_acc improved from 0.74562 to 0.74989, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5609 - acc: 0.7262 - val_loss: 0.5220 - val_acc: 0.7499\n",
      "Epoch 9/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5590 - acc: 0.7307\n",
      "Epoch 9: val_acc did not improve from 0.74989\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5588 - acc: 0.7304 - val_loss: 0.5197 - val_acc: 0.7422\n",
      "Epoch 10/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5536 - acc: 0.7335\n",
      "Epoch 10: val_acc improved from 0.74989 to 0.75075, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.5536 - acc: 0.7335 - val_loss: 0.5409 - val_acc: 0.7507\n",
      "Epoch 11/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5472 - acc: 0.7385\n",
      "Epoch 11: val_acc did not improve from 0.75075\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5472 - acc: 0.7385 - val_loss: 0.5146 - val_acc: 0.7507\n",
      "Epoch 12/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5451 - acc: 0.7385\n",
      "Epoch 12: val_acc did not improve from 0.75075\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5450 - acc: 0.7385 - val_loss: 0.5140 - val_acc: 0.7465\n",
      "Epoch 13/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5458 - acc: 0.7372\n",
      "Epoch 13: val_acc did not improve from 0.75075\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5454 - acc: 0.7365 - val_loss: 0.5099 - val_acc: 0.7486\n",
      "Epoch 14/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5457 - acc: 0.7390\n",
      "Epoch 14: val_acc did not improve from 0.75075\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5455 - acc: 0.7382 - val_loss: 0.5213 - val_acc: 0.7486\n",
      "Epoch 15/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5514 - acc: 0.7422\n",
      "Epoch 15: val_acc improved from 0.75075 to 0.75460, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5513 - acc: 0.7418 - val_loss: 0.5129 - val_acc: 0.7546\n",
      "Epoch 16/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5453 - acc: 0.7432\n",
      "Epoch 16: val_acc did not improve from 0.75460\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5453 - acc: 0.7429 - val_loss: 0.5176 - val_acc: 0.7482\n",
      "Epoch 17/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5411 - acc: 0.7415\n",
      "Epoch 17: val_acc improved from 0.75460 to 0.75802, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5408 - acc: 0.7414 - val_loss: 0.5065 - val_acc: 0.7580\n",
      "Epoch 18/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5394 - acc: 0.7415\n",
      "Epoch 18: val_acc improved from 0.75802 to 0.76015, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5389 - acc: 0.7415 - val_loss: 0.5238 - val_acc: 0.7602\n",
      "Epoch 19/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5515 - acc: 0.7434\n",
      "Epoch 19: val_acc did not improve from 0.76015\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5512 - acc: 0.7432 - val_loss: 0.5026 - val_acc: 0.7525\n",
      "Epoch 20/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5414 - acc: 0.7404\n",
      "Epoch 20: val_acc did not improve from 0.76015\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5412 - acc: 0.7404 - val_loss: 0.5132 - val_acc: 0.7516\n",
      "Epoch 21/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5376 - acc: 0.7487\n",
      "Epoch 21: val_acc improved from 0.76015 to 0.76315, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5376 - acc: 0.7487 - val_loss: 0.5320 - val_acc: 0.7631\n",
      "Epoch 22/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5263 - acc: 0.7533\n",
      "Epoch 22: val_acc did not improve from 0.76315\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5265 - acc: 0.7525 - val_loss: 0.5089 - val_acc: 0.7559\n",
      "Epoch 23/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5421 - acc: 0.7462\n",
      "Epoch 23: val_acc improved from 0.76315 to 0.76828, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5411 - acc: 0.7460 - val_loss: 0.5129 - val_acc: 0.7683\n",
      "Epoch 24/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5403 - acc: 0.7484\n",
      "Epoch 24: val_acc did not improve from 0.76828\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5402 - acc: 0.7484 - val_loss: 0.5062 - val_acc: 0.7623\n",
      "Epoch 25/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5328 - acc: 0.7543\n",
      "Epoch 25: val_acc improved from 0.76828 to 0.76999, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5326 - acc: 0.7539 - val_loss: 0.5179 - val_acc: 0.7700\n",
      "Epoch 26/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5326 - acc: 0.7541\n",
      "Epoch 26: val_acc improved from 0.76999 to 0.78239, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.5326 - acc: 0.7541 - val_loss: 0.5279 - val_acc: 0.7824\n",
      "Epoch 27/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5468 - acc: 0.7534\n",
      "Epoch 27: val_acc did not improve from 0.78239\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5469 - acc: 0.7530 - val_loss: 0.5071 - val_acc: 0.7614\n",
      "Epoch 28/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5397 - acc: 0.7584\n",
      "Epoch 28: val_acc did not improve from 0.78239\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5397 - acc: 0.7584 - val_loss: 0.5170 - val_acc: 0.7781\n",
      "Epoch 29/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5385 - acc: 0.7564\n",
      "Epoch 29: val_acc did not improve from 0.78239\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5379 - acc: 0.7567 - val_loss: 0.5159 - val_acc: 0.7666\n",
      "Epoch 30/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5539 - acc: 0.7538\n",
      "Epoch 30: val_acc did not improve from 0.78239\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5534 - acc: 0.7533 - val_loss: 0.5030 - val_acc: 0.7602\n",
      "Epoch 31/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5288 - acc: 0.7573\n",
      "Epoch 31: val_acc did not improve from 0.78239\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5291 - acc: 0.7568 - val_loss: 0.5165 - val_acc: 0.7657\n",
      "Epoch 32/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5565 - acc: 0.7595\n",
      "Epoch 32: val_acc did not improve from 0.78239\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5550 - acc: 0.7597 - val_loss: 0.5166 - val_acc: 0.7721\n",
      "Epoch 33/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5384 - acc: 0.7583\n",
      "Epoch 33: val_acc did not improve from 0.78239\n",
      "293/293 [==============================] - 7s 23ms/step - loss: 0.5385 - acc: 0.7583 - val_loss: 0.5186 - val_acc: 0.7802\n",
      "Epoch 34/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5384 - acc: 0.7581\n",
      "Epoch 34: val_acc improved from 0.78239 to 0.78623, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5379 - acc: 0.7580 - val_loss: 0.5038 - val_acc: 0.7862\n",
      "Epoch 35/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5334 - acc: 0.7590\n",
      "Epoch 35: val_acc did not improve from 0.78623\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5333 - acc: 0.7591 - val_loss: 0.5515 - val_acc: 0.7687\n",
      "Epoch 36/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5299 - acc: 0.7638\n",
      "Epoch 36: val_acc did not improve from 0.78623\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5289 - acc: 0.7638 - val_loss: 0.5422 - val_acc: 0.7802\n",
      "Epoch 37/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5315 - acc: 0.7560\n",
      "Epoch 37: val_acc did not improve from 0.78623\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5315 - acc: 0.7560 - val_loss: 0.5353 - val_acc: 0.7832\n",
      "Epoch 38/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5515 - acc: 0.7619\n",
      "Epoch 38: val_acc did not improve from 0.78623\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5515 - acc: 0.7619 - val_loss: 0.5215 - val_acc: 0.7798\n",
      "Epoch 39/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5355 - acc: 0.7622\n",
      "Epoch 39: val_acc did not improve from 0.78623\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5348 - acc: 0.7621 - val_loss: 0.5166 - val_acc: 0.7785\n",
      "Epoch 40/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5353 - acc: 0.7641\n",
      "Epoch 40: val_acc did not improve from 0.78623\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5353 - acc: 0.7641 - val_loss: 0.5318 - val_acc: 0.7760\n",
      "Epoch 41/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5434 - acc: 0.7648\n",
      "Epoch 41: val_acc did not improve from 0.78623\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5428 - acc: 0.7642 - val_loss: 0.5241 - val_acc: 0.7572\n",
      "Epoch 42/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5316 - acc: 0.7659\n",
      "Epoch 42: val_acc did not improve from 0.78623\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5310 - acc: 0.7662 - val_loss: 0.5435 - val_acc: 0.7683\n",
      "Epoch 43/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5388 - acc: 0.7629\n",
      "Epoch 43: val_acc did not improve from 0.78623\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5378 - acc: 0.7629 - val_loss: 0.5153 - val_acc: 0.7636\n",
      "Epoch 44/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5409 - acc: 0.7616\n",
      "Epoch 44: val_acc improved from 0.78623 to 0.79136, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5409 - acc: 0.7616 - val_loss: 0.4985 - val_acc: 0.7914\n",
      "Epoch 45/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5239 - acc: 0.7635\n",
      "Epoch 45: val_acc did not improve from 0.79136\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5231 - acc: 0.7630 - val_loss: 0.5301 - val_acc: 0.7760\n",
      "Epoch 46/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5339 - acc: 0.7670\n",
      "Epoch 46: val_acc did not improve from 0.79136\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5334 - acc: 0.7666 - val_loss: 0.5244 - val_acc: 0.7897\n",
      "Epoch 47/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5281 - acc: 0.7676\n",
      "Epoch 47: val_acc did not improve from 0.79136\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5279 - acc: 0.7676 - val_loss: 0.5347 - val_acc: 0.7670\n",
      "Epoch 48/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5426 - acc: 0.7688\n",
      "Epoch 48: val_acc did not improve from 0.79136\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5418 - acc: 0.7684 - val_loss: 0.5266 - val_acc: 0.7832\n",
      "Epoch 49/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5221 - acc: 0.7654\n",
      "Epoch 49: val_acc did not improve from 0.79136\n",
      "293/293 [==============================] - 7s 22ms/step - loss: 0.5215 - acc: 0.7658 - val_loss: 0.5014 - val_acc: 0.7807\n",
      "Epoch 50/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5282 - acc: 0.7689\n",
      "Epoch 50: val_acc did not improve from 0.79136\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5280 - acc: 0.7686 - val_loss: 0.5844 - val_acc: 0.7623\n",
      "Epoch 51/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5599 - acc: 0.7635\n",
      "Epoch 51: val_acc did not improve from 0.79136\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5593 - acc: 0.7633 - val_loss: 0.5271 - val_acc: 0.7875\n",
      "Epoch 52/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5250 - acc: 0.7645\n",
      "Epoch 52: val_acc improved from 0.79136 to 0.79393, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5228 - acc: 0.7655 - val_loss: 0.5379 - val_acc: 0.7939\n",
      "Epoch 53/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5566 - acc: 0.7684\n",
      "Epoch 53: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5555 - acc: 0.7681 - val_loss: 0.5272 - val_acc: 0.7751\n",
      "Epoch 54/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5330 - acc: 0.7620\n",
      "Epoch 54: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5328 - acc: 0.7622 - val_loss: 0.5283 - val_acc: 0.7879\n",
      "Epoch 55/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5381 - acc: 0.7673\n",
      "Epoch 55: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5368 - acc: 0.7679 - val_loss: 0.5273 - val_acc: 0.7905\n",
      "Epoch 56/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5543 - acc: 0.7664\n",
      "Epoch 56: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5531 - acc: 0.7663 - val_loss: 0.5259 - val_acc: 0.7798\n",
      "Epoch 57/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5396 - acc: 0.7698\n",
      "Epoch 57: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5384 - acc: 0.7694 - val_loss: 0.5313 - val_acc: 0.7678\n",
      "Epoch 58/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5555 - acc: 0.7741\n",
      "Epoch 58: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5551 - acc: 0.7735 - val_loss: 0.5615 - val_acc: 0.7811\n",
      "Epoch 59/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5352 - acc: 0.7669\n",
      "Epoch 59: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5346 - acc: 0.7670 - val_loss: 0.5239 - val_acc: 0.7815\n",
      "Epoch 60/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5411 - acc: 0.7714\n",
      "Epoch 60: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5395 - acc: 0.7717 - val_loss: 0.5488 - val_acc: 0.7794\n",
      "Epoch 61/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5726 - acc: 0.7707\n",
      "Epoch 61: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5711 - acc: 0.7702 - val_loss: 0.5442 - val_acc: 0.7760\n",
      "Epoch 62/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5268 - acc: 0.7667\n",
      "Epoch 62: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5266 - acc: 0.7666 - val_loss: 0.5386 - val_acc: 0.7666\n",
      "Epoch 63/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5111 - acc: 0.7750\n",
      "Epoch 63: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5100 - acc: 0.7749 - val_loss: 0.5617 - val_acc: 0.7640\n",
      "Epoch 64/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5577 - acc: 0.7631\n",
      "Epoch 64: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5563 - acc: 0.7626 - val_loss: 0.5654 - val_acc: 0.7653\n",
      "Epoch 65/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5331 - acc: 0.7732\n",
      "Epoch 65: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5318 - acc: 0.7728 - val_loss: 0.5689 - val_acc: 0.7708\n",
      "Epoch 66/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5285 - acc: 0.7702\n",
      "Epoch 66: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5279 - acc: 0.7704 - val_loss: 0.5519 - val_acc: 0.7837\n",
      "Epoch 67/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5502 - acc: 0.7747\n",
      "Epoch 67: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5483 - acc: 0.7747 - val_loss: 0.5479 - val_acc: 0.7820\n",
      "Epoch 68/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5903 - acc: 0.7697\n",
      "Epoch 68: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5889 - acc: 0.7697 - val_loss: 0.5184 - val_acc: 0.7879\n",
      "Epoch 69/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5426 - acc: 0.7735\n",
      "Epoch 69: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5426 - acc: 0.7735 - val_loss: 0.5568 - val_acc: 0.7687\n",
      "Epoch 70/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5505 - acc: 0.7700\n",
      "Epoch 70: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5505 - acc: 0.7700 - val_loss: 0.5351 - val_acc: 0.7584\n",
      "Epoch 71/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5966 - acc: 0.7695\n",
      "Epoch 71: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5966 - acc: 0.7695 - val_loss: 0.5667 - val_acc: 0.7875\n",
      "Epoch 72/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5265 - acc: 0.7807\n",
      "Epoch 72: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5265 - acc: 0.7807 - val_loss: 0.5353 - val_acc: 0.7790\n",
      "Epoch 73/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5135 - acc: 0.7822\n",
      "Epoch 73: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5131 - acc: 0.7820 - val_loss: 0.5795 - val_acc: 0.7649\n",
      "Epoch 74/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5547 - acc: 0.7749\n",
      "Epoch 74: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5539 - acc: 0.7751 - val_loss: 0.5271 - val_acc: 0.7576\n",
      "Epoch 75/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5191 - acc: 0.7784\n",
      "Epoch 75: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5182 - acc: 0.7780 - val_loss: 0.5859 - val_acc: 0.7815\n",
      "Epoch 76/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5624 - acc: 0.7755\n",
      "Epoch 76: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.5621 - acc: 0.7755 - val_loss: 0.5686 - val_acc: 0.7931\n",
      "Epoch 77/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5540 - acc: 0.7779\n",
      "Epoch 77: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5529 - acc: 0.7785 - val_loss: 0.6071 - val_acc: 0.7909\n",
      "Epoch 78/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5497 - acc: 0.7737\n",
      "Epoch 78: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5497 - acc: 0.7737 - val_loss: 0.5856 - val_acc: 0.7879\n",
      "Epoch 79/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5378 - acc: 0.7823\n",
      "Epoch 79: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5378 - acc: 0.7823 - val_loss: 0.5928 - val_acc: 0.7854\n",
      "Epoch 80/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5525 - acc: 0.7777\n",
      "Epoch 80: val_acc did not improve from 0.79393\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5512 - acc: 0.7776 - val_loss: 0.5721 - val_acc: 0.7760\n",
      "Epoch 81/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5698 - acc: 0.7831\n",
      "Epoch 81: val_acc improved from 0.79393 to 0.79778, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5698 - acc: 0.7831 - val_loss: 0.5583 - val_acc: 0.7978\n",
      "Epoch 82/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5313 - acc: 0.7768\n",
      "Epoch 82: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5297 - acc: 0.7772 - val_loss: 0.5564 - val_acc: 0.7922\n",
      "Epoch 83/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5249 - acc: 0.7802\n",
      "Epoch 83: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5243 - acc: 0.7800 - val_loss: 0.5469 - val_acc: 0.7867\n",
      "Epoch 84/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5321 - acc: 0.7859\n",
      "Epoch 84: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5299 - acc: 0.7851 - val_loss: 0.5743 - val_acc: 0.7905\n",
      "Epoch 85/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5535 - acc: 0.7789\n",
      "Epoch 85: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5514 - acc: 0.7786 - val_loss: 0.5286 - val_acc: 0.7969\n",
      "Epoch 86/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5228 - acc: 0.7779\n",
      "Epoch 86: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5222 - acc: 0.7780 - val_loss: 0.5519 - val_acc: 0.7623\n",
      "Epoch 87/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5353 - acc: 0.7811\n",
      "Epoch 87: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5353 - acc: 0.7811 - val_loss: 0.5658 - val_acc: 0.7909\n",
      "Epoch 88/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5188 - acc: 0.7777\n",
      "Epoch 88: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5184 - acc: 0.7778 - val_loss: 0.5565 - val_acc: 0.7837\n",
      "Epoch 89/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5265 - acc: 0.7818\n",
      "Epoch 89: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5257 - acc: 0.7815 - val_loss: 0.5516 - val_acc: 0.7828\n",
      "Epoch 90/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5793 - acc: 0.7803\n",
      "Epoch 90: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5772 - acc: 0.7805 - val_loss: 0.5540 - val_acc: 0.7841\n",
      "Epoch 91/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5341 - acc: 0.7833\n",
      "Epoch 91: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5325 - acc: 0.7831 - val_loss: 0.5556 - val_acc: 0.7807\n",
      "Epoch 92/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5082 - acc: 0.7871\n",
      "Epoch 92: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5072 - acc: 0.7871 - val_loss: 0.6183 - val_acc: 0.7909\n",
      "Epoch 93/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5393 - acc: 0.7784\n",
      "Epoch 93: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5383 - acc: 0.7787 - val_loss: 0.5989 - val_acc: 0.7768\n",
      "Epoch 94/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5683 - acc: 0.7834\n",
      "Epoch 94: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5668 - acc: 0.7835 - val_loss: 0.5401 - val_acc: 0.7790\n",
      "Epoch 95/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5369 - acc: 0.7824\n",
      "Epoch 95: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5370 - acc: 0.7825 - val_loss: 0.5415 - val_acc: 0.7905\n",
      "Epoch 96/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5343 - acc: 0.7826\n",
      "Epoch 96: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5339 - acc: 0.7821 - val_loss: 0.6085 - val_acc: 0.7867\n",
      "Epoch 97/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5587 - acc: 0.7792\n",
      "Epoch 97: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5570 - acc: 0.7787 - val_loss: 0.5583 - val_acc: 0.7909\n",
      "Epoch 98/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5620 - acc: 0.7875\n",
      "Epoch 98: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5603 - acc: 0.7875 - val_loss: 0.5341 - val_acc: 0.7837\n",
      "Epoch 99/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5736 - acc: 0.7824\n",
      "Epoch 99: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5721 - acc: 0.7819 - val_loss: 0.5614 - val_acc: 0.7730\n",
      "Epoch 100/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5383 - acc: 0.7862\n",
      "Epoch 100: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5380 - acc: 0.7862 - val_loss: 0.6206 - val_acc: 0.7871\n",
      "Epoch 101/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5492 - acc: 0.7874\n",
      "Epoch 101: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5485 - acc: 0.7871 - val_loss: 0.5629 - val_acc: 0.7781\n",
      "Epoch 102/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5951 - acc: 0.7871\n",
      "Epoch 102: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5927 - acc: 0.7870 - val_loss: 0.6105 - val_acc: 0.7914\n",
      "Epoch 103/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5384 - acc: 0.7878\n",
      "Epoch 103: val_acc did not improve from 0.79778\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5378 - acc: 0.7878 - val_loss: 0.6130 - val_acc: 0.7888\n",
      "Epoch 104/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5320 - acc: 0.7861\n",
      "Epoch 104: val_acc improved from 0.79778 to 0.80162, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5311 - acc: 0.7858 - val_loss: 0.5268 - val_acc: 0.8016\n",
      "Epoch 105/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5234 - acc: 0.7917\n",
      "Epoch 105: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5214 - acc: 0.7916 - val_loss: 0.5671 - val_acc: 0.7862\n",
      "Epoch 106/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5845 - acc: 0.7853\n",
      "Epoch 106: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5825 - acc: 0.7851 - val_loss: 0.5480 - val_acc: 0.7956\n",
      "Epoch 107/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5255 - acc: 0.7888\n",
      "Epoch 107: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5255 - acc: 0.7887 - val_loss: 0.5752 - val_acc: 0.7764\n",
      "Epoch 108/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5405 - acc: 0.7936\n",
      "Epoch 108: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.5390 - acc: 0.7936 - val_loss: 0.5836 - val_acc: 0.7918\n",
      "Epoch 109/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5532 - acc: 0.7907\n",
      "Epoch 109: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5518 - acc: 0.7907 - val_loss: 0.5276 - val_acc: 0.8008\n",
      "Epoch 110/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5459 - acc: 0.7865\n",
      "Epoch 110: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5459 - acc: 0.7865 - val_loss: 0.5671 - val_acc: 0.7884\n",
      "Epoch 111/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5279 - acc: 0.7884\n",
      "Epoch 111: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5276 - acc: 0.7886 - val_loss: 0.5633 - val_acc: 0.7905\n",
      "Epoch 112/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5212 - acc: 0.7915\n",
      "Epoch 112: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5210 - acc: 0.7916 - val_loss: 0.5141 - val_acc: 0.7726\n",
      "Epoch 113/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5317 - acc: 0.7893\n",
      "Epoch 113: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5313 - acc: 0.7889 - val_loss: 0.5210 - val_acc: 0.7820\n",
      "Epoch 114/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.7927\n",
      "Epoch 114: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5256 - acc: 0.7927 - val_loss: 0.5145 - val_acc: 0.7760\n",
      "Epoch 115/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5150 - acc: 0.7957\n",
      "Epoch 115: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5141 - acc: 0.7953 - val_loss: 0.5445 - val_acc: 0.7948\n",
      "Epoch 116/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4952 - acc: 0.7943\n",
      "Epoch 116: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4952 - acc: 0.7943 - val_loss: 0.5419 - val_acc: 0.7999\n",
      "Epoch 117/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5350 - acc: 0.7900\n",
      "Epoch 117: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5338 - acc: 0.7901 - val_loss: 0.5821 - val_acc: 0.7969\n",
      "Epoch 118/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5429 - acc: 0.7896\n",
      "Epoch 118: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.5425 - acc: 0.7897 - val_loss: 0.5476 - val_acc: 0.8016\n",
      "Epoch 119/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5805 - acc: 0.7919\n",
      "Epoch 119: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5796 - acc: 0.7922 - val_loss: 0.5415 - val_acc: 0.7905\n",
      "Epoch 120/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5099 - acc: 0.7914\n",
      "Epoch 120: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.5083 - acc: 0.7918 - val_loss: 0.5954 - val_acc: 0.7935\n",
      "Epoch 121/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5309 - acc: 0.7975\n",
      "Epoch 121: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5286 - acc: 0.7974 - val_loss: 0.5265 - val_acc: 0.7944\n",
      "Epoch 122/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5411 - acc: 0.7914\n",
      "Epoch 122: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.5409 - acc: 0.7914 - val_loss: 0.5846 - val_acc: 0.7918\n",
      "Epoch 123/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4929 - acc: 0.7966\n",
      "Epoch 123: val_acc improved from 0.80162 to 0.80248, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4921 - acc: 0.7968 - val_loss: 0.6027 - val_acc: 0.8025\n",
      "Epoch 124/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5055 - acc: 0.7959\n",
      "Epoch 124: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5046 - acc: 0.7962 - val_loss: 0.5422 - val_acc: 0.7986\n",
      "Epoch 125/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5346 - acc: 0.7926\n",
      "Epoch 125: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5342 - acc: 0.7927 - val_loss: 0.5592 - val_acc: 0.7790\n",
      "Epoch 126/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5741 - acc: 0.7963\n",
      "Epoch 126: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5720 - acc: 0.7964 - val_loss: 0.5605 - val_acc: 0.7973\n",
      "Epoch 127/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5282 - acc: 0.7974\n",
      "Epoch 127: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5279 - acc: 0.7974 - val_loss: 0.5269 - val_acc: 0.8003\n",
      "Epoch 128/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4890 - acc: 0.7915\n",
      "Epoch 128: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4886 - acc: 0.7916 - val_loss: 0.5648 - val_acc: 0.7961\n",
      "Epoch 129/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5506 - acc: 0.7987\n",
      "Epoch 129: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5506 - acc: 0.7987 - val_loss: 0.5463 - val_acc: 0.7871\n",
      "Epoch 130/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5030 - acc: 0.7990\n",
      "Epoch 130: val_acc did not improve from 0.80248\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.5015 - acc: 0.7986 - val_loss: 0.5879 - val_acc: 0.7931\n",
      "Epoch 131/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5026 - acc: 0.7988\n",
      "Epoch 131: val_acc improved from 0.80248 to 0.80975, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5019 - acc: 0.7990 - val_loss: 0.5359 - val_acc: 0.8097\n",
      "Epoch 132/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5414 - acc: 0.7971\n",
      "Epoch 132: val_acc did not improve from 0.80975\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5414 - acc: 0.7971 - val_loss: 0.5403 - val_acc: 0.8003\n",
      "Epoch 133/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5184 - acc: 0.8013\n",
      "Epoch 133: val_acc did not improve from 0.80975\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5161 - acc: 0.8018 - val_loss: 0.5464 - val_acc: 0.8097\n",
      "Epoch 134/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4786 - acc: 0.8014\n",
      "Epoch 134: val_acc did not improve from 0.80975\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4779 - acc: 0.8016 - val_loss: 0.5185 - val_acc: 0.7965\n",
      "Epoch 135/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4967 - acc: 0.7988\n",
      "Epoch 135: val_acc did not improve from 0.80975\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4964 - acc: 0.7989 - val_loss: 0.5209 - val_acc: 0.7867\n",
      "Epoch 136/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4963 - acc: 0.7996\n",
      "Epoch 136: val_acc did not improve from 0.80975\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4955 - acc: 0.7998 - val_loss: 0.5157 - val_acc: 0.8076\n",
      "Epoch 137/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5057 - acc: 0.8044\n",
      "Epoch 137: val_acc improved from 0.80975 to 0.81445, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5053 - acc: 0.8046 - val_loss: 0.5760 - val_acc: 0.8145\n",
      "Epoch 138/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5177 - acc: 0.8027\n",
      "Epoch 138: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5165 - acc: 0.8033 - val_loss: 0.5633 - val_acc: 0.8050\n",
      "Epoch 139/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4821 - acc: 0.8095\n",
      "Epoch 139: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4803 - acc: 0.8095 - val_loss: 0.5643 - val_acc: 0.8097\n",
      "Epoch 140/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5205 - acc: 0.8021\n",
      "Epoch 140: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 5s 19ms/step - loss: 0.5201 - acc: 0.8024 - val_loss: 0.5227 - val_acc: 0.8085\n",
      "Epoch 141/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5190 - acc: 0.8052\n",
      "Epoch 141: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5186 - acc: 0.8053 - val_loss: 0.5211 - val_acc: 0.8085\n",
      "Epoch 142/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4941 - acc: 0.8075\n",
      "Epoch 142: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4941 - acc: 0.8075 - val_loss: 0.5714 - val_acc: 0.8102\n",
      "Epoch 143/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5309 - acc: 0.8079\n",
      "Epoch 143: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5284 - acc: 0.8081 - val_loss: 0.6283 - val_acc: 0.8080\n",
      "Epoch 144/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5158 - acc: 0.8048\n",
      "Epoch 144: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5136 - acc: 0.8052 - val_loss: 0.5671 - val_acc: 0.8038\n",
      "Epoch 145/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5212 - acc: 0.8091\n",
      "Epoch 145: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5201 - acc: 0.8093 - val_loss: 0.5405 - val_acc: 0.8136\n",
      "Epoch 146/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4893 - acc: 0.8021\n",
      "Epoch 146: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4890 - acc: 0.8022 - val_loss: 0.5659 - val_acc: 0.7935\n",
      "Epoch 147/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5080 - acc: 0.8058\n",
      "Epoch 147: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5071 - acc: 0.8056 - val_loss: 0.5520 - val_acc: 0.8029\n",
      "Epoch 148/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4766 - acc: 0.7969\n",
      "Epoch 148: val_acc improved from 0.81445 to 0.82471, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 6s 20ms/step - loss: 0.4746 - acc: 0.7975 - val_loss: 0.6086 - val_acc: 0.8247\n",
      "Epoch 149/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5049 - acc: 0.8041\n",
      "Epoch 149: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5049 - acc: 0.8041 - val_loss: 0.5454 - val_acc: 0.8068\n",
      "Epoch 150/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5073 - acc: 0.8065\n",
      "Epoch 150: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5070 - acc: 0.8067 - val_loss: 0.5088 - val_acc: 0.8209\n",
      "Epoch 151/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5084 - acc: 0.8096\n",
      "Epoch 151: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5061 - acc: 0.8099 - val_loss: 0.5317 - val_acc: 0.8115\n",
      "Epoch 152/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4831 - acc: 0.8074\n",
      "Epoch 152: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4827 - acc: 0.8076 - val_loss: 0.5566 - val_acc: 0.8132\n",
      "Epoch 153/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5760 - acc: 0.8038\n",
      "Epoch 153: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5739 - acc: 0.8036 - val_loss: 0.5155 - val_acc: 0.8068\n",
      "Epoch 154/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5250 - acc: 0.8088\n",
      "Epoch 154: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5228 - acc: 0.8089 - val_loss: 0.5131 - val_acc: 0.8162\n",
      "Epoch 155/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5003 - acc: 0.8110\n",
      "Epoch 155: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4972 - acc: 0.8114 - val_loss: 0.5310 - val_acc: 0.8106\n",
      "Epoch 156/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5508 - acc: 0.8105\n",
      "Epoch 156: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5476 - acc: 0.8097 - val_loss: 0.4946 - val_acc: 0.8145\n",
      "Epoch 157/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4876 - acc: 0.8095\n",
      "Epoch 157: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4873 - acc: 0.8097 - val_loss: 0.4849 - val_acc: 0.8162\n",
      "Epoch 158/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5068 - acc: 0.8113\n",
      "Epoch 158: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5039 - acc: 0.8119 - val_loss: 0.5389 - val_acc: 0.8145\n",
      "Epoch 159/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4811 - acc: 0.8082\n",
      "Epoch 159: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4801 - acc: 0.8074 - val_loss: 0.4950 - val_acc: 0.7905\n",
      "Epoch 160/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5327 - acc: 0.8053\n",
      "Epoch 160: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5316 - acc: 0.8056 - val_loss: 0.5053 - val_acc: 0.8093\n",
      "Epoch 161/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4911 - acc: 0.8107\n",
      "Epoch 161: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4911 - acc: 0.8107 - val_loss: 0.5068 - val_acc: 0.8174\n",
      "Epoch 162/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4613 - acc: 0.8136\n",
      "Epoch 162: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4610 - acc: 0.8137 - val_loss: 0.5086 - val_acc: 0.8140\n",
      "Epoch 163/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4636 - acc: 0.8114\n",
      "Epoch 163: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4619 - acc: 0.8115 - val_loss: 0.4754 - val_acc: 0.8097\n",
      "Epoch 164/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4642 - acc: 0.8083\n",
      "Epoch 164: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4632 - acc: 0.8082 - val_loss: 0.5055 - val_acc: 0.8089\n",
      "Epoch 165/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4623 - acc: 0.8139\n",
      "Epoch 165: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4623 - acc: 0.8139 - val_loss: 0.4969 - val_acc: 0.8033\n",
      "Epoch 166/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4941 - acc: 0.8108\n",
      "Epoch 166: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4941 - acc: 0.8108 - val_loss: 0.5014 - val_acc: 0.8115\n",
      "Epoch 167/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5078 - acc: 0.8143\n",
      "Epoch 167: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5071 - acc: 0.8144 - val_loss: 0.5012 - val_acc: 0.8042\n",
      "Epoch 168/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4869 - acc: 0.8167\n",
      "Epoch 168: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4860 - acc: 0.8158 - val_loss: 0.5067 - val_acc: 0.7986\n",
      "Epoch 169/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4505 - acc: 0.8135\n",
      "Epoch 169: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4505 - acc: 0.8135 - val_loss: 0.4849 - val_acc: 0.8038\n",
      "Epoch 170/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5020 - acc: 0.8094\n",
      "Epoch 170: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5019 - acc: 0.8095 - val_loss: 0.4851 - val_acc: 0.8102\n",
      "Epoch 171/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.8116\n",
      "Epoch 171: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4679 - acc: 0.8117 - val_loss: 0.4864 - val_acc: 0.8179\n",
      "Epoch 172/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5053 - acc: 0.8091\n",
      "Epoch 172: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5044 - acc: 0.8093 - val_loss: 0.4730 - val_acc: 0.8068\n",
      "Epoch 173/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4823 - acc: 0.8073\n",
      "Epoch 173: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4815 - acc: 0.8074 - val_loss: 0.4905 - val_acc: 0.8063\n",
      "Epoch 174/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4782 - acc: 0.8111\n",
      "Epoch 174: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4773 - acc: 0.8108 - val_loss: 0.5077 - val_acc: 0.8025\n",
      "Epoch 175/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4547 - acc: 0.8139\n",
      "Epoch 175: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4561 - acc: 0.8140 - val_loss: 0.5049 - val_acc: 0.8192\n",
      "Epoch 176/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4929 - acc: 0.8125\n",
      "Epoch 176: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4919 - acc: 0.8127 - val_loss: 0.4863 - val_acc: 0.8183\n",
      "Epoch 177/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4689 - acc: 0.8151\n",
      "Epoch 177: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4689 - acc: 0.8151 - val_loss: 0.4923 - val_acc: 0.8145\n",
      "Epoch 178/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4594 - acc: 0.8127\n",
      "Epoch 178: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4592 - acc: 0.8126 - val_loss: 0.4906 - val_acc: 0.8102\n",
      "Epoch 179/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4871 - acc: 0.8167\n",
      "Epoch 179: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4871 - acc: 0.8167 - val_loss: 0.4893 - val_acc: 0.8187\n",
      "Epoch 180/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5023 - acc: 0.8122\n",
      "Epoch 180: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5016 - acc: 0.8122 - val_loss: 0.4650 - val_acc: 0.8097\n",
      "Epoch 181/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4818 - acc: 0.8128\n",
      "Epoch 181: val_acc did not improve from 0.82471\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4815 - acc: 0.8129 - val_loss: 0.5040 - val_acc: 0.8063\n",
      "Epoch 182/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4695 - acc: 0.8158\n",
      "Epoch 182: val_acc improved from 0.82471 to 0.82856, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4682 - acc: 0.8159 - val_loss: 0.4956 - val_acc: 0.8286\n",
      "Epoch 183/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4825 - acc: 0.8165\n",
      "Epoch 183: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4809 - acc: 0.8161 - val_loss: 0.5132 - val_acc: 0.8234\n",
      "Epoch 184/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4744 - acc: 0.8137\n",
      "Epoch 184: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4738 - acc: 0.8138 - val_loss: 0.4705 - val_acc: 0.8140\n",
      "Epoch 185/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4529 - acc: 0.8151\n",
      "Epoch 185: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4519 - acc: 0.8154 - val_loss: 0.4662 - val_acc: 0.8127\n",
      "Epoch 186/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4792 - acc: 0.8106\n",
      "Epoch 186: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4784 - acc: 0.8106 - val_loss: 0.4694 - val_acc: 0.8055\n",
      "Epoch 187/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4434 - acc: 0.8165\n",
      "Epoch 187: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4431 - acc: 0.8167 - val_loss: 0.5066 - val_acc: 0.7978\n",
      "Epoch 188/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4845 - acc: 0.8117\n",
      "Epoch 188: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4831 - acc: 0.8114 - val_loss: 0.4748 - val_acc: 0.8097\n",
      "Epoch 189/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4491 - acc: 0.8149\n",
      "Epoch 189: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4488 - acc: 0.8150 - val_loss: 0.4852 - val_acc: 0.8110\n",
      "Epoch 190/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4798 - acc: 0.8158\n",
      "Epoch 190: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4779 - acc: 0.8158 - val_loss: 0.5155 - val_acc: 0.8157\n",
      "Epoch 191/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8200\n",
      "Epoch 191: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4656 - acc: 0.8200 - val_loss: 0.4939 - val_acc: 0.8127\n",
      "Epoch 192/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4823 - acc: 0.8122\n",
      "Epoch 192: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4823 - acc: 0.8122 - val_loss: 0.4718 - val_acc: 0.8251\n",
      "Epoch 193/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4676 - acc: 0.8152\n",
      "Epoch 193: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4674 - acc: 0.8152 - val_loss: 0.4975 - val_acc: 0.8029\n",
      "Epoch 194/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4565 - acc: 0.8173\n",
      "Epoch 194: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4562 - acc: 0.8174 - val_loss: 0.4695 - val_acc: 0.8089\n",
      "Epoch 195/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5069 - acc: 0.8159\n",
      "Epoch 195: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5042 - acc: 0.8166 - val_loss: 0.4645 - val_acc: 0.8256\n",
      "Epoch 196/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4365 - acc: 0.8122\n",
      "Epoch 196: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4352 - acc: 0.8122 - val_loss: 0.4630 - val_acc: 0.8187\n",
      "Epoch 197/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4270 - acc: 0.8154\n",
      "Epoch 197: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4255 - acc: 0.8155 - val_loss: 0.4739 - val_acc: 0.8204\n",
      "Epoch 198/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4656 - acc: 0.8137\n",
      "Epoch 198: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4645 - acc: 0.8137 - val_loss: 0.4800 - val_acc: 0.8093\n",
      "Epoch 199/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4385 - acc: 0.8144\n",
      "Epoch 199: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4376 - acc: 0.8148 - val_loss: 0.4789 - val_acc: 0.8149\n",
      "Epoch 200/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4599 - acc: 0.8205\n",
      "Epoch 200: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4596 - acc: 0.8206 - val_loss: 0.4954 - val_acc: 0.8085\n",
      "Epoch 201/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4633 - acc: 0.8192\n",
      "Epoch 201: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4630 - acc: 0.8193 - val_loss: 0.4772 - val_acc: 0.8080\n",
      "Epoch 202/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.8123\n",
      "Epoch 202: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4668 - acc: 0.8126 - val_loss: 0.4816 - val_acc: 0.8127\n",
      "Epoch 203/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4663 - acc: 0.8178\n",
      "Epoch 203: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4654 - acc: 0.8180 - val_loss: 0.4956 - val_acc: 0.8230\n",
      "Epoch 204/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4897 - acc: 0.8137\n",
      "Epoch 204: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4889 - acc: 0.8138 - val_loss: 0.4682 - val_acc: 0.8025\n",
      "Epoch 205/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4329 - acc: 0.8159\n",
      "Epoch 205: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4320 - acc: 0.8158 - val_loss: 0.5215 - val_acc: 0.8217\n",
      "Epoch 206/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4393 - acc: 0.8210\n",
      "Epoch 206: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4382 - acc: 0.8213 - val_loss: 0.4692 - val_acc: 0.8170\n",
      "Epoch 207/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4592 - acc: 0.8132\n",
      "Epoch 207: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4577 - acc: 0.8137 - val_loss: 0.5108 - val_acc: 0.8192\n",
      "Epoch 208/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4802 - acc: 0.8139\n",
      "Epoch 208: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4781 - acc: 0.8137 - val_loss: 0.4753 - val_acc: 0.8281\n",
      "Epoch 209/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4741 - acc: 0.8153\n",
      "Epoch 209: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4741 - acc: 0.8153 - val_loss: 0.4866 - val_acc: 0.8123\n",
      "Epoch 210/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4932 - acc: 0.8156\n",
      "Epoch 210: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4907 - acc: 0.8156 - val_loss: 0.4701 - val_acc: 0.8123\n",
      "Epoch 211/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4692 - acc: 0.8176\n",
      "Epoch 211: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4676 - acc: 0.8181 - val_loss: 0.4828 - val_acc: 0.8183\n",
      "Epoch 212/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5160 - acc: 0.8136\n",
      "Epoch 212: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5137 - acc: 0.8139 - val_loss: 0.4874 - val_acc: 0.8226\n",
      "Epoch 213/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5035 - acc: 0.8117\n",
      "Epoch 213: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5024 - acc: 0.8120 - val_loss: 0.4644 - val_acc: 0.8226\n",
      "Epoch 214/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4503 - acc: 0.8235\n",
      "Epoch 214: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4496 - acc: 0.8233 - val_loss: 0.4723 - val_acc: 0.8097\n",
      "Epoch 215/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4496 - acc: 0.8134\n",
      "Epoch 215: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4474 - acc: 0.8138 - val_loss: 0.4914 - val_acc: 0.8097\n",
      "Epoch 216/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.8150\n",
      "Epoch 216: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4610 - acc: 0.8151 - val_loss: 0.4474 - val_acc: 0.8123\n",
      "Epoch 217/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4753 - acc: 0.8190\n",
      "Epoch 217: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4742 - acc: 0.8189 - val_loss: 0.4939 - val_acc: 0.8256\n",
      "Epoch 218/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4636 - acc: 0.8228\n",
      "Epoch 218: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4621 - acc: 0.8228 - val_loss: 0.4839 - val_acc: 0.8072\n",
      "Epoch 219/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4698 - acc: 0.8235\n",
      "Epoch 219: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.4695 - acc: 0.8236 - val_loss: 0.4733 - val_acc: 0.7995\n",
      "Epoch 220/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.8186\n",
      "Epoch 220: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4608 - acc: 0.8187 - val_loss: 0.4846 - val_acc: 0.8068\n",
      "Epoch 221/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4302 - acc: 0.8243\n",
      "Epoch 221: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4290 - acc: 0.8245 - val_loss: 0.5003 - val_acc: 0.8286\n",
      "Epoch 222/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8166\n",
      "Epoch 222: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4588 - acc: 0.8167 - val_loss: 0.4884 - val_acc: 0.8174\n",
      "Epoch 223/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4763 - acc: 0.8214\n",
      "Epoch 223: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4742 - acc: 0.8215 - val_loss: 0.4536 - val_acc: 0.8140\n",
      "Epoch 224/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4483 - acc: 0.8194\n",
      "Epoch 224: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4470 - acc: 0.8197 - val_loss: 0.4935 - val_acc: 0.8055\n",
      "Epoch 225/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4992 - acc: 0.8152\n",
      "Epoch 225: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4985 - acc: 0.8152 - val_loss: 0.4633 - val_acc: 0.8157\n",
      "Epoch 226/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4551 - acc: 0.8190\n",
      "Epoch 226: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4537 - acc: 0.8189 - val_loss: 0.4989 - val_acc: 0.8260\n",
      "Epoch 227/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.8145\n",
      "Epoch 227: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4685 - acc: 0.8141 - val_loss: 0.4720 - val_acc: 0.8059\n",
      "Epoch 228/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4574 - acc: 0.8173\n",
      "Epoch 228: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4551 - acc: 0.8176 - val_loss: 0.4801 - val_acc: 0.8033\n",
      "Epoch 229/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4752 - acc: 0.8187\n",
      "Epoch 229: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4749 - acc: 0.8188 - val_loss: 0.4712 - val_acc: 0.8145\n",
      "Epoch 230/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4878 - acc: 0.8193\n",
      "Epoch 230: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4875 - acc: 0.8188 - val_loss: 0.4511 - val_acc: 0.8106\n",
      "Epoch 231/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4798 - acc: 0.8199\n",
      "Epoch 231: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4779 - acc: 0.8196 - val_loss: 0.4683 - val_acc: 0.8076\n",
      "Epoch 232/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4648 - acc: 0.8135\n",
      "Epoch 232: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4628 - acc: 0.8136 - val_loss: 0.4759 - val_acc: 0.8132\n",
      "Epoch 233/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4682 - acc: 0.8187\n",
      "Epoch 233: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4668 - acc: 0.8184 - val_loss: 0.4769 - val_acc: 0.8136\n",
      "Epoch 234/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4612 - acc: 0.8252\n",
      "Epoch 234: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4615 - acc: 0.8254 - val_loss: 0.4741 - val_acc: 0.8213\n",
      "Epoch 235/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4765 - acc: 0.8173\n",
      "Epoch 235: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4762 - acc: 0.8173 - val_loss: 0.4727 - val_acc: 0.8157\n",
      "Epoch 236/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4667 - acc: 0.8142\n",
      "Epoch 236: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4659 - acc: 0.8143 - val_loss: 0.4817 - val_acc: 0.8174\n",
      "Epoch 237/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4765 - acc: 0.8168\n",
      "Epoch 237: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4756 - acc: 0.8169 - val_loss: 0.4506 - val_acc: 0.8042\n",
      "Epoch 238/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.8172\n",
      "Epoch 238: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4489 - acc: 0.8173 - val_loss: 0.4712 - val_acc: 0.7978\n",
      "Epoch 239/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4611 - acc: 0.8117\n",
      "Epoch 239: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4601 - acc: 0.8118 - val_loss: 0.4496 - val_acc: 0.8187\n",
      "Epoch 240/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4470 - acc: 0.8199\n",
      "Epoch 240: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4462 - acc: 0.8202 - val_loss: 0.4883 - val_acc: 0.8072\n",
      "Epoch 241/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.8210\n",
      "Epoch 241: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4676 - acc: 0.8207 - val_loss: 0.4581 - val_acc: 0.8187\n",
      "Epoch 242/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4515 - acc: 0.8180\n",
      "Epoch 242: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4515 - acc: 0.8180 - val_loss: 0.4915 - val_acc: 0.8145\n",
      "Epoch 243/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4869 - acc: 0.8170\n",
      "Epoch 243: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4859 - acc: 0.8173 - val_loss: 0.4499 - val_acc: 0.8050\n",
      "Epoch 244/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4427 - acc: 0.8188\n",
      "Epoch 244: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4417 - acc: 0.8191 - val_loss: 0.4887 - val_acc: 0.8221\n",
      "Epoch 245/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4702 - acc: 0.8207\n",
      "Epoch 245: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4702 - acc: 0.8207 - val_loss: 0.4749 - val_acc: 0.8140\n",
      "Epoch 246/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4662 - acc: 0.8237\n",
      "Epoch 246: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4654 - acc: 0.8237 - val_loss: 0.4619 - val_acc: 0.8136\n",
      "Epoch 247/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4786 - acc: 0.8210\n",
      "Epoch 247: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4774 - acc: 0.8211 - val_loss: 0.4665 - val_acc: 0.8204\n",
      "Epoch 248/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4544 - acc: 0.8224\n",
      "Epoch 248: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4523 - acc: 0.8226 - val_loss: 0.4726 - val_acc: 0.8076\n",
      "Epoch 249/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4970 - acc: 0.8184\n",
      "Epoch 249: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4947 - acc: 0.8183 - val_loss: 0.4632 - val_acc: 0.8046\n",
      "Epoch 250/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4572 - acc: 0.8226\n",
      "Epoch 250: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4569 - acc: 0.8227 - val_loss: 0.4594 - val_acc: 0.8123\n",
      "Epoch 251/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4838 - acc: 0.8203\n",
      "Epoch 251: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4830 - acc: 0.8203 - val_loss: 0.5011 - val_acc: 0.8029\n",
      "Epoch 252/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4565 - acc: 0.8175\n",
      "Epoch 252: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4544 - acc: 0.8182 - val_loss: 0.4913 - val_acc: 0.7918\n",
      "Epoch 253/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4689 - acc: 0.8208\n",
      "Epoch 253: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4679 - acc: 0.8207 - val_loss: 0.4522 - val_acc: 0.8123\n",
      "Epoch 254/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4366 - acc: 0.8199\n",
      "Epoch 254: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4363 - acc: 0.8197 - val_loss: 0.4794 - val_acc: 0.8042\n",
      "Epoch 255/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4589 - acc: 0.8228\n",
      "Epoch 255: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4601 - acc: 0.8227 - val_loss: 0.5263 - val_acc: 0.8106\n",
      "Epoch 256/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4500 - acc: 0.8208\n",
      "Epoch 256: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4492 - acc: 0.8206 - val_loss: 0.4601 - val_acc: 0.8166\n",
      "Epoch 257/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4885 - acc: 0.8227\n",
      "Epoch 257: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4876 - acc: 0.8229 - val_loss: 0.4658 - val_acc: 0.8115\n",
      "Epoch 258/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4487 - acc: 0.8260\n",
      "Epoch 258: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4477 - acc: 0.8258 - val_loss: 0.4827 - val_acc: 0.8055\n",
      "Epoch 259/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4700 - acc: 0.8191\n",
      "Epoch 259: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4692 - acc: 0.8192 - val_loss: 0.4702 - val_acc: 0.8085\n",
      "Epoch 260/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4580 - acc: 0.8215\n",
      "Epoch 260: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4580 - acc: 0.8215 - val_loss: 0.4675 - val_acc: 0.8145\n",
      "Epoch 261/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5456 - acc: 0.8240\n",
      "Epoch 261: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5452 - acc: 0.8239 - val_loss: 0.4390 - val_acc: 0.8097\n",
      "Epoch 262/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4642 - acc: 0.8286\n",
      "Epoch 262: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4636 - acc: 0.8286 - val_loss: 0.4536 - val_acc: 0.8286\n",
      "Epoch 263/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4382 - acc: 0.8304\n",
      "Epoch 263: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4382 - acc: 0.8304 - val_loss: 0.4743 - val_acc: 0.8136\n",
      "Epoch 264/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8156\n",
      "Epoch 264: val_acc did not improve from 0.82856\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4632 - acc: 0.8162 - val_loss: 0.5083 - val_acc: 0.8213\n",
      "Epoch 265/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4496 - acc: 0.8184\n",
      "Epoch 265: val_acc improved from 0.82856 to 0.83027, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/3/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4466 - acc: 0.8189 - val_loss: 0.4912 - val_acc: 0.8303\n",
      "Epoch 266/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4530 - acc: 0.8231\n",
      "Epoch 266: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4513 - acc: 0.8233 - val_loss: 0.4742 - val_acc: 0.8221\n",
      "Epoch 267/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4701 - acc: 0.8246\n",
      "Epoch 267: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4699 - acc: 0.8247 - val_loss: 0.4531 - val_acc: 0.8110\n",
      "Epoch 268/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4757 - acc: 0.8221\n",
      "Epoch 268: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4754 - acc: 0.8221 - val_loss: 0.4722 - val_acc: 0.8089\n",
      "Epoch 269/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4365 - acc: 0.8237\n",
      "Epoch 269: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4355 - acc: 0.8235 - val_loss: 0.4570 - val_acc: 0.8157\n",
      "Epoch 270/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4671 - acc: 0.8240\n",
      "Epoch 270: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4666 - acc: 0.8239 - val_loss: 0.4768 - val_acc: 0.8123\n",
      "Epoch 271/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.8261\n",
      "Epoch 271: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4498 - acc: 0.8263 - val_loss: 0.4630 - val_acc: 0.8256\n",
      "Epoch 272/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4453 - acc: 0.8216\n",
      "Epoch 272: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4451 - acc: 0.8216 - val_loss: 0.4784 - val_acc: 0.8016\n",
      "Epoch 273/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4553 - acc: 0.8258\n",
      "Epoch 273: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4529 - acc: 0.8263 - val_loss: 0.4733 - val_acc: 0.8179\n",
      "Epoch 274/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4933 - acc: 0.8193\n",
      "Epoch 274: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4929 - acc: 0.8196 - val_loss: 0.4755 - val_acc: 0.8277\n",
      "Epoch 275/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4749 - acc: 0.8231\n",
      "Epoch 275: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4750 - acc: 0.8231 - val_loss: 0.4557 - val_acc: 0.8192\n",
      "Epoch 276/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4568 - acc: 0.8220\n",
      "Epoch 276: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4560 - acc: 0.8221 - val_loss: 0.4769 - val_acc: 0.8123\n",
      "Epoch 277/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4591 - acc: 0.8186\n",
      "Epoch 277: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4591 - acc: 0.8186 - val_loss: 0.4814 - val_acc: 0.8119\n",
      "Epoch 278/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4452 - acc: 0.8218\n",
      "Epoch 278: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4450 - acc: 0.8218 - val_loss: 0.4708 - val_acc: 0.8136\n",
      "Epoch 279/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4593 - acc: 0.8236\n",
      "Epoch 279: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4580 - acc: 0.8238 - val_loss: 0.4724 - val_acc: 0.8213\n",
      "Epoch 280/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4629 - acc: 0.8273\n",
      "Epoch 280: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4620 - acc: 0.8277 - val_loss: 0.4783 - val_acc: 0.8140\n",
      "Epoch 281/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4485 - acc: 0.8237\n",
      "Epoch 281: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4475 - acc: 0.8239 - val_loss: 0.4881 - val_acc: 0.8183\n",
      "Epoch 282/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4641 - acc: 0.8201\n",
      "Epoch 282: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4641 - acc: 0.8201 - val_loss: 0.4988 - val_acc: 0.8123\n",
      "Epoch 283/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4708 - acc: 0.8196\n",
      "Epoch 283: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4691 - acc: 0.8199 - val_loss: 0.4809 - val_acc: 0.8162\n",
      "Epoch 284/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.8218\n",
      "Epoch 284: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4582 - acc: 0.8215 - val_loss: 0.4800 - val_acc: 0.8157\n",
      "Epoch 285/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4362 - acc: 0.8271\n",
      "Epoch 285: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4360 - acc: 0.8272 - val_loss: 0.4728 - val_acc: 0.8080\n",
      "Epoch 286/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5017 - acc: 0.8263\n",
      "Epoch 286: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4998 - acc: 0.8258 - val_loss: 0.4916 - val_acc: 0.8273\n",
      "Epoch 287/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4626 - acc: 0.8252\n",
      "Epoch 287: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4602 - acc: 0.8255 - val_loss: 0.4910 - val_acc: 0.8226\n",
      "Epoch 288/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4664 - acc: 0.8168\n",
      "Epoch 288: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4645 - acc: 0.8167 - val_loss: 0.5490 - val_acc: 0.8106\n",
      "Epoch 289/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4847 - acc: 0.8262\n",
      "Epoch 289: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4837 - acc: 0.8264 - val_loss: 0.5061 - val_acc: 0.8192\n",
      "Epoch 290/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4941 - acc: 0.8269\n",
      "Epoch 290: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4911 - acc: 0.8273 - val_loss: 0.4710 - val_acc: 0.8170\n",
      "Epoch 291/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5097 - acc: 0.8236\n",
      "Epoch 291: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5080 - acc: 0.8231 - val_loss: 0.4621 - val_acc: 0.8127\n",
      "Epoch 292/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4269 - acc: 0.8234\n",
      "Epoch 292: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4270 - acc: 0.8230 - val_loss: 0.4860 - val_acc: 0.8153\n",
      "Epoch 293/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4513 - acc: 0.8221\n",
      "Epoch 293: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4510 - acc: 0.8222 - val_loss: 0.4844 - val_acc: 0.8076\n",
      "Epoch 294/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4980 - acc: 0.8211\n",
      "Epoch 294: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4971 - acc: 0.8213 - val_loss: 0.4803 - val_acc: 0.8093\n",
      "Epoch 295/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5377 - acc: 0.8277\n",
      "Epoch 295: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5365 - acc: 0.8279 - val_loss: 0.5059 - val_acc: 0.8209\n",
      "Epoch 296/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4650 - acc: 0.8268\n",
      "Epoch 296: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4650 - acc: 0.8268 - val_loss: 0.5361 - val_acc: 0.8174\n",
      "Epoch 297/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4703 - acc: 0.8248\n",
      "Epoch 297: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4703 - acc: 0.8248 - val_loss: 0.4703 - val_acc: 0.8281\n",
      "Epoch 298/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5203 - acc: 0.8279\n",
      "Epoch 298: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5175 - acc: 0.8281 - val_loss: 0.4509 - val_acc: 0.8119\n",
      "Epoch 299/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4454 - acc: 0.8287\n",
      "Epoch 299: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4430 - acc: 0.8295 - val_loss: 0.5127 - val_acc: 0.8239\n",
      "Epoch 300/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4561 - acc: 0.8287\n",
      "Epoch 300: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4553 - acc: 0.8285 - val_loss: 0.4532 - val_acc: 0.8123\n",
      "Epoch 301/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4498 - acc: 0.8281\n",
      "Epoch 301: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4484 - acc: 0.8280 - val_loss: 0.4889 - val_acc: 0.8204\n",
      "Epoch 302/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4805 - acc: 0.8268\n",
      "Epoch 302: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4797 - acc: 0.8269 - val_loss: 0.4733 - val_acc: 0.8162\n",
      "Epoch 303/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4768 - acc: 0.8256\n",
      "Epoch 303: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4744 - acc: 0.8257 - val_loss: 0.4572 - val_acc: 0.8119\n",
      "Epoch 304/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4476 - acc: 0.8252\n",
      "Epoch 304: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4459 - acc: 0.8252 - val_loss: 0.4909 - val_acc: 0.8029\n",
      "Epoch 305/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4681 - acc: 0.8295\n",
      "Epoch 305: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4681 - acc: 0.8295 - val_loss: 0.4949 - val_acc: 0.8243\n",
      "Epoch 306/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5170 - acc: 0.8297\n",
      "Epoch 306: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5170 - acc: 0.8297 - val_loss: 0.4879 - val_acc: 0.8140\n",
      "Epoch 307/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4488 - acc: 0.8217\n",
      "Epoch 307: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4488 - acc: 0.8217 - val_loss: 0.4850 - val_acc: 0.8281\n",
      "Epoch 308/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8253\n",
      "Epoch 308: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4586 - acc: 0.8253 - val_loss: 0.4933 - val_acc: 0.8055\n",
      "Epoch 309/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4780 - acc: 0.8262\n",
      "Epoch 309: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4779 - acc: 0.8263 - val_loss: 0.4782 - val_acc: 0.8127\n",
      "Epoch 310/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4732 - acc: 0.8260\n",
      "Epoch 310: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4725 - acc: 0.8261 - val_loss: 0.4579 - val_acc: 0.8204\n",
      "Epoch 311/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4870 - acc: 0.8224\n",
      "Epoch 311: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4860 - acc: 0.8228 - val_loss: 0.4931 - val_acc: 0.8149\n",
      "Epoch 312/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4982 - acc: 0.8253\n",
      "Epoch 312: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4963 - acc: 0.8251 - val_loss: 0.4984 - val_acc: 0.8157\n",
      "Epoch 313/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4464 - acc: 0.8235\n",
      "Epoch 313: val_acc did not improve from 0.83027\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4447 - acc: 0.8233 - val_loss: 0.4747 - val_acc: 0.8162\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_3 (Reshape)         (None, 96, 1)             0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               49664     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 313,089\n",
      "Trainable params: 313,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 1.4860 - acc: 0.5964\n",
      "Epoch 1: val_acc improved from -inf to 0.64301, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 4s 11ms/step - loss: 1.4821 - acc: 0.5967 - val_loss: 0.6481 - val_acc: 0.6430\n",
      "Epoch 2/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.6987 - acc: 0.6342\n",
      "Epoch 2: val_acc improved from 0.64301 to 0.71526, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.6986 - acc: 0.6342 - val_loss: 0.6316 - val_acc: 0.7153\n",
      "Epoch 3/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.6279 - acc: 0.6702\n",
      "Epoch 3: val_acc improved from 0.71526 to 0.74220, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.6283 - acc: 0.6694 - val_loss: 0.5817 - val_acc: 0.7422\n",
      "Epoch 4/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.6007 - acc: 0.7036\n",
      "Epoch 4: val_acc did not improve from 0.74220\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.6011 - acc: 0.7028 - val_loss: 0.5840 - val_acc: 0.7405\n",
      "Epoch 5/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5868 - acc: 0.7141\n",
      "Epoch 5: val_acc did not improve from 0.74220\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5868 - acc: 0.7133 - val_loss: 0.5889 - val_acc: 0.7401\n",
      "Epoch 6/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5764 - acc: 0.7193\n",
      "Epoch 6: val_acc improved from 0.74220 to 0.75160, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5764 - acc: 0.7191 - val_loss: 0.5524 - val_acc: 0.7516\n",
      "Epoch 7/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5693 - acc: 0.7221\n",
      "Epoch 7: val_acc improved from 0.75160 to 0.76058, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5694 - acc: 0.7213 - val_loss: 0.5626 - val_acc: 0.7606\n",
      "Epoch 8/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5646 - acc: 0.7321\n",
      "Epoch 8: val_acc did not improve from 0.76058\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5638 - acc: 0.7325 - val_loss: 0.5538 - val_acc: 0.7593\n",
      "Epoch 9/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5538 - acc: 0.7326\n",
      "Epoch 9: val_acc did not improve from 0.76058\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5541 - acc: 0.7322 - val_loss: 0.5480 - val_acc: 0.7602\n",
      "Epoch 10/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5584 - acc: 0.7300\n",
      "Epoch 10: val_acc improved from 0.76058 to 0.76956, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5586 - acc: 0.7296 - val_loss: 0.5260 - val_acc: 0.7696\n",
      "Epoch 11/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5498 - acc: 0.7322\n",
      "Epoch 11: val_acc improved from 0.76956 to 0.77127, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5499 - acc: 0.7313 - val_loss: 0.5438 - val_acc: 0.7713\n",
      "Epoch 12/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5501 - acc: 0.7339\n",
      "Epoch 12: val_acc improved from 0.77127 to 0.77255, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5501 - acc: 0.7339 - val_loss: 0.5092 - val_acc: 0.7726\n",
      "Epoch 13/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5485 - acc: 0.7344\n",
      "Epoch 13: val_acc improved from 0.77255 to 0.78025, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5482 - acc: 0.7338 - val_loss: 0.5179 - val_acc: 0.7802\n",
      "Epoch 14/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5394 - acc: 0.7380\n",
      "Epoch 14: val_acc did not improve from 0.78025\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5394 - acc: 0.7380 - val_loss: 0.5118 - val_acc: 0.7785\n",
      "Epoch 15/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5390 - acc: 0.7423\n",
      "Epoch 15: val_acc did not improve from 0.78025\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5392 - acc: 0.7420 - val_loss: 0.5294 - val_acc: 0.7755\n",
      "Epoch 16/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5336 - acc: 0.7460\n",
      "Epoch 16: val_acc improved from 0.78025 to 0.78196, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5336 - acc: 0.7457 - val_loss: 0.5205 - val_acc: 0.7820\n",
      "Epoch 17/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5296 - acc: 0.7445\n",
      "Epoch 17: val_acc did not improve from 0.78196\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5295 - acc: 0.7445 - val_loss: 0.5063 - val_acc: 0.7717\n",
      "Epoch 18/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5482 - acc: 0.7456\n",
      "Epoch 18: val_acc improved from 0.78196 to 0.78239, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5477 - acc: 0.7456 - val_loss: 0.5222 - val_acc: 0.7824\n",
      "Epoch 19/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5355 - acc: 0.7502\n",
      "Epoch 19: val_acc improved from 0.78239 to 0.78623, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5353 - acc: 0.7501 - val_loss: 0.5183 - val_acc: 0.7862\n",
      "Epoch 20/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5311 - acc: 0.7494\n",
      "Epoch 20: val_acc did not improve from 0.78623\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5310 - acc: 0.7494 - val_loss: 0.4930 - val_acc: 0.7862\n",
      "Epoch 21/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5477 - acc: 0.7484\n",
      "Epoch 21: val_acc did not improve from 0.78623\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5468 - acc: 0.7478 - val_loss: 0.5323 - val_acc: 0.7845\n",
      "Epoch 22/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5240 - acc: 0.7511\n",
      "Epoch 22: val_acc improved from 0.78623 to 0.78923, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5238 - acc: 0.7511 - val_loss: 0.5237 - val_acc: 0.7892\n",
      "Epoch 23/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5343 - acc: 0.7526\n",
      "Epoch 23: val_acc did not improve from 0.78923\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5334 - acc: 0.7521 - val_loss: 0.5111 - val_acc: 0.7841\n",
      "Epoch 24/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5306 - acc: 0.7485\n",
      "Epoch 24: val_acc improved from 0.78923 to 0.79478, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5303 - acc: 0.7487 - val_loss: 0.5244 - val_acc: 0.7948\n",
      "Epoch 25/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5234 - acc: 0.7517\n",
      "Epoch 25: val_acc did not improve from 0.79478\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5231 - acc: 0.7516 - val_loss: 0.5197 - val_acc: 0.7944\n",
      "Epoch 26/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5293 - acc: 0.7518\n",
      "Epoch 26: val_acc did not improve from 0.79478\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5290 - acc: 0.7520 - val_loss: 0.5155 - val_acc: 0.7884\n",
      "Epoch 27/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5371 - acc: 0.7545\n",
      "Epoch 27: val_acc improved from 0.79478 to 0.79521, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5364 - acc: 0.7544 - val_loss: 0.5324 - val_acc: 0.7952\n",
      "Epoch 28/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5282 - acc: 0.7518\n",
      "Epoch 28: val_acc did not improve from 0.79521\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5282 - acc: 0.7514 - val_loss: 0.5241 - val_acc: 0.7777\n",
      "Epoch 29/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5247 - acc: 0.7558\n",
      "Epoch 29: val_acc did not improve from 0.79521\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5243 - acc: 0.7560 - val_loss: 0.5130 - val_acc: 0.7862\n",
      "Epoch 30/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5203 - acc: 0.7597\n",
      "Epoch 30: val_acc did not improve from 0.79521\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5203 - acc: 0.7597 - val_loss: 0.5476 - val_acc: 0.7892\n",
      "Epoch 31/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5355 - acc: 0.7621\n",
      "Epoch 31: val_acc improved from 0.79521 to 0.80162, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5351 - acc: 0.7621 - val_loss: 0.5398 - val_acc: 0.8016\n",
      "Epoch 32/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5265 - acc: 0.7620\n",
      "Epoch 32: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5266 - acc: 0.7612 - val_loss: 0.5271 - val_acc: 0.7888\n",
      "Epoch 33/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5249 - acc: 0.7598\n",
      "Epoch 33: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5246 - acc: 0.7597 - val_loss: 0.4972 - val_acc: 0.7815\n",
      "Epoch 34/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5252 - acc: 0.7598\n",
      "Epoch 34: val_acc did not improve from 0.80162\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5250 - acc: 0.7595 - val_loss: 0.5059 - val_acc: 0.7871\n",
      "Epoch 35/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5111 - acc: 0.7647\n",
      "Epoch 35: val_acc improved from 0.80162 to 0.80291, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5109 - acc: 0.7647 - val_loss: 0.5041 - val_acc: 0.8029\n",
      "Epoch 36/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5213 - acc: 0.7629\n",
      "Epoch 36: val_acc did not improve from 0.80291\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5214 - acc: 0.7624 - val_loss: 0.5277 - val_acc: 0.7944\n",
      "Epoch 37/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5189 - acc: 0.7547\n",
      "Epoch 37: val_acc did not improve from 0.80291\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5189 - acc: 0.7541 - val_loss: 0.5305 - val_acc: 0.7858\n",
      "Epoch 38/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5166 - acc: 0.7661\n",
      "Epoch 38: val_acc did not improve from 0.80291\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.5158 - acc: 0.7658 - val_loss: 0.5148 - val_acc: 0.7969\n",
      "Epoch 39/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5141 - acc: 0.7630\n",
      "Epoch 39: val_acc did not improve from 0.80291\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.5141 - acc: 0.7630 - val_loss: 0.5316 - val_acc: 0.7991\n",
      "Epoch 40/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5205 - acc: 0.7687\n",
      "Epoch 40: val_acc improved from 0.80291 to 0.80504, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5201 - acc: 0.7689 - val_loss: 0.5035 - val_acc: 0.8050\n",
      "Epoch 41/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5123 - acc: 0.7658\n",
      "Epoch 41: val_acc did not improve from 0.80504\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5121 - acc: 0.7658 - val_loss: 0.5149 - val_acc: 0.8038\n",
      "Epoch 42/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5052 - acc: 0.7705\n",
      "Epoch 42: val_acc improved from 0.80504 to 0.81445, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5052 - acc: 0.7705 - val_loss: 0.5183 - val_acc: 0.8145\n",
      "Epoch 43/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5142 - acc: 0.7646\n",
      "Epoch 43: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5138 - acc: 0.7649 - val_loss: 0.5278 - val_acc: 0.8123\n",
      "Epoch 44/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5107 - acc: 0.7699\n",
      "Epoch 44: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5105 - acc: 0.7700 - val_loss: 0.5238 - val_acc: 0.7948\n",
      "Epoch 45/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5106 - acc: 0.7672\n",
      "Epoch 45: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5100 - acc: 0.7671 - val_loss: 0.5295 - val_acc: 0.8008\n",
      "Epoch 46/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5228 - acc: 0.7671\n",
      "Epoch 46: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5214 - acc: 0.7671 - val_loss: 0.5169 - val_acc: 0.8123\n",
      "Epoch 47/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5067 - acc: 0.7721\n",
      "Epoch 47: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5076 - acc: 0.7716 - val_loss: 0.5358 - val_acc: 0.8080\n",
      "Epoch 48/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5119 - acc: 0.7651\n",
      "Epoch 48: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5111 - acc: 0.7649 - val_loss: 0.5266 - val_acc: 0.8132\n",
      "Epoch 49/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5173 - acc: 0.7688\n",
      "Epoch 49: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5176 - acc: 0.7689 - val_loss: 0.5115 - val_acc: 0.7948\n",
      "Epoch 50/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5006 - acc: 0.7686\n",
      "Epoch 50: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5000 - acc: 0.7686 - val_loss: 0.5267 - val_acc: 0.8033\n",
      "Epoch 51/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5209 - acc: 0.7772\n",
      "Epoch 51: val_acc did not improve from 0.81445\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5204 - acc: 0.7768 - val_loss: 0.5218 - val_acc: 0.8085\n",
      "Epoch 52/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5083 - acc: 0.7725\n",
      "Epoch 52: val_acc improved from 0.81445 to 0.81873, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5076 - acc: 0.7724 - val_loss: 0.5241 - val_acc: 0.8187\n",
      "Epoch 53/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5153 - acc: 0.7714\n",
      "Epoch 53: val_acc did not improve from 0.81873\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5147 - acc: 0.7715 - val_loss: 0.5009 - val_acc: 0.8166\n",
      "Epoch 54/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5148 - acc: 0.7732\n",
      "Epoch 54: val_acc did not improve from 0.81873\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5145 - acc: 0.7736 - val_loss: 0.5327 - val_acc: 0.8136\n",
      "Epoch 55/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5028 - acc: 0.7679\n",
      "Epoch 55: val_acc did not improve from 0.81873\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5025 - acc: 0.7679 - val_loss: 0.5149 - val_acc: 0.8106\n",
      "Epoch 56/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5120 - acc: 0.7745\n",
      "Epoch 56: val_acc improved from 0.81873 to 0.82642, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5113 - acc: 0.7742 - val_loss: 0.5198 - val_acc: 0.8264\n",
      "Epoch 57/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4973 - acc: 0.7780\n",
      "Epoch 57: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4965 - acc: 0.7778 - val_loss: 0.5198 - val_acc: 0.8029\n",
      "Epoch 58/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5088 - acc: 0.7756\n",
      "Epoch 58: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5081 - acc: 0.7757 - val_loss: 0.5308 - val_acc: 0.8140\n",
      "Epoch 59/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5081 - acc: 0.7774\n",
      "Epoch 59: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5068 - acc: 0.7777 - val_loss: 0.5446 - val_acc: 0.8247\n",
      "Epoch 60/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5129 - acc: 0.7774\n",
      "Epoch 60: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5118 - acc: 0.7773 - val_loss: 0.5335 - val_acc: 0.8196\n",
      "Epoch 61/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5150 - acc: 0.7750\n",
      "Epoch 61: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5143 - acc: 0.7750 - val_loss: 0.4851 - val_acc: 0.8162\n",
      "Epoch 62/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4907 - acc: 0.7787\n",
      "Epoch 62: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4905 - acc: 0.7782 - val_loss: 0.4957 - val_acc: 0.8204\n",
      "Epoch 63/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5102 - acc: 0.7797\n",
      "Epoch 63: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5081 - acc: 0.7799 - val_loss: 0.5059 - val_acc: 0.8179\n",
      "Epoch 64/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4954 - acc: 0.7873\n",
      "Epoch 64: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4946 - acc: 0.7873 - val_loss: 0.5097 - val_acc: 0.8230\n",
      "Epoch 65/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5010 - acc: 0.7787\n",
      "Epoch 65: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5003 - acc: 0.7788 - val_loss: 0.4738 - val_acc: 0.8085\n",
      "Epoch 66/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5058 - acc: 0.7784\n",
      "Epoch 66: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5055 - acc: 0.7784 - val_loss: 0.5110 - val_acc: 0.8209\n",
      "Epoch 67/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4974 - acc: 0.7842\n",
      "Epoch 67: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4965 - acc: 0.7841 - val_loss: 0.4995 - val_acc: 0.8166\n",
      "Epoch 68/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4972 - acc: 0.7848\n",
      "Epoch 68: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4955 - acc: 0.7847 - val_loss: 0.5216 - val_acc: 0.8192\n",
      "Epoch 69/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5094 - acc: 0.7748\n",
      "Epoch 69: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.5085 - acc: 0.7748 - val_loss: 0.5055 - val_acc: 0.8183\n",
      "Epoch 70/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4975 - acc: 0.7838\n",
      "Epoch 70: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4975 - acc: 0.7838 - val_loss: 0.4821 - val_acc: 0.8251\n",
      "Epoch 71/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4923 - acc: 0.7802\n",
      "Epoch 71: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4921 - acc: 0.7802 - val_loss: 0.4902 - val_acc: 0.8085\n",
      "Epoch 72/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4990 - acc: 0.7836\n",
      "Epoch 72: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4990 - acc: 0.7836 - val_loss: 0.5068 - val_acc: 0.8174\n",
      "Epoch 73/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4902 - acc: 0.7826\n",
      "Epoch 73: val_acc did not improve from 0.82642\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4896 - acc: 0.7827 - val_loss: 0.5365 - val_acc: 0.8157\n",
      "Epoch 74/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5076 - acc: 0.7855\n",
      "Epoch 74: val_acc improved from 0.82642 to 0.83198, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5053 - acc: 0.7863 - val_loss: 0.5036 - val_acc: 0.8320\n",
      "Epoch 75/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4923 - acc: 0.7898\n",
      "Epoch 75: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4911 - acc: 0.7900 - val_loss: 0.4911 - val_acc: 0.8251\n",
      "Epoch 76/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4916 - acc: 0.7805\n",
      "Epoch 76: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4911 - acc: 0.7805 - val_loss: 0.5242 - val_acc: 0.8162\n",
      "Epoch 77/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4918 - acc: 0.7823\n",
      "Epoch 77: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4908 - acc: 0.7820 - val_loss: 0.5180 - val_acc: 0.8174\n",
      "Epoch 78/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4886 - acc: 0.7852\n",
      "Epoch 78: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4877 - acc: 0.7849 - val_loss: 0.5188 - val_acc: 0.8230\n",
      "Epoch 79/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4872 - acc: 0.7888\n",
      "Epoch 79: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4865 - acc: 0.7889 - val_loss: 0.5236 - val_acc: 0.8256\n",
      "Epoch 80/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4900 - acc: 0.7861\n",
      "Epoch 80: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4891 - acc: 0.7860 - val_loss: 0.5103 - val_acc: 0.8106\n",
      "Epoch 81/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4801 - acc: 0.7933\n",
      "Epoch 81: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4799 - acc: 0.7934 - val_loss: 0.5236 - val_acc: 0.8187\n",
      "Epoch 82/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5105 - acc: 0.7834\n",
      "Epoch 82: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5105 - acc: 0.7834 - val_loss: 0.4942 - val_acc: 0.8157\n",
      "Epoch 83/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4792 - acc: 0.7872\n",
      "Epoch 83: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4784 - acc: 0.7872 - val_loss: 0.4924 - val_acc: 0.8277\n",
      "Epoch 84/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4772 - acc: 0.7894\n",
      "Epoch 84: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4763 - acc: 0.7897 - val_loss: 0.5155 - val_acc: 0.8290\n",
      "Epoch 85/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5017 - acc: 0.7838\n",
      "Epoch 85: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5006 - acc: 0.7838 - val_loss: 0.5037 - val_acc: 0.8307\n",
      "Epoch 86/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4896 - acc: 0.7863\n",
      "Epoch 86: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4896 - acc: 0.7863 - val_loss: 0.4940 - val_acc: 0.8286\n",
      "Epoch 87/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4744 - acc: 0.7905\n",
      "Epoch 87: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4744 - acc: 0.7905 - val_loss: 0.4632 - val_acc: 0.8251\n",
      "Epoch 88/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4894 - acc: 0.7832\n",
      "Epoch 88: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4894 - acc: 0.7832 - val_loss: 0.5268 - val_acc: 0.8179\n",
      "Epoch 89/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5005 - acc: 0.7932\n",
      "Epoch 89: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4998 - acc: 0.7935 - val_loss: 0.5386 - val_acc: 0.8320\n",
      "Epoch 90/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4954 - acc: 0.7808\n",
      "Epoch 90: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4939 - acc: 0.7812 - val_loss: 0.5564 - val_acc: 0.8234\n",
      "Epoch 91/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5018 - acc: 0.7892\n",
      "Epoch 91: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5015 - acc: 0.7893 - val_loss: 0.5543 - val_acc: 0.8247\n",
      "Epoch 92/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4932 - acc: 0.7875\n",
      "Epoch 92: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.4932 - acc: 0.7875 - val_loss: 0.4867 - val_acc: 0.8166\n",
      "Epoch 93/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4854 - acc: 0.7831\n",
      "Epoch 93: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4854 - acc: 0.7831 - val_loss: 0.4773 - val_acc: 0.8132\n",
      "Epoch 94/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4819 - acc: 0.7908\n",
      "Epoch 94: val_acc did not improve from 0.83198\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4819 - acc: 0.7908 - val_loss: 0.4960 - val_acc: 0.8290\n",
      "Epoch 95/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4928 - acc: 0.7897\n",
      "Epoch 95: val_acc improved from 0.83198 to 0.83882, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4919 - acc: 0.7893 - val_loss: 0.4993 - val_acc: 0.8388\n",
      "Epoch 96/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4830 - acc: 0.7939\n",
      "Epoch 96: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4825 - acc: 0.7941 - val_loss: 0.5204 - val_acc: 0.8162\n",
      "Epoch 97/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4909 - acc: 0.7895\n",
      "Epoch 97: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4891 - acc: 0.7894 - val_loss: 0.5617 - val_acc: 0.8221\n",
      "Epoch 98/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5029 - acc: 0.7871\n",
      "Epoch 98: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5013 - acc: 0.7875 - val_loss: 0.5245 - val_acc: 0.8286\n",
      "Epoch 99/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4893 - acc: 0.7937\n",
      "Epoch 99: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4881 - acc: 0.7938 - val_loss: 0.5345 - val_acc: 0.8256\n",
      "Epoch 100/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4790 - acc: 0.7875\n",
      "Epoch 100: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4786 - acc: 0.7875 - val_loss: 0.5254 - val_acc: 0.8217\n",
      "Epoch 101/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4978 - acc: 0.7875\n",
      "Epoch 101: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4971 - acc: 0.7878 - val_loss: 0.5046 - val_acc: 0.8345\n",
      "Epoch 102/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4905 - acc: 0.7952\n",
      "Epoch 102: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4892 - acc: 0.7950 - val_loss: 0.4851 - val_acc: 0.8324\n",
      "Epoch 103/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4861 - acc: 0.7901\n",
      "Epoch 103: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4851 - acc: 0.7902 - val_loss: 0.5275 - val_acc: 0.8320\n",
      "Epoch 104/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4658 - acc: 0.7955\n",
      "Epoch 104: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4654 - acc: 0.7956 - val_loss: 0.5806 - val_acc: 0.8354\n",
      "Epoch 105/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4800 - acc: 0.7916\n",
      "Epoch 105: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4793 - acc: 0.7917 - val_loss: 0.4881 - val_acc: 0.8192\n",
      "Epoch 106/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4739 - acc: 0.7936\n",
      "Epoch 106: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4729 - acc: 0.7934 - val_loss: 0.5134 - val_acc: 0.8157\n",
      "Epoch 107/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4943 - acc: 0.7889\n",
      "Epoch 107: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4922 - acc: 0.7895 - val_loss: 0.5233 - val_acc: 0.8328\n",
      "Epoch 108/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4858 - acc: 0.7905\n",
      "Epoch 108: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4847 - acc: 0.7906 - val_loss: 0.5429 - val_acc: 0.8281\n",
      "Epoch 109/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4729 - acc: 0.7942\n",
      "Epoch 109: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4717 - acc: 0.7942 - val_loss: 0.4802 - val_acc: 0.8179\n",
      "Epoch 110/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4811 - acc: 0.7965\n",
      "Epoch 110: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4807 - acc: 0.7963 - val_loss: 0.4951 - val_acc: 0.8371\n",
      "Epoch 111/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4860 - acc: 0.7971\n",
      "Epoch 111: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4852 - acc: 0.7973 - val_loss: 0.5304 - val_acc: 0.8209\n",
      "Epoch 112/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4948 - acc: 0.7945\n",
      "Epoch 112: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4937 - acc: 0.7951 - val_loss: 0.4842 - val_acc: 0.8363\n",
      "Epoch 113/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4832 - acc: 0.7959\n",
      "Epoch 113: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4833 - acc: 0.7951 - val_loss: 0.4990 - val_acc: 0.8170\n",
      "Epoch 114/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4943 - acc: 0.7943\n",
      "Epoch 114: val_acc did not improve from 0.83882\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4953 - acc: 0.7939 - val_loss: 0.5299 - val_acc: 0.8337\n",
      "Epoch 115/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4912 - acc: 0.7954\n",
      "Epoch 115: val_acc improved from 0.83882 to 0.84053, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4912 - acc: 0.7954 - val_loss: 0.5190 - val_acc: 0.8405\n",
      "Epoch 116/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4763 - acc: 0.7946\n",
      "Epoch 116: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4751 - acc: 0.7940 - val_loss: 0.5213 - val_acc: 0.8328\n",
      "Epoch 117/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4819 - acc: 0.7943\n",
      "Epoch 117: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4816 - acc: 0.7943 - val_loss: 0.5029 - val_acc: 0.8316\n",
      "Epoch 118/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4854 - acc: 0.7950\n",
      "Epoch 118: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4840 - acc: 0.7952 - val_loss: 0.5122 - val_acc: 0.8333\n",
      "Epoch 119/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4546 - acc: 0.7967\n",
      "Epoch 119: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4538 - acc: 0.7965 - val_loss: 0.5376 - val_acc: 0.8204\n",
      "Epoch 120/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4765 - acc: 0.7977\n",
      "Epoch 120: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4756 - acc: 0.7979 - val_loss: 0.5086 - val_acc: 0.8247\n",
      "Epoch 121/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4813 - acc: 0.7962\n",
      "Epoch 121: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4794 - acc: 0.7966 - val_loss: 0.5190 - val_acc: 0.8358\n",
      "Epoch 122/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4856 - acc: 0.7913\n",
      "Epoch 122: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4848 - acc: 0.7917 - val_loss: 0.5370 - val_acc: 0.8221\n",
      "Epoch 123/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4746 - acc: 0.7964\n",
      "Epoch 123: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4743 - acc: 0.7965 - val_loss: 0.4904 - val_acc: 0.8290\n",
      "Epoch 124/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4881 - acc: 0.7948\n",
      "Epoch 124: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4881 - acc: 0.7948 - val_loss: 0.5193 - val_acc: 0.8371\n",
      "Epoch 125/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4781 - acc: 0.7895\n",
      "Epoch 125: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4776 - acc: 0.7895 - val_loss: 0.5399 - val_acc: 0.8213\n",
      "Epoch 126/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4804 - acc: 0.8019\n",
      "Epoch 126: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4786 - acc: 0.8020 - val_loss: 0.4657 - val_acc: 0.8341\n",
      "Epoch 127/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5102 - acc: 0.7923\n",
      "Epoch 127: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5083 - acc: 0.7927 - val_loss: 0.5673 - val_acc: 0.8384\n",
      "Epoch 128/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4726 - acc: 0.7953\n",
      "Epoch 128: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4726 - acc: 0.7953 - val_loss: 0.5061 - val_acc: 0.8328\n",
      "Epoch 129/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4804 - acc: 0.7961\n",
      "Epoch 129: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4801 - acc: 0.7962 - val_loss: 0.4955 - val_acc: 0.8243\n",
      "Epoch 130/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4796 - acc: 0.7959\n",
      "Epoch 130: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4794 - acc: 0.7958 - val_loss: 0.5334 - val_acc: 0.8183\n",
      "Epoch 131/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4768 - acc: 0.7999\n",
      "Epoch 131: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4762 - acc: 0.8001 - val_loss: 0.5014 - val_acc: 0.8281\n",
      "Epoch 132/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4756 - acc: 0.7954\n",
      "Epoch 132: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4752 - acc: 0.7955 - val_loss: 0.4810 - val_acc: 0.8363\n",
      "Epoch 133/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4821 - acc: 0.7966\n",
      "Epoch 133: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4821 - acc: 0.7966 - val_loss: 0.5028 - val_acc: 0.8333\n",
      "Epoch 134/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4909 - acc: 0.7942\n",
      "Epoch 134: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4904 - acc: 0.7940 - val_loss: 0.4958 - val_acc: 0.8243\n",
      "Epoch 135/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4912 - acc: 0.7982\n",
      "Epoch 135: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4912 - acc: 0.7982 - val_loss: 0.5005 - val_acc: 0.8388\n",
      "Epoch 136/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4695 - acc: 0.7986\n",
      "Epoch 136: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4695 - acc: 0.7986 - val_loss: 0.5136 - val_acc: 0.8367\n",
      "Epoch 137/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4868 - acc: 0.7960\n",
      "Epoch 137: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4857 - acc: 0.7960 - val_loss: 0.4936 - val_acc: 0.8333\n",
      "Epoch 138/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.7994\n",
      "Epoch 138: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4610 - acc: 0.7990 - val_loss: 0.4820 - val_acc: 0.8320\n",
      "Epoch 139/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8010\n",
      "Epoch 139: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4579 - acc: 0.8007 - val_loss: 0.5389 - val_acc: 0.8221\n",
      "Epoch 140/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5005 - acc: 0.7991\n",
      "Epoch 140: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4997 - acc: 0.7990 - val_loss: 0.4932 - val_acc: 0.8294\n",
      "Epoch 141/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4988 - acc: 0.7967\n",
      "Epoch 141: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4977 - acc: 0.7968 - val_loss: 0.4840 - val_acc: 0.8294\n",
      "Epoch 142/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4653 - acc: 0.8064\n",
      "Epoch 142: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4631 - acc: 0.8068 - val_loss: 0.4921 - val_acc: 0.8256\n",
      "Epoch 143/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4649 - acc: 0.8000\n",
      "Epoch 143: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4641 - acc: 0.7999 - val_loss: 0.5295 - val_acc: 0.8345\n",
      "Epoch 144/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4880 - acc: 0.8001\n",
      "Epoch 144: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4880 - acc: 0.8001 - val_loss: 0.4995 - val_acc: 0.8341\n",
      "Epoch 145/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4872 - acc: 0.7963\n",
      "Epoch 145: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4872 - acc: 0.7963 - val_loss: 0.4804 - val_acc: 0.8384\n",
      "Epoch 146/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4787 - acc: 0.8004\n",
      "Epoch 146: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4784 - acc: 0.8005 - val_loss: 0.4919 - val_acc: 0.8324\n",
      "Epoch 147/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4910 - acc: 0.8004\n",
      "Epoch 147: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4902 - acc: 0.8000 - val_loss: 0.5081 - val_acc: 0.8085\n",
      "Epoch 148/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4704 - acc: 0.7991\n",
      "Epoch 148: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4704 - acc: 0.7991 - val_loss: 0.5267 - val_acc: 0.8328\n",
      "Epoch 149/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4687 - acc: 0.8032\n",
      "Epoch 149: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4675 - acc: 0.8031 - val_loss: 0.5035 - val_acc: 0.8273\n",
      "Epoch 150/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4786 - acc: 0.8022\n",
      "Epoch 150: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4776 - acc: 0.8024 - val_loss: 0.5252 - val_acc: 0.8281\n",
      "Epoch 151/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4617 - acc: 0.8022\n",
      "Epoch 151: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.4614 - acc: 0.8024 - val_loss: 0.5591 - val_acc: 0.8174\n",
      "Epoch 152/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4631 - acc: 0.8038\n",
      "Epoch 152: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4628 - acc: 0.8038 - val_loss: 0.6178 - val_acc: 0.8307\n",
      "Epoch 153/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4709 - acc: 0.7929\n",
      "Epoch 153: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4703 - acc: 0.7933 - val_loss: 0.5357 - val_acc: 0.8277\n",
      "Epoch 154/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4806 - acc: 0.8012\n",
      "Epoch 154: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4798 - acc: 0.8015 - val_loss: 0.5332 - val_acc: 0.8345\n",
      "Epoch 155/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4586 - acc: 0.7950\n",
      "Epoch 155: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4586 - acc: 0.7950 - val_loss: 0.5470 - val_acc: 0.8371\n",
      "Epoch 156/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4787 - acc: 0.7999\n",
      "Epoch 156: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4780 - acc: 0.8002 - val_loss: 0.5768 - val_acc: 0.8221\n",
      "Epoch 157/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4745 - acc: 0.7963\n",
      "Epoch 157: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4731 - acc: 0.7964 - val_loss: 0.5063 - val_acc: 0.8371\n",
      "Epoch 158/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4917 - acc: 0.7975\n",
      "Epoch 158: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4896 - acc: 0.7978 - val_loss: 0.5418 - val_acc: 0.8320\n",
      "Epoch 159/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4965 - acc: 0.8001\n",
      "Epoch 159: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4942 - acc: 0.8005 - val_loss: 0.4790 - val_acc: 0.8392\n",
      "Epoch 160/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4839 - acc: 0.8035\n",
      "Epoch 160: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4837 - acc: 0.8033 - val_loss: 0.4348 - val_acc: 0.8324\n",
      "Epoch 161/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4571 - acc: 0.8055\n",
      "Epoch 161: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4571 - acc: 0.8055 - val_loss: 0.5319 - val_acc: 0.8354\n",
      "Epoch 162/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5030 - acc: 0.8034\n",
      "Epoch 162: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5008 - acc: 0.8035 - val_loss: 0.4987 - val_acc: 0.8401\n",
      "Epoch 163/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4644 - acc: 0.8071\n",
      "Epoch 163: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4640 - acc: 0.8067 - val_loss: 0.5055 - val_acc: 0.8298\n",
      "Epoch 164/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4712 - acc: 0.7998\n",
      "Epoch 164: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4719 - acc: 0.7998 - val_loss: 0.5656 - val_acc: 0.8268\n",
      "Epoch 165/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4929 - acc: 0.7970\n",
      "Epoch 165: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4930 - acc: 0.7972 - val_loss: 0.5945 - val_acc: 0.8281\n",
      "Epoch 166/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4682 - acc: 0.7995\n",
      "Epoch 166: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4665 - acc: 0.7999 - val_loss: 0.5545 - val_acc: 0.8405\n",
      "Epoch 167/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4835 - acc: 0.7982\n",
      "Epoch 167: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4817 - acc: 0.7982 - val_loss: 0.5533 - val_acc: 0.8286\n",
      "Epoch 168/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4661 - acc: 0.8033\n",
      "Epoch 168: val_acc did not improve from 0.84053\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4665 - acc: 0.8030 - val_loss: 0.5517 - val_acc: 0.8298\n",
      "Epoch 169/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4900 - acc: 0.8003\n",
      "Epoch 169: val_acc improved from 0.84053 to 0.84438, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4897 - acc: 0.8003 - val_loss: 0.5319 - val_acc: 0.8444\n",
      "Epoch 170/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4705 - acc: 0.8022\n",
      "Epoch 170: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4695 - acc: 0.8022 - val_loss: 0.4716 - val_acc: 0.8337\n",
      "Epoch 171/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4559 - acc: 0.8059\n",
      "Epoch 171: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4550 - acc: 0.8062 - val_loss: 0.5556 - val_acc: 0.8363\n",
      "Epoch 172/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4880 - acc: 0.8057\n",
      "Epoch 172: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4864 - acc: 0.8058 - val_loss: 0.5270 - val_acc: 0.8380\n",
      "Epoch 173/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4773 - acc: 0.7969\n",
      "Epoch 173: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4755 - acc: 0.7970 - val_loss: 0.4914 - val_acc: 0.8367\n",
      "Epoch 174/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4671 - acc: 0.8067\n",
      "Epoch 174: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4666 - acc: 0.8063 - val_loss: 0.5171 - val_acc: 0.8371\n",
      "Epoch 175/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4836 - acc: 0.8042\n",
      "Epoch 175: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4822 - acc: 0.8042 - val_loss: 0.5109 - val_acc: 0.8277\n",
      "Epoch 176/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4942 - acc: 0.7988\n",
      "Epoch 176: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4939 - acc: 0.7989 - val_loss: 0.5199 - val_acc: 0.8324\n",
      "Epoch 177/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4774 - acc: 0.8049\n",
      "Epoch 177: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4770 - acc: 0.8049 - val_loss: 0.5423 - val_acc: 0.8392\n",
      "Epoch 178/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4612 - acc: 0.7996\n",
      "Epoch 178: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4605 - acc: 0.7999 - val_loss: 0.4992 - val_acc: 0.8273\n",
      "Epoch 179/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4716 - acc: 0.8030\n",
      "Epoch 179: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4710 - acc: 0.8030 - val_loss: 0.5081 - val_acc: 0.8166\n",
      "Epoch 180/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4817 - acc: 0.8007\n",
      "Epoch 180: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4813 - acc: 0.8009 - val_loss: 0.4698 - val_acc: 0.8264\n",
      "Epoch 181/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4739 - acc: 0.8065\n",
      "Epoch 181: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4736 - acc: 0.8065 - val_loss: 0.5314 - val_acc: 0.8328\n",
      "Epoch 182/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4801 - acc: 0.8033\n",
      "Epoch 182: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4779 - acc: 0.8035 - val_loss: 0.4755 - val_acc: 0.8414\n",
      "Epoch 183/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4889 - acc: 0.8086\n",
      "Epoch 183: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.4885 - acc: 0.8086 - val_loss: 0.5265 - val_acc: 0.8273\n",
      "Epoch 184/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4585 - acc: 0.8021\n",
      "Epoch 184: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4582 - acc: 0.8021 - val_loss: 0.5055 - val_acc: 0.8243\n",
      "Epoch 185/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4719 - acc: 0.8080\n",
      "Epoch 185: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4712 - acc: 0.8079 - val_loss: 0.5024 - val_acc: 0.8256\n",
      "Epoch 186/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4566 - acc: 0.8074\n",
      "Epoch 186: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4566 - acc: 0.8074 - val_loss: 0.4844 - val_acc: 0.8418\n",
      "Epoch 187/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4812 - acc: 0.8048\n",
      "Epoch 187: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4803 - acc: 0.8048 - val_loss: 0.5830 - val_acc: 0.8431\n",
      "Epoch 188/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4841 - acc: 0.8036\n",
      "Epoch 188: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4823 - acc: 0.8035 - val_loss: 0.5301 - val_acc: 0.8350\n",
      "Epoch 189/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4623 - acc: 0.7979\n",
      "Epoch 189: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4623 - acc: 0.7979 - val_loss: 0.5335 - val_acc: 0.8388\n",
      "Epoch 190/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4478 - acc: 0.8048\n",
      "Epoch 190: val_acc did not improve from 0.84438\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4478 - acc: 0.8048 - val_loss: 0.5614 - val_acc: 0.8397\n",
      "Epoch 191/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4982 - acc: 0.8006\n",
      "Epoch 191: val_acc improved from 0.84438 to 0.84481, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4969 - acc: 0.8009 - val_loss: 0.5571 - val_acc: 0.8448\n",
      "Epoch 192/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4631 - acc: 0.8020\n",
      "Epoch 192: val_acc improved from 0.84481 to 0.84523, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4621 - acc: 0.8019 - val_loss: 0.4769 - val_acc: 0.8452\n",
      "Epoch 193/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5037 - acc: 0.8071\n",
      "Epoch 193: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5028 - acc: 0.8073 - val_loss: 0.5284 - val_acc: 0.8226\n",
      "Epoch 194/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4464 - acc: 0.8115\n",
      "Epoch 194: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4461 - acc: 0.8117 - val_loss: 0.5764 - val_acc: 0.8316\n",
      "Epoch 195/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4615 - acc: 0.8072\n",
      "Epoch 195: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4615 - acc: 0.8072 - val_loss: 0.5196 - val_acc: 0.8418\n",
      "Epoch 196/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4651 - acc: 0.8035\n",
      "Epoch 196: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4651 - acc: 0.8035 - val_loss: 0.5054 - val_acc: 0.8371\n",
      "Epoch 197/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4601 - acc: 0.8089\n",
      "Epoch 197: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4599 - acc: 0.8089 - val_loss: 0.5634 - val_acc: 0.8384\n",
      "Epoch 198/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4536 - acc: 0.7999\n",
      "Epoch 198: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4524 - acc: 0.7997 - val_loss: 0.5616 - val_acc: 0.8320\n",
      "Epoch 199/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.8044\n",
      "Epoch 199: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4582 - acc: 0.8043 - val_loss: 0.5789 - val_acc: 0.8410\n",
      "Epoch 200/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8009\n",
      "Epoch 200: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4647 - acc: 0.8013 - val_loss: 0.6047 - val_acc: 0.8380\n",
      "Epoch 201/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4703 - acc: 0.8085\n",
      "Epoch 201: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4691 - acc: 0.8087 - val_loss: 0.5421 - val_acc: 0.8448\n",
      "Epoch 202/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4510 - acc: 0.8116\n",
      "Epoch 202: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4503 - acc: 0.8117 - val_loss: 0.5518 - val_acc: 0.8320\n",
      "Epoch 203/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8096\n",
      "Epoch 203: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4579 - acc: 0.8099 - val_loss: 0.6035 - val_acc: 0.8401\n",
      "Epoch 204/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4650 - acc: 0.8065\n",
      "Epoch 204: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4642 - acc: 0.8067 - val_loss: 0.5589 - val_acc: 0.8422\n",
      "Epoch 205/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4651 - acc: 0.8080\n",
      "Epoch 205: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4650 - acc: 0.8079 - val_loss: 0.5308 - val_acc: 0.8363\n",
      "Epoch 206/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4605 - acc: 0.8041\n",
      "Epoch 206: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4605 - acc: 0.8041 - val_loss: 0.6187 - val_acc: 0.8354\n",
      "Epoch 207/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4715 - acc: 0.8035\n",
      "Epoch 207: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4715 - acc: 0.8035 - val_loss: 0.5899 - val_acc: 0.8371\n",
      "Epoch 208/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4817 - acc: 0.8079\n",
      "Epoch 208: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4809 - acc: 0.8080 - val_loss: 0.5475 - val_acc: 0.8316\n",
      "Epoch 209/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4539 - acc: 0.8107\n",
      "Epoch 209: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4522 - acc: 0.8110 - val_loss: 0.5221 - val_acc: 0.8354\n",
      "Epoch 210/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4702 - acc: 0.8103\n",
      "Epoch 210: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4685 - acc: 0.8111 - val_loss: 0.5427 - val_acc: 0.8401\n",
      "Epoch 211/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4699 - acc: 0.8070\n",
      "Epoch 211: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4696 - acc: 0.8071 - val_loss: 0.5200 - val_acc: 0.8192\n",
      "Epoch 212/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4667 - acc: 0.8094\n",
      "Epoch 212: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4661 - acc: 0.8095 - val_loss: 0.6254 - val_acc: 0.8320\n",
      "Epoch 213/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4517 - acc: 0.8106\n",
      "Epoch 213: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4509 - acc: 0.8107 - val_loss: 0.5393 - val_acc: 0.8290\n",
      "Epoch 214/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4780 - acc: 0.8057\n",
      "Epoch 214: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4776 - acc: 0.8056 - val_loss: 0.4588 - val_acc: 0.8311\n",
      "Epoch 215/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4383 - acc: 0.8067\n",
      "Epoch 215: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.4383 - acc: 0.8067 - val_loss: 0.4989 - val_acc: 0.8422\n",
      "Epoch 216/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4451 - acc: 0.8178\n",
      "Epoch 216: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4442 - acc: 0.8176 - val_loss: 0.4797 - val_acc: 0.8380\n",
      "Epoch 217/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4484 - acc: 0.8143\n",
      "Epoch 217: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 5s 17ms/step - loss: 0.4484 - acc: 0.8143 - val_loss: 0.5568 - val_acc: 0.8392\n",
      "Epoch 218/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4490 - acc: 0.8108\n",
      "Epoch 218: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4470 - acc: 0.8109 - val_loss: 0.5997 - val_acc: 0.8328\n",
      "Epoch 219/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4700 - acc: 0.8052\n",
      "Epoch 219: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4692 - acc: 0.8050 - val_loss: 0.4781 - val_acc: 0.8268\n",
      "Epoch 220/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4473 - acc: 0.8141\n",
      "Epoch 220: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4472 - acc: 0.8141 - val_loss: 0.5821 - val_acc: 0.8243\n",
      "Epoch 221/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8140\n",
      "Epoch 221: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4678 - acc: 0.8141 - val_loss: 0.5950 - val_acc: 0.8435\n",
      "Epoch 222/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4751 - acc: 0.8133\n",
      "Epoch 222: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4747 - acc: 0.8130 - val_loss: 0.4732 - val_acc: 0.8350\n",
      "Epoch 223/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4593 - acc: 0.8063\n",
      "Epoch 223: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4589 - acc: 0.8065 - val_loss: 0.5725 - val_acc: 0.8405\n",
      "Epoch 224/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4411 - acc: 0.8128\n",
      "Epoch 224: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 5s 18ms/step - loss: 0.4409 - acc: 0.8129 - val_loss: 0.5035 - val_acc: 0.8328\n",
      "Epoch 225/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4431 - acc: 0.8143\n",
      "Epoch 225: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4423 - acc: 0.8141 - val_loss: 0.5540 - val_acc: 0.8290\n",
      "Epoch 226/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4939 - acc: 0.8136\n",
      "Epoch 226: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4929 - acc: 0.8137 - val_loss: 0.4763 - val_acc: 0.8384\n",
      "Epoch 227/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4854 - acc: 0.8108\n",
      "Epoch 227: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4844 - acc: 0.8105 - val_loss: 0.4216 - val_acc: 0.8320\n",
      "Epoch 228/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4682 - acc: 0.8131\n",
      "Epoch 228: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4672 - acc: 0.8134 - val_loss: 0.4961 - val_acc: 0.8414\n",
      "Epoch 229/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4653 - acc: 0.8145\n",
      "Epoch 229: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4653 - acc: 0.8145 - val_loss: 0.4362 - val_acc: 0.8422\n",
      "Epoch 230/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4730 - acc: 0.8131\n",
      "Epoch 230: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4730 - acc: 0.8131 - val_loss: 0.4618 - val_acc: 0.8311\n",
      "Epoch 231/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4917 - acc: 0.8112\n",
      "Epoch 231: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4908 - acc: 0.8106 - val_loss: 0.4723 - val_acc: 0.8281\n",
      "Epoch 232/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8128\n",
      "Epoch 232: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4639 - acc: 0.8126 - val_loss: 0.5651 - val_acc: 0.8311\n",
      "Epoch 233/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4667 - acc: 0.8108\n",
      "Epoch 233: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4658 - acc: 0.8107 - val_loss: 0.5086 - val_acc: 0.8273\n",
      "Epoch 234/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4476 - acc: 0.8147\n",
      "Epoch 234: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4474 - acc: 0.8149 - val_loss: 0.5666 - val_acc: 0.8371\n",
      "Epoch 235/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4585 - acc: 0.8137\n",
      "Epoch 235: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4669 - acc: 0.8131 - val_loss: 0.5544 - val_acc: 0.8273\n",
      "Epoch 236/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8085\n",
      "Epoch 236: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4588 - acc: 0.8081 - val_loss: 0.5424 - val_acc: 0.8333\n",
      "Epoch 237/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4550 - acc: 0.8072\n",
      "Epoch 237: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4531 - acc: 0.8075 - val_loss: 0.6280 - val_acc: 0.8337\n",
      "Epoch 238/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4479 - acc: 0.8186\n",
      "Epoch 238: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4455 - acc: 0.8190 - val_loss: 0.5952 - val_acc: 0.8354\n",
      "Epoch 239/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4346 - acc: 0.8141\n",
      "Epoch 239: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4343 - acc: 0.8141 - val_loss: 0.4803 - val_acc: 0.8405\n",
      "Epoch 240/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4542 - acc: 0.8146\n",
      "Epoch 240: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4518 - acc: 0.8149 - val_loss: 0.4988 - val_acc: 0.8444\n",
      "Epoch 241/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4571 - acc: 0.8130\n",
      "Epoch 241: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 7s 23ms/step - loss: 0.4553 - acc: 0.8134 - val_loss: 0.5045 - val_acc: 0.8418\n",
      "Epoch 242/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4275 - acc: 0.8174\n",
      "Epoch 242: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4269 - acc: 0.8173 - val_loss: 0.6252 - val_acc: 0.8350\n",
      "Epoch 243/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4636 - acc: 0.8123\n",
      "Epoch 243: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4633 - acc: 0.8124 - val_loss: 0.5842 - val_acc: 0.8307\n",
      "Epoch 244/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4646 - acc: 0.8136\n",
      "Epoch 244: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4643 - acc: 0.8136 - val_loss: 0.5892 - val_acc: 0.8320\n",
      "Epoch 245/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4676 - acc: 0.8097\n",
      "Epoch 245: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4661 - acc: 0.8097 - val_loss: 0.6096 - val_acc: 0.8234\n",
      "Epoch 246/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4435 - acc: 0.8183\n",
      "Epoch 246: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4431 - acc: 0.8185 - val_loss: 0.5809 - val_acc: 0.8452\n",
      "Epoch 247/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4955 - acc: 0.8128\n",
      "Epoch 247: val_acc did not improve from 0.84523\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4927 - acc: 0.8133 - val_loss: 0.4830 - val_acc: 0.8427\n",
      "Epoch 248/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8182\n",
      "Epoch 248: val_acc improved from 0.84523 to 0.84566, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4496 - acc: 0.8185 - val_loss: 0.5103 - val_acc: 0.8457\n",
      "Epoch 249/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4854 - acc: 0.8079\n",
      "Epoch 249: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4844 - acc: 0.8081 - val_loss: 0.4659 - val_acc: 0.8431\n",
      "Epoch 250/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.8162\n",
      "Epoch 250: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4611 - acc: 0.8159 - val_loss: 0.4615 - val_acc: 0.8401\n",
      "Epoch 251/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8064\n",
      "Epoch 251: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4641 - acc: 0.8064 - val_loss: 0.5698 - val_acc: 0.8311\n",
      "Epoch 252/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4403 - acc: 0.8174\n",
      "Epoch 252: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4403 - acc: 0.8174 - val_loss: 0.5458 - val_acc: 0.8427\n",
      "Epoch 253/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4750 - acc: 0.8071\n",
      "Epoch 253: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4750 - acc: 0.8071 - val_loss: 0.6171 - val_acc: 0.8354\n",
      "Epoch 254/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4939 - acc: 0.8097\n",
      "Epoch 254: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4920 - acc: 0.8096 - val_loss: 0.5297 - val_acc: 0.8350\n",
      "Epoch 255/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4545 - acc: 0.8141\n",
      "Epoch 255: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4529 - acc: 0.8144 - val_loss: 0.5631 - val_acc: 0.8392\n",
      "Epoch 256/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4772 - acc: 0.8129\n",
      "Epoch 256: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4762 - acc: 0.8130 - val_loss: 0.5317 - val_acc: 0.8311\n",
      "Epoch 257/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4574 - acc: 0.8069\n",
      "Epoch 257: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4567 - acc: 0.8073 - val_loss: 0.5634 - val_acc: 0.8277\n",
      "Epoch 258/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4764 - acc: 0.8133\n",
      "Epoch 258: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4756 - acc: 0.8131 - val_loss: 0.5195 - val_acc: 0.8273\n",
      "Epoch 259/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4556 - acc: 0.8114\n",
      "Epoch 259: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4545 - acc: 0.8114 - val_loss: 0.5600 - val_acc: 0.8281\n",
      "Epoch 260/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4510 - acc: 0.8187\n",
      "Epoch 260: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4494 - acc: 0.8188 - val_loss: 0.5040 - val_acc: 0.8345\n",
      "Epoch 261/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4866 - acc: 0.8128\n",
      "Epoch 261: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4849 - acc: 0.8126 - val_loss: 0.5463 - val_acc: 0.8192\n",
      "Epoch 262/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4968 - acc: 0.8147\n",
      "Epoch 262: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4966 - acc: 0.8146 - val_loss: 0.4402 - val_acc: 0.8303\n",
      "Epoch 263/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4590 - acc: 0.8115\n",
      "Epoch 263: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4590 - acc: 0.8115 - val_loss: 0.5133 - val_acc: 0.8273\n",
      "Epoch 264/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4507 - acc: 0.8133\n",
      "Epoch 264: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4497 - acc: 0.8134 - val_loss: 0.5369 - val_acc: 0.8397\n",
      "Epoch 265/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4717 - acc: 0.8166\n",
      "Epoch 265: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4705 - acc: 0.8157 - val_loss: 0.5162 - val_acc: 0.8209\n",
      "Epoch 266/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4586 - acc: 0.8166\n",
      "Epoch 266: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4578 - acc: 0.8167 - val_loss: 0.5292 - val_acc: 0.8273\n",
      "Epoch 267/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8151\n",
      "Epoch 267: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4579 - acc: 0.8151 - val_loss: 0.4950 - val_acc: 0.8384\n",
      "Epoch 268/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4462 - acc: 0.8176\n",
      "Epoch 268: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4459 - acc: 0.8176 - val_loss: 0.6460 - val_acc: 0.8294\n",
      "Epoch 269/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4333 - acc: 0.8205\n",
      "Epoch 269: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4333 - acc: 0.8205 - val_loss: 0.5178 - val_acc: 0.8234\n",
      "Epoch 270/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4649 - acc: 0.8174\n",
      "Epoch 270: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4628 - acc: 0.8181 - val_loss: 0.5578 - val_acc: 0.8311\n",
      "Epoch 271/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4595 - acc: 0.8168\n",
      "Epoch 271: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4595 - acc: 0.8168 - val_loss: 0.5094 - val_acc: 0.8324\n",
      "Epoch 272/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4592 - acc: 0.8110\n",
      "Epoch 272: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4583 - acc: 0.8114 - val_loss: 0.6541 - val_acc: 0.8260\n",
      "Epoch 273/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4872 - acc: 0.8160\n",
      "Epoch 273: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4872 - acc: 0.8160 - val_loss: 0.5588 - val_acc: 0.8294\n",
      "Epoch 274/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4842 - acc: 0.8115\n",
      "Epoch 274: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4824 - acc: 0.8114 - val_loss: 0.6047 - val_acc: 0.8333\n",
      "Epoch 275/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4376 - acc: 0.8219\n",
      "Epoch 275: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4376 - acc: 0.8219 - val_loss: 0.5892 - val_acc: 0.8333\n",
      "Epoch 276/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4821 - acc: 0.8159\n",
      "Epoch 276: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4817 - acc: 0.8160 - val_loss: 0.5025 - val_acc: 0.8277\n",
      "Epoch 277/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4480 - acc: 0.8143\n",
      "Epoch 277: val_acc did not improve from 0.84566\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4481 - acc: 0.8142 - val_loss: 0.5381 - val_acc: 0.8337\n",
      "Epoch 278/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4377 - acc: 0.8205\n",
      "Epoch 278: val_acc improved from 0.84566 to 0.84865, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4374 - acc: 0.8206 - val_loss: 0.5321 - val_acc: 0.8487\n",
      "Epoch 279/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4604 - acc: 0.8128\n",
      "Epoch 279: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4595 - acc: 0.8129 - val_loss: 0.5494 - val_acc: 0.8350\n",
      "Epoch 280/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4396 - acc: 0.8160\n",
      "Epoch 280: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4383 - acc: 0.8156 - val_loss: 0.5034 - val_acc: 0.8388\n",
      "Epoch 281/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4529 - acc: 0.8175\n",
      "Epoch 281: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4526 - acc: 0.8176 - val_loss: 0.5705 - val_acc: 0.8303\n",
      "Epoch 282/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4406 - acc: 0.8130\n",
      "Epoch 282: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4393 - acc: 0.8128 - val_loss: 0.5769 - val_acc: 0.8268\n",
      "Epoch 283/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4704 - acc: 0.8123\n",
      "Epoch 283: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4704 - acc: 0.8123 - val_loss: 0.5071 - val_acc: 0.8286\n",
      "Epoch 284/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4917 - acc: 0.8115\n",
      "Epoch 284: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4917 - acc: 0.8115 - val_loss: 0.5580 - val_acc: 0.8469\n",
      "Epoch 285/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4714 - acc: 0.8135\n",
      "Epoch 285: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4712 - acc: 0.8134 - val_loss: 0.4914 - val_acc: 0.8337\n",
      "Epoch 286/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4767 - acc: 0.8121\n",
      "Epoch 286: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4767 - acc: 0.8121 - val_loss: 0.4662 - val_acc: 0.8388\n",
      "Epoch 287/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4594 - acc: 0.8140\n",
      "Epoch 287: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4594 - acc: 0.8140 - val_loss: 0.4834 - val_acc: 0.8354\n",
      "Epoch 288/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4565 - acc: 0.8183\n",
      "Epoch 288: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4563 - acc: 0.8183 - val_loss: 0.4196 - val_acc: 0.8354\n",
      "Epoch 289/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4608 - acc: 0.8166\n",
      "Epoch 289: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4600 - acc: 0.8167 - val_loss: 0.3796 - val_acc: 0.8431\n",
      "Epoch 290/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4619 - acc: 0.8097\n",
      "Epoch 290: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4602 - acc: 0.8102 - val_loss: 0.4853 - val_acc: 0.8440\n",
      "Epoch 291/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4658 - acc: 0.8150\n",
      "Epoch 291: val_acc did not improve from 0.84865\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4652 - acc: 0.8152 - val_loss: 0.4610 - val_acc: 0.8418\n",
      "Epoch 292/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4359 - acc: 0.8178\n",
      "Epoch 292: val_acc improved from 0.84865 to 0.84994, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4360 - acc: 0.8176 - val_loss: 0.4638 - val_acc: 0.8499\n",
      "Epoch 293/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4694 - acc: 0.8125\n",
      "Epoch 293: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4681 - acc: 0.8124 - val_loss: 0.5512 - val_acc: 0.8358\n",
      "Epoch 294/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5030 - acc: 0.8107\n",
      "Epoch 294: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5027 - acc: 0.8108 - val_loss: 0.5209 - val_acc: 0.8371\n",
      "Epoch 295/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4722 - acc: 0.8101\n",
      "Epoch 295: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 8s 27ms/step - loss: 0.4711 - acc: 0.8100 - val_loss: 0.5913 - val_acc: 0.8234\n",
      "Epoch 296/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4617 - acc: 0.8189\n",
      "Epoch 296: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4609 - acc: 0.8190 - val_loss: 0.4924 - val_acc: 0.8307\n",
      "Epoch 297/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4361 - acc: 0.8206\n",
      "Epoch 297: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4356 - acc: 0.8203 - val_loss: 0.5600 - val_acc: 0.8320\n",
      "Epoch 298/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.8192\n",
      "Epoch 298: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4691 - acc: 0.8192 - val_loss: 0.4886 - val_acc: 0.8367\n",
      "Epoch 299/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4601 - acc: 0.8191\n",
      "Epoch 299: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4588 - acc: 0.8188 - val_loss: 0.5997 - val_acc: 0.8444\n",
      "Epoch 300/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4403 - acc: 0.8130\n",
      "Epoch 300: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4401 - acc: 0.8131 - val_loss: 0.5558 - val_acc: 0.8311\n",
      "Epoch 301/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4494 - acc: 0.8130\n",
      "Epoch 301: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4486 - acc: 0.8134 - val_loss: 0.5235 - val_acc: 0.8298\n",
      "Epoch 302/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4690 - acc: 0.8140\n",
      "Epoch 302: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4677 - acc: 0.8138 - val_loss: 0.5363 - val_acc: 0.8268\n",
      "Epoch 303/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4305 - acc: 0.8180\n",
      "Epoch 303: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4286 - acc: 0.8184 - val_loss: 0.5092 - val_acc: 0.8457\n",
      "Epoch 304/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4551 - acc: 0.8226\n",
      "Epoch 304: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4548 - acc: 0.8223 - val_loss: 0.5217 - val_acc: 0.8388\n",
      "Epoch 305/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4871 - acc: 0.8184\n",
      "Epoch 305: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4857 - acc: 0.8182 - val_loss: 0.5304 - val_acc: 0.8341\n",
      "Epoch 306/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4559 - acc: 0.8192\n",
      "Epoch 306: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4558 - acc: 0.8187 - val_loss: 0.5513 - val_acc: 0.8380\n",
      "Epoch 307/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4643 - acc: 0.8127\n",
      "Epoch 307: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4643 - acc: 0.8127 - val_loss: 0.6043 - val_acc: 0.8401\n",
      "Epoch 308/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4487 - acc: 0.8218\n",
      "Epoch 308: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4474 - acc: 0.8215 - val_loss: 0.5491 - val_acc: 0.8427\n",
      "Epoch 309/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.8121\n",
      "Epoch 309: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4408 - acc: 0.8124 - val_loss: 0.6035 - val_acc: 0.8448\n",
      "Epoch 310/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4519 - acc: 0.8183\n",
      "Epoch 310: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4513 - acc: 0.8186 - val_loss: 0.5771 - val_acc: 0.8427\n",
      "Epoch 311/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4512 - acc: 0.8162\n",
      "Epoch 311: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4503 - acc: 0.8160 - val_loss: 0.5809 - val_acc: 0.8474\n",
      "Epoch 312/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4644 - acc: 0.8158\n",
      "Epoch 312: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4639 - acc: 0.8154 - val_loss: 0.5729 - val_acc: 0.8333\n",
      "Epoch 313/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4785 - acc: 0.8083\n",
      "Epoch 313: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4785 - acc: 0.8083 - val_loss: 0.5824 - val_acc: 0.8410\n",
      "Epoch 314/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.8225\n",
      "Epoch 314: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4492 - acc: 0.8226 - val_loss: 0.5121 - val_acc: 0.8457\n",
      "Epoch 315/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4623 - acc: 0.8152\n",
      "Epoch 315: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4610 - acc: 0.8154 - val_loss: 0.4742 - val_acc: 0.8457\n",
      "Epoch 316/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4729 - acc: 0.8210\n",
      "Epoch 316: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4729 - acc: 0.8210 - val_loss: 0.4965 - val_acc: 0.8354\n",
      "Epoch 317/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8155\n",
      "Epoch 317: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4648 - acc: 0.8156 - val_loss: 0.4291 - val_acc: 0.8341\n",
      "Epoch 318/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4633 - acc: 0.8179\n",
      "Epoch 318: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4633 - acc: 0.8179 - val_loss: 0.4967 - val_acc: 0.8465\n",
      "Epoch 319/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4870 - acc: 0.8215\n",
      "Epoch 319: val_acc did not improve from 0.84994\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4857 - acc: 0.8211 - val_loss: 0.4997 - val_acc: 0.8268\n",
      "Epoch 320/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5071 - acc: 0.8147\n",
      "Epoch 320: val_acc improved from 0.84994 to 0.85464, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5053 - acc: 0.8151 - val_loss: 0.5034 - val_acc: 0.8546\n",
      "Epoch 321/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4467 - acc: 0.8153\n",
      "Epoch 321: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4458 - acc: 0.8150 - val_loss: 0.5227 - val_acc: 0.8286\n",
      "Epoch 322/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4613 - acc: 0.8173\n",
      "Epoch 322: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4600 - acc: 0.8175 - val_loss: 0.4955 - val_acc: 0.8380\n",
      "Epoch 323/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4545 - acc: 0.8184\n",
      "Epoch 323: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4545 - acc: 0.8184 - val_loss: 0.5219 - val_acc: 0.8294\n",
      "Epoch 324/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4685 - acc: 0.8150\n",
      "Epoch 324: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4682 - acc: 0.8151 - val_loss: 0.5347 - val_acc: 0.8290\n",
      "Epoch 325/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.6089 - acc: 0.8154\n",
      "Epoch 325: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.6050 - acc: 0.8158 - val_loss: 0.5430 - val_acc: 0.8371\n",
      "Epoch 326/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4451 - acc: 0.8190\n",
      "Epoch 326: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4441 - acc: 0.8187 - val_loss: 0.4560 - val_acc: 0.8457\n",
      "Epoch 327/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4653 - acc: 0.8187\n",
      "Epoch 327: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4649 - acc: 0.8188 - val_loss: 0.5729 - val_acc: 0.8440\n",
      "Epoch 328/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5077 - acc: 0.8170\n",
      "Epoch 328: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5062 - acc: 0.8168 - val_loss: 0.5558 - val_acc: 0.8469\n",
      "Epoch 329/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4637 - acc: 0.8137\n",
      "Epoch 329: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4785 - acc: 0.8130 - val_loss: 0.5825 - val_acc: 0.8341\n",
      "Epoch 330/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4721 - acc: 0.8173\n",
      "Epoch 330: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 17ms/step - loss: 0.4721 - acc: 0.8173 - val_loss: 0.5006 - val_acc: 0.8290\n",
      "Epoch 331/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.8203\n",
      "Epoch 331: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4469 - acc: 0.8205 - val_loss: 0.5359 - val_acc: 0.8457\n",
      "Epoch 332/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4582 - acc: 0.8154\n",
      "Epoch 332: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4575 - acc: 0.8153 - val_loss: 0.6291 - val_acc: 0.8174\n",
      "Epoch 333/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4378 - acc: 0.8213\n",
      "Epoch 333: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4368 - acc: 0.8214 - val_loss: 0.5680 - val_acc: 0.8491\n",
      "Epoch 334/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4685 - acc: 0.8148\n",
      "Epoch 334: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4682 - acc: 0.8146 - val_loss: 0.4790 - val_acc: 0.8307\n",
      "Epoch 335/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4395 - acc: 0.8216\n",
      "Epoch 335: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4379 - acc: 0.8216 - val_loss: 0.4928 - val_acc: 0.8380\n",
      "Epoch 336/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4644 - acc: 0.8159\n",
      "Epoch 336: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4641 - acc: 0.8156 - val_loss: 0.4902 - val_acc: 0.8388\n",
      "Epoch 337/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4533 - acc: 0.8161\n",
      "Epoch 337: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4533 - acc: 0.8161 - val_loss: 0.4252 - val_acc: 0.8422\n",
      "Epoch 338/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4784 - acc: 0.8157\n",
      "Epoch 338: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4776 - acc: 0.8156 - val_loss: 0.5118 - val_acc: 0.8294\n",
      "Epoch 339/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.8186\n",
      "Epoch 339: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4499 - acc: 0.8186 - val_loss: 0.5136 - val_acc: 0.8375\n",
      "Epoch 340/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4422 - acc: 0.8229\n",
      "Epoch 340: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4409 - acc: 0.8228 - val_loss: 0.5868 - val_acc: 0.8320\n",
      "Epoch 341/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4702 - acc: 0.8132\n",
      "Epoch 341: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4689 - acc: 0.8129 - val_loss: 0.4974 - val_acc: 0.8367\n",
      "Epoch 342/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4664 - acc: 0.8152\n",
      "Epoch 342: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4661 - acc: 0.8152 - val_loss: 0.5013 - val_acc: 0.8504\n",
      "Epoch 343/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4714 - acc: 0.8149\n",
      "Epoch 343: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4711 - acc: 0.8150 - val_loss: 0.5052 - val_acc: 0.8341\n",
      "Epoch 344/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4571 - acc: 0.8178\n",
      "Epoch 344: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 17ms/step - loss: 0.4558 - acc: 0.8175 - val_loss: 0.5522 - val_acc: 0.8345\n",
      "Epoch 345/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4525 - acc: 0.8181\n",
      "Epoch 345: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4525 - acc: 0.8181 - val_loss: 0.5390 - val_acc: 0.8260\n",
      "Epoch 346/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4559 - acc: 0.8213\n",
      "Epoch 346: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4557 - acc: 0.8213 - val_loss: 0.4661 - val_acc: 0.8440\n",
      "Epoch 347/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4470 - acc: 0.8235\n",
      "Epoch 347: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4453 - acc: 0.8241 - val_loss: 0.5110 - val_acc: 0.8444\n",
      "Epoch 348/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4668 - acc: 0.8151\n",
      "Epoch 348: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4668 - acc: 0.8151 - val_loss: 0.5725 - val_acc: 0.8469\n",
      "Epoch 349/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4617 - acc: 0.8186\n",
      "Epoch 349: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4598 - acc: 0.8188 - val_loss: 0.5087 - val_acc: 0.8504\n",
      "Epoch 350/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4576 - acc: 0.8204\n",
      "Epoch 350: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4576 - acc: 0.8204 - val_loss: 0.5406 - val_acc: 0.8465\n",
      "Epoch 351/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8147\n",
      "Epoch 351: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4667 - acc: 0.8142 - val_loss: 0.4934 - val_acc: 0.8311\n",
      "Epoch 352/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4541 - acc: 0.8198\n",
      "Epoch 352: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4519 - acc: 0.8206 - val_loss: 0.4931 - val_acc: 0.8534\n",
      "Epoch 353/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4349 - acc: 0.8222\n",
      "Epoch 353: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4346 - acc: 0.8223 - val_loss: 0.5946 - val_acc: 0.8504\n",
      "Epoch 354/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4634 - acc: 0.8179\n",
      "Epoch 354: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4634 - acc: 0.8179 - val_loss: 0.6031 - val_acc: 0.8290\n",
      "Epoch 355/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4635 - acc: 0.8130\n",
      "Epoch 355: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4625 - acc: 0.8134 - val_loss: 0.5565 - val_acc: 0.8465\n",
      "Epoch 356/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4778 - acc: 0.8110\n",
      "Epoch 356: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4778 - acc: 0.8110 - val_loss: 0.4873 - val_acc: 0.8401\n",
      "Epoch 357/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4577 - acc: 0.8197\n",
      "Epoch 357: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4570 - acc: 0.8198 - val_loss: 0.5488 - val_acc: 0.8457\n",
      "Epoch 358/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4547 - acc: 0.8243\n",
      "Epoch 358: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4524 - acc: 0.8250 - val_loss: 0.4479 - val_acc: 0.8546\n",
      "Epoch 359/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4360 - acc: 0.8214\n",
      "Epoch 359: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4354 - acc: 0.8213 - val_loss: 0.4979 - val_acc: 0.8298\n",
      "Epoch 360/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5249 - acc: 0.8155\n",
      "Epoch 360: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.5236 - acc: 0.8153 - val_loss: 0.4945 - val_acc: 0.8525\n",
      "Epoch 361/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4724 - acc: 0.8203\n",
      "Epoch 361: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4704 - acc: 0.8207 - val_loss: 0.4625 - val_acc: 0.8333\n",
      "Epoch 362/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4554 - acc: 0.8195\n",
      "Epoch 362: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 17ms/step - loss: 0.4551 - acc: 0.8196 - val_loss: 0.5411 - val_acc: 0.8478\n",
      "Epoch 363/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4917 - acc: 0.8153\n",
      "Epoch 363: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4895 - acc: 0.8160 - val_loss: 0.4870 - val_acc: 0.8440\n",
      "Epoch 364/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4573 - acc: 0.8173\n",
      "Epoch 364: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4617 - acc: 0.8169 - val_loss: 0.5257 - val_acc: 0.8388\n",
      "Epoch 365/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4665 - acc: 0.8196\n",
      "Epoch 365: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4662 - acc: 0.8196 - val_loss: 0.4781 - val_acc: 0.8375\n",
      "Epoch 366/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4632 - acc: 0.8186\n",
      "Epoch 366: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4611 - acc: 0.8187 - val_loss: 0.4870 - val_acc: 0.8465\n",
      "Epoch 367/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4600 - acc: 0.8205\n",
      "Epoch 367: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 18ms/step - loss: 0.4600 - acc: 0.8205 - val_loss: 0.4624 - val_acc: 0.8495\n",
      "Epoch 368/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4885 - acc: 0.8165\n",
      "Epoch 368: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4882 - acc: 0.8165 - val_loss: 0.4573 - val_acc: 0.8414\n",
      "Epoch 369/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4896 - acc: 0.8169\n",
      "Epoch 369: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 17ms/step - loss: 0.4894 - acc: 0.8169 - val_loss: 0.5036 - val_acc: 0.8397\n",
      "Epoch 370/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4656 - acc: 0.8168\n",
      "Epoch 370: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4649 - acc: 0.8168 - val_loss: 0.4733 - val_acc: 0.8371\n",
      "Epoch 371/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4689 - acc: 0.8207\n",
      "Epoch 371: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4673 - acc: 0.8212 - val_loss: 0.4980 - val_acc: 0.8491\n",
      "Epoch 372/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4463 - acc: 0.8179\n",
      "Epoch 372: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4452 - acc: 0.8181 - val_loss: 0.5274 - val_acc: 0.8499\n",
      "Epoch 373/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4633 - acc: 0.8250\n",
      "Epoch 373: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 19ms/step - loss: 0.4617 - acc: 0.8249 - val_loss: 0.4915 - val_acc: 0.8516\n",
      "Epoch 374/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4792 - acc: 0.8227\n",
      "Epoch 374: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4787 - acc: 0.8224 - val_loss: 0.4822 - val_acc: 0.8482\n",
      "Epoch 375/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4440 - acc: 0.8177\n",
      "Epoch 375: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 6s 19ms/step - loss: 0.4437 - acc: 0.8179 - val_loss: 0.4989 - val_acc: 0.8435\n",
      "Epoch 376/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4446 - acc: 0.8122\n",
      "Epoch 376: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4454 - acc: 0.8120 - val_loss: 0.5291 - val_acc: 0.8260\n",
      "Epoch 377/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.8149\n",
      "Epoch 377: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4617 - acc: 0.8150 - val_loss: 0.5777 - val_acc: 0.8418\n",
      "Epoch 378/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4389 - acc: 0.8151\n",
      "Epoch 378: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4380 - acc: 0.8154 - val_loss: 0.5191 - val_acc: 0.8380\n",
      "Epoch 379/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4701 - acc: 0.8207\n",
      "Epoch 379: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4690 - acc: 0.8210 - val_loss: 0.5082 - val_acc: 0.8461\n",
      "Epoch 380/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4445 - acc: 0.8170\n",
      "Epoch 380: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4445 - acc: 0.8170 - val_loss: 0.4693 - val_acc: 0.8371\n",
      "Epoch 381/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4633 - acc: 0.8165\n",
      "Epoch 381: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4630 - acc: 0.8164 - val_loss: 0.4752 - val_acc: 0.8534\n",
      "Epoch 382/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5238 - acc: 0.8169\n",
      "Epoch 382: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5235 - acc: 0.8169 - val_loss: 0.6181 - val_acc: 0.8392\n",
      "Epoch 383/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4593 - acc: 0.8196\n",
      "Epoch 383: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4590 - acc: 0.8196 - val_loss: 0.5224 - val_acc: 0.8290\n",
      "Epoch 384/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4543 - acc: 0.8232\n",
      "Epoch 384: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4535 - acc: 0.8231 - val_loss: 0.4305 - val_acc: 0.8474\n",
      "Epoch 385/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4226 - acc: 0.8206\n",
      "Epoch 385: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4232 - acc: 0.8206 - val_loss: 0.4631 - val_acc: 0.8427\n",
      "Epoch 386/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4658 - acc: 0.8165\n",
      "Epoch 386: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4638 - acc: 0.8167 - val_loss: 0.4731 - val_acc: 0.8448\n",
      "Epoch 387/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4671 - acc: 0.8169\n",
      "Epoch 387: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4668 - acc: 0.8170 - val_loss: 0.5293 - val_acc: 0.8414\n",
      "Epoch 388/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4855 - acc: 0.8186\n",
      "Epoch 388: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4855 - acc: 0.8186 - val_loss: 0.5065 - val_acc: 0.8375\n",
      "Epoch 389/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4604 - acc: 0.8187\n",
      "Epoch 389: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 17ms/step - loss: 0.4604 - acc: 0.8187 - val_loss: 0.4882 - val_acc: 0.8469\n",
      "Epoch 390/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4718 - acc: 0.8187\n",
      "Epoch 390: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4721 - acc: 0.8187 - val_loss: 0.4821 - val_acc: 0.8469\n",
      "Epoch 391/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4951 - acc: 0.8189\n",
      "Epoch 391: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 6s 21ms/step - loss: 0.4933 - acc: 0.8188 - val_loss: 0.4002 - val_acc: 0.8465\n",
      "Epoch 392/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4771 - acc: 0.8190\n",
      "Epoch 392: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4757 - acc: 0.8192 - val_loss: 0.4127 - val_acc: 0.8341\n",
      "Epoch 393/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4707 - acc: 0.8131\n",
      "Epoch 393: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4707 - acc: 0.8131 - val_loss: 0.4717 - val_acc: 0.8307\n",
      "Epoch 394/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5272 - acc: 0.8119\n",
      "Epoch 394: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5250 - acc: 0.8115 - val_loss: 0.5227 - val_acc: 0.8350\n",
      "Epoch 395/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4564 - acc: 0.8181\n",
      "Epoch 395: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4559 - acc: 0.8179 - val_loss: 0.4634 - val_acc: 0.8204\n",
      "Epoch 396/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4548 - acc: 0.8213\n",
      "Epoch 396: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4545 - acc: 0.8214 - val_loss: 0.4217 - val_acc: 0.8452\n",
      "Epoch 397/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4595 - acc: 0.8192\n",
      "Epoch 397: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4593 - acc: 0.8192 - val_loss: 0.4698 - val_acc: 0.8324\n",
      "Epoch 398/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4747 - acc: 0.8203\n",
      "Epoch 398: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 17ms/step - loss: 0.4744 - acc: 0.8203 - val_loss: 0.4284 - val_acc: 0.8431\n",
      "Epoch 399/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5011 - acc: 0.8210\n",
      "Epoch 399: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4981 - acc: 0.8210 - val_loss: 0.4359 - val_acc: 0.8431\n",
      "Epoch 400/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4646 - acc: 0.8156\n",
      "Epoch 400: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 5s 17ms/step - loss: 0.4639 - acc: 0.8155 - val_loss: 0.4556 - val_acc: 0.8281\n",
      "Epoch 401/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4637 - acc: 0.8196\n",
      "Epoch 401: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4625 - acc: 0.8198 - val_loss: 0.5127 - val_acc: 0.8521\n",
      "Epoch 402/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4759 - acc: 0.8210\n",
      "Epoch 402: val_acc did not improve from 0.85464\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4744 - acc: 0.8214 - val_loss: 0.4677 - val_acc: 0.8516\n",
      "Epoch 403/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4456 - acc: 0.8214\n",
      "Epoch 403: val_acc improved from 0.85464 to 0.85507, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/4/256/best_model.h5\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4447 - acc: 0.8215 - val_loss: 0.4965 - val_acc: 0.8551\n",
      "Epoch 404/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4773 - acc: 0.8177\n",
      "Epoch 404: val_acc did not improve from 0.85507\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4761 - acc: 0.8175 - val_loss: 0.4644 - val_acc: 0.8264\n",
      "Epoch 405/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4749 - acc: 0.8158\n",
      "Epoch 405: val_acc did not improve from 0.85507\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4734 - acc: 0.8155 - val_loss: 0.4909 - val_acc: 0.8337\n",
      "Epoch 406/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4399 - acc: 0.8248\n",
      "Epoch 406: val_acc did not improve from 0.85507\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4396 - acc: 0.8249 - val_loss: 0.4356 - val_acc: 0.8397\n",
      "Epoch 407/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4448 - acc: 0.8219\n",
      "Epoch 407: val_acc did not improve from 0.85507\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4445 - acc: 0.8220 - val_loss: 0.4858 - val_acc: 0.8512\n",
      "Epoch 408/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4777 - acc: 0.8199\n",
      "Epoch 408: val_acc did not improve from 0.85507\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4777 - acc: 0.8199 - val_loss: 0.4834 - val_acc: 0.8512\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_4 (Reshape)         (None, 96, 1)             0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               49664     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 313,089\n",
      "Trainable params: 313,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 1.5492 - acc: 0.5988\n",
      "Epoch 1: val_acc improved from -inf to 0.61719, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 9s 13ms/step - loss: 1.5492 - acc: 0.5988 - val_loss: 0.6592 - val_acc: 0.6172\n",
      "Epoch 2/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.6866 - acc: 0.6529\n",
      "Epoch 2: val_acc improved from 0.61719 to 0.70231, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.6866 - acc: 0.6529 - val_loss: 0.6311 - val_acc: 0.7023\n",
      "Epoch 3/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.6127 - acc: 0.6884\n",
      "Epoch 3: val_acc improved from 0.70231 to 0.71471, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.6123 - acc: 0.6883 - val_loss: 0.5962 - val_acc: 0.7147\n",
      "Epoch 4/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5871 - acc: 0.7101\n",
      "Epoch 4: val_acc improved from 0.71471 to 0.71557, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5871 - acc: 0.7099 - val_loss: 0.5749 - val_acc: 0.7156\n",
      "Epoch 5/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5781 - acc: 0.7181\n",
      "Epoch 5: val_acc improved from 0.71557 to 0.73439, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5781 - acc: 0.7181 - val_loss: 0.5761 - val_acc: 0.7344\n",
      "Epoch 6/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5677 - acc: 0.7198\n",
      "Epoch 6: val_acc did not improve from 0.73439\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5680 - acc: 0.7194 - val_loss: 0.5747 - val_acc: 0.7327\n",
      "Epoch 7/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5639 - acc: 0.7313\n",
      "Epoch 7: val_acc improved from 0.73439 to 0.74123, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5639 - acc: 0.7308 - val_loss: 0.5508 - val_acc: 0.7412\n",
      "Epoch 8/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5587 - acc: 0.7335\n",
      "Epoch 8: val_acc did not improve from 0.74123\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5586 - acc: 0.7331 - val_loss: 0.5688 - val_acc: 0.7370\n",
      "Epoch 9/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5575 - acc: 0.7326\n",
      "Epoch 9: val_acc did not improve from 0.74123\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5571 - acc: 0.7325 - val_loss: 0.5453 - val_acc: 0.7378\n",
      "Epoch 10/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5494 - acc: 0.7349\n",
      "Epoch 10: val_acc improved from 0.74123 to 0.74722, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5493 - acc: 0.7350 - val_loss: 0.5825 - val_acc: 0.7472\n",
      "Epoch 11/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5595 - acc: 0.7408\n",
      "Epoch 11: val_acc did not improve from 0.74722\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5592 - acc: 0.7409 - val_loss: 0.5639 - val_acc: 0.7408\n",
      "Epoch 12/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5441 - acc: 0.7432\n",
      "Epoch 12: val_acc did not improve from 0.74722\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5432 - acc: 0.7437 - val_loss: 0.5245 - val_acc: 0.7378\n",
      "Epoch 13/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5424 - acc: 0.7421\n",
      "Epoch 13: val_acc did not improve from 0.74722\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5425 - acc: 0.7414 - val_loss: 0.5698 - val_acc: 0.7365\n",
      "Epoch 14/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5454 - acc: 0.7413\n",
      "Epoch 14: val_acc improved from 0.74722 to 0.74893, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5454 - acc: 0.7413 - val_loss: 0.5516 - val_acc: 0.7489\n",
      "Epoch 15/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5334 - acc: 0.7478\n",
      "Epoch 15: val_acc improved from 0.74893 to 0.76305, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5326 - acc: 0.7478 - val_loss: 0.5418 - val_acc: 0.7630\n",
      "Epoch 16/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5279 - acc: 0.7475\n",
      "Epoch 16: val_acc did not improve from 0.76305\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5279 - acc: 0.7475 - val_loss: 0.5422 - val_acc: 0.7596\n",
      "Epoch 17/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5348 - acc: 0.7511\n",
      "Epoch 17: val_acc did not improve from 0.76305\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.5346 - acc: 0.7510 - val_loss: 0.5466 - val_acc: 0.7571\n",
      "Epoch 18/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5405 - acc: 0.7564\n",
      "Epoch 18: val_acc did not improve from 0.76305\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5394 - acc: 0.7562 - val_loss: 0.5347 - val_acc: 0.7532\n",
      "Epoch 19/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5431 - acc: 0.7490\n",
      "Epoch 19: val_acc did not improve from 0.76305\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5423 - acc: 0.7493 - val_loss: 0.5459 - val_acc: 0.7532\n",
      "Epoch 20/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5337 - acc: 0.7566\n",
      "Epoch 20: val_acc did not improve from 0.76305\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5330 - acc: 0.7563 - val_loss: 0.5347 - val_acc: 0.7562\n",
      "Epoch 21/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5192 - acc: 0.7534\n",
      "Epoch 21: val_acc improved from 0.76305 to 0.76775, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5181 - acc: 0.7536 - val_loss: 0.5658 - val_acc: 0.7678\n",
      "Epoch 22/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5313 - acc: 0.7553\n",
      "Epoch 22: val_acc did not improve from 0.76775\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5313 - acc: 0.7553 - val_loss: 0.5580 - val_acc: 0.7498\n",
      "Epoch 23/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5291 - acc: 0.7535\n",
      "Epoch 23: val_acc did not improve from 0.76775\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5285 - acc: 0.7529 - val_loss: 0.5311 - val_acc: 0.7511\n",
      "Epoch 24/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5363 - acc: 0.7539\n",
      "Epoch 24: val_acc did not improve from 0.76775\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5360 - acc: 0.7534 - val_loss: 0.5456 - val_acc: 0.7506\n",
      "Epoch 25/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5292 - acc: 0.7547\n",
      "Epoch 25: val_acc did not improve from 0.76775\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5292 - acc: 0.7547 - val_loss: 0.5068 - val_acc: 0.7566\n",
      "Epoch 26/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5203 - acc: 0.7668\n",
      "Epoch 26: val_acc did not improve from 0.76775\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5198 - acc: 0.7665 - val_loss: 0.5294 - val_acc: 0.7481\n",
      "Epoch 27/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5302 - acc: 0.7612\n",
      "Epoch 27: val_acc did not improve from 0.76775\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5301 - acc: 0.7605 - val_loss: 0.5306 - val_acc: 0.7451\n",
      "Epoch 28/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5374 - acc: 0.7553\n",
      "Epoch 28: val_acc did not improve from 0.76775\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5374 - acc: 0.7553 - val_loss: 0.5294 - val_acc: 0.7549\n",
      "Epoch 29/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5211 - acc: 0.7594\n",
      "Epoch 29: val_acc did not improve from 0.76775\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5208 - acc: 0.7590 - val_loss: 0.5282 - val_acc: 0.7579\n",
      "Epoch 30/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5375 - acc: 0.7642\n",
      "Epoch 30: val_acc did not improve from 0.76775\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5374 - acc: 0.7638 - val_loss: 0.5115 - val_acc: 0.7519\n",
      "Epoch 31/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5212 - acc: 0.7725\n",
      "Epoch 31: val_acc did not improve from 0.76775\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5206 - acc: 0.7724 - val_loss: 0.5275 - val_acc: 0.7656\n",
      "Epoch 32/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5200 - acc: 0.7692\n",
      "Epoch 32: val_acc improved from 0.76775 to 0.77074, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5185 - acc: 0.7695 - val_loss: 0.5331 - val_acc: 0.7707\n",
      "Epoch 33/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5201 - acc: 0.7600\n",
      "Epoch 33: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5191 - acc: 0.7600 - val_loss: 0.5233 - val_acc: 0.7678\n",
      "Epoch 34/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5199 - acc: 0.7712\n",
      "Epoch 34: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5194 - acc: 0.7715 - val_loss: 0.5433 - val_acc: 0.7630\n",
      "Epoch 35/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5196 - acc: 0.7713\n",
      "Epoch 35: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5185 - acc: 0.7712 - val_loss: 0.5361 - val_acc: 0.7541\n",
      "Epoch 36/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5246 - acc: 0.7665\n",
      "Epoch 36: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5246 - acc: 0.7665 - val_loss: 0.5400 - val_acc: 0.7648\n",
      "Epoch 37/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5245 - acc: 0.7700\n",
      "Epoch 37: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5245 - acc: 0.7700 - val_loss: 0.5264 - val_acc: 0.7583\n",
      "Epoch 38/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5273 - acc: 0.7693\n",
      "Epoch 38: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5256 - acc: 0.7693 - val_loss: 0.5382 - val_acc: 0.7678\n",
      "Epoch 39/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5296 - acc: 0.7705\n",
      "Epoch 39: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5283 - acc: 0.7702 - val_loss: 0.5422 - val_acc: 0.7643\n",
      "Epoch 40/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5277 - acc: 0.7699\n",
      "Epoch 40: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5275 - acc: 0.7699 - val_loss: 0.5472 - val_acc: 0.7665\n",
      "Epoch 41/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5195 - acc: 0.7703\n",
      "Epoch 41: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5192 - acc: 0.7705 - val_loss: 0.5220 - val_acc: 0.7635\n",
      "Epoch 42/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5155 - acc: 0.7764\n",
      "Epoch 42: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5141 - acc: 0.7762 - val_loss: 0.5230 - val_acc: 0.7673\n",
      "Epoch 43/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5403 - acc: 0.7755\n",
      "Epoch 43: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5402 - acc: 0.7752 - val_loss: 0.5372 - val_acc: 0.7494\n",
      "Epoch 44/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5073 - acc: 0.7719\n",
      "Epoch 44: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.5070 - acc: 0.7720 - val_loss: 0.5116 - val_acc: 0.7502\n",
      "Epoch 45/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5469 - acc: 0.7760\n",
      "Epoch 45: val_acc did not improve from 0.77074\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.5469 - acc: 0.7760 - val_loss: 0.5104 - val_acc: 0.7673\n",
      "Epoch 46/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5104 - acc: 0.7731\n",
      "Epoch 46: val_acc improved from 0.77074 to 0.77459, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5104 - acc: 0.7731 - val_loss: 0.5322 - val_acc: 0.7746\n",
      "Epoch 47/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5317 - acc: 0.7692\n",
      "Epoch 47: val_acc did not improve from 0.77459\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5314 - acc: 0.7693 - val_loss: 0.5238 - val_acc: 0.7678\n",
      "Epoch 48/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.5008 - acc: 0.7786\n",
      "Epoch 48: val_acc did not improve from 0.77459\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4996 - acc: 0.7781 - val_loss: 0.5328 - val_acc: 0.7703\n",
      "Epoch 49/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5137 - acc: 0.7785\n",
      "Epoch 49: val_acc did not improve from 0.77459\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5133 - acc: 0.7782 - val_loss: 0.5469 - val_acc: 0.7583\n",
      "Epoch 50/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5162 - acc: 0.7767\n",
      "Epoch 50: val_acc did not improve from 0.77459\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5159 - acc: 0.7765 - val_loss: 0.5463 - val_acc: 0.7665\n",
      "Epoch 51/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5001 - acc: 0.7794\n",
      "Epoch 51: val_acc did not improve from 0.77459\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5001 - acc: 0.7794 - val_loss: 0.5387 - val_acc: 0.7690\n",
      "Epoch 52/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5083 - acc: 0.7817\n",
      "Epoch 52: val_acc did not improve from 0.77459\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5079 - acc: 0.7819 - val_loss: 0.5394 - val_acc: 0.7703\n",
      "Epoch 53/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5225 - acc: 0.7795\n",
      "Epoch 53: val_acc did not improve from 0.77459\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5221 - acc: 0.7797 - val_loss: 0.5415 - val_acc: 0.7639\n",
      "Epoch 54/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5195 - acc: 0.7763\n",
      "Epoch 54: val_acc did not improve from 0.77459\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5186 - acc: 0.7764 - val_loss: 0.5472 - val_acc: 0.7699\n",
      "Epoch 55/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5118 - acc: 0.7800\n",
      "Epoch 55: val_acc did not improve from 0.77459\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5108 - acc: 0.7800 - val_loss: 0.5220 - val_acc: 0.7648\n",
      "Epoch 56/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5028 - acc: 0.7833\n",
      "Epoch 56: val_acc did not improve from 0.77459\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5015 - acc: 0.7831 - val_loss: 0.5253 - val_acc: 0.7553\n",
      "Epoch 57/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5229 - acc: 0.7822\n",
      "Epoch 57: val_acc did not improve from 0.77459\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5288 - acc: 0.7821 - val_loss: 0.5319 - val_acc: 0.7712\n",
      "Epoch 58/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5009 - acc: 0.7850\n",
      "Epoch 58: val_acc improved from 0.77459 to 0.77802, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5009 - acc: 0.7850 - val_loss: 0.5269 - val_acc: 0.7780\n",
      "Epoch 59/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5300 - acc: 0.7870\n",
      "Epoch 59: val_acc improved from 0.77802 to 0.78315, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5289 - acc: 0.7873 - val_loss: 0.5116 - val_acc: 0.7831\n",
      "Epoch 60/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5553 - acc: 0.7801\n",
      "Epoch 60: val_acc did not improve from 0.78315\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5532 - acc: 0.7800 - val_loss: 0.5299 - val_acc: 0.7772\n",
      "Epoch 61/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4979 - acc: 0.7820\n",
      "Epoch 61: val_acc did not improve from 0.78315\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4977 - acc: 0.7820 - val_loss: 0.5422 - val_acc: 0.7665\n",
      "Epoch 62/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5240 - acc: 0.7854\n",
      "Epoch 62: val_acc did not improve from 0.78315\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.5230 - acc: 0.7855 - val_loss: 0.5150 - val_acc: 0.7767\n",
      "Epoch 63/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4941 - acc: 0.7870\n",
      "Epoch 63: val_acc improved from 0.78315 to 0.79042, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4926 - acc: 0.7872 - val_loss: 0.5229 - val_acc: 0.7904\n",
      "Epoch 64/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5029 - acc: 0.7815\n",
      "Epoch 64: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.5021 - acc: 0.7814 - val_loss: 0.5400 - val_acc: 0.7776\n",
      "Epoch 65/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5086 - acc: 0.7869\n",
      "Epoch 65: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5086 - acc: 0.7869 - val_loss: 0.5250 - val_acc: 0.7879\n",
      "Epoch 66/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5243 - acc: 0.7861\n",
      "Epoch 66: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5243 - acc: 0.7861 - val_loss: 0.5168 - val_acc: 0.7742\n",
      "Epoch 67/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5118 - acc: 0.7882\n",
      "Epoch 67: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5118 - acc: 0.7882 - val_loss: 0.5147 - val_acc: 0.7733\n",
      "Epoch 68/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5011 - acc: 0.7945\n",
      "Epoch 68: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5007 - acc: 0.7948 - val_loss: 0.5263 - val_acc: 0.7827\n",
      "Epoch 69/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4893 - acc: 0.7936\n",
      "Epoch 69: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4898 - acc: 0.7932 - val_loss: 0.5356 - val_acc: 0.7720\n",
      "Epoch 70/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4862 - acc: 0.7935\n",
      "Epoch 70: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4859 - acc: 0.7936 - val_loss: 0.5204 - val_acc: 0.7879\n",
      "Epoch 71/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5126 - acc: 0.7926\n",
      "Epoch 71: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5122 - acc: 0.7928 - val_loss: 0.5071 - val_acc: 0.7776\n",
      "Epoch 72/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5154 - acc: 0.7877\n",
      "Epoch 72: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5144 - acc: 0.7879 - val_loss: 0.5118 - val_acc: 0.7613\n",
      "Epoch 73/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4917 - acc: 0.7903\n",
      "Epoch 73: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4917 - acc: 0.7903 - val_loss: 0.5151 - val_acc: 0.7746\n",
      "Epoch 74/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5122 - acc: 0.7939\n",
      "Epoch 74: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5117 - acc: 0.7935 - val_loss: 0.5072 - val_acc: 0.7750\n",
      "Epoch 75/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5021 - acc: 0.7960\n",
      "Epoch 75: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5019 - acc: 0.7961 - val_loss: 0.5031 - val_acc: 0.7857\n",
      "Epoch 76/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4805 - acc: 0.7990\n",
      "Epoch 76: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4806 - acc: 0.7985 - val_loss: 0.5124 - val_acc: 0.7874\n",
      "Epoch 77/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5093 - acc: 0.7974\n",
      "Epoch 77: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5078 - acc: 0.7977 - val_loss: 0.5117 - val_acc: 0.7819\n",
      "Epoch 78/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4729 - acc: 0.7919\n",
      "Epoch 78: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4718 - acc: 0.7922 - val_loss: 0.5176 - val_acc: 0.7772\n",
      "Epoch 79/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5011 - acc: 0.7914\n",
      "Epoch 79: val_acc did not improve from 0.79042\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5014 - acc: 0.7912 - val_loss: 0.5124 - val_acc: 0.7750\n",
      "Epoch 80/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5005 - acc: 0.7967\n",
      "Epoch 80: val_acc improved from 0.79042 to 0.79213, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4985 - acc: 0.7971 - val_loss: 0.5101 - val_acc: 0.7921\n",
      "Epoch 81/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5064 - acc: 0.7948\n",
      "Epoch 81: val_acc did not improve from 0.79213\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5060 - acc: 0.7946 - val_loss: 0.5238 - val_acc: 0.7784\n",
      "Epoch 82/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4972 - acc: 0.7966\n",
      "Epoch 82: val_acc did not improve from 0.79213\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4972 - acc: 0.7961 - val_loss: 0.5007 - val_acc: 0.7802\n",
      "Epoch 83/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5088 - acc: 0.7945\n",
      "Epoch 83: val_acc did not improve from 0.79213\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5083 - acc: 0.7938 - val_loss: 0.4910 - val_acc: 0.7874\n",
      "Epoch 84/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4850 - acc: 0.7966\n",
      "Epoch 84: val_acc improved from 0.79213 to 0.79983, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4850 - acc: 0.7966 - val_loss: 0.4853 - val_acc: 0.7998\n",
      "Epoch 85/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4814 - acc: 0.7976\n",
      "Epoch 85: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4801 - acc: 0.7980 - val_loss: 0.4994 - val_acc: 0.7857\n",
      "Epoch 86/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4877 - acc: 0.8008\n",
      "Epoch 86: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4874 - acc: 0.8009 - val_loss: 0.5007 - val_acc: 0.7754\n",
      "Epoch 87/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4931 - acc: 0.7944\n",
      "Epoch 87: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4927 - acc: 0.7946 - val_loss: 0.4911 - val_acc: 0.7793\n",
      "Epoch 88/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4790 - acc: 0.7993\n",
      "Epoch 88: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4794 - acc: 0.7992 - val_loss: 0.4934 - val_acc: 0.7827\n",
      "Epoch 89/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5064 - acc: 0.7982\n",
      "Epoch 89: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5050 - acc: 0.7984 - val_loss: 0.4850 - val_acc: 0.7870\n",
      "Epoch 90/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4815 - acc: 0.8002\n",
      "Epoch 90: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4811 - acc: 0.8000 - val_loss: 0.5058 - val_acc: 0.7891\n",
      "Epoch 91/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4846 - acc: 0.8004\n",
      "Epoch 91: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4840 - acc: 0.8002 - val_loss: 0.4971 - val_acc: 0.7776\n",
      "Epoch 92/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4963 - acc: 0.8024\n",
      "Epoch 92: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4960 - acc: 0.8019 - val_loss: 0.4980 - val_acc: 0.7763\n",
      "Epoch 93/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4890 - acc: 0.7967\n",
      "Epoch 93: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4890 - acc: 0.7964 - val_loss: 0.4940 - val_acc: 0.7913\n",
      "Epoch 94/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4704 - acc: 0.8021\n",
      "Epoch 94: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4692 - acc: 0.8021 - val_loss: 0.4974 - val_acc: 0.7819\n",
      "Epoch 95/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4906 - acc: 0.8002\n",
      "Epoch 95: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4901 - acc: 0.8004 - val_loss: 0.5010 - val_acc: 0.7926\n",
      "Epoch 96/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4951 - acc: 0.7941\n",
      "Epoch 96: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4946 - acc: 0.7938 - val_loss: 0.4963 - val_acc: 0.7844\n",
      "Epoch 97/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4942 - acc: 0.8005\n",
      "Epoch 97: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4935 - acc: 0.8003 - val_loss: 0.5146 - val_acc: 0.7793\n",
      "Epoch 98/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4805 - acc: 0.7995\n",
      "Epoch 98: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4805 - acc: 0.7995 - val_loss: 0.5038 - val_acc: 0.7716\n",
      "Epoch 99/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5012 - acc: 0.7989\n",
      "Epoch 99: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5008 - acc: 0.7992 - val_loss: 0.4973 - val_acc: 0.7921\n",
      "Epoch 100/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4779 - acc: 0.8045\n",
      "Epoch 100: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4774 - acc: 0.8040 - val_loss: 0.4908 - val_acc: 0.7802\n",
      "Epoch 101/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4998 - acc: 0.7992\n",
      "Epoch 101: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4998 - acc: 0.7992 - val_loss: 0.4985 - val_acc: 0.7810\n",
      "Epoch 102/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4654 - acc: 0.8049\n",
      "Epoch 102: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4654 - acc: 0.8049 - val_loss: 0.4821 - val_acc: 0.7921\n",
      "Epoch 103/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5112 - acc: 0.8052\n",
      "Epoch 103: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5242 - acc: 0.8050 - val_loss: 0.5045 - val_acc: 0.7827\n",
      "Epoch 104/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4967 - acc: 0.8038\n",
      "Epoch 104: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4963 - acc: 0.8040 - val_loss: 0.4999 - val_acc: 0.7720\n",
      "Epoch 105/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4822 - acc: 0.8024\n",
      "Epoch 105: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4813 - acc: 0.8025 - val_loss: 0.4854 - val_acc: 0.7819\n",
      "Epoch 106/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4905 - acc: 0.7986\n",
      "Epoch 106: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4905 - acc: 0.7986 - val_loss: 0.4918 - val_acc: 0.7784\n",
      "Epoch 107/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4783 - acc: 0.8095\n",
      "Epoch 107: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4783 - acc: 0.8095 - val_loss: 0.4801 - val_acc: 0.7973\n",
      "Epoch 108/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5008 - acc: 0.8097\n",
      "Epoch 108: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.5005 - acc: 0.8097 - val_loss: 0.4761 - val_acc: 0.7943\n",
      "Epoch 109/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4821 - acc: 0.8084\n",
      "Epoch 109: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4821 - acc: 0.8084 - val_loss: 0.4910 - val_acc: 0.7998\n",
      "Epoch 110/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4786 - acc: 0.8049\n",
      "Epoch 110: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4767 - acc: 0.8056 - val_loss: 0.4842 - val_acc: 0.7998\n",
      "Epoch 111/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4887 - acc: 0.8053\n",
      "Epoch 111: val_acc did not improve from 0.79983\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4884 - acc: 0.8050 - val_loss: 0.4928 - val_acc: 0.7968\n",
      "Epoch 112/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4668 - acc: 0.8048\n",
      "Epoch 112: val_acc improved from 0.79983 to 0.80282, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4668 - acc: 0.8048 - val_loss: 0.4887 - val_acc: 0.8028\n",
      "Epoch 113/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4898 - acc: 0.8051\n",
      "Epoch 113: val_acc improved from 0.80282 to 0.80753, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4896 - acc: 0.8048 - val_loss: 0.4842 - val_acc: 0.8075\n",
      "Epoch 114/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4553 - acc: 0.8095\n",
      "Epoch 114: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4560 - acc: 0.8092 - val_loss: 0.5011 - val_acc: 0.7840\n",
      "Epoch 115/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4756 - acc: 0.8113\n",
      "Epoch 115: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4744 - acc: 0.8115 - val_loss: 0.4743 - val_acc: 0.7973\n",
      "Epoch 116/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4794 - acc: 0.8090\n",
      "Epoch 116: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4778 - acc: 0.8090 - val_loss: 0.4795 - val_acc: 0.8041\n",
      "Epoch 117/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.8117\n",
      "Epoch 117: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4786 - acc: 0.8115 - val_loss: 0.4828 - val_acc: 0.7943\n",
      "Epoch 118/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4634 - acc: 0.8093\n",
      "Epoch 118: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4630 - acc: 0.8095 - val_loss: 0.4799 - val_acc: 0.8020\n",
      "Epoch 119/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4663 - acc: 0.8071\n",
      "Epoch 119: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4660 - acc: 0.8073 - val_loss: 0.4848 - val_acc: 0.7716\n",
      "Epoch 120/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4946 - acc: 0.8135\n",
      "Epoch 120: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4942 - acc: 0.8132 - val_loss: 0.4904 - val_acc: 0.7754\n",
      "Epoch 121/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4861 - acc: 0.8094\n",
      "Epoch 121: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4853 - acc: 0.8092 - val_loss: 0.4864 - val_acc: 0.7956\n",
      "Epoch 122/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4605 - acc: 0.8086\n",
      "Epoch 122: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4602 - acc: 0.8087 - val_loss: 0.4858 - val_acc: 0.8007\n",
      "Epoch 123/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4824 - acc: 0.8049\n",
      "Epoch 123: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4824 - acc: 0.8049 - val_loss: 0.4888 - val_acc: 0.7793\n",
      "Epoch 124/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4833 - acc: 0.8092\n",
      "Epoch 124: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4826 - acc: 0.8090 - val_loss: 0.4932 - val_acc: 0.7767\n",
      "Epoch 125/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4574 - acc: 0.8056\n",
      "Epoch 125: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4572 - acc: 0.8054 - val_loss: 0.4755 - val_acc: 0.7827\n",
      "Epoch 126/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4709 - acc: 0.8061\n",
      "Epoch 126: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4696 - acc: 0.8060 - val_loss: 0.4891 - val_acc: 0.8003\n",
      "Epoch 127/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4928 - acc: 0.8058\n",
      "Epoch 127: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4921 - acc: 0.8056 - val_loss: 0.4806 - val_acc: 0.7930\n",
      "Epoch 128/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4658 - acc: 0.8130\n",
      "Epoch 128: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4642 - acc: 0.8135 - val_loss: 0.5059 - val_acc: 0.7767\n",
      "Epoch 129/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4714 - acc: 0.8122\n",
      "Epoch 129: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4713 - acc: 0.8120 - val_loss: 0.5049 - val_acc: 0.8020\n",
      "Epoch 130/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4566 - acc: 0.8076\n",
      "Epoch 130: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4563 - acc: 0.8077 - val_loss: 0.5093 - val_acc: 0.7947\n",
      "Epoch 131/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4935 - acc: 0.8166\n",
      "Epoch 131: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4935 - acc: 0.8164 - val_loss: 0.4857 - val_acc: 0.8050\n",
      "Epoch 132/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4876 - acc: 0.8114\n",
      "Epoch 132: val_acc did not improve from 0.80753\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4858 - acc: 0.8111 - val_loss: 0.4905 - val_acc: 0.7806\n",
      "Epoch 133/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4759 - acc: 0.8105\n",
      "Epoch 133: val_acc improved from 0.80753 to 0.81180, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4759 - acc: 0.8105 - val_loss: 0.4913 - val_acc: 0.8118\n",
      "Epoch 134/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4686 - acc: 0.8132\n",
      "Epoch 134: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4675 - acc: 0.8130 - val_loss: 0.4911 - val_acc: 0.7784\n",
      "Epoch 135/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4944 - acc: 0.8093\n",
      "Epoch 135: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4923 - acc: 0.8097 - val_loss: 0.4787 - val_acc: 0.8041\n",
      "Epoch 136/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4751 - acc: 0.8121\n",
      "Epoch 136: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4748 - acc: 0.8122 - val_loss: 0.4758 - val_acc: 0.8109\n",
      "Epoch 137/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4697 - acc: 0.8114\n",
      "Epoch 137: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 6s 22ms/step - loss: 0.4696 - acc: 0.8112 - val_loss: 0.4837 - val_acc: 0.7990\n",
      "Epoch 138/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4535 - acc: 0.8119\n",
      "Epoch 138: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4535 - acc: 0.8119 - val_loss: 0.5011 - val_acc: 0.8101\n",
      "Epoch 139/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5019 - acc: 0.8117\n",
      "Epoch 139: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5019 - acc: 0.8117 - val_loss: 0.4972 - val_acc: 0.7849\n",
      "Epoch 140/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4825 - acc: 0.8096\n",
      "Epoch 140: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4813 - acc: 0.8093 - val_loss: 0.5027 - val_acc: 0.8033\n",
      "Epoch 141/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4533 - acc: 0.8153\n",
      "Epoch 141: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4530 - acc: 0.8154 - val_loss: 0.4612 - val_acc: 0.8033\n",
      "Epoch 142/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4807 - acc: 0.8115\n",
      "Epoch 142: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4807 - acc: 0.8115 - val_loss: 0.4769 - val_acc: 0.7960\n",
      "Epoch 143/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4480 - acc: 0.8155\n",
      "Epoch 143: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4477 - acc: 0.8156 - val_loss: 0.4776 - val_acc: 0.8011\n",
      "Epoch 144/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4586 - acc: 0.8141\n",
      "Epoch 144: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4586 - acc: 0.8141 - val_loss: 0.4815 - val_acc: 0.7810\n",
      "Epoch 145/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4741 - acc: 0.8125\n",
      "Epoch 145: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4731 - acc: 0.8124 - val_loss: 0.4780 - val_acc: 0.7973\n",
      "Epoch 146/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4585 - acc: 0.8155\n",
      "Epoch 146: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4567 - acc: 0.8158 - val_loss: 0.4708 - val_acc: 0.8058\n",
      "Epoch 147/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5086 - acc: 0.8154\n",
      "Epoch 147: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5085 - acc: 0.8155 - val_loss: 0.4826 - val_acc: 0.7725\n",
      "Epoch 148/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4989 - acc: 0.8167\n",
      "Epoch 148: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4967 - acc: 0.8166 - val_loss: 0.4723 - val_acc: 0.7900\n",
      "Epoch 149/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4742 - acc: 0.8158\n",
      "Epoch 149: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5011 - acc: 0.8152 - val_loss: 0.4832 - val_acc: 0.7840\n",
      "Epoch 150/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.8119\n",
      "Epoch 150: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4500 - acc: 0.8119 - val_loss: 0.4855 - val_acc: 0.7938\n",
      "Epoch 151/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4769 - acc: 0.8125\n",
      "Epoch 151: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4760 - acc: 0.8123 - val_loss: 0.4883 - val_acc: 0.7776\n",
      "Epoch 152/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4725 - acc: 0.8160\n",
      "Epoch 152: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4711 - acc: 0.8159 - val_loss: 0.4842 - val_acc: 0.7904\n",
      "Epoch 153/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4990 - acc: 0.8183\n",
      "Epoch 153: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4986 - acc: 0.8184 - val_loss: 0.4668 - val_acc: 0.8045\n",
      "Epoch 154/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4876 - acc: 0.8130\n",
      "Epoch 154: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4854 - acc: 0.8132 - val_loss: 0.4804 - val_acc: 0.7998\n",
      "Epoch 155/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4823 - acc: 0.8108\n",
      "Epoch 155: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4825 - acc: 0.8103 - val_loss: 0.4683 - val_acc: 0.7985\n",
      "Epoch 156/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4590 - acc: 0.8099\n",
      "Epoch 156: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4590 - acc: 0.8099 - val_loss: 0.4831 - val_acc: 0.7973\n",
      "Epoch 157/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4604 - acc: 0.8126\n",
      "Epoch 157: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4594 - acc: 0.8124 - val_loss: 0.4726 - val_acc: 0.7977\n",
      "Epoch 158/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4560 - acc: 0.8048\n",
      "Epoch 158: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4545 - acc: 0.8047 - val_loss: 0.4707 - val_acc: 0.8033\n",
      "Epoch 159/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4703 - acc: 0.8141\n",
      "Epoch 159: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4700 - acc: 0.8140 - val_loss: 0.4715 - val_acc: 0.8050\n",
      "Epoch 160/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4388 - acc: 0.8150\n",
      "Epoch 160: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4381 - acc: 0.8148 - val_loss: 0.4693 - val_acc: 0.7908\n",
      "Epoch 161/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4834 - acc: 0.8193\n",
      "Epoch 161: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4815 - acc: 0.8197 - val_loss: 0.4688 - val_acc: 0.8109\n",
      "Epoch 162/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4893 - acc: 0.8128\n",
      "Epoch 162: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4872 - acc: 0.8132 - val_loss: 0.4705 - val_acc: 0.7934\n",
      "Epoch 163/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5079 - acc: 0.8149\n",
      "Epoch 163: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5074 - acc: 0.8150 - val_loss: 0.4684 - val_acc: 0.8011\n",
      "Epoch 164/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4669 - acc: 0.8120\n",
      "Epoch 164: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4669 - acc: 0.8120 - val_loss: 0.4768 - val_acc: 0.7866\n",
      "Epoch 165/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4611 - acc: 0.8115\n",
      "Epoch 165: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4597 - acc: 0.8115 - val_loss: 0.4747 - val_acc: 0.7836\n",
      "Epoch 166/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4730 - acc: 0.8116\n",
      "Epoch 166: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4726 - acc: 0.8118 - val_loss: 0.4768 - val_acc: 0.8003\n",
      "Epoch 167/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5578 - acc: 0.8099\n",
      "Epoch 167: val_acc did not improve from 0.81180\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5560 - acc: 0.8100 - val_loss: 0.4821 - val_acc: 0.8084\n",
      "Epoch 168/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4683 - acc: 0.8175\n",
      "Epoch 168: val_acc improved from 0.81180 to 0.81437, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4679 - acc: 0.8176 - val_loss: 0.4750 - val_acc: 0.8144\n",
      "Epoch 169/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4872 - acc: 0.8123\n",
      "Epoch 169: val_acc did not improve from 0.81437\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4860 - acc: 0.8123 - val_loss: 0.4845 - val_acc: 0.7921\n",
      "Epoch 170/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.8175\n",
      "Epoch 170: val_acc did not improve from 0.81437\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4606 - acc: 0.8176 - val_loss: 0.4818 - val_acc: 0.8097\n",
      "Epoch 171/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4668 - acc: 0.8141\n",
      "Epoch 171: val_acc improved from 0.81437 to 0.82335, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4649 - acc: 0.8143 - val_loss: 0.4834 - val_acc: 0.8234\n",
      "Epoch 172/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4676 - acc: 0.8117\n",
      "Epoch 172: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4656 - acc: 0.8122 - val_loss: 0.4795 - val_acc: 0.8135\n",
      "Epoch 173/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4487 - acc: 0.8191\n",
      "Epoch 173: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4477 - acc: 0.8188 - val_loss: 0.4889 - val_acc: 0.8015\n",
      "Epoch 174/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4908 - acc: 0.8137\n",
      "Epoch 174: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4905 - acc: 0.8132 - val_loss: 0.4806 - val_acc: 0.7849\n",
      "Epoch 175/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.8121\n",
      "Epoch 175: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4570 - acc: 0.8121 - val_loss: 0.4793 - val_acc: 0.7883\n",
      "Epoch 176/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4592 - acc: 0.8130\n",
      "Epoch 176: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4592 - acc: 0.8130 - val_loss: 0.4730 - val_acc: 0.8033\n",
      "Epoch 177/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4712 - acc: 0.8163\n",
      "Epoch 177: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4704 - acc: 0.8164 - val_loss: 0.4682 - val_acc: 0.8122\n",
      "Epoch 178/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4635 - acc: 0.8169\n",
      "Epoch 178: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4621 - acc: 0.8169 - val_loss: 0.4921 - val_acc: 0.7964\n",
      "Epoch 179/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4578 - acc: 0.8173\n",
      "Epoch 179: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4575 - acc: 0.8174 - val_loss: 0.4707 - val_acc: 0.8054\n",
      "Epoch 180/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4900 - acc: 0.8207\n",
      "Epoch 180: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4884 - acc: 0.8206 - val_loss: 0.4752 - val_acc: 0.7904\n",
      "Epoch 181/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5186 - acc: 0.8139\n",
      "Epoch 181: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5172 - acc: 0.8135 - val_loss: 0.5100 - val_acc: 0.7956\n",
      "Epoch 182/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4737 - acc: 0.8137\n",
      "Epoch 182: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4730 - acc: 0.8135 - val_loss: 0.4966 - val_acc: 0.8101\n",
      "Epoch 183/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5031 - acc: 0.8167\n",
      "Epoch 183: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5031 - acc: 0.8167 - val_loss: 0.4858 - val_acc: 0.8067\n",
      "Epoch 184/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4858 - acc: 0.8166\n",
      "Epoch 184: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 5s 18ms/step - loss: 0.4841 - acc: 0.8169 - val_loss: 0.4776 - val_acc: 0.7938\n",
      "Epoch 185/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4464 - acc: 0.8186\n",
      "Epoch 185: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4460 - acc: 0.8188 - val_loss: 0.4789 - val_acc: 0.8101\n",
      "Epoch 186/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4555 - acc: 0.8233\n",
      "Epoch 186: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4555 - acc: 0.8233 - val_loss: 0.4904 - val_acc: 0.7887\n",
      "Epoch 187/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4805 - acc: 0.8199\n",
      "Epoch 187: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4792 - acc: 0.8188 - val_loss: 0.4698 - val_acc: 0.7874\n",
      "Epoch 188/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4578 - acc: 0.8162\n",
      "Epoch 188: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4565 - acc: 0.8162 - val_loss: 0.4853 - val_acc: 0.7874\n",
      "Epoch 189/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4925 - acc: 0.8184\n",
      "Epoch 189: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4903 - acc: 0.8187 - val_loss: 0.4652 - val_acc: 0.8020\n",
      "Epoch 190/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4777 - acc: 0.8198\n",
      "Epoch 190: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4769 - acc: 0.8197 - val_loss: 0.4609 - val_acc: 0.8033\n",
      "Epoch 191/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4814 - acc: 0.8151\n",
      "Epoch 191: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4807 - acc: 0.8151 - val_loss: 0.4763 - val_acc: 0.7904\n",
      "Epoch 192/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4988 - acc: 0.8191\n",
      "Epoch 192: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4968 - acc: 0.8189 - val_loss: 0.4677 - val_acc: 0.7891\n",
      "Epoch 193/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4800 - acc: 0.8187\n",
      "Epoch 193: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4775 - acc: 0.8186 - val_loss: 0.4665 - val_acc: 0.7900\n",
      "Epoch 194/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4600 - acc: 0.8135\n",
      "Epoch 194: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4599 - acc: 0.8133 - val_loss: 0.4581 - val_acc: 0.8020\n",
      "Epoch 195/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4445 - acc: 0.8222\n",
      "Epoch 195: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4436 - acc: 0.8221 - val_loss: 0.4798 - val_acc: 0.8003\n",
      "Epoch 196/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.8186\n",
      "Epoch 196: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4681 - acc: 0.8187 - val_loss: 0.4844 - val_acc: 0.7964\n",
      "Epoch 197/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4535 - acc: 0.8197\n",
      "Epoch 197: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4527 - acc: 0.8197 - val_loss: 0.4704 - val_acc: 0.8058\n",
      "Epoch 198/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4701 - acc: 0.8226\n",
      "Epoch 198: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4682 - acc: 0.8230 - val_loss: 0.4833 - val_acc: 0.8195\n",
      "Epoch 199/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4608 - acc: 0.8182\n",
      "Epoch 199: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4599 - acc: 0.8183 - val_loss: 0.4734 - val_acc: 0.7938\n",
      "Epoch 200/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4768 - acc: 0.8151\n",
      "Epoch 200: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4765 - acc: 0.8152 - val_loss: 0.4696 - val_acc: 0.8114\n",
      "Epoch 201/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4744 - acc: 0.8152\n",
      "Epoch 201: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4730 - acc: 0.8155 - val_loss: 0.4514 - val_acc: 0.8075\n",
      "Epoch 202/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.8212\n",
      "Epoch 202: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4598 - acc: 0.8213 - val_loss: 0.4616 - val_acc: 0.8062\n",
      "Epoch 203/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4936 - acc: 0.8212\n",
      "Epoch 203: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4930 - acc: 0.8209 - val_loss: 0.4550 - val_acc: 0.7956\n",
      "Epoch 204/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4392 - acc: 0.8253\n",
      "Epoch 204: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4389 - acc: 0.8254 - val_loss: 0.4618 - val_acc: 0.7938\n",
      "Epoch 205/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.8231\n",
      "Epoch 205: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4602 - acc: 0.8231 - val_loss: 0.4782 - val_acc: 0.8067\n",
      "Epoch 206/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5156 - acc: 0.8268\n",
      "Epoch 206: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5151 - acc: 0.8265 - val_loss: 0.4749 - val_acc: 0.8033\n",
      "Epoch 207/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.8171\n",
      "Epoch 207: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5170 - acc: 0.8168 - val_loss: 0.4889 - val_acc: 0.7840\n",
      "Epoch 208/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4814 - acc: 0.8161\n",
      "Epoch 208: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4805 - acc: 0.8164 - val_loss: 0.4767 - val_acc: 0.8007\n",
      "Epoch 209/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4955 - acc: 0.8173\n",
      "Epoch 209: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4952 - acc: 0.8173 - val_loss: 0.4832 - val_acc: 0.7934\n",
      "Epoch 210/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4491 - acc: 0.8162\n",
      "Epoch 210: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4489 - acc: 0.8163 - val_loss: 0.4778 - val_acc: 0.7930\n",
      "Epoch 211/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4946 - acc: 0.8154\n",
      "Epoch 211: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4932 - acc: 0.8155 - val_loss: 0.4687 - val_acc: 0.7960\n",
      "Epoch 212/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4565 - acc: 0.8159\n",
      "Epoch 212: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4565 - acc: 0.8159 - val_loss: 0.4740 - val_acc: 0.8127\n",
      "Epoch 213/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4644 - acc: 0.8156\n",
      "Epoch 213: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4641 - acc: 0.8152 - val_loss: 0.4879 - val_acc: 0.7823\n",
      "Epoch 214/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4753 - acc: 0.8182\n",
      "Epoch 214: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4750 - acc: 0.8182 - val_loss: 0.4614 - val_acc: 0.7964\n",
      "Epoch 215/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5124 - acc: 0.8182\n",
      "Epoch 215: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5124 - acc: 0.8182 - val_loss: 0.4643 - val_acc: 0.8139\n",
      "Epoch 216/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4820 - acc: 0.8139\n",
      "Epoch 216: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4800 - acc: 0.8143 - val_loss: 0.5020 - val_acc: 0.7951\n",
      "Epoch 217/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4995 - acc: 0.8160\n",
      "Epoch 217: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4982 - acc: 0.8159 - val_loss: 0.4873 - val_acc: 0.7836\n",
      "Epoch 218/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4826 - acc: 0.8136\n",
      "Epoch 218: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4822 - acc: 0.8137 - val_loss: 0.4679 - val_acc: 0.8028\n",
      "Epoch 219/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4703 - acc: 0.8164\n",
      "Epoch 219: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4688 - acc: 0.8168 - val_loss: 0.4581 - val_acc: 0.8080\n",
      "Epoch 220/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4572 - acc: 0.8171\n",
      "Epoch 220: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4555 - acc: 0.8176 - val_loss: 0.4601 - val_acc: 0.8028\n",
      "Epoch 221/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4834 - acc: 0.8162\n",
      "Epoch 221: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4819 - acc: 0.8164 - val_loss: 0.4797 - val_acc: 0.7985\n",
      "Epoch 222/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4844 - acc: 0.8164\n",
      "Epoch 222: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4841 - acc: 0.8164 - val_loss: 0.4663 - val_acc: 0.8011\n",
      "Epoch 223/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4796 - acc: 0.8146\n",
      "Epoch 223: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4796 - acc: 0.8146 - val_loss: 0.4708 - val_acc: 0.8097\n",
      "Epoch 224/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5131 - acc: 0.8173\n",
      "Epoch 224: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.5135 - acc: 0.8168 - val_loss: 0.4736 - val_acc: 0.8015\n",
      "Epoch 225/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4625 - acc: 0.8170\n",
      "Epoch 225: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4609 - acc: 0.8170 - val_loss: 0.4749 - val_acc: 0.7904\n",
      "Epoch 226/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4393 - acc: 0.8200\n",
      "Epoch 226: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4390 - acc: 0.8200 - val_loss: 0.4620 - val_acc: 0.7973\n",
      "Epoch 227/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4640 - acc: 0.8239\n",
      "Epoch 227: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 5s 15ms/step - loss: 0.4619 - acc: 0.8239 - val_loss: 0.4545 - val_acc: 0.8148\n",
      "Epoch 228/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4735 - acc: 0.8191\n",
      "Epoch 228: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4721 - acc: 0.8189 - val_loss: 0.4578 - val_acc: 0.8118\n",
      "Epoch 229/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.8178\n",
      "Epoch 229: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4420 - acc: 0.8180 - val_loss: 0.4641 - val_acc: 0.8114\n",
      "Epoch 230/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4812 - acc: 0.8204\n",
      "Epoch 230: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4807 - acc: 0.8205 - val_loss: 0.4622 - val_acc: 0.8062\n",
      "Epoch 231/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4703 - acc: 0.8226\n",
      "Epoch 231: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4700 - acc: 0.8227 - val_loss: 0.4706 - val_acc: 0.8135\n",
      "Epoch 232/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4999 - acc: 0.8212\n",
      "Epoch 232: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 5s 17ms/step - loss: 0.4985 - acc: 0.8212 - val_loss: 0.4630 - val_acc: 0.8071\n",
      "Epoch 233/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4513 - acc: 0.8158\n",
      "Epoch 233: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4550 - acc: 0.8157 - val_loss: 0.4614 - val_acc: 0.8020\n",
      "Epoch 234/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.8195\n",
      "Epoch 234: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4606 - acc: 0.8197 - val_loss: 0.4725 - val_acc: 0.8178\n",
      "Epoch 235/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4876 - acc: 0.8252\n",
      "Epoch 235: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4855 - acc: 0.8251 - val_loss: 0.4613 - val_acc: 0.7981\n",
      "Epoch 236/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5242 - acc: 0.8161\n",
      "Epoch 236: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5219 - acc: 0.8161 - val_loss: 0.4763 - val_acc: 0.7793\n",
      "Epoch 237/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4702 - acc: 0.8153\n",
      "Epoch 237: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4686 - acc: 0.8150 - val_loss: 0.4632 - val_acc: 0.8028\n",
      "Epoch 238/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4691 - acc: 0.8201\n",
      "Epoch 238: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4691 - acc: 0.8201 - val_loss: 0.4803 - val_acc: 0.7951\n",
      "Epoch 239/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4460 - acc: 0.8181\n",
      "Epoch 239: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4447 - acc: 0.8187 - val_loss: 0.4565 - val_acc: 0.8105\n",
      "Epoch 240/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4726 - acc: 0.8184\n",
      "Epoch 240: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4726 - acc: 0.8184 - val_loss: 0.4766 - val_acc: 0.8058\n",
      "Epoch 241/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4499 - acc: 0.8214\n",
      "Epoch 241: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4490 - acc: 0.8208 - val_loss: 0.4605 - val_acc: 0.7784\n",
      "Epoch 242/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4462 - acc: 0.8225\n",
      "Epoch 242: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4452 - acc: 0.8224 - val_loss: 0.4623 - val_acc: 0.8139\n",
      "Epoch 243/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4952 - acc: 0.8223\n",
      "Epoch 243: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4947 - acc: 0.8220 - val_loss: 0.4681 - val_acc: 0.8088\n",
      "Epoch 244/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4903 - acc: 0.8235\n",
      "Epoch 244: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4898 - acc: 0.8230 - val_loss: 0.4590 - val_acc: 0.8139\n",
      "Epoch 245/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4826 - acc: 0.8199\n",
      "Epoch 245: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4812 - acc: 0.8197 - val_loss: 0.4770 - val_acc: 0.7938\n",
      "Epoch 246/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4541 - acc: 0.8210\n",
      "Epoch 246: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4517 - acc: 0.8211 - val_loss: 0.4697 - val_acc: 0.8075\n",
      "Epoch 247/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4667 - acc: 0.8229\n",
      "Epoch 247: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4649 - acc: 0.8228 - val_loss: 0.4885 - val_acc: 0.8011\n",
      "Epoch 248/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5053 - acc: 0.8208\n",
      "Epoch 248: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.5046 - acc: 0.8205 - val_loss: 0.4633 - val_acc: 0.7900\n",
      "Epoch 249/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4394 - acc: 0.8254\n",
      "Epoch 249: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4499 - acc: 0.8255 - val_loss: 0.4675 - val_acc: 0.8020\n",
      "Epoch 250/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4202 - acc: 0.8267\n",
      "Epoch 250: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4188 - acc: 0.8272 - val_loss: 0.4569 - val_acc: 0.8058\n",
      "Epoch 251/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4667 - acc: 0.8225\n",
      "Epoch 251: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4650 - acc: 0.8225 - val_loss: 0.4681 - val_acc: 0.8007\n",
      "Epoch 252/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5072 - acc: 0.8217\n",
      "Epoch 252: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5067 - acc: 0.8218 - val_loss: 0.4613 - val_acc: 0.8084\n",
      "Epoch 253/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4530 - acc: 0.8224\n",
      "Epoch 253: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4521 - acc: 0.8225 - val_loss: 0.4715 - val_acc: 0.8003\n",
      "Epoch 254/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4636 - acc: 0.8275\n",
      "Epoch 254: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 5s 17ms/step - loss: 0.4622 - acc: 0.8281 - val_loss: 0.4689 - val_acc: 0.8067\n",
      "Epoch 255/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4546 - acc: 0.8200\n",
      "Epoch 255: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4538 - acc: 0.8199 - val_loss: 0.4713 - val_acc: 0.8037\n",
      "Epoch 256/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4795 - acc: 0.8277\n",
      "Epoch 256: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4785 - acc: 0.8276 - val_loss: 0.4710 - val_acc: 0.8015\n",
      "Epoch 257/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4676 - acc: 0.8212\n",
      "Epoch 257: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4655 - acc: 0.8212 - val_loss: 0.4675 - val_acc: 0.8015\n",
      "Epoch 258/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4696 - acc: 0.8211\n",
      "Epoch 258: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4675 - acc: 0.8214 - val_loss: 0.4789 - val_acc: 0.8122\n",
      "Epoch 259/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4378 - acc: 0.8303\n",
      "Epoch 259: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4370 - acc: 0.8304 - val_loss: 0.4747 - val_acc: 0.8122\n",
      "Epoch 260/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5027 - acc: 0.8257\n",
      "Epoch 260: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5019 - acc: 0.8257 - val_loss: 0.4614 - val_acc: 0.7947\n",
      "Epoch 261/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4574 - acc: 0.8247\n",
      "Epoch 261: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4574 - acc: 0.8247 - val_loss: 0.4791 - val_acc: 0.8045\n",
      "Epoch 262/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4810 - acc: 0.8237\n",
      "Epoch 262: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4792 - acc: 0.8239 - val_loss: 0.4739 - val_acc: 0.8041\n",
      "Epoch 263/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4780 - acc: 0.8283\n",
      "Epoch 263: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4775 - acc: 0.8285 - val_loss: 0.4648 - val_acc: 0.7994\n",
      "Epoch 264/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4605 - acc: 0.8283\n",
      "Epoch 264: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4587 - acc: 0.8287 - val_loss: 0.4995 - val_acc: 0.7904\n",
      "Epoch 265/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4622 - acc: 0.8227\n",
      "Epoch 265: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4606 - acc: 0.8228 - val_loss: 0.4645 - val_acc: 0.8007\n",
      "Epoch 266/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4736 - acc: 0.8286\n",
      "Epoch 266: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4728 - acc: 0.8287 - val_loss: 0.4754 - val_acc: 0.8033\n",
      "Epoch 267/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4462 - acc: 0.8269\n",
      "Epoch 267: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4446 - acc: 0.8271 - val_loss: 0.4801 - val_acc: 0.8152\n",
      "Epoch 268/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4724 - acc: 0.8247\n",
      "Epoch 268: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4717 - acc: 0.8245 - val_loss: 0.4772 - val_acc: 0.8114\n",
      "Epoch 269/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4747 - acc: 0.8204\n",
      "Epoch 269: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4744 - acc: 0.8204 - val_loss: 0.4963 - val_acc: 0.7913\n",
      "Epoch 270/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4523 - acc: 0.8210\n",
      "Epoch 270: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4520 - acc: 0.8210 - val_loss: 0.4627 - val_acc: 0.8075\n",
      "Epoch 271/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4633 - acc: 0.8210\n",
      "Epoch 271: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4628 - acc: 0.8208 - val_loss: 0.4766 - val_acc: 0.7776\n",
      "Epoch 272/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4726 - acc: 0.8258\n",
      "Epoch 272: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4707 - acc: 0.8261 - val_loss: 0.4733 - val_acc: 0.8058\n",
      "Epoch 273/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.8266\n",
      "Epoch 273: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4681 - acc: 0.8266 - val_loss: 0.4689 - val_acc: 0.7938\n",
      "Epoch 274/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4565 - acc: 0.8257\n",
      "Epoch 274: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4565 - acc: 0.8257 - val_loss: 0.4692 - val_acc: 0.7981\n",
      "Epoch 275/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4509 - acc: 0.8250\n",
      "Epoch 275: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4505 - acc: 0.8251 - val_loss: 0.4674 - val_acc: 0.8028\n",
      "Epoch 276/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4946 - acc: 0.8246\n",
      "Epoch 276: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4940 - acc: 0.8243 - val_loss: 0.4818 - val_acc: 0.7990\n",
      "Epoch 277/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4582 - acc: 0.8265\n",
      "Epoch 277: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4576 - acc: 0.8264 - val_loss: 0.4629 - val_acc: 0.8037\n",
      "Epoch 278/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4938 - acc: 0.8229\n",
      "Epoch 278: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4915 - acc: 0.8225 - val_loss: 0.4791 - val_acc: 0.7908\n",
      "Epoch 279/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4600 - acc: 0.8239\n",
      "Epoch 279: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4588 - acc: 0.8240 - val_loss: 0.4714 - val_acc: 0.7960\n",
      "Epoch 280/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4940 - acc: 0.8278\n",
      "Epoch 280: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4926 - acc: 0.8276 - val_loss: 0.4783 - val_acc: 0.7943\n",
      "Epoch 281/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8231\n",
      "Epoch 281: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4650 - acc: 0.8233 - val_loss: 0.4696 - val_acc: 0.8028\n",
      "Epoch 282/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4781 - acc: 0.8273\n",
      "Epoch 282: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4778 - acc: 0.8273 - val_loss: 0.4626 - val_acc: 0.7896\n",
      "Epoch 283/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5054 - acc: 0.8253\n",
      "Epoch 283: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5046 - acc: 0.8250 - val_loss: 0.4652 - val_acc: 0.8186\n",
      "Epoch 284/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4628 - acc: 0.8223\n",
      "Epoch 284: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4610 - acc: 0.8220 - val_loss: 0.4588 - val_acc: 0.8011\n",
      "Epoch 285/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5084 - acc: 0.8202\n",
      "Epoch 285: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5065 - acc: 0.8196 - val_loss: 0.4746 - val_acc: 0.7874\n",
      "Epoch 286/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4497 - acc: 0.8244\n",
      "Epoch 286: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4473 - acc: 0.8246 - val_loss: 0.4701 - val_acc: 0.8024\n",
      "Epoch 287/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4706 - acc: 0.8227\n",
      "Epoch 287: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4706 - acc: 0.8227 - val_loss: 0.4856 - val_acc: 0.8161\n",
      "Epoch 288/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4650 - acc: 0.8223\n",
      "Epoch 288: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4635 - acc: 0.8223 - val_loss: 0.4969 - val_acc: 0.8033\n",
      "Epoch 289/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4538 - acc: 0.8262\n",
      "Epoch 289: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4527 - acc: 0.8259 - val_loss: 0.4744 - val_acc: 0.8015\n",
      "Epoch 290/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.8219\n",
      "Epoch 290: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4584 - acc: 0.8211 - val_loss: 0.5005 - val_acc: 0.7840\n",
      "Epoch 291/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4807 - acc: 0.8249\n",
      "Epoch 291: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4777 - acc: 0.8252 - val_loss: 0.4863 - val_acc: 0.7981\n",
      "Epoch 292/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4997 - acc: 0.8193\n",
      "Epoch 292: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4972 - acc: 0.8194 - val_loss: 0.4729 - val_acc: 0.8007\n",
      "Epoch 293/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4740 - acc: 0.8223\n",
      "Epoch 293: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4737 - acc: 0.8224 - val_loss: 0.4765 - val_acc: 0.8045\n",
      "Epoch 294/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4559 - acc: 0.8240\n",
      "Epoch 294: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4554 - acc: 0.8241 - val_loss: 0.4753 - val_acc: 0.8105\n",
      "Epoch 295/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4524 - acc: 0.8271\n",
      "Epoch 295: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4515 - acc: 0.8270 - val_loss: 0.4901 - val_acc: 0.8101\n",
      "Epoch 296/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4801 - acc: 0.8215\n",
      "Epoch 296: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4783 - acc: 0.8217 - val_loss: 0.4714 - val_acc: 0.7866\n",
      "Epoch 297/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.5267 - acc: 0.8290\n",
      "Epoch 297: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5241 - acc: 0.8289 - val_loss: 0.5022 - val_acc: 0.7951\n",
      "Epoch 298/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4931 - acc: 0.8259\n",
      "Epoch 298: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4928 - acc: 0.8259 - val_loss: 0.5116 - val_acc: 0.8174\n",
      "Epoch 299/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4799 - acc: 0.8215\n",
      "Epoch 299: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4794 - acc: 0.8217 - val_loss: 0.4739 - val_acc: 0.7968\n",
      "Epoch 300/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4940 - acc: 0.8248\n",
      "Epoch 300: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4925 - acc: 0.8248 - val_loss: 0.4898 - val_acc: 0.7930\n",
      "Epoch 301/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4904 - acc: 0.8254\n",
      "Epoch 301: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4881 - acc: 0.8255 - val_loss: 0.4583 - val_acc: 0.7981\n",
      "Epoch 302/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4893 - acc: 0.8289\n",
      "Epoch 302: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4893 - acc: 0.8289 - val_loss: 0.4937 - val_acc: 0.7904\n",
      "Epoch 303/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4690 - acc: 0.8271\n",
      "Epoch 303: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4678 - acc: 0.8273 - val_loss: 0.4660 - val_acc: 0.8080\n",
      "Epoch 304/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4563 - acc: 0.8267\n",
      "Epoch 304: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4560 - acc: 0.8267 - val_loss: 0.4547 - val_acc: 0.8204\n",
      "Epoch 305/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4755 - acc: 0.8285\n",
      "Epoch 305: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4732 - acc: 0.8286 - val_loss: 0.4766 - val_acc: 0.7981\n",
      "Epoch 306/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4721 - acc: 0.8293\n",
      "Epoch 306: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4704 - acc: 0.8291 - val_loss: 0.4642 - val_acc: 0.7994\n",
      "Epoch 307/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4609 - acc: 0.8241\n",
      "Epoch 307: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4609 - acc: 0.8241 - val_loss: 0.4935 - val_acc: 0.7926\n",
      "Epoch 308/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4672 - acc: 0.8238\n",
      "Epoch 308: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4663 - acc: 0.8237 - val_loss: 0.4744 - val_acc: 0.7866\n",
      "Epoch 309/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4540 - acc: 0.8319\n",
      "Epoch 309: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4540 - acc: 0.8319 - val_loss: 0.4635 - val_acc: 0.8174\n",
      "Epoch 310/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4611 - acc: 0.8251\n",
      "Epoch 310: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4611 - acc: 0.8251 - val_loss: 0.4696 - val_acc: 0.8067\n",
      "Epoch 311/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4691 - acc: 0.8264\n",
      "Epoch 311: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4685 - acc: 0.8262 - val_loss: 0.5015 - val_acc: 0.8067\n",
      "Epoch 312/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4930 - acc: 0.8291\n",
      "Epoch 312: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4907 - acc: 0.8289 - val_loss: 0.4992 - val_acc: 0.8139\n",
      "Epoch 313/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4658 - acc: 0.8281\n",
      "Epoch 313: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4644 - acc: 0.8282 - val_loss: 0.4891 - val_acc: 0.7985\n",
      "Epoch 314/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4622 - acc: 0.8288\n",
      "Epoch 314: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4608 - acc: 0.8286 - val_loss: 0.4690 - val_acc: 0.8084\n",
      "Epoch 315/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4662 - acc: 0.8221\n",
      "Epoch 315: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4652 - acc: 0.8220 - val_loss: 0.4909 - val_acc: 0.8071\n",
      "Epoch 316/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5033 - acc: 0.8221\n",
      "Epoch 316: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5030 - acc: 0.8221 - val_loss: 0.4825 - val_acc: 0.8020\n",
      "Epoch 317/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4835 - acc: 0.8280\n",
      "Epoch 317: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4835 - acc: 0.8280 - val_loss: 0.4980 - val_acc: 0.7926\n",
      "Epoch 318/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4503 - acc: 0.8288\n",
      "Epoch 318: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4488 - acc: 0.8290 - val_loss: 0.5190 - val_acc: 0.8114\n",
      "Epoch 319/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4726 - acc: 0.8249\n",
      "Epoch 319: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4722 - acc: 0.8249 - val_loss: 0.4976 - val_acc: 0.8054\n",
      "Epoch 320/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4874 - acc: 0.8166\n",
      "Epoch 320: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4855 - acc: 0.8168 - val_loss: 0.4766 - val_acc: 0.7763\n",
      "Epoch 321/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4728 - acc: 0.8248\n",
      "Epoch 321: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4728 - acc: 0.8248 - val_loss: 0.4841 - val_acc: 0.8199\n",
      "Epoch 322/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4951 - acc: 0.8313\n",
      "Epoch 322: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4944 - acc: 0.8311 - val_loss: 0.4691 - val_acc: 0.8015\n",
      "Epoch 323/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4724 - acc: 0.8296\n",
      "Epoch 323: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4717 - acc: 0.8293 - val_loss: 0.4614 - val_acc: 0.7977\n",
      "Epoch 324/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4618 - acc: 0.8303\n",
      "Epoch 324: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4607 - acc: 0.8302 - val_loss: 0.4694 - val_acc: 0.8024\n",
      "Epoch 325/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4592 - acc: 0.8264\n",
      "Epoch 325: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4564 - acc: 0.8271 - val_loss: 0.4777 - val_acc: 0.8088\n",
      "Epoch 326/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4588 - acc: 0.8290\n",
      "Epoch 326: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4604 - acc: 0.8287 - val_loss: 0.4791 - val_acc: 0.7951\n",
      "Epoch 327/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4628 - acc: 0.8326\n",
      "Epoch 327: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4628 - acc: 0.8326 - val_loss: 0.4873 - val_acc: 0.8169\n",
      "Epoch 328/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.8252\n",
      "Epoch 328: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4691 - acc: 0.8254 - val_loss: 0.4884 - val_acc: 0.8161\n",
      "Epoch 329/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.5131 - acc: 0.8264\n",
      "Epoch 329: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5131 - acc: 0.8264 - val_loss: 0.4564 - val_acc: 0.8041\n",
      "Epoch 330/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4871 - acc: 0.8199\n",
      "Epoch 330: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4864 - acc: 0.8196 - val_loss: 0.4641 - val_acc: 0.7849\n",
      "Epoch 331/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4636 - acc: 0.8244\n",
      "Epoch 331: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4619 - acc: 0.8243 - val_loss: 0.4634 - val_acc: 0.7827\n",
      "Epoch 332/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4945 - acc: 0.8305\n",
      "Epoch 332: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4930 - acc: 0.8303 - val_loss: 0.4501 - val_acc: 0.8135\n",
      "Epoch 333/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4515 - acc: 0.8265\n",
      "Epoch 333: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4500 - acc: 0.8263 - val_loss: 0.4625 - val_acc: 0.8097\n",
      "Epoch 334/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4666 - acc: 0.8309\n",
      "Epoch 334: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4662 - acc: 0.8310 - val_loss: 0.4674 - val_acc: 0.8007\n",
      "Epoch 335/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4946 - acc: 0.8260\n",
      "Epoch 335: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4926 - acc: 0.8260 - val_loss: 0.4581 - val_acc: 0.7951\n",
      "Epoch 336/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4706 - acc: 0.8268\n",
      "Epoch 336: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4702 - acc: 0.8264 - val_loss: 0.4734 - val_acc: 0.8088\n",
      "Epoch 337/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4981 - acc: 0.8305\n",
      "Epoch 337: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4955 - acc: 0.8306 - val_loss: 0.4530 - val_acc: 0.8071\n",
      "Epoch 338/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4369 - acc: 0.8309\n",
      "Epoch 338: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4356 - acc: 0.8309 - val_loss: 0.4417 - val_acc: 0.8135\n",
      "Epoch 339/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4641 - acc: 0.8287\n",
      "Epoch 339: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4637 - acc: 0.8287 - val_loss: 0.4585 - val_acc: 0.7968\n",
      "Epoch 340/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4756 - acc: 0.8305\n",
      "Epoch 340: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4756 - acc: 0.8305 - val_loss: 0.4610 - val_acc: 0.7750\n",
      "Epoch 341/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4441 - acc: 0.8311\n",
      "Epoch 341: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4432 - acc: 0.8312 - val_loss: 0.4484 - val_acc: 0.8195\n",
      "Epoch 342/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4638 - acc: 0.8254\n",
      "Epoch 342: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4631 - acc: 0.8251 - val_loss: 0.4551 - val_acc: 0.8045\n",
      "Epoch 343/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4573 - acc: 0.8266\n",
      "Epoch 343: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4552 - acc: 0.8268 - val_loss: 0.4892 - val_acc: 0.8037\n",
      "Epoch 344/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.8306\n",
      "Epoch 344: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4611 - acc: 0.8306 - val_loss: 0.4616 - val_acc: 0.7908\n",
      "Epoch 345/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4886 - acc: 0.8316\n",
      "Epoch 345: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4861 - acc: 0.8317 - val_loss: 0.4721 - val_acc: 0.8144\n",
      "Epoch 346/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4826 - acc: 0.8246\n",
      "Epoch 346: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4826 - acc: 0.8246 - val_loss: 0.4874 - val_acc: 0.7870\n",
      "Epoch 347/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4579 - acc: 0.8299\n",
      "Epoch 347: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4557 - acc: 0.8296 - val_loss: 0.4880 - val_acc: 0.7840\n",
      "Epoch 348/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5862 - acc: 0.8328\n",
      "Epoch 348: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5857 - acc: 0.8326 - val_loss: 0.4615 - val_acc: 0.8092\n",
      "Epoch 349/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4688 - acc: 0.8311\n",
      "Epoch 349: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4669 - acc: 0.8307 - val_loss: 0.4561 - val_acc: 0.7990\n",
      "Epoch 350/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4525 - acc: 0.8341\n",
      "Epoch 350: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4510 - acc: 0.8334 - val_loss: 0.4764 - val_acc: 0.7870\n",
      "Epoch 351/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.8327\n",
      "Epoch 351: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4487 - acc: 0.8322 - val_loss: 0.4718 - val_acc: 0.8028\n",
      "Epoch 352/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4704 - acc: 0.8319\n",
      "Epoch 352: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4704 - acc: 0.8319 - val_loss: 0.4908 - val_acc: 0.8058\n",
      "Epoch 353/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5478 - acc: 0.8260\n",
      "Epoch 353: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5465 - acc: 0.8260 - val_loss: 0.4808 - val_acc: 0.7985\n",
      "Epoch 354/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4513 - acc: 0.8290\n",
      "Epoch 354: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4510 - acc: 0.8288 - val_loss: 0.4664 - val_acc: 0.8045\n",
      "Epoch 355/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4773 - acc: 0.8301\n",
      "Epoch 355: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4773 - acc: 0.8301 - val_loss: 0.4578 - val_acc: 0.8037\n",
      "Epoch 356/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4440 - acc: 0.8298\n",
      "Epoch 356: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 5s 18ms/step - loss: 0.4440 - acc: 0.8298 - val_loss: 0.4788 - val_acc: 0.8122\n",
      "Epoch 357/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4542 - acc: 0.8319\n",
      "Epoch 357: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4531 - acc: 0.8319 - val_loss: 0.4620 - val_acc: 0.8037\n",
      "Epoch 358/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5129 - acc: 0.8308\n",
      "Epoch 358: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.5114 - acc: 0.8307 - val_loss: 0.4738 - val_acc: 0.8131\n",
      "Epoch 359/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.8357\n",
      "Epoch 359: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4459 - acc: 0.8361 - val_loss: 0.4672 - val_acc: 0.8139\n",
      "Epoch 360/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4513 - acc: 0.8312\n",
      "Epoch 360: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4508 - acc: 0.8309 - val_loss: 0.4596 - val_acc: 0.8011\n",
      "Epoch 361/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4574 - acc: 0.8296\n",
      "Epoch 361: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4564 - acc: 0.8289 - val_loss: 0.4658 - val_acc: 0.8062\n",
      "Epoch 362/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4467 - acc: 0.8300\n",
      "Epoch 362: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4455 - acc: 0.8295 - val_loss: 0.4822 - val_acc: 0.7891\n",
      "Epoch 363/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4485 - acc: 0.8268\n",
      "Epoch 363: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4459 - acc: 0.8276 - val_loss: 0.4883 - val_acc: 0.8221\n",
      "Epoch 364/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4807 - acc: 0.8306\n",
      "Epoch 364: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4791 - acc: 0.8306 - val_loss: 0.4664 - val_acc: 0.8028\n",
      "Epoch 365/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4632 - acc: 0.8265\n",
      "Epoch 365: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4619 - acc: 0.8265 - val_loss: 0.4747 - val_acc: 0.8169\n",
      "Epoch 366/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4748 - acc: 0.8319\n",
      "Epoch 366: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4732 - acc: 0.8316 - val_loss: 0.4632 - val_acc: 0.7973\n",
      "Epoch 367/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4871 - acc: 0.8353\n",
      "Epoch 367: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4871 - acc: 0.8353 - val_loss: 0.4836 - val_acc: 0.7930\n",
      "Epoch 368/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4737 - acc: 0.8326\n",
      "Epoch 368: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4729 - acc: 0.8325 - val_loss: 0.4618 - val_acc: 0.8199\n",
      "Epoch 369/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4694 - acc: 0.8306\n",
      "Epoch 369: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4682 - acc: 0.8305 - val_loss: 0.4661 - val_acc: 0.8075\n",
      "Epoch 370/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4297 - acc: 0.8331\n",
      "Epoch 370: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4289 - acc: 0.8329 - val_loss: 0.4784 - val_acc: 0.8165\n",
      "Epoch 371/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4611 - acc: 0.8328\n",
      "Epoch 371: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4608 - acc: 0.8328 - val_loss: 0.4727 - val_acc: 0.8062\n",
      "Epoch 372/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.5031 - acc: 0.8244\n",
      "Epoch 372: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5015 - acc: 0.8242 - val_loss: 0.4887 - val_acc: 0.7879\n",
      "Epoch 373/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4569 - acc: 0.8306\n",
      "Epoch 373: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4565 - acc: 0.8305 - val_loss: 0.4740 - val_acc: 0.8020\n",
      "Epoch 374/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4687 - acc: 0.8325\n",
      "Epoch 374: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4687 - acc: 0.8325 - val_loss: 0.4967 - val_acc: 0.7973\n",
      "Epoch 375/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4344 - acc: 0.8340\n",
      "Epoch 375: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4340 - acc: 0.8337 - val_loss: 0.4800 - val_acc: 0.8024\n",
      "Epoch 376/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.5032 - acc: 0.8280\n",
      "Epoch 376: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5025 - acc: 0.8277 - val_loss: 0.4487 - val_acc: 0.7930\n",
      "Epoch 377/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4316 - acc: 0.8312\n",
      "Epoch 377: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4302 - acc: 0.8313 - val_loss: 0.4521 - val_acc: 0.8135\n",
      "Epoch 378/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4380 - acc: 0.8317\n",
      "Epoch 378: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4378 - acc: 0.8317 - val_loss: 0.4675 - val_acc: 0.8020\n",
      "Epoch 379/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4815 - acc: 0.8283\n",
      "Epoch 379: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4800 - acc: 0.8281 - val_loss: 0.4667 - val_acc: 0.8114\n",
      "Epoch 380/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4606 - acc: 0.8338\n",
      "Epoch 380: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4594 - acc: 0.8340 - val_loss: 0.4928 - val_acc: 0.8199\n",
      "Epoch 381/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4750 - acc: 0.8329\n",
      "Epoch 381: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4747 - acc: 0.8329 - val_loss: 0.4762 - val_acc: 0.7891\n",
      "Epoch 382/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4758 - acc: 0.8330\n",
      "Epoch 382: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4751 - acc: 0.8328 - val_loss: 0.4484 - val_acc: 0.7977\n",
      "Epoch 383/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4598 - acc: 0.8304\n",
      "Epoch 383: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4594 - acc: 0.8305 - val_loss: 0.4851 - val_acc: 0.8033\n",
      "Epoch 384/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4527 - acc: 0.8321\n",
      "Epoch 384: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4523 - acc: 0.8321 - val_loss: 0.4737 - val_acc: 0.8011\n",
      "Epoch 385/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4766 - acc: 0.8346\n",
      "Epoch 385: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4747 - acc: 0.8342 - val_loss: 0.4925 - val_acc: 0.8067\n",
      "Epoch 386/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4469 - acc: 0.8348\n",
      "Epoch 386: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4502 - acc: 0.8343 - val_loss: 0.4733 - val_acc: 0.7981\n",
      "Epoch 387/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4631 - acc: 0.8334\n",
      "Epoch 387: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4617 - acc: 0.8333 - val_loss: 0.4668 - val_acc: 0.7921\n",
      "Epoch 388/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4304 - acc: 0.8305\n",
      "Epoch 388: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4304 - acc: 0.8305 - val_loss: 0.4644 - val_acc: 0.8114\n",
      "Epoch 389/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4691 - acc: 0.8324\n",
      "Epoch 389: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4686 - acc: 0.8325 - val_loss: 0.4828 - val_acc: 0.8139\n",
      "Epoch 390/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4720 - acc: 0.8360\n",
      "Epoch 390: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4716 - acc: 0.8363 - val_loss: 0.4602 - val_acc: 0.8084\n",
      "Epoch 391/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4393 - acc: 0.8330\n",
      "Epoch 391: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4388 - acc: 0.8330 - val_loss: 0.4776 - val_acc: 0.8092\n",
      "Epoch 392/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4720 - acc: 0.8380\n",
      "Epoch 392: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4713 - acc: 0.8379 - val_loss: 0.4649 - val_acc: 0.8135\n",
      "Epoch 393/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4511 - acc: 0.8408\n",
      "Epoch 393: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4507 - acc: 0.8407 - val_loss: 0.4846 - val_acc: 0.7981\n",
      "Epoch 394/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4781 - acc: 0.8334\n",
      "Epoch 394: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4781 - acc: 0.8334 - val_loss: 0.4731 - val_acc: 0.8105\n",
      "Epoch 395/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4564 - acc: 0.8376\n",
      "Epoch 395: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4560 - acc: 0.8373 - val_loss: 0.4731 - val_acc: 0.7836\n",
      "Epoch 396/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4744 - acc: 0.8314\n",
      "Epoch 396: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4744 - acc: 0.8314 - val_loss: 0.4631 - val_acc: 0.8131\n",
      "Epoch 397/2000\n",
      "288/293 [============================>.] - ETA: 0s - loss: 0.4889 - acc: 0.8333\n",
      "Epoch 397: val_acc did not improve from 0.82335\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4860 - acc: 0.8334 - val_loss: 0.4820 - val_acc: 0.8011\n",
      "Epoch 398/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4604 - acc: 0.8357\n",
      "Epoch 398: val_acc improved from 0.82335 to 0.82592, saving model to train_logs/logs7/RWB_ANN_512_256_512_RMSprop/5/256/best_model.h5\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4613 - acc: 0.8356 - val_loss: 0.5086 - val_acc: 0.8259\n",
      "Epoch 399/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4383 - acc: 0.8337\n",
      "Epoch 399: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4367 - acc: 0.8339 - val_loss: 0.4768 - val_acc: 0.7964\n",
      "Epoch 400/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.8329\n",
      "Epoch 400: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4766 - acc: 0.8338 - val_loss: 0.4766 - val_acc: 0.8148\n",
      "Epoch 401/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4599 - acc: 0.8334\n",
      "Epoch 401: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4599 - acc: 0.8334 - val_loss: 0.4794 - val_acc: 0.8062\n",
      "Epoch 402/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4387 - acc: 0.8306\n",
      "Epoch 402: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 0.4375 - acc: 0.8305 - val_loss: 0.5045 - val_acc: 0.7960\n",
      "Epoch 403/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4401 - acc: 0.8328\n",
      "Epoch 403: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4407 - acc: 0.8327 - val_loss: 0.4812 - val_acc: 0.8058\n",
      "Epoch 404/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4779 - acc: 0.8337\n",
      "Epoch 404: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4777 - acc: 0.8336 - val_loss: 0.5061 - val_acc: 0.8067\n",
      "Epoch 405/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4274 - acc: 0.8335\n",
      "Epoch 405: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4271 - acc: 0.8336 - val_loss: 0.4956 - val_acc: 0.7883\n",
      "Epoch 406/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4784 - acc: 0.8353\n",
      "Epoch 406: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4784 - acc: 0.8353 - val_loss: 0.5095 - val_acc: 0.8127\n",
      "Epoch 407/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4431 - acc: 0.8298\n",
      "Epoch 407: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4459 - acc: 0.8295 - val_loss: 0.4864 - val_acc: 0.7921\n",
      "Epoch 408/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4979 - acc: 0.8347\n",
      "Epoch 408: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4972 - acc: 0.8347 - val_loss: 0.4796 - val_acc: 0.8015\n",
      "Epoch 409/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4363 - acc: 0.8402\n",
      "Epoch 409: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4356 - acc: 0.8399 - val_loss: 0.4681 - val_acc: 0.7977\n",
      "Epoch 410/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4544 - acc: 0.8305\n",
      "Epoch 410: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4544 - acc: 0.8305 - val_loss: 0.4684 - val_acc: 0.8191\n",
      "Epoch 411/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4300 - acc: 0.8317\n",
      "Epoch 411: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4288 - acc: 0.8319 - val_loss: 0.5006 - val_acc: 0.8037\n",
      "Epoch 412/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4855 - acc: 0.8371\n",
      "Epoch 412: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4848 - acc: 0.8369 - val_loss: 0.4773 - val_acc: 0.8075\n",
      "Epoch 413/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4394 - acc: 0.8398\n",
      "Epoch 413: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4383 - acc: 0.8396 - val_loss: 0.4858 - val_acc: 0.8003\n",
      "Epoch 414/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4969 - acc: 0.8370\n",
      "Epoch 414: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 5s 18ms/step - loss: 0.4953 - acc: 0.8369 - val_loss: 0.4651 - val_acc: 0.7943\n",
      "Epoch 415/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4636 - acc: 0.8326\n",
      "Epoch 415: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4633 - acc: 0.8326 - val_loss: 0.4654 - val_acc: 0.8204\n",
      "Epoch 416/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4648 - acc: 0.8344\n",
      "Epoch 416: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4645 - acc: 0.8338 - val_loss: 0.4811 - val_acc: 0.7853\n",
      "Epoch 417/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.5020 - acc: 0.8287\n",
      "Epoch 417: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5008 - acc: 0.8288 - val_loss: 0.4698 - val_acc: 0.8088\n",
      "Epoch 418/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4734 - acc: 0.8317\n",
      "Epoch 418: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4713 - acc: 0.8320 - val_loss: 0.4647 - val_acc: 0.8097\n",
      "Epoch 419/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4375 - acc: 0.8331\n",
      "Epoch 419: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4369 - acc: 0.8329 - val_loss: 0.4713 - val_acc: 0.8050\n",
      "Epoch 420/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4601 - acc: 0.8317\n",
      "Epoch 420: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4597 - acc: 0.8312 - val_loss: 0.5159 - val_acc: 0.8041\n",
      "Epoch 421/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4602 - acc: 0.8340\n",
      "Epoch 421: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4602 - acc: 0.8340 - val_loss: 0.5040 - val_acc: 0.8080\n",
      "Epoch 422/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.5263 - acc: 0.8358\n",
      "Epoch 422: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.5258 - acc: 0.8360 - val_loss: 0.4910 - val_acc: 0.8118\n",
      "Epoch 423/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8386\n",
      "Epoch 423: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4404 - acc: 0.8383 - val_loss: 0.4949 - val_acc: 0.7994\n",
      "Epoch 424/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4933 - acc: 0.8383\n",
      "Epoch 424: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4925 - acc: 0.8381 - val_loss: 0.4756 - val_acc: 0.8054\n",
      "Epoch 425/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4746 - acc: 0.8333\n",
      "Epoch 425: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 5s 19ms/step - loss: 0.4746 - acc: 0.8333 - val_loss: 0.4823 - val_acc: 0.7938\n",
      "Epoch 426/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8319\n",
      "Epoch 426: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4643 - acc: 0.8320 - val_loss: 0.4634 - val_acc: 0.8127\n",
      "Epoch 427/2000\n",
      "287/293 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.8262\n",
      "Epoch 427: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4593 - acc: 0.8264 - val_loss: 0.4634 - val_acc: 0.8024\n",
      "Epoch 428/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4528 - acc: 0.8331\n",
      "Epoch 428: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4522 - acc: 0.8328 - val_loss: 0.4891 - val_acc: 0.8084\n",
      "Epoch 429/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4535 - acc: 0.8330\n",
      "Epoch 429: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4527 - acc: 0.8328 - val_loss: 0.4727 - val_acc: 0.7947\n",
      "Epoch 430/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.8316\n",
      "Epoch 430: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4610 - acc: 0.8313 - val_loss: 0.4828 - val_acc: 0.8122\n",
      "Epoch 431/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4346 - acc: 0.8311\n",
      "Epoch 431: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.4328 - acc: 0.8316 - val_loss: 0.4659 - val_acc: 0.8105\n",
      "Epoch 432/2000\n",
      "289/293 [============================>.] - ETA: 0s - loss: 0.4734 - acc: 0.8249\n",
      "Epoch 432: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 4s 13ms/step - loss: 0.4723 - acc: 0.8246 - val_loss: 0.4703 - val_acc: 0.7956\n",
      "Epoch 433/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4454 - acc: 0.8348\n",
      "Epoch 433: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4454 - acc: 0.8348 - val_loss: 0.4653 - val_acc: 0.7990\n",
      "Epoch 434/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4580 - acc: 0.8348\n",
      "Epoch 434: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4578 - acc: 0.8344 - val_loss: 0.4582 - val_acc: 0.7985\n",
      "Epoch 435/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4668 - acc: 0.8332\n",
      "Epoch 435: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4668 - acc: 0.8332 - val_loss: 0.4633 - val_acc: 0.7908\n",
      "Epoch 436/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4735 - acc: 0.8329\n",
      "Epoch 436: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 12ms/step - loss: 0.4725 - acc: 0.8324 - val_loss: 0.4793 - val_acc: 0.7840\n",
      "Epoch 437/2000\n",
      "290/293 [============================>.] - ETA: 0s - loss: 0.4812 - acc: 0.8298\n",
      "Epoch 437: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4799 - acc: 0.8295 - val_loss: 0.4727 - val_acc: 0.7934\n",
      "Epoch 438/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4209 - acc: 0.8332\n",
      "Epoch 438: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 6s 19ms/step - loss: 0.4209 - acc: 0.8332 - val_loss: 0.4843 - val_acc: 0.7934\n",
      "Epoch 439/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4821 - acc: 0.8362\n",
      "Epoch 439: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4817 - acc: 0.8361 - val_loss: 0.4725 - val_acc: 0.7938\n",
      "Epoch 440/2000\n",
      "292/293 [============================>.] - ETA: 0s - loss: 0.4438 - acc: 0.8337\n",
      "Epoch 440: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 4s 14ms/step - loss: 0.4434 - acc: 0.8339 - val_loss: 0.4705 - val_acc: 0.8161\n",
      "Epoch 441/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4702 - acc: 0.8371\n",
      "Epoch 441: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4702 - acc: 0.8371 - val_loss: 0.4782 - val_acc: 0.8122\n",
      "Epoch 442/2000\n",
      "291/293 [============================>.] - ETA: 0s - loss: 0.4641 - acc: 0.8325\n",
      "Epoch 442: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 0.4637 - acc: 0.8321 - val_loss: 0.5010 - val_acc: 0.8067\n",
      "Epoch 443/2000\n",
      "293/293 [==============================] - ETA: 0s - loss: 0.4870 - acc: 0.8357\n",
      "Epoch 443: val_acc did not improve from 0.82592\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 0.4870 - acc: 0.8357 - val_loss: 0.4821 - val_acc: 0.8067\n",
      "92/92 [==============================] - 2s 6ms/step - loss: 0.4959 - acc: 0.8150\n"
     ]
    }
   ],
   "source": [
    "for log_dir in log_dirs:\n",
    "    recap = pd.DataFrame(index=lags, columns=range(1, 6))\n",
    "    training_time = pd.DataFrame(index=lags, columns=[f'CPU_Time_{i}' for i in range(1, 6)] + [f'Wall_Time_{i}' for i in range(1, 6)])\n",
    "\n",
    "    for lag in lags:\n",
    "        train_temp_dir = train_dir + '_' + str(lag)\n",
    "        train = tf.data.Dataset.load(train_temp_dir)\n",
    "        flattened_train = train.unbatch()\n",
    "\n",
    "        train_data = list(flattened_train.as_numpy_iterator())\n",
    "        train_size = len(list(train_data))\n",
    "\n",
    "        kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(train_data), 1):\n",
    "            train_fold_data = ([train_data[i][0] for i in train_index], [train_data[i][1] for i in train_index])\n",
    "            val_fold_data = ([train_data[i][0] for i in val_index], [train_data[i][1] for i in val_index])\n",
    "\n",
    "            train_fold = tf.data.Dataset.from_tensor_slices(train_fold_data).batch(32)\n",
    "            val_fold = tf.data.Dataset.from_tensor_slices(val_fold_data).batch(32)\n",
    "\n",
    "            log_path = os.path.join(log_dir, str(fold), str(lag))\n",
    "\n",
    "            model = create_model()\n",
    "            model.summary()\n",
    "\n",
    "            model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.RMSprop(momentum=0.01), metrics=['acc'])\n",
    "\n",
    "            cpu_start = time.process_time()\n",
    "            wt_start = time.time()\n",
    "\n",
    "            history = model.fit(train_fold, epochs=epochs, validation_data=val_fold, callbacks=myCallbacks(log_path))\n",
    "\n",
    "            wt_end = time.time()\n",
    "            cpu_end = time.process_time()\n",
    "            wall_time = wt_end - wt_start\n",
    "            cpu_time = cpu_end - cpu_start\n",
    "\n",
    "            training_time.loc[lag, f'CPU_Time_{fold}'] = cpu_time\n",
    "            training_time.loc[lag, f'Wall_Time_{fold}'] = wall_time\n",
    "\n",
    "            recap.loc[lag, fold] = history.history['acc'][-1]\n",
    "\n",
    "\n",
    "    # Evaluate on the test dataset after cross-validation\n",
    "    test_temp_dir = test_dir + '_' + str(lag)\n",
    "    test_ds = tf.data.Dataset.load(test_temp_dir)\n",
    "    results = model.evaluate(test_ds, callbacks=myCallbacks(log_path))\n",
    "\n",
    "    recap[f'test_{lag}'] = results[1]\n",
    "\n",
    "    log_recap_dir = os.path.join(log_dir, 'Recap')\n",
    "    if not os.path.exists(log_recap_dir):\n",
    "        os.makedirs(log_recap_dir)\n",
    "\n",
    "    recap.to_csv(os.path.join(log_recap_dir, 'recap.csv'))\n",
    "    training_time.to_csv(os.path.join(log_recap_dir, 'Training_time.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Best Model\n",
    "LAG = 256\n",
    "\n",
    "test_dir = f\"datasets/tf_batch/rwb/segment_1 seconds/test_{LAG}\"\n",
    "test_ds = tf.data.Dataset.load(test_dir)\n",
    "model_dir = [f\"train_logs/logs7/RWB_ANN_512_256_512_RMSprop/{i}/{LAG}/best_model.h5\" for i in range(1,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_test = test_ds.unbatch()\n",
    "test_data = list(flattened_test.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_value = np.array([test_data[i][0] for i in range(len(test_data))])\n",
    "test_data_label = np.array([test_data[i][1] for i in range(len(test_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2924, 96)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_value.reshape(test_data_value.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 4ms/step - loss: 0.4838 - acc: 0.8290\n",
      "0.4838296175003052 0.8290013670921326\n",
      "92/92 [==============================] - 1s 4ms/step\n",
      "92/92 [==============================] - 1s 4ms/step - loss: 0.4574 - acc: 0.8273\n",
      "0.4574301838874817 0.8272913694381714\n",
      "92/92 [==============================] - 0s 3ms/step\n",
      "92/92 [==============================] - 1s 4ms/step - loss: 0.4773 - acc: 0.8276\n",
      "0.47731253504753113 0.8276333808898926\n",
      "92/92 [==============================] - 0s 3ms/step\n",
      "92/92 [==============================] - 1s 4ms/step - loss: 0.4522 - acc: 0.8396\n",
      "0.45217084884643555 0.8396033048629761\n",
      "92/92 [==============================] - 0s 3ms/step\n",
      "92/92 [==============================] - 1s 4ms/step - loss: 0.5127 - acc: 0.8341\n",
      "0.5127482414245605 0.8341313004493713\n",
      "92/92 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i, model_path in enumerate(model_dir):\n",
    "    model = keras.models.load_model(model_path)\n",
    "    loss, acc = model.evaluate(test_ds)\n",
    "    print(loss, acc)\n",
    "    pred = model.predict(test_data_value.reshape(test_data_value.shape[0], -1))\n",
    "    results.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAHHCAYAAACStX1aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB1DUlEQVR4nO3deXhMVx8H8O9M9m0mEpKIRiTUEoKWlthVKrHEXkUQS2lVrLW1ttgrWruiqoKiWkptRVB7LEFaJVJLiCJLRRIJWee8f+SdW2MSssxIZL6f57nPkzn33HPPvZnlN2cbmRBCgIiIiIh0Ql7SFSAiIiIqSxhcEREREekQgysiIiIiHWJwRURERKRDDK6IiIiIdIjBFREREZEOMbgiIiIi0iEGV0REREQ6xOCKiIiISIfKXHAlk8kQFBRU0tWgQjh37hxMTU1x586dkq4KFUJWVhZcXFzwzTff5JsnODgYNWvWhEqleoU1e/0V5N4+6/bt25DJZAgJCdFvxV4jCxYsgLu7O4yMjFC/fv2Sro5ehYSEQCaT4fbt24U+NigoCDKZ7KX5BgwYgCpVqhS+ci9w/fp1tG3bFkqlEjKZDDt37izwsUePHoVMJsPRo0dfmrdVq1Zo1apVketZFIUKrtT/QPVmbGyMSpUqYcCAAbh3756+6lgsp0+fRlBQEJKSkopVTpUqVTSu3crKCu+++y42bNigkc/DwwP16tXTOn7Hjh2QyWRo2bKl1r7vv/8eMpkMBw8eBKB9n2UyGRwcHNC6dWv89ttvha77u+++C5lMhpUrV+a5X30+c3PzPP+PrVq1Qp06dTTS1PdjxIgRWvnVT/pt27YVqH6TJ09G79694erqKqUNGDBA6x7IZDLUrFlT6/g5c+agU6dOcHR0fGFw/csvv+DDDz+Eu7s7LC0tUaNGDXz22WcFfm4U5vjnny/q7ZNPPsmz7EOHDuG9996DUqmEjY0NGjRogK1bt760Tuo3xuc3c3NzrbwrV67EBx98gMqVK0Mmk2HAgAF5lnn48GEMGjQI1atXh6WlJdzd3fHRRx/hwYMHGvlMTEwwduxYzJkzB+np6VrlpKSkYP78+Zg4cSLk8v/eap6vq0KhQMuWLbF3716tMp59LZw8eVJrvxACLi4ukMlk6Nixo8a+1NRUTJ8+HXXq1IGVlRXs7e1Rv359jBo1Cvfv38/z2kuLl93b0qQ0vi4OHjyICRMmoGnTpli3bh3mzp1b3MskPQgICMDly5cxZ84cbNy4EQ0bNiyxujx58gQrVqxA27ZtUbFiRdjY2OCtt97CypUrkZOTU+jyjItSiZkzZ8LNzQ3p6ek4c+YMQkJCcPLkSfz11195vqmXpNOnT2PGjBkYMGAAbG1ti1VW/fr18dlnnwEAHjx4gO+++w4BAQHIyMjAkCFDAADNmjXD2rVrkZycDKVSKR176tQpGBsb4/z588jKyoKJiYnGPiMjI3h5eWmcT32fhRCIi4tDSEgI2rdvj927d2t9kOTn+vXrOH/+PKpUqYJNmzZh2LBh+ebNyMjAl19+iWXLlhX4nqxZswaff/45nJ2dC3zMsyIiInDo0CGcPn1aa5+ZmRm+++47jbRn76nalClT4OTkhLfeegsHDhzI91xDhw6Fs7Mz+vbti8qVK+Py5ctYvnw59u3bh4sXL8LCwuKFdS3s8c8+X9SqV6+uVe66deswePBgvP/++5g7dy6MjIwQFRWFu3fvvrA+z1q5ciWsra2lx0ZGRlp55s+fj8ePH+Pdd9/VCpSeNXHiRCQmJuKDDz7Am2++iVu3bmH58uXYs2cPIiIi4OTkJOUdOHAgJk2ahM2bN2PQoEEa5Xz//ffIzs5G7969tc7x/vvvo3///hBC4M6dO1i5ciX8/Pzw22+/wcfHRyu/ubk5Nm/ejGbNmmmkHzt2DP/88w/MzMw00rOystCiRQtcu3YNAQEBGDFiBFJTU3HlyhVs3rwZXbt2LfJz9lV50b0tTUrj6+LIkSOQy+VYu3YtTE1Ni3eBBCD3vV6XLdBPnz5FWFgYJk+ejMDAQJ2VW1S3bt3CiBEj0KZNG4wdOxYKhQIHDhzAp59+ijNnzmD9+vWFK1AUwrp16wQAcf78eY30iRMnCgBi69athSlOLwCI6dOnS48XLFggAIjo6Ohilevq6io6dOigkRYfHy+sra1FrVq1pLT169cLAGLfvn0aeRs3biz69OkjAIiwsDCNfdWrVxdvvfWW9Di/+5yYmChMTExEnz59ClzvadOmCQcHB7F9+3Yhk8nyvA/q89WvX1+YmZmJe/fuaexv2bKlqF27tkaaq6urqF27tjA2NhYjRozQ2Pf7778LAOLnn39+af1GjhwpKleuLFQqlUZ6QECAsLKyKtA1qq8pISFB6///fL2ep/5/rVmz5qXnKczxeT1f8hIdHS0sLCzEyJEjX5o3L9OnTxcAREJCwkvz3r59W7rPVlZWIiAgIM98x44dEzk5OVppAMTkyZO18nfs2FE0b95cK71u3bqib9++WukAxPDhwzXSrl69KgCIdu3aaaSrn5vdunUT5cuXF1lZWRr7hwwZIho0aKB1v3/66ScBQGzatEnr/E+fPhXJycl5XHnhZWVliYyMDJ2UlZf87u3zoqOjBQCxbt06vdUlP6XxdTFw4MACv38UhEqlEk+ePNFZebqmfp0U5XNO/R7yqt25c0cAEAsWLCjS8erPmbyef89r2bKlaNmy5QvzJCQkiL/++ksrfeDAgQKAuH79eqHqp5MxV82bNwcA3Lx5UyP92rVr6NGjB+zs7GBubo6GDRti165dGnmysrIwY8YMvPnmmzA3N4e9vT2aNWuG0NBQKU9+/aUv6wMOCgrC+PHjAQBubm5SE7S6X/rff//FtWvX8OTJkyJcNVChQgXUrFlT47rV36xPnTolpaWnp+PixYvo1q0b3N3dNfYlJCTg77//1vpGnhdbW1tYWFjA2LjgDY6bN29Gjx490LFjRyiVSmzevDnfvF988QVycnLw5ZdfFqjsKlWqoH///lizZk2Ru1l27tyJ9957L98+/5ycHKSkpLy0HgWR13Ooa9euAIDIyEi9HJ+ZmYm0tLR8y1y1ahVycnIwc+ZMALldWUKIl9bleUIIpKSkvPBYV1fXAo2taNGihUY3njrNzs4uz+t8//33cfLkSSQmJkpp0dHR+PPPP+Ht7V2g+teqVQvly5fXeg9R6927Nx4+fKjxvpCZmYlt27ahT58+WvnV5TRt2lRrn7m5ORQKhfR4wIABsLa2xq1bt+Dj4wMrKys4Oztj5syZGvdTPa7pq6++wuLFi1G1alWYmZnh6tWrAHJbS5o3bw4rKyvY2tqic+fOWvdL3Y177do19OzZEwqFAvb29hg1alSe3X953duC+vPPPzFgwAC4u7vD3NwcTk5OGDRoEB4+fKiV9+jRo2jYsCHMzc1RtWpVrF69usBjcUrb60Imk2HdunVIS0uT3vPVY9Gys7Mxa9Ys6X9XpUoVfPHFF8jIyNAoo0qVKujYsSMOHDiAhg0bwsLCAqtXr873nOqhE3/++SdatmwJS0tLVKtWTRoacezYMTRq1AgWFhaoUaMGDh06pFXGpUuX0K5dOygUClhbW6NNmzY4c+aMVr4rV67gvffeg4WFBd544w3Mnj073xal3377TXpO2tjYoEOHDrhy5UqB7uPznv+8ffb18O2330r39J133sH58+dfWFZQUJA0DGT8+PGQyWQaZRf0XuRFXRcLCwu8++67OHHiRIGOK1++PGrXrq2VXpjPiGfpJLhSByvlypWT0q5cuYLGjRsjMjISkyZNwtdffw0rKyt06dIFO3bskPIFBQVhxowZaN26NZYvX47JkyejcuXKuHjxYrHr1a1bN6lLYtGiRdi4cSM2btyIChUqAACWL1+OWrVq4dy5c0UqPzs7G//884/Gdbu7u8PZ2VljfMj58+eRmZmJJk2aoEmTJhrBlbo7LK/gKjk5Gf/++y8SEhJw5coVDBs2DKmpqejbt2+B6nf27FncuHEDvXv3hqmpKbp164ZNmzblm9/Nza3QwdLkyZORnZ1d4IDsWffu3UNMTAzefvvtPPc/efIECoUCSqUSdnZ2GD58OFJTUwt9nheJjY0FkPvC0vXxR44cgaWlJaytrVGlShUsWbJEK8+hQ4dQs2ZN7Nu3D2+88QZsbGxgb2+PqVOnFqoJ3t3dXRqX0rdvX8TFxRXpevKTmpqK1NTUPK+zQYMGEEJodO2q/87vf/u85ORkPHr0SOO19KwqVarAy8sLW7ZskdJ+++03JCcno1evXlr51W/cGzZsKNCHck5ODnx9feHo6Ijg4GA0aNAA06dPx/Tp07Xyrlu3DsuWLcPQoUPx9ddfw87ODocOHYKPjw/i4+MRFBSEsWPH4vTp02jatGmeg4x79uyJ9PR0zJs3D+3bt8fSpUsxdOhQrXx53duCCg0Nxa1btzBw4EAsW7YMvXr1wo8//oj27dtr3JNLly7B19cXDx8+xIwZMzB48GDMnDmzUIOLn1eSr4uNGzeiefPmMDMzk97zW7RoAQD46KOPMG3aNLz99ttYtGgRWrZsiXnz5uX5HIqKikLv3r3x/vvvY8mSJS8dFP/o0SN07NgRjRo1QnBwMMzMzNCrVy9s3boVvXr1Qvv27fHll18iLS0NPXr0wOPHj6Vjr1y5gubNm+OPP/7AhAkTMHXqVERHR6NVq1Y4e/asxn1t3bo1IiIiMGnSJIwePRobNmzI8x5u3LgRHTp0gLW1NebPn4+pU6fi6tWraNasWZEGvudn8+bNWLBgAT7++GPMnj0bt2/fRrdu3ZCVlZXvMd26dcOiRYsA5H5x2rhxIxYvXlyoe5GXtWvX4uOPP4aTkxOCg4PRtGlTdOrUqVBDLJ5X5M+IwjRzqZseDx06JBISEsTdu3fFtm3bRIUKFYSZmZm4e/eulLdNmzbC09NTpKenS2kqlUo0adJEvPnmm1JavXr1XtpMnF+TXkBAgHB1ddVIQyG6BdXNoQVpVnR1dRVt27YVCQkJIiEhQVy+fFn069cvzy6ODz74QFhYWIjMzEwhhBDz5s0Tbm5uQgghvvnmG+Hg4CDlHTdunACg0RWnvs/Pb2ZmZiIkJOSldVULDAwULi4uUlfQwYMHBQBx6dIljXzPdkPevHlTGBsbazTH59ctqP6/DRw4UJibm4v79+8LIQreLXjo0CEBQOzevVtr36RJk8TEiRPF1q1bxZYtW0RAQIAAIJo2barVNaT2sm7BvAwePFgYGRmJv//+u8DHFOR4Pz8/MX/+fLFz506xdu1a0bx5cwFATJgwQSOfQqEQ5cqVE2ZmZmLq1Kli27ZtUvfxpEmTXnr+xYsXi8DAQLFp0yaxbds2MWrUKGFsbCzefPPNF3Z9vahbMC+zZs0SAMThw4e19t2/f18AEPPnz5fSpkyZIgCIx48fa+UHIAYPHiwSEhJEfHy8CA8PF76+vnl2ETz73Fy+fLmwsbGRumc++OAD0bp1ayGEdnfTkydPRI0aNQQA4erqKgYMGCDWrl0r4uLitOqjfm49272tUqlEhw4dhKmpqdTlqu56UygUIj4+XqOM+vXrCwcHB/Hw4UMp7Y8//hByuVz0799fSlO/53Tq1Enj+E8//VQAEH/88cdL721e8uoWzKsba8uWLQKAOH78uJTm5+cnLC0tNd6Drl+/LoyNjYvcXVTSr4u8hhVEREQIAOKjjz7SSFe/Bx85ckRKc3V1FQDE/v37C3S9LVu2FADE5s2bpbRr164JAEIul4szZ85I6QcOHND6X3Xp0kWYmpqKmzdvSmn3798XNjY2okWLFlLa6NGjBQBx9uxZKS0+Pl4olUqNz7nHjx8LW1tbMWTIEI16xsbGCqVSqZFe0G7B5z9v1c85e3t7kZiYKKX/+uuv+b6vP0t9/POv+YLei+e7BTMzM4WDg4OoX7++Rlf9t99+KwC8tFswLxkZGcLDw0O4ubnl+7mTnyIFV89vVapUEQcOHJDyPXz4UMhkMjFr1iwpGFFvM2bMEADEP//8I4TIfVJWqVLlhR9u+gquCkP9Ynt+GzhwoNab2JIlSzTGVnXs2FH4+/sLIXLfcAFI1+vl5SUFXmrq+7xixQoRGhoqQkNDxQ8//CB8fX2FsbGx2L59+0vrm5WVJSpUqCDGjRsnpWVnZwsHBweNtGfPpx7j9Xyw9LLg6vmArKDB1datWwUAcfLkyZdejxBCzJkzRwAQW7ZsyXN/YYOrTZs25fnGXlCFOV6lUgkfHx9hbGys8SVELpcLAOLLL7/UyO/r6yssLCxESkpKkes1b968fPMUJrg6duyYMDY2Fj179sxz/9OnTwUAMX78eClt2LBhwtjYOM/8eb2OTExMxIQJE7TGej373IyPjxfGxsbip59+EikpKcLCwkIa05PXWJ6kpCQxfvx4jdeuXC4XgYGBGl/61MFVVFSUxvG//fabxvNN/WEwcOBAjXzqACiv54GPj48oX7689Fj9Qfbs+6UQQkRGRub5P8vr3ublZWOunj59KhISEqR8ixcvFkLkvidYWFjkOY7Tz8+vSMFVaXhd5BVczZ07VwAQV69e1Uh/8OCBACA+++wzKc3V1VXrfflFWrZsKaytrbXGjtra2mq9dyYlJQkAYurUqUKI3P+BpaVlnq+vjz/+WMjlcumLUvXq1UXjxo218qmDc/Xn3C+//CIFjM9/Brdt21ZUq1ZNOra4wdWnn36qkS8xMVEAEEuWLHlheXkFV4W5F88HV6dPnxYAxKpVqzSOy8zMFEqlskjB1ZAhQwQAsXfv3kIfW6RuwRUrViA0NBTbtm1D+/bt8e+//2rM1rlx4waEEJg6dSoqVKigsamb2ePj4wHkzohLSkpC9erV4enpifHjx+PPP/8sSrX0rlGjRggNDcX+/fvx1VdfwdbWFo8ePdKajfLsuCvx/yZ99diPOnXqQKFQ4NSpU0hPT8eFCxfyHW/17rvvwtvbG97e3vD398fevXvh4eGBwMBAZGZmvrCuBw8eREJCAt59913cuHEDN27cQHR0NFq3bo0tW7a8sGl9ypQpherqc3d3R79+/fDtt9++cBZafkQBx1KMGTMGcrk8z/EKhXXixAkMHjwYPj4+mDNnjt6Pl8lkGDNmDLKzszXWZVHPpHp+Rl3v3r3x9OlTXLp0qdB169OnD5ycnHRyn65du4auXbuiTp06WjM31dT/v4KMz1Hr3LkzQkNDsXfvXmlsz5MnT7TGej2rQoUK8Pb2xubNm/HLL78gJycHPXr0yDe/UqlEcHAwbt++jdu3b2Pt2rWoUaMGli9fjlmzZmnklcvlcHd310hTz2B7vgvFzc1N47F6fbYaNWpo1aFWrVr4999/tcYXvfnmmxqPq1atCrlcrnWuotxbtcTERIwaNQqOjo6wsLBAhQoVpLonJycDyH0ffvr0KapVq6Z1fF5pL1OaXxd37tyBXC7Xui4nJyfY2tpqrbP3/P/5Zd544w2t/5NSqYSLi4tWGpDbjQjkjrt98uRJvs8flUoldWvduXNH67kDaD/3rl+/DgB47733tD6DDx48KH3+6kLlypU1Hqu79tXXVxiFuRfPU///nr8/JiYmWq/tgliwYAHWrFmDWbNmoX379oU+vkhLMbz77rvSehRdunRBs2bN0KdPH0RFRcHa2lr64B43blye06qB/164LVq0wM2bN/Hrr7/i4MGD+O6777Bo0SKsWrUKH330EYDcF2BeH8BFWXuiOMqXLy8N0PXx8UHNmjXRsWNHLFmyBGPHjpXy1atXDzY2Njh58iTat2+PxMRENGnSBEDum3ijRo1w8uRJVK1aFZmZmQUazK4+tnXr1liyZAmuX7+e5+A7NfXYqp49e+a5/9ixY2jdunWe+9zd3dG3b198++23mDRpUoHqNnnyZGzcuBHz589Hly5dCnSMvb09gIK/CC0sLGBvb1+kwb3P+uOPP9CpUyfUqVMH27ZtK9QEgeIcr36Tfbb+zs7OuH79OhwdHTXyOjg4ACjaG5T6XMW9T3fv3pUW+Nu3bx9sbGzyzKeu47NjEuzt7ZGdnY3Hjx/nedwbb7whvZbat2+P8uXLIzAwEK1bt0a3bt3yrVOfPn0wZMgQxMbGol27dgVeXsXV1RWDBg1C165d4e7ujk2bNmH27NkFOvZ5L1uyoyjyC57yurcF1bNnT5w+fRrjx49H/fr1pfdmX19fvSzq+jq8LoCCB6qF/T/ntfzJi9IL+qWyKNT/340bN2osnaJW2Pe8FymJ69O3kJAQTJw4EZ988gmmTJlSpDKKPaDdyMgI8+bNw/3797F8+XIAkKJEExMTqeXl+e3ZN1w7OzsMHDgQW7Zswd27d1G3bl2NhSDLlSuX54J0BVnRuyjf+AqqQ4cOaNmyJebOnavxzdTIyAiNGzfGqVOncPLkSSgUCnh6ekr71YPa1QPbCxpcAbmD6AG8cGB3Wloafv31V3z44Yf4+eeftbaKFSu+cGA78F/r1fz58wtUr6pVq6Jv375YvXp1gVuv1AuCRkdHFyj/48eP8e+//0oTEori5s2b8PX1hYODA/bt26exNpS+j7916xYAaNS/QYMGAKC1eKt6QkFRrlUIgdu3bxfrPj18+BBt27ZFRkYGDhw4gIoVK+abV/3/q1WrlpRW2P/txx9/jKpVq2LKlCkvfFPu2rUr5HI5zpw5k+cswZcpV64cqlatqvUcValU0v9H7e+//wbw8tmo6sHzUVFRWvuuXbuG8uXLw8rKSiNd3bKgduPGDahUKq1z5XVvC+LRo0c4fPgwJk2ahBkzZqBr1654//33tb7BOzg4wNzcHDdu3NAqI6+0/LwOrwtXV1eoVCqtex8XF4ekpCSNRYxfpQoVKsDS0jLf549cLpcCUFdXV636A9rPvapVqwLI/f/m9fn7qlcrL6jC3Ivnqf9/z9+frKysAr8PAcCvv/6Kjz76CN26dcOKFSsKUXtNOpkt2KpVK7z77rtYvHgx0tPT4eDggFatWuX7QZuQkCD9/fy0YGtra1SrVk1jamzVqlVx7do1jeP++OMPjVl3+VG/qeUVnBV3KQYgd8HFhw8fYs2aNRrpzZo1Q0JCAtatW4dGjRppdHc0adIEUVFR+PXXX2Fvb1/gN86srCwcPHgQpqamLzxmx44dSEtLw/Dhw9GjRw+trWPHjti+fbvW9ONnPRssqWdLvMyUKVOQlZWF4ODgAuWvVKkSXFxcEB4erpGenp6uMZNGbdasWRBCwNfXt0DlPy82NhZt27aFXC7HgQMHCv0GXdDjExMTtVpVs7Ky8OWXX8LU1FSjxfDDDz8EkDvLRU2lUmHdunWws7OTPmTy8+xrQm3lypVISEgo8n1KS0tD+/btce/ePezbty/PbohnXbhwATKZTGMRXPXfz/9v82NsbIzPPvsMkZGR+PXXX/PNZ21tjZUrVyIoKAh+fn755vvjjz/w77//aqXfuXMHV69ezbPbQf3lEMgNUJcvXw4TExO0adPmhXWvWLEi6tevj/Xr12u8z/z11184ePBgnl0Kz79pqxfubdeunUZ6Xve2INStCc8HquoZWc/m8/b2xs6dOzVmCN+4caPAvwZRGl8XeVH/H56/BwsXLgSQ+2W5JBgZGaFt27b49ddfNbqF4+LipIVz1UuHtG/fHmfOnNGY4Z6QkKD1ZdnHxwcKhQJz587Nc9ZeXu8bpUFh7sXzGjZsiAoVKmDVqlUaw2ZCQkIK/Cscx48fR69evdCiRQts2rTphcMUXkZnbYPjx4/HBx98gJCQEHzyySdYsWIFmjVrBk9PTwwZMgTu7u6Ii4tDWFgY/vnnH/zxxx8Acn8uplWrVmjQoAHs7OwQHh6Obdu2aazYOmjQICxcuBA+Pj4YPHgw4uPjsWrVKtSuXfulayCpX4STJ09Gr169YGJiAj8/P1hZWWH58uWYMWMGfv/99yJH8u3atUOdOnWwcOFCDB8+XFp5Xd0aFRYWpvVzLI0bN4ZMJsOZM2fg5+eXb+vab7/9hmvXrgHIHRuxefNmXL9+HZMmTcr3CQbkdgna29tLXZHP69SpE9asWYO9e/e+sAtG3dUXFRX1wi5INXVAVpiVbDt37owdO3ZACCHdh9jYWLz11lvo3bu31AJy4MAB7Nu3D76+vujcubNGGRs3bsSdO3ekIPn48eNSl0+/fv2kbzS+vr64desWJkyYgJMnT2osl+Ho6Ij3339fejxgwACsX78e0dHRUmtCQY/ftWsXZs+ejR49esDNzQ2JiYnYvHkz/vrrL8ydO1ejmb5z585o06YN5s2bh3///Rf16tXDzp07cfLkSaxevVpjLGNedXJ1dcWHH34IT09PmJub4+TJk/jxxx9Rv359fPzxxxr3affu3dLrLisrC3/++ad0nzp16oS6desCAPz9/XHu3DkMGjQIkZGRGuu7WFtba3X7hoaGomnTplI3L5Dbel2nTh0cOnSowKuLDxgwANOmTXtp13JAQMBLywoNDcX06dPRqVMnNG7cWFrH6vvvv0dGRobWa9Lc3Bz79+9HQEAAGjVqhN9++w179+7FF198UaAgfMGCBWjXrh28vLwwePBgPH36FMuWLYNSqczz55iio6PRqVMn+Pr6IiwsDD/88AP69Omj9dNZed3bglAoFGjRogWCg4ORlZWFSpUq4eDBg3l+gw8KCsLBgwfRtGlTDBs2DDk5OVi+fDnq1KmDiIiIl56rpF8XBVWvXj0EBATg22+/RVJSElq2bIlz585h/fr16NKlS77DJF6F2bNnIzQ0FM2aNcOnn34KY2NjrF69GhkZGRpfVidMmICNGzfC19cXo0aNgpWVFb799lu4urpqjFVWKBRYuXIl+vXrh7fffhu9evVChQoVEBMTg71796Jp06YaXyZKk4Lei+eZmJhg9uzZ+Pjjj/Hee+/hww8/RHR0NNatW1egMVd37txBp06dIJPJ0KNHD/z8888a++vWrSu9RxZIYUa/57dyuBBC5OTkiKpVq4qqVauK7OxsIUTuLLL+/fsLJycnYWJiIipVqiQ6duwotm3bJh03e/Zs8e677wpbW1thYWEhatasKebMmSMtY6D2ww8/CHd3d2Fqairq168vDhw4UKDZgkLkTiOvVKmSNANFPaOisEsx5LdkREhIiNZMnbS0NGkq88GDB7WOqVu3br5TrPOalWlubi7q168vVq5cqTUj5VlxcXHC2NhY9OvXL988T548EZaWlqJr164a58vr/6qeSfWi2YLPun79ujAyMirQbEEhhLh48aIAIE6cOCGlPXr0SPTt21dUq1ZNWFpaCjMzM1G7dm0xd+5creeFEP9Ng85re/Z/m18e5DFNt3v37sLCwkI8evSo0MeHh4cLPz8/UalSJWFqaiqsra1Fs2bNxE8//ZTnPXj8+LEYNWqUcHJyEqampsLT01P88MMPWvnyqtNHH30kPDw8hI2NjTAxMRHVqlUTEydOzHM2lfp/mdf27HM3v5mxALReb0lJScLU1FR89913WudbuHChsLa21ppNC2gvX6IWFBSk8X970XPzWc8/H2/duiWmTZsmGjduLBwcHISxsbGoUKGC6NChg8aUe/V9sbKyEjdv3hRt27YVlpaWwtHRUUyfPl1j9mJ+U8fVDh06JJo2bSosLCyEQqEQfn5+WjPT1O85V69eFT169BA2NjaiXLlyIjAwUDx9+lQj74vu7fPymi34zz//iK5duwpbW1uhVCrFBx98IM1sfP498vDhw+Ktt94SpqamomrVquK7774Tn332mTA3N3/puUv6dZGX/H7hISsrS8yYMUO4ubkJExMT4eLiIj7//HON2aNCFHwlebW8ZlS/qJy8XgMXL14UPj4+wtraWlhaWorWrVuL06dPax37559/ipYtWwpzc3NRqVIlMWvWLLF27VqNzza133//Xfj4+AilUinMzc1F1apVxYABA0R4eLiUp7izBfN6PeT1HHvei44vyL3Ib4X2b775Rri5uQkzMzPRsGFDcfz48QKt0K4uL7+tMEv8CFHIpRiI9OG9997L82dSSlJeS1aUtNJYp0WLFomKFSvmuaZSUlKSsLOzK1BwUJIK81NLxVWYnyt60b19FTp37qwxZZ+ICk4nY66IimPu3LnYunVrgSYovApXrlzB06dPMXHixJKuiqQ01ikrKwsLFy7ElClT8pxZpVQqMWHCBCxYsEAvs9PKspfdW117+vSpxuPr169j3759pXbgM1FpJxPiNZ4vSURUTAMGDMC2bdt0/tNKeVH/3FdCQkKRf3JJHypWrCj9DuGdO3ewcuVKZGRk4NKlSy+d0EBE2nS32AUREb2WfH19sWXLFsTGxsLMzAxeXl6YO3cuAyuiImLLFREREZEOccwVERERkQ4xuCIiIiLSIY65KiNUKhXu378PGxsbvf7kDxER6Z4QAo8fP4azs3OxVgZ/mfT0dI0VzIvD1NQU5ubmOimrrGFwVUbcv38/399cIiKi18Pdu3fxxhtv6KXs9PR0uLlaIzY+5+WZC8DJyQnR0dEMsPLA4KqMUP8QdoN2k2Fkwic6lU02Vx++PBPRayhblYFjt1ZK7+X6kJmZidj4HNy5UAUKm+K1jqU8VsG1wW1kZmYyuMoDg6syQt0VaGRiDmMGV1RGGRsV/jfliF4nr2JYh7WNDNY2xTuPCoU7/vjx41iwYAEuXLiABw8eYMeOHRq/IZqamopJkyZh586dePjwIdzc3DBy5Eh88sknUp709HR89tln+PHHH5GRkQEfHx988803cHR0lPLExMRg2LBh+P3332FtbY2AgADMmzcPxsavNtzhgHYiIiIDkiNUOtkKIy0tDfXq1cOKFSvy3D927Fjs378fP/zwAyIjIzF69GgEBgZi165dUp4xY8Zg9+7d+Pnnn3Hs2DHcv38f3bp1+++6cnLQoUMHZGZm4vTp01i/fj1CQkIwbdq0ot2oYmDLFRERkQFRQUCF4i1xWdjj27Vrh3bt2uW7//Tp0wgICJB+cmno0KFYvXo1zp07h06dOiE5ORlr167F5s2b8d577wEA1q1bh1q1auHMmTNo3LgxDh48iKtXr+LQoUNwdHRE/fr1MWvWLEycOBFBQUEwNTUt8vUWFluuiIiIqEQ1adIEu3btwr179yCEwO+//46///4bbdu2BQBcuHABWVlZ8Pb2lo6pWbMmKleujLCwMABAWFgYPD09NboJfXx8kJKSgitXrrzS62HLFRERkQFRQYXi/pS6uoSUlBSNdDMzM5iZFX5s5LJlyzB06FC88cYbMDY2hlwux5o1a9CiRQsAQGxsLExNTWFra6txnKOjI2JjY6U8zwZW6v3qfa8SW66IiIgMSI4QOtkAwMXFBUqlUtrmzZtXpDotW7YMZ86cwa5du3DhwgV8/fXXGD58OA4dOqTLS39l2HJFRERERXL37l0oFArpcVFarZ4+fYovvvgCO3bsQIcOHQAAdevWRUREBL766it4e3vDyckJmZmZSEpK0mi9iouLg5OTE4DcdbfOnTunUXZcXJy071ViyxUREZEBUQ9oL+4GAAqFQmMrSnCVlZWFrKwsrZXpjYyMoFLldj82aNAAJiYmOHz4sLQ/KioKMTEx8PLyAgB4eXnh8uXLiI+Pl/KEhoZCoVDAw8Oj0PUqDrZcERERGRAVBHJe8WzB1NRU3LhxQ3ocHR2NiIgI2NnZoXLlymjZsiXGjx8PCwsLuLq64tixY9iwYQMWLlwIAFAqlRg8eDDGjh0LOzs7KBQKjBgxAl5eXmjcuDEAoG3btvDw8EC/fv0QHByM2NhYTJkyBcOHDy9S0FccDK6IiIhIr8LDw9G6dWvp8dixYwEAAQEBCAkJwY8//ojPP/8c/v7+SExMhKurK+bMmaOxiOiiRYsgl8vRvXt3jUVE1YyMjLBnzx4MGzYMXl5esLKyQkBAAGbOnPnqLvT/ZEKI4oWvVCqkpKRAqVTi3U6zuEI7lVk2f/1b0lUg0ovsnAwcvrEYycnJGmOYdEn9OXHzmhNsivnzN48fq1C1Zqxe6/s6Y8sVERGRAXl2tl9xyqD8cUA7ERERkQ6x5YqIiMiAqP6/FbcMyh+DKyIiIgOSo4PZgsU9vqxjcEVERGRAckTuVtwyKH8cc0VERESkQ2y5IiIiMiAcc6V/DK6IiIgMiAoy5EBW7DIof+wWJCIiItIhtlwREREZEJXI3YpbBuWPwRUREZEBydFBt2Bxjy/r2C1IREREpENsuSIiIjIgbLnSPwZXREREBkQlZFCJYs4WLObxZR27BYmIiIh0iC1XREREBoTdgvrH4IqIiMiA5ECOnGJ2XOXoqC5lFYMrIiIiAyJ0MOZKcMzVC3HMFREREZEOseWKiIjIgHDMlf4xuCIiIjIgOUKOHFHMMVf8+ZsXYrcgERERkQ6x5YqIiMiAqCCDqphtKyqw6epFGFwREREZEI650j92CxIRERHpEFuuiIiIDIhuBrSzW/BFGFwREREZkNwxV8X84WZ2C74QuwWJiIiIdIgtV0RERAZEpYPfFuRswRdjcEVERGRAOOZK/xhcERERGRAV5FznSs845oqIiIhIh9hyRUREZEByhAw5opiLiBbz+LKOwRUREZEBydHBgPYcdgu+ELsFiYiISK+OHz8OPz8/ODs7QyaTYefOnVp5IiMj0alTJyiVSlhZWeGdd95BTEyMtD89PR3Dhw+Hvb09rK2t0b17d8TFxWmUERMTgw4dOsDS0hIODg4YP348srOz9X15WhhcERERGRCVkOtkK4y0tDTUq1cPK1asyHP/zZs30axZM9SsWRNHjx7Fn3/+ialTp8Lc3FzKM2bMGOzevRs///wzjh07hvv376Nbt27S/pycHHTo0AGZmZk4ffo01q9fj5CQEEybNq1oN6oY2C1IRERkQEqiW7Bdu3Zo165dvvsnT56M9u3bIzg4WEqrWrWq9HdycjLWrl2LzZs347333gMArFu3DrVq1cKZM2fQuHFjHDx4EFevXsWhQ4fg6OiI+vXrY9asWZg4cSKCgoJgampayKssOrZcERERUZGkpKRobBkZGYUuQ6VSYe/evahevTp8fHzg4OCARo0aaXQdXrhwAVlZWfD29pbSatasicqVKyMsLAwAEBYWBk9PTzg6Okp5fHx8kJKSgitXrhT9IouAwRUREZEBUeG/GYNF3VT/L8vFxQVKpVLa5s2bV+j6xMfHIzU1FV9++SV8fX1x8OBBdO3aFd26dcOxY8cAALGxsTA1NYWtra3GsY6OjoiNjZXyPBtYqfer971K7BYkIiIyILpZRDT3+Lt370KhUEjpZmZmhS9LlRuqde7cGWPGjAEA1K9fH6dPn8aqVavQsmXLYtW1JLDlioiIiIpEoVBobEUJrsqXLw9jY2N4eHhopNeqVUuaLejk5ITMzEwkJSVp5ImLi4OTk5OU5/nZg+rH6jyvCoMrIiIiA6L+bcHibrpiamqKd955B1FRURrpf//9N1xdXQEADRo0gImJCQ4fPiztj4qKQkxMDLy8vAAAXl5euHz5MuLj46U8oaGhUCgUWoGbvrFbkIiIyICoIIMKxVthvbDHp6am4saNG9Lj6OhoREREwM7ODpUrV8b48ePx4YcfokWLFmjdujX279+P3bt34+jRowAApVKJwYMHY+zYsbCzs4NCocCIESPg5eWFxo0bAwDatm0LDw8P9OvXD8HBwYiNjcWUKVMwfPjwIrWoFQeDKyIiIgOii5anwh4fHh6O1q1bS4/Hjh0LAAgICEBISAi6du2KVatWYd68eRg5ciRq1KiB7du3o1mzZtIxixYtglwuR/fu3ZGRkQEfHx9888030n4jIyPs2bMHw4YNg5eXF6ysrBAQEICZM2cW61qLQiaE4Br2ZUBKSgqUSiXe7TQLxibmLz+A6DVk89e/JV0FIr3IzsnA4RuLkZycrDFAXJfUnxOLwpvAwrp4bStPU7MxpuFpvdb3dcaWKyIiIgOim0VEOWT7RRhcERERGRCVkEElijnmqpjHl3UMPYmIiIh0iC1XREREBkSlg27B4i5CWtYxuCIiIjIgKiGHqpizBYt7fFnHu0NERESkQ2y5IiIiMiA5kCGnmIuIFvf4so7BFRERkQFht6D+8e4QERER6RBbroiIiAxIDorfrZejm6qUWQyuiIiIDAi7BfWPwRUREZEBKYkfbjY0vDtEREREOsSWKyIiIgMiIIOqmGOuBJdieCEGV0RERAaE3YL6x7tDREREpENsuSIiIjIgKiGDShSvW6+4x5d1DK6IiIgMSA7kyClmx1Vxjy/reHeIiIiIdIgtV0RERAaE3YL6x+CKiIjIgKggh6qYHVfFPb6s490hIiIi0iG2XBERERmQHCFDTjG79Yp7fFnH4IqIiMiAcMyV/jG4IiIiMiBCyKEq5grrgiu0vxDvDhEREZEOseWKiIjIgORAhpxi/vBycY8v6xhcERERGRCVKP6YKZXQUWXKKHYLEhEREekQW65KqSpVqmD06NEYPXp0SVfFYAxsH45B7S9qpN2JVaLv7A8BAM7lUzC86xnUdY+FiXEOzka6YPHPTfDosaWU38YyHaM/OI2mde5AJWQ4FuGGpdua4GmmySu9FqK8tO90Cx0634Kj0xMAwJ3bCmxZXxPh55yeyykwc/5pNGwUh1lTGiPspLNWWTaKDKxYexjlK6Tjg44dkZZq+gqugHRBpYMB7cU9vqxjcEX0jFv3y2HMsg7S4xxV7huIuWkWFg7fixv37DFqWUcAwEcdzuPLjw/gk6+7QPy/iX1awO+wVz7B2OUdYGSkwud9j2J8n+OYGdLm1V8M0XP+TbDAum/r4P4/1pDJBNr4xGDqnDCMGNIGMbcVUr4uPW5AvKTbZ/SEi4i+qUT5Cul6rjXpmgoyqIo5Zqq4x5d1DD2LKDMzs6SrQHqQo5Ij8bGltCWnmQMAPN3j4GSfirk/tMKt+3a4dd8Ocza2Rs3KCXi7+j0AgKvjIzSufRfzN7fA1TsOuHzLCYt/boo2b9+EvTKtJC+LCABwLqwiws864f49a9z7xwYb1tZG+lNj1PRIlPK4V0tCtw+vY3Fwg3zLad/pFqyss/DL1jdfRbWJXjsGE1y1atUKI0eOxIQJE2BnZwcnJycEBQVJ+2NiYtC5c2dYW1tDoVCgZ8+eiIuLk/YHBQWhfv36+O677+Dm5gZz89wPXZlMhtWrV6Njx46wtLRErVq1EBYWhhs3bqBVq1awsrJCkyZNcPPmTamsmzdvonPnznB0dIS1tTXeeecdHDp06JXdC8rfGxWSsWPOD9gatAVTA47AoVwqAMDEOAdCAFnZRlLezGwjqIQMdavGAgBqu8Xh8RNTRMVUkPJciKoElZDBwzX+1V4I0UvI5QIt3rsLc/McRF6xAwCYmWVjwpTz+GZxfTxKNM/zOBfXFPQJiMTXcxtyIcnXlHqF9uJulD+DCa4AYP369bCyssLZs2cRHByMmTNnIjQ0FCqVCp07d0ZiYiKOHTuG0NBQ3Lp1Cx9++KHG8Tdu3MD27dvxyy+/ICIiQkqfNWsW+vfvj4iICNSsWRN9+vTBxx9/jM8//xzh4eEQQiAwMFDKn5qaivbt2+Pw4cO4dOkSfH194efnh5iYmFd1KygPV287YO4PrTBuRTt8vbUZKto/xooxu2Bhlomrtx2QnmmMTzqfhZlJNsxNszC86xkYGwnYK3LHr9grnuLRYwuNMnNUcjx+YgZ7xdOSuCQiLVXckrH9t1/xa+hOBI6NwKypjXH3Tm6X4JDhfyLyih3OnNIeYwUAxiY5mDj1PNau8kRCvGWeeaj0U4+5Ku5WGMePH4efnx+cnZ0hk8mwc+fOfPN+8sknkMlkWLx4sUZ6YmIi/P39oVAoYGtri8GDByM1NVUjz59//onmzZvD3NwcLi4uCA4OLlQ9dcWgxlzVrVsX06dPBwC8+eabWL58OQ4fPgwAuHz5MqKjo+Hi4gIA2LBhA2rXro3z58/jnXfeAZDbFbhhwwZUqFBBo9yBAweiZ8+eAICJEyfCy8sLU6dOhY+PDwBg1KhRGDhwoJS/Xr16qFevnvR41qxZ2LFjB3bt2qURhL1IRkYGMjIypMcpKSmFuhek7ezVytLfN+/b4+ptB/w8czPee/sW9obVxLS17+OzD0+gR8u/oBIyHL5QFVEx5aXxVkSvg3/u2iDwozawsspCs5b38Nnn4ZgwqgWcK6Wi3tsJGDEk//GBA4dcwd0YG/weWjnfPER5SUtLQ7169TBo0CB069Yt33w7duzAmTNn4OysHeD7+/vjwYMHCA0NRVZWFgYOHIihQ4di8+bNAHI/B9u2bQtvb2+sWrUKly9fxqBBg2Bra4uhQ4fq7dryYnDB1bMqVqyI+Ph4REZGwsXFRQqsAMDDwwO2traIjIyUgitXV1etwOr5ch0dHQEAnp6eGmnp6elISUmBQqFAamoqgoKCsHfvXjx48ADZ2dl4+vRpoVqu5s2bhxkzZhQ4PxVe6lMz3I23xRsVcgPX89feQK8ZvaG0SkeOSobUp2bYOXcj7l+oCgB4mGKBcjaaLVRGchVsLDPwMMVCq3yikpCdLceDe9YAgBt/l8ObNR+hc/cbyMw0QkXnNPy8Z7dG/i9mnMGVy+UxaXQL1H07AVXcktHs8L3/780d9f7jr3vx48Ya2BTi8SovhYpIBR38tmAhB7S3a9cO7dq1e2Gee/fuYcSIEThw4AA6dOigsS8yMhL79+/H+fPn0bBhQwDAsmXL0L59e3z11VdwdnbGpk2bkJmZie+//x6mpqaoXbs2IiIisHDhQgZX+mRiojkdXiaTQaVSFfh4Kyurl5Yrk8nyTVOfa9y4cQgNDcVXX32FatWqwcLCAj169CjUIPnPP/8cY8eOlR6npKRoBIdUfBamWahUPgUHzmkO2lUPcn+7+j2Us36Kk5ddAQBXoh1hY5mJ6i4J+Ptuhf/nuQ+5TODqHYdXW3miApLLABNTFTaFeODA3ioa+1auO4w1K+ri7OmKAIA50xrBzCxH2l+9xiOMmXQR40e0wIP7eb8/UukjdDBbUPz/+Od7TczMzGBmZlbo8lQqFfr164fx48ejdu3aWvvDwsJga2srBVYA4O3tDblcjrNnz6Jr164ICwtDixYtYGr637IgPj4+mD9/Ph49eoRy5coVul5FZVDBVX5q1aqFu3fv4u7du1KAcvXqVSQlJcHDQ/ffxE6dOoUBAwaga9euAHLHYN2+fbtQZRT1CUz5+7TrGZy+XBmxiTYor0zDoA4XoFLldv8BQPvGUbgda4ukVAvUcYvDyB6n8dPvnrgbbwsAuBNXDmeuuGBin+P46sfmMDZSYUzPUzh8sSoeJvODh0regCF/IfysE+LjLWBpkY1W3nfhWT8BU8c3xaNE8zwHsSfEWyIuNvf5G3vfWmOfQpn7hfBujA3XuXqNqIQOWq7+f/zzX+qnT5+uMVmsoObPnw9jY2OMHDkyz/2xsbFwcND8kmpsbAw7OzvExsZKedzc3DTyqHuTYmNjGVy9at7e3vD09IS/vz8WL16M7OxsfPrpp2jZsqVGlKwrb775Jn755Rf4+flBJpNh6tSphWpBI/1wsE3F9IFHoLBMR1KqBS7fcsTHX3dBUmpul56LQxKGdjoHhWUGYhNtsPHAW9h6xFOjjJnrW2NMz1NYPGIvVAI4FuGGJT83LYnLIdKitM3AZ1+Ew84uHWlpJoi+pcDU8U1x6YJjSVeNXlN3796FQvHfGmlF+dJ/4cIFLFmyBBcvXpR6el53DK6Q223366+/YsSIEWjRogXkcjl8fX2xbNkyvZxv4cKFGDRoEJo0aYLy5ctj4sSJHJBeCgSt837h/tW7GmH1rkYvzPP4iTkXDKVSa8mC/Neuykv7VvkPPAaAyxEVXpqHSh9drtCuUCg0gquiOHHiBOLj41G58n8TJXJycvDZZ59h8eLFuH37NpycnBAfr7mkTXZ2NhITE+HklPsLA05OThpLKAGQHqvzvCoyIV62Di+9DlJSUqBUKvFup1kwNsl7fRqi153NX/+WdBWI9CI7JwOHbyxGcnJysYOV/Kg/JzofHAQTq+J142alZeLXtt8Xqb4ymQw7duxAly5dAAAPHz7EgwcPNPL4+PigX79+GDhwIGrUqIHIyEh4eHggPDwcDRrkfkk4ePAgfH198c8//8DZ2RkrV67E5MmTERcXJ417/uKLL/DLL7/g2rVrxbrewmLLFREREelVamoqbty4IT2Ojo5GREQE7OzsULlyZdjb22vkNzExgZOTE2rUqAEgd2y0r68vhgwZglWrViErKwuBgYHo1auXtGxDnz59MGPGDAwePBgTJ07EX3/9hSVLlmDRokWv7kL/j8EVERGRASmJ3xYMDw9H69atpcfq2e4BAQEICQkpUBmbNm1CYGAg2rRpA7lcju7du2Pp0qXSfqVSiYMHD2L48OFo0KABypcvj2nTpr3yZRgABldEREQGRZezBQuqVatWKMwopLxm0NvZ2UkLhuanbt26OHHiRKHqpg8G9fM3RERERPrGlisiIiIDUhItV4aGwRUREZEBYXClf+wWJCIiItIhtlwREREZELZc6R+DKyIiIgMiUPilFPIqg/LH4IqIiMiAsOVK/zjmioiIiEiH2HJFRERkQNhypX8MroiIiAwIgyv9Y7cgERERkQ6x5YqIiMiAsOVK/xhcERERGRAhZBDFDI6Ke3xZx25BIiIiIh1iyxUREZEBUUFW7EVEi3t8WcfgioiIyIBwzJX+sVuQiIiISIfYckVERGRAOKBd/xhcERERGRB2C+ofgysiIiIDwpYr/eOYKyIiIiIdYssVERGRARE66BZky9WLMbgiIiIyIAKAEMUvg/LHbkEiIiIiHWLLFRERkQFRQQYZV2jXKwZXREREBoSzBfWP3YJEREREOsSWKyIiIgOiEjLIuIioXjG4IiIiMiBC6GC2IKcLvhC7BYmIiIh0iC1XREREBoQD2vWPwRUREZEBYXClfwyuiIiIDAgHtOsfx1wRERGRXh0/fhx+fn5wdnaGTCbDzp07pX1ZWVmYOHEiPD09YWVlBWdnZ/Tv3x/379/XKCMxMRH+/v5QKBSwtbXF4MGDkZqaqpHnzz//RPPmzWFubg4XFxcEBwe/isvTwuCKiIjIgKhnCxZ3K4y0tDTUq1cPK1as0Nr35MkTXLx4EVOnTsXFixfxyy+/ICoqCp06ddLI5+/vjytXriA0NBR79uzB8ePHMXToUGl/SkoK2rZtC1dXV1y4cAELFixAUFAQvv322yLdp+JgtyAREZEByQ2OijvmqnD527Vrh3bt2uW5T6lUIjQ0VCNt+fLlePfddxETE4PKlSsjMjIS+/fvx/nz59GwYUMAwLJly9C+fXt89dVXcHZ2xqZNm5CZmYnvv/8epqamqF27NiIiIrBw4UKNIOxVYMsVERERFUlKSorGlpGRoZNyk5OTIZPJYGtrCwAICwuDra2tFFgBgLe3N+RyOc6ePSvladGiBUxNTaU8Pj4+iIqKwqNHj3RSr4JicEVERGRA1LMFi7sBgIuLC5RKpbTNmzev2PVLT0/HxIkT0bt3bygUCgBAbGwsHBwcNPIZGxvDzs4OsbGxUh5HR0eNPOrH6jyvCrsFiYiIDIj4/1bcMgDg7t27UgAEAGZmZsUqNysrCz179oQQAitXrixWWSWJwRUREREViUKh0AiuikMdWN25cwdHjhzRKNfJyQnx8fEa+bOzs5GYmAgnJycpT1xcnEYe9WN1nleF3YJEREQGRJfdgrqiDqyuX7+OQ4cOwd7eXmO/l5cXkpKScOHCBSntyJEjUKlUaNSokZTn+PHjyMrKkvKEhoaiRo0aKFeunE7r+zIMroiIiAyJ0NFWCKmpqYiIiEBERAQAIDo6GhEREYiJiUFWVhZ69OiB8PBwbNq0CTk5OYiNjUVsbCwyMzMBALVq1YKvry+GDBmCc+fO4dSpUwgMDESvXr3g7OwMAOjTpw9MTU0xePBgXLlyBVu3bsWSJUswduzYYtysomG3IBERkSHRRctTIY8PDw9H69atpcfqgCcgIABBQUHYtWsXAKB+/foax/3+++9o1aoVAGDTpk0IDAxEmzZtIJfL0b17dyxdulTKq1QqcfDgQQwfPhwNGjRA+fLlMW3atFe+DAPA4IqIiIj0rFWrVhAvWBzrRfvU7OzssHnz5hfmqVu3Lk6cOFHo+ukagysiIiIDUpQV1vMqg/LH4IqIiMiA6GJAuq4HtJc1HNBOREREpENsuSIiIjIkQlboAel5lkH5YnBFRERkQDjmSv/YLUhERESkQ2y5IiIiMiS6/HFBylOpC67UC4kVRKdOnfRYEyIiorKHswX1r9QFV126dClQPplMhpycHP1WhoiIiKiQSl1wpVKpSroKREREZRu79fSq1AVX+UlPT4e5uXlJV4OIiOi1xm5B/SvVswVzcnIwa9YsVKpUCdbW1rh16xYAYOrUqVi7dm0J146IiOg1JHS0Ub5KdXA1Z84chISEIDg4GKamplJ6nTp18N1335VgzYiIiIjyVqqDqw0bNuDbb7+Fv78/jIyMpPR69erh2rVrJVgzIiKi15VMRxvlp1SPubp37x6qVaumla5SqZCVlVUCNSIiInrNcZ0rvSvVLVceHh44ceKEVvq2bdvw1ltvlUCNiIiIiF6sVLdcTZs2DQEBAbh37x5UKhV++eUXREVFYcOGDdizZ09JV4+IiOj1w5YrvSvVLVedO3fG7t27cejQIVhZWWHatGmIjIzE7t278f7775d09YiIiF4/QqabjfJVqluuAKB58+YIDQ0t6WoQERERFUipD64AIDw8HJGRkQByx2E1aNCghGtERET0ehIidytuGZS/Uh1c/fPPP+jduzdOnToFW1tbAEBSUhKaNGmCH3/8EW+88UbJVpCIiOh1wzFXeleqx1x99NFHyMrKQmRkJBITE5GYmIjIyEioVCp89NFHJV09IiIiIi2luuXq2LFjOH36NGrUqCGl1ahRA8uWLUPz5s1LsGZERESvKV0MSOeA9hcq1cGVi4tLnouF5uTkwNnZuQRqRERE9HqTidytuGVQ/kp1t+CCBQswYsQIhIeHS2nh4eEYNWoUvvrqqxKsGRER0WuKP9ysd6Wu5apcuXKQyf5rbkxLS0OjRo1gbJxb1ezsbBgbG2PQoEHo0qVLCdWSiIiIKG+lLrhavHhxSVeBiIio7OKYK70rdcFVQEBASVeBiIio7OJSDHpX6oKr/KSnpyMzM1MjTaFQlFBtiIiIiPJWqge0p6WlITAwEA4ODrCyskK5cuU0NiIiIiokDmjXu1IdXE2YMAFHjhzBypUrYWZmhu+++w4zZsyAs7MzNmzYUNLVIyIiev0wuNK7Ut0tuHv3bmzYsAGtWrXCwIED0bx5c1SrVg2urq7YtGkT/P39S7qKRERERBpKdctVYmIi3N3dAeSOr0pMTAQANGvWDMePHy/JqhEREb2e1LMFi7tRvkp1cOXu7o7o6GgAQM2aNfHTTz8ByG3RUv+QMxERERWceoX24m6Uv1IdXA0cOBB//PEHAGDSpElYsWIFzM3NMWbMGIwfP76Ea0dEREQFcfz4cfj5+cHZ2RkymQw7d+7U2C+EwLRp01CxYkVYWFjA29sb169f18iTmJgIf39/KBQK2NraYvDgwUhNTdXI8+eff6J58+YwNzeHi4sLgoOD9X1peSrVwdWYMWMwcuRIAIC3tzeuXbuGzZs349KlSxg1alQJ146IiOg1VAID2tPS0lCvXj2sWLEiz/3BwcFYunQpVq1ahbNnz8LKygo+Pj5IT0+X8vj7++PKlSsIDQ3Fnj17cPz4cQwdOlTan5KSgrZt28LV1RUXLlzAggULEBQUhG+//bZwldWBUj2g/Xmurq5wdXUt6WoQERFRIbRr1w7t2rXLc58QAosXL8aUKVPQuXNnAMCGDRvg6OiInTt3olevXoiMjMT+/ftx/vx5NGzYEACwbNkytG/fHl999RWcnZ2xadMmZGZm4vvvv4epqSlq166NiIgILFy4UCMIexVKXXC1dOnSAudVt2oRERFRwchQ/DFT6uHsKSkpGulmZmYwMzMrVFnR0dGIjY2Ft7e3lKZUKtGoUSOEhYWhV69eCAsLg62trRRYAbk9WnK5HGfPnkXXrl0RFhaGFi1awNTUVMrj4+OD+fPn49GjR690fcxSF1wtWrSoQPlkMhmDKyIiohLk4uKi8Xj69OkICgoqVBmxsbEAAEdHR410R0dHaV9sbCwcHBw09hsbG8POzk4jj5ubm1YZ6n0GHVypZwdS0VjuCoexzKSkq0GkF/vuR5R0FYj0IuWxCuWqv6KT6fCHm+/evavxU3SFbbUqq0r1gHYiIiLSMR0OaFcoFBpbUYIrJycnAEBcXJxGelxcnLTPyckJ8fHxGvuzs7ORmJiokSevMp49x6vC4IqIiIhKjJubG5ycnHD48GEpLSUlBWfPnoWXlxcAwMvLC0lJSbhw4YKU58iRI1CpVGjUqJGU5/jx48jKypLyhIaGokaNGq/894gZXBERERmSEliKITU1FREREYiIiACQOwQoIiICMTExkMlkGD16NGbPno1du3bh8uXL6N+/P5ydndGlSxcAQK1ateDr64shQ4bg3LlzOHXqFAIDA9GrVy84OzsDAPr06QNTU1MMHjwYV65cwdatW7FkyRKMHTu26PeqiErdmCsiIiLSH12ssF7Y48PDw9G6dWvpsTrgCQgIQEhICCZMmIC0tDQMHToUSUlJaNasGfbv3w9zc3PpmE2bNiEwMBBt2rSBXC5H9+7dNVYYUCqVOHjwIIYPH44GDRqgfPnymDZt2itfhgEAZEIILmJfBqSkpECpVKIVOnNAO5VZBzigncqo3AHtt5CcnKwxQFyn5/j/50SVOXMgfyZoKQpVejpuT56s1/q+zkp9t+CJEyfQt29feHl54d69ewCAjRs34uTJkyVcMyIiotdQCXQLGppSHVxt374dPj4+sLCwwKVLl5CRkQEASE5Oxty5c0u4dkRERK8hBld6V6qDq9mzZ2PVqlVYs2YNTEz+6+pq2rQpLl68WII1IyIiIspbqR7QHhUVhRYtWmilK5VKJCUlvfoKERERveZKYkC7oSnVLVdOTk64ceOGVvrJkyfh7u5eAjUiIiJ6zalXaC/uRvkq1cHVkCFDMGrUKJw9exYymQz379/Hpk2bMG7cOAwbNqykq0dERPT64ZgrvSvV3YKTJk2CSqVCmzZt8OTJE7Ro0QJmZmYYN24cRowYUdLVIyIiItJSqoMrmUyGyZMnY/z48bhx4wZSU1Ph4eEBa2vrkq4aERHRa4ljrvSvVAdXaqampvDw8CjpahAREb3+dNGtx+DqhUp1cNW6dWvIZPkPmjty5MgrrA0RERHRy5Xq4Kp+/foaj7OyshAREYG//voLAQEBJVMpIiKi15kOugXZcvVipTq4WrRoUZ7pQUFBSE1NfcW1ISIiKgPYLah3pXophvz07dsX33//fUlXg4iIiEhLqW65yk9YWBjMi/mL3kRERAaJLVd6V6qDq27dumk8FkLgwYMHCA8Px9SpU0uoVkRERK8vLsWgf6U6uFIqlRqP5XI5atSogZkzZ6Jt27YlVCsiIiKi/JXa4ConJwcDBw6Ep6cnypUrV9LVISIiIiqQUjug3cjICG3btkVSUlJJV4WIiKjs4G8L6l2pDa4AoE6dOrh161ZJV4OIiKjMUI+5Ku5G+SvVwdXs2bMxbtw47NmzBw8ePEBKSorGRkRERFTalMoxVzNnzsRnn32G9u3bAwA6deqk8TM4QgjIZDLk5OSUVBWJiIheX2x50qtSGVzNmDEDn3zyCX7//feSrgoREVHZwnWu9K5UBldC5P7XWrZsWcI1ISIiIiqcUhlcAdDoBiQiIiLd4CKi+ldqg6vq1au/NMBKTEx8RbUhIiIqI9gtqHelNriaMWOG1grtRERERKVdqQ2uevXqBQcHh5KuBhERUZnCbkH9K5XBFcdbERER6Qm7BfWuVC4iqp4tSERERPS6KZUtVyqVqqSrQEREVDax5UrvSmVwRURERPrBMVf6x+CKiIjIkLDlSu9K5ZgrIiIiotcVgysiIiJDInS0FVBOTg6mTp0KNzc3WFhYoGrVqpg1a5bG5DUhBKZNm4aKFSvCwsIC3t7euH79ukY5iYmJ8Pf3h0KhgK2tLQYPHozU1NQi3gT9YnBFRERkQNRjroq7FdT8+fOxcuVKLF++HJGRkZg/fz6Cg4OxbNkyKU9wcDCWLl2KVatW4ezZs7CysoKPjw/S09OlPP7+/rhy5QpCQ0OxZ88eHD9+HEOHDtXlrdEZjrkiIiIivTl9+jQ6d+6MDh06AACqVKmCLVu24Ny5cwByW60WL16MKVOmoHPnzgCADRs2wNHRETt37kSvXr0QGRmJ/fv34/z582jYsCEAYNmyZWjfvj2++uorODs7l8zF5YMtV0RERIZEh92CKSkpGltGRobW6Zo0aYLDhw/j77//BgD88ccfOHnyJNq1awcAiI6ORmxsLLy9vaVjlEolGjVqhLCwMABAWFgYbG1tpcAKALy9vSGXy3H27Fkd3RjdYcsVERGRAdHlUgwuLi4a6dOnT0dQUJBG2qRJk5CSkoKaNWvCyMgIOTk5mDNnDvz9/QEAsbGxAABHR0eN4xwdHaV9sbGxWj+JZ2xsDDs7OylPacLgioiIiIrk7t27UCgU0mMzMzOtPD/99BM2bdqEzZs3o3bt2oiIiMDo0aPh7OyMgICAV1ndV4bBFRERkSHR4TpXCoVCI7jKy/jx4zFp0iT06tULAODp6Yk7d+5g3rx5CAgIgJOTEwAgLi4OFStWlI6Li4tD/fr1AQBOTk6Ij4/XKDc7OxuJiYnS8aUJx1wREREZkle8FMOTJ08gl2uGG0ZGRtJP3bm5ucHJyQmHDx+W9qekpODs2bPw8vICAHh5eSEpKQkXLlyQ8hw5cgQqlQqNGjUqeGVeEbZcERERkd74+flhzpw5qFy5MmrXro1Lly5h4cKFGDRoEABAJpNh9OjRmD17Nt588024ublh6tSpcHZ2RpcuXQAAtWrVgq+vL4YMGYJVq1YhKysLgYGB6NWrV6mbKQgwuCIiIjIosv9vxS2joJYtW4apU6fi008/RXx8PJydnfHxxx9j2rRpUp4JEyYgLS0NQ4cORVJSEpo1a4b9+/fD3NxcyrNp0yYEBgaiTZs2kMvl6N69O5YuXVrMK9EPmXh2iVR6baWkpECpVKIVOsNYZlLS1SHSiwP3I0q6CkR6kfJYhXLVbyE5OfmlY5iKfI7/f054DJsLIzPzlx/wAjkZ6bi68gu91vd1xpYrIiIiA6LLpRgobxzQTkRERKRDbLkiIiIyJDpcioHyxuCKiIjI0DA40it2CxIRERHpEFuuiIiIDAgHtOsfgysiIiJDwjFXesduQSIiIiIdYssVERGRAWG3oP4xuCIiIjIk7BbUO3YLEhEREekQW66IiIgMCLsF9Y/BFRERkSFht6DeMbgiIiIyJAyu9I5jroiIiIh0iC1XREREBoRjrvSPwRUREZEhYbeg3rFbkIiIiEiH2HJFRERkQGRCQCaK1/RU3OPLOgZXREREhoTdgnrHbkEiIiIiHWLLFRERkQHhbEH9Y3BFRERkSNgtqHfsFiQiIiLSIbZcERERGRB2C+ofgysiIiJDwm5BvWNwRUREZEDYcqV/HHNFREREpENsuSIiIjIk7BbUOwZXREREBobdevrFbkEiIiIiHWLLFRERkSERIncrbhmULwZXREREBoSzBfWP3YJERESkV/fu3UPfvn1hb28PCwsLeHp6Ijw8XNovhMC0adNQsWJFWFhYwNvbG9evX9coIzExEf7+/lAoFLC1tcXgwYORmpr6qi+lQBhcERERGRKho62AHj16hKZNm8LExAS//fYbrl69iq+//hrlypWT8gQHB2Pp0qVYtWoVzp49CysrK/j4+CA9PV3K4+/vjytXriA0NBR79uzB8ePHMXTo0GLcCP1htyAREZEBkalyt+KWUVDz58+Hi4sL1q1bJ6W5ublJfwshsHjxYkyZMgWdO3cGAGzYsAGOjo7YuXMnevXqhcjISOzfvx/nz59Hw4YNAQDLli1D+/bt8dVXX8HZ2bl4F6RjbLkiIiKiIklJSdHYMjIytPLs2rULDRs2xAcffAAHBwe89dZbWLNmjbQ/OjoasbGx8Pb2ltKUSiUaNWqEsLAwAEBYWBhsbW2lwAoAvL29IZfLcfbsWT1eYdEwuNKRKlWqYPHixSVdDSqGOo1SMWN9NDZfvIID9/+Al2+yVh6XaukIConGL9cu49cbl7F039+oUClT2t/O/yGCt93AL1GXceD+H7BS5LzKSyDScPmMFab1d0Pvt2rDx7k+Tv+m1Nj/NE2O5V9Ugn8DD/i518WQljWxZ4O9tD/lkRFWTK6Ewc1qws+9Lvo29MA3UyohLUXzo+PSCWuM9nsTXd70RK96tfHd7IrIyX4ll0hFocNuQRcXFyiVSmmbN2+e1ulu3bqFlStX4s0338SBAwcwbNgwjBw5EuvXrwcAxMbGAgAcHR01jnN0dJT2xcbGwsHBQWO/sbEx7OzspDylCbsFCykkJASjR49GUlKSRvr58+dhZWVVMpUinTC3VOHWFXMc2GKH6d/f1tpf0TUDC3fewP4f7bDxK0c8eWwE1xrpyEyX/VeGhQrhR20QftQGg78ofS94MizpT+Rwr/0UPr0TMXOwm9b+1UHOiDhlgwnLYuDokomLx2yw7PM3YO+YBS+fFCTGmeBhnAmGTLuPytXTEf+PKZZOegMP40wwdc1tAMDNK+aY2s8dvUbGYfzSO3gYa4KlE12gypFh6PT7r/iKqSB0OVvw7t27UCgUUrqZmZlWXpVKhYYNG2Lu3LkAgLfeegt//fUXVq1ahYCAgOJVpJRicKUjFSpUKOkqUDGF/65A+O+KfPcPmBSLc0cUWDv7v779B3c030h2fJf7PKjrVTpnsJBheee9x3jnvcf57r8aboX3P0hEvSa5z9f2fR9i70Z7REVYwssnBVVqpmPad7el/M5VMjFg4gMEj3BFTjZgZAwc21UObrXS0XdsHACgklsmPppyH3M+qYK+n8XC0rqYg3tI93S4zpVCodAIrvJSsWJFeHh4aKTVqlUL27dvBwA4OTkBAOLi4lCxYkUpT1xcHOrXry/liY+P1ygjOzsbiYmJ0vGlicF1C+7fvx/NmjWDra0t7O3t0bFjR9y8eRMAcPToUchkMo1WqYiICMhkMty+fRtHjx7FwIEDkZycDJlMBplMhqCgIACa3YJCCAQFBaFy5cowMzODs7MzRo4cKZVZpUoVzJ49G/3794e1tTVcXV2xa9cuJCQkoHPnzrC2tkbdunU1pqlSyZLJBN5tk4J7t8wwZ/NNbP3zCpbsuZ5n1yHR68KjYRrOHFTi3wcmEAKIOGWNe7fM0KBl/gFZWooRLK1VMPr/V/OsTBlMzDQDKFNzFTLT5bj+p6U+q0+viaZNmyIqKkoj7e+//4arqyuA3MHtTk5OOHz4sLQ/JSUFZ8+ehZeXFwDAy8sLSUlJuHDhgpTnyJEjUKlUaNSo0Su4isIxuOAqLS0NY8eORXh4OA4fPgy5XI6uXbtCpXr5t6smTZpg8eLFUCgUePDgAR48eIBx48Zp5du+fTsWLVqE1atX4/r169i5cyc8PT018ixatAhNmzbFpUuX0KFDB/Tr1w/9+/dH3759cfHiRVStWhX9+/eHyOfbRUZGhtZAQtIf2/LZsLRW4cPAeIT/rsDnvd1xar8C0767Dc/GbKWi19Ons++hcvV0+DeojQ6u9TDF3x3D5/4Dz8ZpeeZPfmiEzYud0K7vv1Jaw5aPERluhd932CInB/j3gQk2LcptSUiMY+dIaaTuFizuVlBjxozBmTNnMHfuXNy4cQObN2/Gt99+i+HDh+fWRybD6NGjMXv2bOzatQuXL19G//794ezsjC5dugDIbeny9fXFkCFDcO7cOZw6dQqBgYHo1atXqZspCBhgt2D37t01Hn///feoUKECrl69+tJjTU1NoVQqIZPJXtgMGRMTAycnJ3h7e8PExASVK1fGu+++q5Gnffv2+PjjjwEA06ZNw8qVK/HOO+/ggw8+AABMnDgRXl5eiIuLy/Nc8+bNw4wZM15aZ9IN2f+/hoQdUGDHmtyuv1tXLODR8Ak69H+Iy2esS7B2REXz6/flce2CJWaE3ILDG5m4fMYaK77IHXP1dgvNLw1pj+WY2t8dlauno99n/40nbNDqMT6aeh9LJ7kgeKQrTExV8B8dh7/OWkuvGyplCrlOVb5lFNA777yDHTt24PPPP8fMmTPh5uaGxYsXw9/fX8ozYcIEpKWlYejQoUhKSkKzZs2wf/9+mJubS3k2bdqEwMBAtGnTBnK5HN27d8fSpUuLeSH6YXDB1fXr1zFt2jScPXsW//77r9RiFRMTA0tL3TRhf/DBB1i8eDHc3d3h6+uL9u3bw8/PD8bG/93uunXrSn+rZ0g827qlTouPj88zuPr8888xduxY6XFKSgpcXFx0Un/SlpJohOws4M7f5hrpd6+bofa7eX/LJyrNMp7KEPJlRUxbexuNvHNbvt090nHrigW2rXLQCK6epMoxuU9VWFipMH1tNIxNNMvq/nECug1NQGKcMayVOYj7xxTfz3NGRVftaflkmDp27IiOHTvmu18mk2HmzJmYOXNmvnns7OywefNmfVRP5wzue4Wfnx8SExOxZs0anD17VlofIzMzE3J57u14tisuKyur0OdwcXFBVFQUvvnmG1hYWODTTz9FixYtNMoyMfnv3Ukmk+Wbll93pZmZmTSQsCADCql4srPk+PsPS7xRVfPDopJ7BuL/MS2hWhEVXXa2DNlZcsjlmk0QciMB8czbTtpjOb7oXRUmpgIzQm7B1DzvJguZDLB3yoaZhcDvO8qhgnMmqnk+1eclUBG96m5BQ2RQLVcPHz5EVFQU1qxZg+bNmwMATp48Ke1Xz/h78OCBtCx/RESERhmmpqbIyXn52kUWFhbw8/ODn58fhg8fjpo1a+Ly5ct4++23dXQ1pGvmljlwdvtvzSonl0y4136Kx0lGSLhnip+/ccAXq+7grzNW+OO0NRq2fozG76dgfI+q0jHlKmShnEM2nN1ygzC3mk/xJM0ICfdM8DjJoF5uVAo8TZPjfvR/M1pj75ri5l8WsLHNhsMbWajrlYo1s5xhan4Pjm9k4s8waxzaZoeh0+8B+C+wyngqx4Rl0XiSaoQn/2/QUtpnw8go9++fv6mAhq0fQyYHTu1T4qcVDpi86o60n0oZHc4WpLwZ1Lt9uXLlYG9vj2+//RYVK1ZETEwMJk2aJO2vVq0aXFxcEBQUhDlz5uDvv//G119/rVFGlSpVkJqaisOHD6NevXqwtLTU6k4MCQlBTk4OGjVqBEtLS/zwww+wsLCQZkZQ6VS93lMs2H5TevzJjNw1eg5uLYevx1TG6f1KLJ1UCb0C4zFs1j38c8sMs4ZUwZVz/4236tD/Ifp9Fic9/npnbnlfjXZB6E92r+hKiHL9/YclJvSoJj1eHVQJAPB+z0SMWxyDz1fexvdzK2J+YGU8TjKGQ6XcpRY69n8IALhx2RLXLuau3zewieZU+vVnr8LJJffLyPnfFdiy1AlZmTK4ezxF0LroFy4BQVTWGVRwJZfL8eOPP2LkyJGoU6cOatSogaVLl6JVq1YAcrvltmzZgmHDhqFu3bp45513MHv2bGmQOZA7Y/CTTz7Bhx9+iIcPH2L69OnScgxqtra2+PLLLzF27Fjk5OTA09MTu3fvhr29Paj0+jPMGj7O9V6Y5+CP9jj4Y/7/xx++dsIPX5e+NVfIMNVrkooD9yPy3W/nkI1xi+8W+Xi14J9vvjQPlR66XESU8iYT+c31p9dKSkoKlEolWqEzjGUmLz+A6DVUkA96otdRymMVylW/heTkZL2NoVV/Tnj5zoSxifnLD3iB7Kx0hO2fptf6vs4MbkA7ERERkT4ZVLcgERGRoWO3oP4xuCIiIjIkKpG7FbcMyheDKyIiIkPyildoN0Qcc0VERESkQ2y5IiIiMiAy6GDMlU5qUnYxuCIiIjIkXKFd79gtSERERKRDbLkiIiIyIFyKQf8YXBERERkSzhbUO3YLEhEREekQW66IiIgMiEwIyIo5IL24x5d1DK6IiIgMier/W3HLoHyxW5CIiIhIh9hyRUREZEDYLah/DK6IiIgMCWcL6h2DKyIiIkPCFdr1jmOuiIiIiHSILVdEREQGhCu06x+DKyIiIkPCbkG9Y7cgERERkQ6x5YqIiMiAyFS5W3HLoPwxuCIiIjIk7BbUO3YLEhEREekQW66IiIgMCRcR1TsGV0RERAaEP3+jf+wWJCIiItIhtlwREREZEg5o1zu2XBERERkSAUBVzK0YsdWXX34JmUyG0aNHS2np6ekYPnw47O3tYW1tje7duyMuLk7juJiYGHTo0AGWlpZwcHDA+PHjkZ2dXfSK6BGDKyIiIgOiHnNV3K0ozp8/j9WrV6Nu3boa6WPGjMHu3bvx888/49ixY7h//z66desm7c/JyUGHDh2QmZmJ06dPY/369QgJCcG0adOKdS/0hcEVERER6V1qair8/f2xZs0alCtXTkpPTk7G2rVrsXDhQrz33nto0KAB1q1bh9OnT+PMmTMAgIMHD+Lq1av44YcfUL9+fbRr1w6zZs3CihUrkJmZWVKXlC8GV0RERIZE4L9xV0XeCn/a4cOHo0OHDvD29tZIv3DhArKysjTSa9asicqVKyMsLAwAEBYWBk9PTzg6Okp5fHx8kJKSgitXrhTpNugTB7QTEREZEh0OaE9JSdFINjMzg5mZmVb2H3/8ERcvXsT58+e19sXGxsLU1BS2trYa6Y6OjoiNjZXyPBtYqfer95U2bLkiIiKiInFxcYFSqZS2efPmaeW5e/cuRo0ahU2bNsHc3LwEavnqseWKiIjIkKgAyHRQBnIDJ4VCISXn1Wp14cIFxMfH4+2335bScnJycPz4cSxfvhwHDhxAZmYmkpKSNFqv4uLi4OTkBABwcnLCuXPnNMpVzyZU5ylN2HJFRERkQHQ5W1ChUGhseQVXbdq0weXLlxERESFtDRs2hL+/v/S3iYkJDh8+LB0TFRWFmJgYeHl5AQC8vLxw+fJlxMfHS3lCQ0OhUCjg4eGh5ztWeGy5IiIiIr2xsbFBnTp1NNKsrKxgb28vpQ8ePBhjx46FnZ0dFAoFRowYAS8vLzRu3BgA0LZtW3h4eKBfv34IDg5GbGwspkyZguHDh+cZ0JU0BldERESGpBSu0L5o0SLI5XJ0794dGRkZ8PHxwTfffCPtNzIywp49ezBs2DB4eXnBysoKAQEBmDlzpk7roSsMroiIiAxJKQiujh49qvHY3NwcK1aswIoVK/I9xtXVFfv27SvWeV8VjrkiIiIi0iG2XBERERmSUtByVdYxuCIiIjIkOlyKgfLG4IqIiMiAFOeHl58tg/LHMVdEREREOsSWKyIiIkPCMVd6x+CKiIjIkKgEICtmcKRicPUi7BYkIiIi0iG2XBERERkSdgvqHYMrIiIig6KD4AoMrl6E3YJEREREOsSWKyIiIkPCbkG9Y3BFRERkSFQCxe7W42zBF2K3IBEREZEOseWKiIjIkAhV7lbcMihfDK6IiIgMCcdc6R2DKyIiIkPCMVd6xzFXRERERDrElisiIiJDwm5BvWNwRUREZEgEdBBc6aQmZRa7BYmIiIh0iC1XREREhoTdgnrH4IqIiMiQqFQAirlOlYrrXL0IuwWJiIiIdIgtV0RERIaE3YJ6x+CKiIjIkDC40jt2CxIRERHpEFuuiIiIDAl//kbvGFwREREZECFUEKJ4s/2Ke3xZx+CKiIjIkAhR/JYnjrl6IY65IiIiItIhtlwREREZEqGDMVdsuXohBldERESGRKUCZMUcM8UxVy/EbkEiIiIiHWJwRUREZEjUi4gWdyugefPm4Z133oGNjQ0cHBzQpUsXREVFaeRJT0/H8OHDYW9vD2tra3Tv3h1xcXEaeWJiYtChQwdYWlrCwcEB48ePR3Z2tk5uia4xuCIiIjIgQqXSyVZQx44dw/Dhw3HmzBmEhoYiKysLbdu2RVpampRnzJgx2L17N37++WccO3YM9+/fR7du3aT9OTk56NChAzIzM3H69GmsX78eISEhmDZtmk7vja7IhOCotLIgJSUFSqUSrdAZxjKTkq4OkV4cuB9R0lUg0ouUxyqUq34LycnJUCgU+jnH/z8n3rPsBWOZabHKyhaZOPLkxyLVNyEhAQ4ODjh27BhatGiB5ORkVKhQAZs3b0aPHj0AANeuXUOtWrUQFhaGxo0b47fffkPHjh1x//59ODo6AgBWrVqFiRMnIiEhAaamxbseXWPLFRERkSHRYbdgSkqKxpaRkfHS0ycnJwMA7OzsAAAXLlxAVlYWvL29pTw1a9ZE5cqVERYWBgAICwuDp6enFFgBgI+PD1JSUnDlyhWd3RpdYXBFRERkSFRCNxsAFxcXKJVKaZs3b96LT61SYfTo0WjatCnq1KkDAIiNjYWpqSlsbW018jo6OiI2NlbK82xgpd6v3lfacCkGIiIiKpK7d+9qdAuamZm9MP/w4cPx119/4eTJk/quWolicEVERGRIhABQ3HWucluuFApFgcdcBQYGYs+ePTh+/DjeeOMNKd3JyQmZmZlISkrSaL2Ki4uDk5OTlOfcuXMa5alnE6rzlCbsFiQiIjIgQiV0shX4fEIgMDAQO3bswJEjR+Dm5qaxv0GDBjAxMcHhw4eltKioKMTExMDLywsA4OXlhcuXLyM+Pl7KExoaCoVCAQ8Pj2LeEd1jyxUREZEhESoUv+Wq4McPHz4cmzdvxq+//gobGxtpjJRSqYSFhQWUSiUGDx6MsWPHws7ODgqFAiNGjICXlxcaN24MAGjbti08PDzQr18/BAcHIzY2FlOmTMHw4cNf2hVZEhhcERERkd6sXLkSANCqVSuN9HXr1mHAgAEAgEWLFkEul6N79+7IyMiAj48PvvnmGymvkZER9uzZg2HDhsHLywtWVlYICAjAzJkzX9VlFAqDKyIiIgMiVAJCVrwlLguzRGZB8pqbm2PFihVYsWJFvnlcXV2xb9++Ap+3JDG4IiIiMiSvuFvQEDG4KiPU3wyykQVwzX0qo1Ie8w2dyqaU1Nzn9qv40RRdfE5kI0s3lSmjGFyVEY8fPwYAnMTr0WRKVBTlqpd0DYj06/Hjx1AqlXop29TUFE5OTjgZq5vPCScnp1L3szOlBX9bsIxQqVS4f/8+bGxsIJPJSro6ZV5KSgpcXFy0FtAjKiv4HH+1hBB4/PgxnJ2dIZfrb5Wk9PR0ZGZm6qQsU1NTmJub66SssoYtV2WEXC7XWJSNXo3CLKBH9Dric/zV0VeL1bPMzc0ZEL0CXESUiIiISIcYXBERERHpEIMroiIwMzPD9OnTS+XKwES6wOc4UdFxQDsRERGRDrHlioiIiEiHGFwRERER6RCDKyIiIiIdYnBFVIpUqVIFixcvLulqEAHg85GoqBhcEREZuJCQENja2mqlnz9/HkOHDn31FSJ6zXGFdqJCyMzM5G9pkcGoUKFCSVeB6LXElisq01q1aoWRI0diwoQJsLOzg5OTE4KCgqT9MTEx6Ny5M6ytraFQKNCzZ0/ExcVJ+4OCglC/fn189913cHNzk342QiaTYfXq1ejYsSMsLS1Rq1YthIWF4caNG2jVqhWsrKzQpEkT3Lx5Uyrr5s2b6Ny5MxwdHWFtbY133nkHhw4demX3gsqu/fv3o1mzZrC1tYW9vT06duwoPfeOHj0KmUyGpKQkKX9ERARkMhlu376No0ePYuDAgUhOToZMJoNMJpNeI892CwohEBQUhMqVK8PMzAzOzs4YOXKkVGaVKlUwe/Zs9O/fH9bW1nB1dcWuXbuQkJAgvcbq1q2L8PDwV3VbiEoMgysq89avXw8rKyucPXsWwcHBmDlzJkJDQ6FSqdC5c2ckJibi2LFjCA0Nxa1bt/Dhhx9qHH/jxg1s374dv/zyCyIiIqT0WbNmoX///oiIiEDNmjXRp08ffPzxx/j8888RHh4OIQQCAwOl/KmpqWjfvj0OHz6MS5cuwdfXF35+foiJiXlVt4LKqLS0NIwdOxbh4eE4fPgw5HI5unbtCpVK9dJjmzRpgsWLF0OhUODBgwd48OABxo0bp5Vv+/btWLRoEVavXo3r169j586d8PT01MizaNEiNG3aFJcuXUKHDh3Qr18/9O/fH3379sXFixdRtWpV9O/fH1xekco8QVSGtWzZUjRr1kwj7Z133hETJ04UBw8eFEZGRiImJkbad+XKFQFAnDt3TgghxPTp04WJiYmIj4/XKAOAmDJlivQ4LCxMABBr166V0rZs2SLMzc1fWL/atWuLZcuWSY9dXV3FokWLCn2dRM9KSEgQAMTly5fF77//LgCIR48eSfsvXbokAIjo6GghhBDr1q0TSqVSq5xnn49ff/21qF69usjMzMzznK6urqJv377S4wcPHggAYurUqVKa+nXy4MGDYl8jUWnGlisq8+rWravxuGLFioiPj0dkZCRcXFzg4uIi7fPw8ICtrS0iIyOlNFdX1zzHnjxbrqOjIwBofJN3dHREeno6UlJSAOS2XI0bNw61atWCra0trK2tERkZyZYrKrbr16+jd+/ecHd3h0KhQJUqVQBAp8+tDz74AE+fPoW7uzuGDBmCHTt2IDs7WyNPQV4TABAfH6+zehGVRgyuqMwzMTHReCyTyQrUXaJmZWX10nJlMlm+aepzjRs3Djt27MDcuXNx4sQJREREwNPTE5mZmQWuC1Fe/Pz8kJiYiDVr1uDs2bM4e/YsgNwJGHJ57tu8eKYrLisrq9DncHFxQVRUFL755htYWFjg008/RYsWLTTKKuxrgqisYnBFBqtWrVq4e/cu7t69K6VdvXoVSUlJ8PDw0Pn5Tp06hQEDBqBr167w9PSEk5MTbt++rfPzkGF5+PAhoqKiMGXKFLRp0wa1atXCo0ePpP3qVtcHDx5Iac+OHQQAU1NT5OTkvPRcFhYW8PPzw9KlS3H06FGEhYXh8uXLurkQojKESzGQwfL29oanpyf8/f2xePFiZGdn49NPP0XLli3RsGFDnZ/vzTffxC+//AI/Pz/IZDJMnTqV3+Cp2MqVKwd7e3t8++23qFixImJiYjBp0iRpf7Vq1eDi4oKgoCDMmTMHf//9N77++muNMqpUqYLU1FQcPnwY9erVg6WlJSwtLTXyhISEICcnB40aNYKlpSV++OEHWFhYwNXV9ZVcJ9HrhC1XZLBkMhl+/fVXlCtXDi1atIC3tzfc3d2xdetWvZxv4cKFKFeuHJo0aQI/Pz/4+Pjg7bff1su5yHDI5XL8+OOPuHDhAurUqYMxY8ZgwYIF0n4TExNs2bIF165dQ926dTF//nzMnj1bo4wmTZrgk08+wYcffogKFSogODhY6zy2trZYs2YNmjZtirp16+LQoUPYvXs37O3t9X6NRK8bmRCcE0tERESkK2y5IiIiItIhBldEREREOsTgioiIiEiHGFwRERER6RCDKyIiIiIdYnBFREREpEMMroiIiIh0iMEVEenMgAED0KVLF+lxq1atMHr06Fdej6NHj0ImkyEpKSnfPDKZDDt37ixwmUFBQahfv36x6nX79m3IZDKtn58horKFwRVRGTdgwADIZDLIZDKYmpqiWrVqmDlzJrKzs/V+7l9++QWzZs0qUN6CBERERK8D/rYgkQHw9fXFunXrkJGRgX379mH48OEwMTHB559/rpU3MzMTpqamOjmvnZ2dTsohInqdsOWKyACYmZnByckJrq6uGDZsGLy9vbFr1y4A/3XlzZkzB87OzqhRowYA4O7du+jZsydsbW1hZ2eHzp074/bt21KZOTk5GDt2LGxtbWFvb48JEybg+V/Ter5bMCMjAxMnToSLiwvMzMxQrVo1rF27Frdv30br1q0B5P4QsUwmw4ABAwAAKpUK8+bNg5ubGywsLFCvXj1s27ZN4zz79u1D9erVYWFhgdatW2vUs6AmTpyI6tWrw9LSEu7u7pg6dSqysrK08q1evRouLi6wtLREz549kZycrLH/u+++Q61atWBubo6aNWvim2++KXRdiOj1xuCKyABZWFggMzNTenz48GFERUUhNDQUe/bsQVZWFnx8fGBjY4MTJ07g1KlTsLa2hq+vr3Tc119/jZCQEHz//fc4efIkEhMTsWPHjheet3///tiyZQuWLl2KyMhIrF69GtbW1nBxccH27dsBAFFRUXjw4AGWLFkCAJg3bx42bNiAVatW4cqVKxgzZgz69u2LY8eOAcgNArt16wY/Pz9ERETgo48+wqRJkwp9T2xsbBASEoKrV69iyZIlWLNmDRYtWqSR58aNG/jpp5+we/du7N+/H5cuXcKnn34q7d+0aROmTZuGOXPmIDIyEnPnzsXUqVOxfv36QteHiF5jgojKtICAANG5c2chhBAqlUqEhoYKMzMzMW7cOGm/o6OjyMjIkI7ZuHGjqFGjhlCpVFJaRkaGsLCwEAcOHBBCCFGxYkURHBws7c/KyhJvvPGGdC4hhGjZsqUYNWqUEEKIqKgoAUCEhobmWc/ff/9dABCPHj2S0tLT04WlpaU4ffq0Rt7BgweL3r17CyGE+Pzzz4WHh4fG/okTJ2qV9TwAYseOHfnuX7BggWjQoIH0ePr06cLIyEj8888/Utpvv/0m5HK5ePDggRBCiKpVq4rNmzdrlDNr1izh5eUlhBAiOjpaABCXLl3K97xE9PrjmCsiA7Bnzx5YW1sjKysLKpUKffr0QVBQkLTf09NTY5zVH3/8gRs3bsDGxkajnPT0dNy8eRPJycl48OABGjVqJO0zNjZGw4YNtboG1SIiImBkZISWLVsWuN43btzAkydP8P7772ukZ2Zm4q233gIAREZGatQDALy8vAp8DrWtW7di6dKluHnzJlJTU5GdnQ2FQqGRp3LlyqhUqZLGeVQqFaKiomBjY4ObN29i8ODBGDJkiJQnOzsbSqWy0PUhotcXgysiA9C6dWusXLkSpqamcHZ2hrGx5kvfyspK43FqaioaNGiATZs2aZVVoUKFItXBwsKi0MekpqYCAPbu3asR1AC548h0JSwsDP7+/pgxYwZ8fHygVCrx448/4uuvvy50XdesWaMV7BkZGemsrkRU+jG4IjIAVlZWqFatWoHzv/3229i6dSscHBy0Wm/UKlasiLNnz6JFixYAcltoLly4gLfffjvP/J6enlCpVDh27Bi8vb219qtbznJycqQ0Dw8PmJmZISYmJt8Wr1q1akmD89XOnDnz8ot8xunTp+Hq6orJkydLaXfu3NHKFxMTg/v378PZ2Vk6j1wuR40aNeDo6AhnZ2fcunUL/v7+hTo/EZUtHNBORFr8/f1Rvnx5dO7cGSdOnEB0dDSOHj2KkSNH4p9//gEAjBo1Cl9++SV27tyJa9eu4dNPP33hGlVVqlRBQEAABg0ahJ07d0pl/vTTTwAAV1dXyGQy7NmzBwkJCUhNTYWNjQ3GjRuHMWPGYP369bh58yYuXryIZcuWSYPEP/nkE1y/fh3jx49HVFQUNm/ejJCQkEJd75tvvomYmBj8+OOPuHnzJpYuXZrn4Hxzc3MEBATgjz/+wIkTJzBy5Ej07NkTTk5OAIAZM2Zg3rx5WLp0Kf7++29cvnwZ69atw8KFCwtVHyJ6vTG4IiItlpaWOH78OCpXroxu3bqhVq1aGDx4MNLT06WWrM8++wz9+vVDQEAAvLy8YGNjg65du76w3JUrV6JHjx749NNPUbNmTQwZMgRpaWkAgEqVKmHGjBmYNGkSHB0dERgYCACYNWsWpk6dinnz5qFWrVrw9fXF3r174ebmBiB3HNT27duxc+dO1KtXD6tWrcLcuXMLdb2dOnXCmDFjEBgYiPr16+P06dOYOnWqVr5q1aqhW7duaN++Pdq2bYu6detqLLXw0Ucf4bvvvsO6devg6emJli1bIiQkRKorERkGmchv9CkRERERFRpbroiIiIh0iMEVERERkQ4xuCIiIiLSIQZXRERERDrE4IqIiIhIhxhcEREREekQgysiIiIiHWJwRURERKRDDK6IiIiIdIjBFREREZEOMbgiIiIi0iEGV0REREQ69D9YPOSZgAfrSAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "for i, res in enumerate(results, 1):\n",
    "    pred = np.round(res.reshape(res.shape[0])).astype(bool)\n",
    "    confusion_matrix = metrics.confusion_matrix(test_data_label.astype(bool), pred)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['normal', 'autism'])\n",
    "    cm_display.plot()\n",
    "    plt.title(f\"Result: RWB ANN (512,256,512)(RMSprop) lag 256 for model in fold {i}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: RWB ANN (512,256,512)(RMSprop) lag 256 for model in fold 1\n",
      "Precision: 0.8244773519163763\n",
      "Recall: 0.9512562814070352\n",
      "Accuracy: 0.8290013679890561\n",
      "F1-score: 0.8833411105926272\n",
      "\n",
      "\n",
      "Result: RWB ANN (512,256,512)(RMSprop) lag 256 for model in fold 2\n",
      "Precision: 0.8416935112747354\n",
      "Recall: 0.9190954773869346\n",
      "Accuracy: 0.8272913816689467\n",
      "F1-score: 0.8786932500600527\n",
      "\n",
      "\n",
      "Result: RWB ANN (512,256,512)(RMSprop) lag 256 for model in fold 3\n",
      "Precision: 0.8267370272647317\n",
      "Recall: 0.9447236180904522\n",
      "Accuracy: 0.8276333789329685\n",
      "F1-score: 0.8818011257035647\n",
      "\n",
      "\n",
      "Result: RWB ANN (512,256,512)(RMSprop) lag 256 for model in fold 4\n",
      "Precision: 0.8535564853556485\n",
      "Recall: 0.9226130653266331\n",
      "Accuracy: 0.8396032831737346\n",
      "F1-score: 0.8867423327698624\n",
      "\n",
      "\n",
      "Result: RWB ANN (512,256,512)(RMSprop) lag 256 for model in fold 5\n",
      "Precision: 0.846934071000461\n",
      "Recall: 0.9231155778894472\n",
      "Accuracy: 0.8341313269493844\n",
      "F1-score: 0.8833854291897091\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, res in enumerate(results, 1):\n",
    "    pred = np.round(res.reshape(res.shape[0])).astype(bool)\n",
    "    test_data_label = test_data_label.astype(bool)  \n",
    "\n",
    "    print(f\"Result: RWB ANN (512,256,512)(RMSprop) lag 256 for model in fold {i}\")\n",
    "\n",
    "    TP = np.sum((test_data_label == True) & (pred == True))\n",
    "    FP = np.sum((test_data_label == False) & (pred == True))\n",
    "    TN = np.sum((test_data_label == False) & (pred == False))\n",
    "    FN = np.sum((test_data_label == True) & (pred == False))  \n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1-score: {f1_score}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.353625170998632\n",
      "Precision: 0.9807692307692307\n",
      "Recall (Sensitivity): 0.05125628140703518\n",
      "F1-Score: 0.09742120343839542\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# # Calculate accuracy\n",
    "# accuracy = accuracy_score(test_data_label, results[0].reshape(results[0].shape[0]).astype('int64'))\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# # Calculate precision\n",
    "# precision = precision_score(test_data_label, results[0].reshape(results[0].shape[0]).astype('int64'))\n",
    "# print(\"Precision:\", precision)\n",
    "\n",
    "# # Calculate recall (sensitivity)\n",
    "# recall = recall_score(test_data_label, results[0].reshape(results[0].shape[0]).astype('int64'))\n",
    "# print(\"Recall (Sensitivity):\", recall)\n",
    "\n",
    "# # Calculate F1-score\n",
    "# f1 = f1_score(test_data_label, results[0].reshape(results[0].shape[0]).astype('int64'))\n",
    "# print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for log_dir in log_dirs:\n",
    "#     recap = pd.DataFrame(index=lags, columns=folds)\n",
    "#     training_time = pd.DataFrame(index=lags, columns=time_measured)\n",
    "#     for fold in range(1,3):\n",
    "#         for lag in lags:\n",
    "#             if fold == 2:\n",
    "#                 train_dir, test_dir = test_dir, train_dir\n",
    "            \n",
    "#             train_temp_dir = train_dir + '_' + str(lag)\n",
    "#             test_temp_dir = test_dir + '_' + str(lag)\n",
    "\n",
    "#             train = get_batch(train_temp_dir)\n",
    "#             test_ds = get_batch(test_temp_dir)\n",
    "\n",
    "#             train_size = int(len(list(train.as_numpy_iterator()))*0.8)\n",
    "#             train_ds = train.take(train_size)\n",
    "#             val_ds = train.skip(train_size)\n",
    "\n",
    "#             log_path = os.path.join(log_dir, str(fold), str(lag))\n",
    "\n",
    "#             model = create_model()\n",
    "#             model.summary()\n",
    "\n",
    "#             model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['acc'])\n",
    "\n",
    "#             cpu_start = time.process_time()\n",
    "#             wt_start = time.time()\n",
    "\n",
    "#             history = model.fit(train_ds, epochs=epochs, validation_data=(val_ds), callbacks = myCallbacks(log_path))\n",
    "\n",
    "#             wt_end = time.time()\n",
    "#             cpu_end = time.process_time()\n",
    "#             wall_time = wt_end - wt_start\n",
    "#             cpu_time = cpu_end - cpu_start\n",
    "#             training_time.loc[lag, 'CPU_Time'+ '_' + str(fold)] = cpu_time\n",
    "#             training_time.loc[lag, 'Wall_Time'+ '_' + str(fold)] = wall_time\n",
    "\n",
    "#             results = model.evaluate(test_ds, callbacks = myCallbacks(log_path))\n",
    "\n",
    "#             recap.loc[lag, 'train'+ '_' + str(fold)] = history.history['acc']\n",
    "#             recap.loc[lag, 'test'+ '_' + str(fold)] = results[1]\n",
    "#             recap.loc[lag, 'epoch'+ '_' + str(fold)] = len(history.history['acc'])\n",
    "#     log_dir = os.path.join(log_dir,'Recap')\n",
    "#     if not os.path.exists(log_dir):\n",
    "#         os.makedirs(log_dir)\n",
    "#     recap.to_csv(os.path.join(log_dir,'recap.csv'))\n",
    "#     training_time.to_csv(os.path.join(log_dir,'Training_time.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir c:/Users/farra/Documents/Pribadi/EEG/EEG-Autism-Classification --port=8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs --port=8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\farra\\Documents\\Pribadi\\EEG\\EEG-Autism-Classification\n"
     ]
    }
   ],
   "source": [
    "! cd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
